{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Station3 batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purposes\n",
    "- Quatify and Visualize over performance space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib import reload\n",
    "import batch_utils\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import altair as alt\n",
    "from scipy.stats.mstats import zscore\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = 'station_3'\n",
    "con = sqlite3.connect(f\"models/{batch_name}/results.db\")\n",
    "cursor = con.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * FROM TARABAN\n",
    "\"\"\"\n",
    "\n",
    "with sqlite3.connect(f\"models/{batch_name}/results.db\") as c:\n",
    "    taraban = pd.read_sql(query, con=c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taraban.word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Taraban as a reference to align epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = taraban.loc[taraban['timetick'].isin(range(8, 13))]\n",
    "df = df.groupby(['code_name', 'batch_size', 'learning_rate', 'epoch', 'output_name']).mean().reset_index()\n",
    "\n",
    "alt.Chart(df).mark_line(point=True).encode(\n",
    "    x='epoch:Q',\n",
    "    y='mean(acc):Q',\n",
    "    column='learning_rate:Q',\n",
    "    row='batch_size:Q',\n",
    "    color='output_name:N'\n",
    ").save('Taraban_acc.html')\n",
    "\n",
    "acc_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_to_mean_acc(batch_size, learning_rate, epoch):\n",
    "    return acc_df.loc[(acc_df.epoch==epoch) & \n",
    "        (acc_df.output_name=='pho') & \n",
    "        (acc_df.batch_size==batch_size) & \n",
    "        (acc_df.learning_rate==learning_rate), 'acc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN cell GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidying up\n",
    "df = taraban.loc[taraban['timetick'].isin(range(8, 13)) & (taraban['output_name'] == 'pho')].copy()\n",
    "df = df.groupby(['code_name', 'batch_size', 'learning_rate', 'epoch', 'output_name', 'freq', 'reg']).mean().reset_index()\n",
    "df['reg_num'] = df.reg.apply(lambda x: 0.5 if x == 'Regular' else -0.5)\n",
    "df['freq_num'] = df.freq.apply(lambda x: 0.5 if x == 'High' else -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taraban_beta(df: pd.DataFrame, batch_size:int, learning_rate:float, epoch:int, metric='acc', standardize=False) -> pd.DataFrame:\n",
    "    # Parse the dataframe to get the parameters\n",
    "    df = df.loc[(df.batch_size == batch_size) & (df.learning_rate == learning_rate) & (df.epoch == epoch)]\n",
    "\n",
    "    y = f'zscore({metric})' if standardize else metric  # pick y\n",
    "\n",
    "    try:\n",
    "        m = smf.glm(formula=f\"{y} ~ freq_num * reg_num\", data=df).fit()\n",
    "        p = m.params\n",
    "        p['batch_size'] = batch_size\n",
    "        p['learning_rate'] = learning_rate\n",
    "        p['epoch'] = epoch\n",
    "\n",
    "        p['acc'] = epoch_to_mean_acc(batch_size, learning_rate, epoch)\n",
    "        return pd.DataFrame(p).T\n",
    "    except Exception as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(df.epoch.unique())\n",
    "batch_sizes = list(df.batch_size.unique())\n",
    "learning_rates = list(df.learning_rate.unique())\n",
    "\n",
    "def run_taraban(metric, standardize):\n",
    "\n",
    "    bdf = pd.DataFrame()\n",
    "\n",
    "    for epoch in tqdm(epochs):\n",
    "        for batch_size in batch_sizes:\n",
    "            for learning_rate in learning_rates:\n",
    "                bdf = bdf.append(get_taraban_beta(df, batch_size, learning_rate, epoch, metric, standardize))\n",
    "\n",
    "    \n",
    "    mdf = bdf.melt(id_vars=['batch_size', 'learning_rate', 'acc'], \n",
    "        value_vars=['Intercept', 'reg_num', 'freq_num', 'freq_num:reg_num'], var_name='param', value_name='beta')\n",
    "\n",
    "    return alt.Chart(mdf).mark_line(point=True).encode(\n",
    "        y='beta:Q',\n",
    "        x='acc:Q',\n",
    "        column='learning_rate:O',\n",
    "        row='batch_size:O',\n",
    "        color='param:N'\n",
    "    ).properties(title=f'Beta in Taraban (z:{standardize}, y:{metric}) ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_taraban('acc', True).save('Taraban_beta_zacc.html')\n",
    "run_taraban('acc', False).save('Taraban_beta_acc.html')\n",
    "run_taraban('sse', True).save('Taraban_beta_zsse.html')\n",
    "run_taraban('sse', False).save('Taraban_beta_sse.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = 'station_3'\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT * FROM LEXICALITY\n",
    "\"\"\"\n",
    "\n",
    "with sqlite3.connect(f\"models/{batch_name}/results.db\") as c:\n",
    "    lex = pd.read_sql(query, con=c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicality effect over epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lex.loc[(lex.timetick.isin(range(8, 13))) & (lex.output_name == 'pho')]\n",
    "df = df.groupby(['code_name', 'batch_size', 'learning_rate', 'epoch', 'cond']).mean().reset_index()\n",
    "\n",
    "df['lex_num'] = df.cond.apply(lambda x: 0.5 if x == 'word' else -0.5)\n",
    "\n",
    "alt.Chart(df).mark_line(point=True).encode(\n",
    "    x='epoch:Q',\n",
    "    y='mean(acc):Q',\n",
    "    column='learning_rate:Q',\n",
    "    row='batch_size:Q',\n",
    "    color='cond:N'\n",
    ").save('lexicality_over_epoch.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NW vs. W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df.pivot_table(index=['code_name', 'batch_size', 'learning_rate', 'epoch'], columns='cond', values='acc').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(pdf).mark_point().encode(\n",
    "    x=alt.X('word:Q', scale=alt.Scale(domain=[0,1])),\n",
    "    y=alt.Y('nonword:Q', scale=alt.Scale(domain=[0,1])),\n",
    "    column='learning_rate:Q',\n",
    "    row='batch_size:Q',\n",
    "    color='code_name:N'\n",
    ").save('nonword_word.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_to_mean_acc(batch_size, learning_rate, epoch):\n",
    "    return acc_df.loc[(acc_df.epoch==epoch) & \n",
    "        (acc_df.output_name=='pho') & \n",
    "        (acc_df.batch_size==batch_size) & \n",
    "        (acc_df.learning_rate==learning_rate), 'acc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lex_beta(df: pd.DataFrame, batch_size:int, learning_rate:float, epoch:int, metric='acc', standardize=False) -> pd.DataFrame:\n",
    "    # Parse the dataframe to get the parameters\n",
    "    df = df.loc[(df.batch_size == batch_size) & (df.learning_rate == learning_rate) & (df.epoch == epoch)]\n",
    "    y = f'zscore({metric})' if standardize else metric  # pick y\n",
    "\n",
    "    try:\n",
    "        m = smf.glm(formula=f\"{y} ~ lex_num\", data=df).fit()\n",
    "        p = m.params\n",
    "        p['batch_size'] = batch_size\n",
    "        p['learning_rate'] = learning_rate\n",
    "        p['epoch'] = epoch\n",
    "\n",
    "        p['acc'] = epoch_to_mean_acc(batch_size, learning_rate, epoch)\n",
    "        return pd.DataFrame(p).T\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(df.epoch.unique())\n",
    "batch_sizes = list(df.batch_size.unique())\n",
    "learning_rates = list(df.learning_rate.unique())\n",
    "\n",
    "def run_lex(metric, standardize):\n",
    "\n",
    "    bdf = pd.DataFrame()\n",
    "\n",
    "    for epoch in tqdm(epochs):\n",
    "        for batch_size in batch_sizes:\n",
    "            for learning_rate in learning_rates:\n",
    "                bdf = bdf.append(get_lex_beta(df, batch_size, learning_rate, epoch, metric, standardize))\n",
    "\n",
    "    \n",
    "    mdf = bdf.melt(id_vars=['batch_size', 'learning_rate', 'acc'], \n",
    "        value_vars=['Intercept', 'lex_num'], var_name='param', value_name='beta')\n",
    "\n",
    "    return alt.Chart(mdf).mark_line(point=True).encode(\n",
    "        y='beta:Q',\n",
    "        x='acc:Q',\n",
    "        column='learning_rate:O',\n",
    "        row='batch_size:O',\n",
    "        color='param:N'\n",
    "    ).properties(title=f'Beta in Taraban (z:{standardize}, y:{metric}) ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_lex('acc', False).save('Lexicality_beta_acc.html')\n",
    "run_lex('acc', True).save('Lexicality_zbeta_acc.html')\n",
    "run_lex('csse', False).save('Lexicality_beta_csse.html')\n",
    "run_lex('csse', True).save('Lexicality_zbeta_csse.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imageability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * FROM imageability\n",
    "\"\"\"\n",
    "\n",
    "with sqlite3.connect(f\"models/{batch_name}/results.db\") as c:\n",
    "    img = pd.read_sql(query, con=c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = img.loc[(img.timetick.isin(range(8, 13)))]\n",
    "df = df.groupby(['code_name', 'batch_size', 'learning_rate', 'epoch', 'cond', 'output_name']).mean().reset_index()\n",
    "\n",
    "df[[\"freq\", \"op\", \"img\"]] = df.cond.str.split(\"_\", expand=True)\n",
    "df[\"fc\"] = df.cond.apply(lambda x: x[:5])\n",
    "df[\"freq_num\"] = df.freq.apply(lambda x: 0.5 if x == \"hf\" else -0.5)\n",
    "df[\"op_num\"] = df.op.apply(lambda x: 0.5 if x == \"ls\" else -0.5)\n",
    "df[\"img_num\"] = df.img.apply(lambda x: 0.5 if x == \"hi\" else -0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_beta(df: pd.DataFrame, output_name: str, batch_size:int, learning_rate:float, epoch:int, metric='acc', standardize=False) -> pd.DataFrame:\n",
    "    # Parse the dataframe to get the parameters\n",
    "    df = df.loc[(df.batch_size == batch_size) & (df.learning_rate == learning_rate) & (df.epoch == epoch) & (df.output_name == output_name)]\n",
    "    y = f'zscore({metric})' if standardize else metric  # pick y\n",
    "\n",
    "    try:\n",
    "        m = smf.glm(formula=f\"{y} ~ img_num\", data=df).fit()\n",
    "        p = m.params\n",
    "        p['batch_size'] = batch_size\n",
    "        p['learning_rate'] = learning_rate\n",
    "        p['epoch'] = epoch\n",
    "\n",
    "        p['acc'] = epoch_to_mean_acc(batch_size, learning_rate, epoch)\n",
    "        return pd.DataFrame(p).T\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(df.epoch.unique())\n",
    "batch_sizes = list(df.batch_size.unique())\n",
    "learning_rates = list(df.learning_rate.unique())\n",
    "\n",
    "def run_img(output_name, metric, standardize):\n",
    "\n",
    "    bdf = pd.DataFrame()\n",
    "\n",
    "    for epoch in tqdm(epochs):\n",
    "        for batch_size in batch_sizes:\n",
    "            for learning_rate in learning_rates:\n",
    "                bdf = bdf.append(get_img_beta(df, output_name, batch_size, learning_rate, epoch, metric, standardize))\n",
    "\n",
    "    \n",
    "    mdf = bdf.melt(id_vars=['batch_size', 'learning_rate', 'acc'], \n",
    "        value_vars=['Intercept', 'img_num'], var_name='param', value_name='beta')\n",
    "\n",
    "    return alt.Chart(mdf).mark_line(point=True).encode(\n",
    "        y='beta:Q',\n",
    "        x='acc:Q',\n",
    "        column='learning_rate:O',\n",
    "        row='batch_size:O',\n",
    "        color='param:N'\n",
    "    ).properties(title=f'Beta in IMG (out: {output_name} z:{standardize}, y:{metric}) ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_img(output_name='pho', metric='acc', standardize=False).save('pho_IMG_beta_acc.html')\n",
    "run_img(output_name='pho', metric='acc', standardize=True).save('pho_IMG_zbeta_acc.html')\n",
    "run_img(output_name='pho', metric='csse', standardize=False).save('pho_IMG_beta_csse.html')\n",
    "run_img(output_name='pho', metric='csse', standardize=True).save('pho_IMG_zbeta_csse.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_img(output_name='sem', metric='acc', standardize=False).save('SEM_IMG_beta_acc.html')\n",
    "run_img(output_name='sem', metric='acc', standardize=True).save('SEM_IMG_zbeta_acc.html')\n",
    "run_img(output_name='sem', metric='csse', standardize=False).save('SEM_IMG_beta_csse.html')\n",
    "run_img(output_name='sem', metric='csse', standardize=True).save('SEM_IMG_zbeta_csse.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swap to continuous regressors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import zscore\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import evaluate\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.tf_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_name = \"tmp_64_005\"\n",
    "cfg = meta.Config.from_json(f\"models/{code_name}/model_config.json\")\n",
    "test = evaluate.TestSet(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test.eval_train('triangle')\n",
    "df = df.loc[(df.timetick.isin(range(8, 13))) & (df.output_name == 'pho')]\n",
    "df = df.groupby(['epoch', 'word']).mean().reset_index()\n",
    "df = df[['epoch', 'word', 'acc', 'sse']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprisal = pd.read_csv(\"/home/jupyter/triangle_model/corpus/noam_surprisal.csv\")\n",
    "word2op_dict = {word: op for word, op in zip(surprisal.word, surprisal[\"uncond.surprisal\"])}\n",
    "\n",
    "df_train = pd.read_csv(\"/home/jupyter/triangle_model/dataset/df_train.csv\")\n",
    "word2wf_dict = {word: wf for word, wf in zip(df_train.word, df_train.wf)}\n",
    "\n",
    "def word2op(word):\n",
    "    try:\n",
    "        return word2op_dict[word]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def word2wf(word):\n",
    "    try:\n",
    "        return np.log10(word2wf_dict[word] + 1)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wf'] = df.word.apply(lambda x: word2wf(x))\n",
    "df['op'] = df.word.apply(lambda x: word2op(x))\n",
    "df = df.dropna()\n",
    "df['csse'] = df.sse.loc[df.acc == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean acc in each epoch\n",
    "m_acc_epoch = df.groupby(['epoch']).mean().reset_index()\n",
    "epo_acc = {epoch: acc for epoch, acc in zip(m_acc_epoch.epoch, m_acc_epoch.acc)}\n",
    "df['epo_macc'] = df.epoch.apply(lambda x: epo_acc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fc_beta(df: pd.DataFrame, epoch:int, metric='acc') -> pd.DataFrame:\n",
    "    # Parse the dataframe to get the parameters\n",
    "    # df = df.loc[(df.batch_size == batch_size) & (df.learning_rate == learning_rate) & (df.epoch == epoch)]\n",
    "    sdf = df.loc[(df.epoch == epoch)].dropna()\n",
    "    m = smf.glm(formula=f\"{metric} ~ zscore(op) * zscore(wf) + 0\", family=sm.families.Binomial(), data=sdf).fit()\n",
    "    p = m.params\n",
    "    p['epoch'] = epoch\n",
    "\n",
    "    return pd.DataFrame(p).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zbeta_acc = pd.concat([get_fc_beta(df, epoch=i, metric='acc') for i in cfg.saved_epochs], ignore_index=True)\n",
    "zbeta_acc_long = zbeta_acc.melt(id_vars=['epoch'], var_name='param', value_name='beta')\n",
    "zbeta_acc_long['acc'] = zbeta_acc_long.epoch.apply(lambda x: epo_acc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zbeta_csse = pd.concat([get_fc_beta(df, epoch=i, metric='csse') for i in cfg.saved_epochs], ignore_index=True)\n",
    "zbeta_csse_long = zbeta_csse.melt(id_vars=['epoch'], var_name='param', value_name='beta')\n",
    "zbeta_csse_long['acc'] = zbeta_csse_long.epoch.apply(lambda x: epo_acc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = alt.Chart(zbeta_long).mark_line(point=True).encode(\n",
    "    x=\"epoch:Q\",\n",
    "    y=\"beta:Q\",\n",
    "    color=\"param:N\")\n",
    "\n",
    "per = dev.encode(x=\"acc:Q\")\n",
    "\n",
    "dev | per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_60 = df.loc[df.epoch == 60].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_60['wf_gp'] = df_60.wf.apply(lambda x: 'HF' if x > df_60.wf.median() else 'LF')\n",
    "df_60['wf_op'] = df_60.op.apply(lambda x: 'INC' if x > df_60.op.median() else 'CON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()\n",
    "alt.Chart(df_60).mark_line().encode(\n",
    "    x='wf_gp:N',\n",
    "    y='mean(acc):Q',\n",
    "    color='wf_op:N'\n",
    ").properties(width=200, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full grid F X C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import meta\n",
    "import json\n",
    "from scipy.stats.mstats import zscore\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve batch settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"models/station_3/batch_config.json\"\n",
    "\n",
    "with open(json_file) as f:\n",
    "    batch_cfgs = json.load(f)\n",
    "\n",
    "all_params = [pd.DataFrame(cfg[\"params\"]) for cfg in batch_cfgs if type(cfg[\"params\"].values()) is not list]\n",
    "cfgs = pd.concat(all_params, ignore_index=True)\n",
    "cfgs = cfgs.groupby(['code_name', 'batch_size', 'learning_rate']).mean().reset_index()\n",
    "cfgs = cfgs[['code_name', 'batch_size', 'learning_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bigquery df\n",
    "# SELECT\n",
    "#   code_name, epoch, word, acc, sse \n",
    "# FROM\n",
    "#   `majestic-camp-303620.station_3.train`\n",
    "# WHERE\n",
    "#   timetick = 12\n",
    "#   AND output_name = 'pho'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"models/station_3/pho_lasttick.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"models/station_3/pho_lasttick.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprisal = pd.read_csv(\"/home/jupyter/triangle_model/corpus/noam_surprisal.csv\")\n",
    "word2op_dict = {word: op for word, op in zip(surprisal.word, surprisal[\"uncond.surprisal\"])}\n",
    "\n",
    "df_train = pd.read_csv(\"/home/jupyter/triangle_model/dataset/df_train.csv\")\n",
    "word2wf_dict = {word: wf for word, wf in zip(df_train.word, df_train.wf)}\n",
    "\n",
    "def word2op(word):\n",
    "    try:\n",
    "        return word2op_dict[word]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def word2wf(word):\n",
    "    try:\n",
    "        return np.log10(word2wf_dict[word] + 1)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate csse\n",
    "df['csse'] = df.sse.loc[df.acc == 1]\n",
    "\n",
    "# Get wf and op for each word\n",
    "df['wf'] = df.word.apply(lambda x: word2wf(x))\n",
    "df['op'] = df.word.apply(lambda x: word2op(x))\n",
    "\n",
    "# Get batch size and learning rate\n",
    "df = df.merge(cfgs, on=['code_name'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "df.to_csv(\"models/station_3/pho_lasttick.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta_acc(df: pd.DataFrame, code_name:str, epoch:int) -> pd.DataFrame:\n",
    "    sdf = df.loc[(df.epoch == epoch) & (df.code_name == code_name)]\n",
    "    batch_size = sdf.batch_size.unique()[0]\n",
    "    learning_rate = sdf.learning_rate.unique()[0]\n",
    "\n",
    "    sdf = sdf[['word', 'acc', 'op', 'wf']].dropna()\n",
    "    \n",
    "    m = smf.glm(formula=\"acc ~ zscore(op) * zscore(wf) + 0\", family=sm.families.Binomial(), data=sdf).fit()\n",
    "    p = m.params\n",
    "    p['epoch'] = epoch\n",
    "    p['code_name'] = code_name\n",
    "    p['batch_size'] = batch_size\n",
    "    p['learning_rate'] = learning_rate\n",
    "\n",
    "    return pd.DataFrame(p).T\n",
    "\n",
    "def get_beta_csse(df: pd.DataFrame, code_name:str, epoch:int) -> pd.DataFrame:\n",
    "    try: # Prevent no correact answer epochs returning error\n",
    "        sdf = df.loc[(df.epoch == epoch) & (df.code_name == code_name)]\n",
    "        batch_size = sdf.batch_size.unique()[0]\n",
    "        learning_rate = sdf.learning_rate.unique()[0]\n",
    "\n",
    "        sdf = sdf[['word', 'csse', 'op', 'wf']].dropna()\n",
    "        \n",
    "        m = smf.glm(formula=\"zscore(csse) ~ zscore(op) * zscore(wf) + 0\", data=sdf).fit()\n",
    "        p = m.params\n",
    "        p['epoch'] = epoch\n",
    "        p['code_name'] = code_name\n",
    "        p['batch_size'] = batch_size\n",
    "        p['learning_rate'] = learning_rate\n",
    "\n",
    "        return pd.DataFrame(p).T\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_beta_df(df, func):\n",
    "    \n",
    "    epoch_acc_map = df.groupby(['code_name', 'epoch']).mean().reset_index()[['code_name', 'epoch', 'acc']]\n",
    "    code_names = sorted(df.code_name.unique())\n",
    "    epochs = sorted(df.epoch.unique())\n",
    "    beta_df = pd.concat([func(df, code_name, epoch) for code_name in code_names for epoch in epochs], ignore_index=True)\n",
    "\n",
    "    beta_df = beta_df.melt(id_vars=['code_name', 'epoch', 'batch_size', 'learning_rate'], var_name='param', value_name='beta')\n",
    "    beta_df = pd.merge(beta_df, epoch_acc_map, on=['code_name', 'epoch'], how='left').dropna()\n",
    "\n",
    "    return beta_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csse_beta = make_beta_df(df, get_beta_csse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save(df, file_suffix:str):\n",
    "    \"\"\"Plot beta and save developmental and performance space\"\"\"\n",
    "    dev = alt.Chart(df).mark_line(point=True).encode(\n",
    "        x=\"epoch:Q\",\n",
    "        y=\"beta:Q\",\n",
    "        color=\"param:N\",\n",
    "        row=\"batch_size:O\",\n",
    "        column=\"learning_rate:O\"\n",
    "    )\n",
    "\n",
    "    per = dev.encode(x=\"acc:Q\")\n",
    "\n",
    "    dev.save(f'dev{file_suffix}.html')\n",
    "    per.save(f'per{file_suffix}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save(csse_beta, \"_csse\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
