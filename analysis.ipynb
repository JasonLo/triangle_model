{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Station3 batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purposes\n",
    "- Quatify and Visualize over performance space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib import reload\n",
    "import batch_utils\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import altair as alt\n",
    "from scipy.stats.mstats import zscore\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(f\"models/{batch_name}/results.db\")\n",
    "cursor = con.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = 'station_3'\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT * FROM TARABAN\n",
    "\"\"\"\n",
    "\n",
    "with sqlite3.connect(f\"models/{batch_name}/results.db\") as c:\n",
    "    taraban = pd.read_sql(query, con=c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Taraban as a reference to align epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = taraban.loc[taraban['timetick'].isin(range(8, 13))]\n",
    "df = df.groupby(['code_name', 'batch_size', 'learning_rate', 'epoch', 'output_name']).mean().reset_index()\n",
    "\n",
    "alt.Chart(df).mark_line(point=True).encode(\n",
    "    x='epoch:Q',\n",
    "    y='mean(acc):Q',\n",
    "    column='learning_rate:Q',\n",
    "    row='batch_size:Q',\n",
    "    color='output_name:N'\n",
    ").save('Taraban_acc.html')\n",
    "\n",
    "acc_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_to_mean_acc(batch_size, learning_rate, epoch):\n",
    "    return acc_df.loc[(acc_df.epoch==epoch) & \n",
    "        (acc_df.output_name=='pho') & \n",
    "        (acc_df.batch_size==batch_size) & \n",
    "        (acc_df.learning_rate==learning_rate), 'acc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN cell GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidying up\n",
    "df = taraban.loc[taraban['timetick'].isin(range(8, 13)) & (taraban['output_name'] == 'pho')].copy()\n",
    "df = df.groupby(['code_name', 'batch_size', 'learning_rate', 'epoch', 'output_name', 'freq', 'reg']).mean().reset_index()\n",
    "df['reg_num'] = df.reg.apply(lambda x: 0.5 if x == 'Regular' else -0.5)\n",
    "df['freq_num'] = df.freq.apply(lambda x: 0.5 if x == 'High' else -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taraban_beta(df: pd.DataFrame, batch_size:int, learning_rate:float, epoch:int, metric='acc', standardize=False) -> pd.DataFrame:\n",
    "    # Parse the dataframe to get the parameters\n",
    "    df = df.loc[(df.batch_size == batch_size) & (df.learning_rate == learning_rate) & (df.epoch == epoch)]\n",
    "\n",
    "    y = f'zscore({metric})' if standardize else metric  # pick y\n",
    "\n",
    "    try:\n",
    "        m = smf.glm(formula=f\"{y} ~ freq_num * reg_num\", data=df).fit()\n",
    "        p = m.params\n",
    "        p['batch_size'] = batch_size\n",
    "        p['learning_rate'] = learning_rate\n",
    "        p['epoch'] = epoch\n",
    "\n",
    "        p['acc'] = epoch_to_mean_acc(batch_size, learning_rate, epoch)\n",
    "        return pd.DataFrame(p).T\n",
    "    except Exception as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(df.epoch.unique())\n",
    "batch_sizes = list(df.batch_size.unique())\n",
    "learning_rates = list(df.learning_rate.unique())\n",
    "\n",
    "def run_taraban(metric, standardize):\n",
    "\n",
    "    bdf = pd.DataFrame()\n",
    "\n",
    "    for epoch in tqdm(epochs):\n",
    "        for batch_size in batch_sizes:\n",
    "            for learning_rate in learning_rates:\n",
    "                bdf = bdf.append(get_taraban_beta(df, batch_size, learning_rate, epoch, metric, standardize))\n",
    "\n",
    "    \n",
    "    mdf = bdf.melt(id_vars=['batch_size', 'learning_rate', 'acc'], \n",
    "        value_vars=['Intercept', 'reg_num', 'freq_num', 'freq_num:reg_num'], var_name='param', value_name='beta')\n",
    "\n",
    "    return alt.Chart(mdf).mark_line(point=True).encode(\n",
    "        y='beta:Q',\n",
    "        x='acc:Q',\n",
    "        column='learning_rate:O',\n",
    "        row='batch_size:O',\n",
    "        color='param:N'\n",
    "    ).properties(title=f'Beta in Taraban (z:{standardize}, y:{metric}) ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_taraban('acc', True).save('Taraban_beta_zacc.html')\n",
    "run_taraban('acc', False).save('Taraban_beta_acc.html')\n",
    "run_taraban('sse', True).save('Taraban_beta_zsse.html')\n",
    "run_taraban('sse', False).save('Taraban_beta_sse.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = 'station_3'\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT * FROM LEXICALITY\n",
    "\"\"\"\n",
    "\n",
    "with sqlite3.connect(f\"models/{batch_name}/results.db\") as c:\n",
    "    lex = pd.read_sql(query, con=c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicality effect over epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lex.loc[(lex.timetick.isin(range(8, 13))) & (lex.output_name == 'pho')]\n",
    "df = df.groupby(['code_name', 'batch_size', 'learning_rate', 'epoch', 'cond']).mean().reset_index()\n",
    "\n",
    "df['lex_num'] = df.cond.apply(lambda x: 0.5 if x == 'word' else -0.5)\n",
    "\n",
    "alt.Chart(df).mark_line(point=True).encode(\n",
    "    x='epoch:Q',\n",
    "    y='mean(acc):Q',\n",
    "    column='learning_rate:Q',\n",
    "    row='batch_size:Q',\n",
    "    color='cond:N'\n",
    ").save('lexicality_over_epoch.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NW vs. W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df.pivot_table(index=['code_name', 'batch_size', 'learning_rate', 'epoch'], columns='cond', values='acc').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(pdf).mark_point().encode(\n",
    "    x=alt.X('word:Q', scale=alt.Scale(domain=[0,1])),\n",
    "    y=alt.Y('nonword:Q', scale=alt.Scale(domain=[0,1])),\n",
    "    column='learning_rate:Q',\n",
    "    row='batch_size:Q',\n",
    "    color='code_name:N'\n",
    ").save('nonword_word.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_to_mean_acc(batch_size, learning_rate, epoch):\n",
    "    return acc_df.loc[(acc_df.epoch==epoch) & \n",
    "        (acc_df.output_name=='pho') & \n",
    "        (acc_df.batch_size==batch_size) & \n",
    "        (acc_df.learning_rate==learning_rate), 'acc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lex_beta(df: pd.DataFrame, batch_size:int, learning_rate:float, epoch:int, metric='acc', standardize=False) -> pd.DataFrame:\n",
    "    # Parse the dataframe to get the parameters\n",
    "    df = df.loc[(df.batch_size == batch_size) & (df.learning_rate == learning_rate) & (df.epoch == epoch)]\n",
    "    y = f'zscore({metric})' if standardize else metric  # pick y\n",
    "\n",
    "    try:\n",
    "        m = smf.glm(formula=f\"{y} ~ lex_num\", data=df).fit()\n",
    "        p = m.params\n",
    "        p['batch_size'] = batch_size\n",
    "        p['learning_rate'] = learning_rate\n",
    "        p['epoch'] = epoch\n",
    "\n",
    "        p['acc'] = epoch_to_mean_acc(batch_size, learning_rate, epoch)\n",
    "        return pd.DataFrame(p).T\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(df.epoch.unique())\n",
    "batch_sizes = list(df.batch_size.unique())\n",
    "learning_rates = list(df.learning_rate.unique())\n",
    "\n",
    "def run_lex(metric, standardize):\n",
    "\n",
    "    bdf = pd.DataFrame()\n",
    "\n",
    "    for epoch in tqdm(epochs):\n",
    "        for batch_size in batch_sizes:\n",
    "            for learning_rate in learning_rates:\n",
    "                bdf = bdf.append(get_lex_beta(df, batch_size, learning_rate, epoch, metric, standardize))\n",
    "\n",
    "    \n",
    "    mdf = bdf.melt(id_vars=['batch_size', 'learning_rate', 'acc'], \n",
    "        value_vars=['Intercept', 'lex_num'], var_name='param', value_name='beta')\n",
    "\n",
    "    return alt.Chart(mdf).mark_line(point=True).encode(\n",
    "        y='beta:Q',\n",
    "        x='acc:Q',\n",
    "        column='learning_rate:O',\n",
    "        row='batch_size:O',\n",
    "        color='param:N'\n",
    "    ).properties(title=f'Beta in Taraban (z:{standardize}, y:{metric}) ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_lex('acc', False).save('Lexicality_beta_acc.html')\n",
    "run_lex('acc', True).save('Lexicality_zbeta_acc.html')\n",
    "run_lex('csse', False).save('Lexicality_beta_csse.html')\n",
    "run_lex('csse', True).save('Lexicality_zbeta_csse.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imageability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * FROM imageability\n",
    "\"\"\"\n",
    "\n",
    "with sqlite3.connect(f\"models/{batch_name}/results.db\") as c:\n",
    "    img = pd.read_sql(query, con=c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = img.loc[(img.timetick.isin(range(8, 13)))]\n",
    "df = df.groupby(['code_name', 'batch_size', 'learning_rate', 'epoch', 'cond', 'output_name']).mean().reset_index()\n",
    "\n",
    "df[[\"freq\", \"op\", \"img\"]] = df.cond.str.split(\"_\", expand=True)\n",
    "df[\"fc\"] = df.cond.apply(lambda x: x[:5])\n",
    "df[\"freq_num\"] = df.freq.apply(lambda x: 0.5 if x == \"hf\" else -0.5)\n",
    "df[\"op_num\"] = df.op.apply(lambda x: 0.5 if x == \"ls\" else -0.5)\n",
    "df[\"img_num\"] = df.img.apply(lambda x: 0.5 if x == \"hi\" else -0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_beta(df: pd.DataFrame, output_name: str, batch_size:int, learning_rate:float, epoch:int, metric='acc', standardize=False) -> pd.DataFrame:\n",
    "    # Parse the dataframe to get the parameters\n",
    "    df = df.loc[(df.batch_size == batch_size) & (df.learning_rate == learning_rate) & (df.epoch == epoch) & (df.output_name == output_name)]\n",
    "    y = f'zscore({metric})' if standardize else metric  # pick y\n",
    "\n",
    "    try:\n",
    "        m = smf.glm(formula=f\"{y} ~ img_num\", data=df).fit()\n",
    "        p = m.params\n",
    "        p['batch_size'] = batch_size\n",
    "        p['learning_rate'] = learning_rate\n",
    "        p['epoch'] = epoch\n",
    "\n",
    "        p['acc'] = epoch_to_mean_acc(batch_size, learning_rate, epoch)\n",
    "        return pd.DataFrame(p).T\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(df.epoch.unique())\n",
    "batch_sizes = list(df.batch_size.unique())\n",
    "learning_rates = list(df.learning_rate.unique())\n",
    "\n",
    "def run_img(output_name, metric, standardize):\n",
    "\n",
    "    bdf = pd.DataFrame()\n",
    "\n",
    "    for epoch in tqdm(epochs):\n",
    "        for batch_size in batch_sizes:\n",
    "            for learning_rate in learning_rates:\n",
    "                bdf = bdf.append(get_img_beta(df, output_name, batch_size, learning_rate, epoch, metric, standardize))\n",
    "\n",
    "    \n",
    "    mdf = bdf.melt(id_vars=['batch_size', 'learning_rate', 'acc'], \n",
    "        value_vars=['Intercept', 'img_num'], var_name='param', value_name='beta')\n",
    "\n",
    "    return alt.Chart(mdf).mark_line(point=True).encode(\n",
    "        y='beta:Q',\n",
    "        x='acc:Q',\n",
    "        column='learning_rate:O',\n",
    "        row='batch_size:O',\n",
    "        color='param:N'\n",
    "    ).properties(title=f'Beta in IMG (out: {output_name} z:{standardize}, y:{metric}) ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_img(output_name='pho', metric='acc', standardize=False).save('pho_IMG_beta_acc.html')\n",
    "run_img(output_name='pho', metric='acc', standardize=True).save('pho_IMG_zbeta_acc.html')\n",
    "run_img(output_name='pho', metric='csse', standardize=False).save('pho_IMG_beta_csse.html')\n",
    "run_img(output_name='pho', metric='csse', standardize=True).save('pho_IMG_zbeta_csse.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_img(output_name='sem', metric='acc', standardize=False).save('SEM_IMG_beta_acc.html')\n",
    "run_img(output_name='sem', metric='acc', standardize=True).save('SEM_IMG_zbeta_acc.html')\n",
    "run_img(output_name='sem', metric='csse', standardize=False).save('SEM_IMG_beta_csse.html')\n",
    "run_img(output_name='sem', metric='csse', standardize=True).save('SEM_IMG_zbeta_csse.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
