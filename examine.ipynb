{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- speed\n",
    "- GCP BQ support\n",
    "- support for v4 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consideration\n",
    "- Everything on tensorboard is convienient and fast af. \n",
    "- Need item level details down the line --> which BigQuery comes into play, but not so important until triangle model v4 is stable\n",
    "- currently I am doing things in between, store data locally per model, then aggregate mean level statistic if batch run (varying h-param or multi runs). \n",
    "- I already almost coded everything in bit and pieces, just need to have a better integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext lab_black\n",
    "import os\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import meta, data_wrangling, modeling, metrics, evaluate\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(evaluate)\n",
    "reload(data_wrangling)\n",
    "reload(metrics)\n",
    "\n",
    "code_name = \"triangle_with_strain\"\n",
    "\n",
    "cfg = meta.ModelConfig.from_json(os.path.join(\"models\", code_name, \"model_config.json\"))\n",
    "\n",
    "model = modeling.MyModel(cfg)\n",
    "checkpoint = cfg.path[\"weights_checkpoint_fstring\"].format(epoch=250)\n",
    "model.load_weights(checkpoint)\n",
    "\n",
    "data = data_wrangling.MyData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_active_task(\"triangle\")\n",
    "y_pred = model([data.testsets[\"strain\"][\"ort\"]] * cfg.n_timesteps)\n",
    "y_true = {out: data.testsets[\"strain\"][out] for out in ('pho', 'sem')}\n",
    "\n",
    "pho_acc = metrics.PhoAccuracy()\n",
    "pho_sse = metrics.SumSquaredError()\n",
    "sem_acc = metrics.RightSideAccuracy()\n",
    "sem_sse = metrics.SumSquaredError()\n",
    "\n",
    "pho_acc.update_state(y_true['pho'], y_pred['pho'][-1])\n",
    "pho_sse.update_state(y_true['pho'], y_pred['pho'][-1])\n",
    "sem_acc.update_state(y_true['sem'], y_pred['sem'][-1])\n",
    "sem_sse.update_state(y_true['sem'], y_pred['sem'][-1])\n",
    "print(f\"pho accuracy:{pho_acc.out.numpy():04f}, sem accuracy:{sem_acc.out.numpy():04f}\")\n",
    "print(f\"pho sse:{pho_sse.out.numpy():04f}, sem sse:{sem_sse.out.numpy():04f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto type testset implemetation manually\n",
    "We need a vectorized map at these dimensions:\n",
    "- model (1 for now)\n",
    "- epoch (39)\n",
    "- timestep (11)\n",
    "- testset x cond (taraban, glushko, hs04 img)\n",
    "- task (9, 5 main, 4 experimental)\n",
    "- output (2 in triangle, otherwise 1)\n",
    "- metrics (acc, sse, cosine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_active_task(\"ort_sem\")\n",
    "y_pred = model([data.testsets[\"strain\"][\"ort\"]] * cfg.n_timesteps)\n",
    "y_true = data.testsets[\"strain\"][\"sem\"]\n",
    "sem_acc.update_state(y_true, y_pred['sem'][-1])\n",
    "sem_sse.update_state(y_true, y_pred['sem'][-1])\n",
    "print(f\"sem accuracy:{sem_acc.out.numpy():04f}, sse:{sem_sse.out.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_active_task(\"exp_ops\")\n",
    "y_pred = model([data.testsets[\"strain\"][\"ort\"]] * cfg.n_timesteps)\n",
    "y_true = data.testsets[\"strain\"][\"sem\"]\n",
    "sem_acc.update_state(y_true, y_pred['sem'][-1])\n",
    "sem_sse.update_state(y_true, y_pred['sem'][-1])\n",
    "print(f\"sem accuracy:{sem_acc.out.numpy():04f}, sse:{sem_sse.out.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_active_task(\"ort_pho\")\n",
    "y_pred = model([data.testsets[\"strain\"][\"ort\"]] * cfg.n_timesteps)\n",
    "y_true = data.testsets[\"strain\"][\"pho\"]\n",
    "pho_acc.update_state(y_true, y_pred['pho'][-1])\n",
    "pho_sse.update_state(y_true, y_pred['pho'][-1])\n",
    "print(f\"pho accuracy:{pho_acc.out.numpy():04f}, pho sse:{pho_sse.out.numpy():04f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_active_task(\"exp_osp\")\n",
    "y_pred = model([data.testsets[\"strain\"][\"ort\"]] * cfg.n_timesteps)\n",
    "y_true = data.testsets[\"strain\"][\"pho\"]\n",
    "pho_acc.update_state(y_true, y_pred['pho'][-1])\n",
    "pho_sse.update_state(y_true, y_pred['pho'][-1])\n",
    "print(f\"pho accuracy:{pho_acc.out.numpy():04f}, pho sse:{pho_sse.out.numpy():04f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- timestep (11)\n",
    "- testset x cond (taraban, glushko, hs04 img)\n",
    "- task (9, 5 main, 4 experimental)\n",
    "- output (2 in triangle, otherwise 1)\n",
    "- metrics (acc, sse, cosine) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.testset object:\n",
    "'ort': shape = (n items, ort_units)\n",
    "'pho': shape = () \n",
    "\n",
    "### Steps\n",
    "1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.testsets['strain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class TestSet:\n",
    "    \"\"\"Universal test set object for evaluating model results\n",
    "    1. Single condition, single metric, single value output for maximum capatibility\n",
    "    2. Model level info should be stored at separate table, and merge it in the end\n",
    "    \"\"\"\n",
    "\n",
    "    METRICS_MAP = {\n",
    "            'pho':{'acc': metrics.PhoAccuracy(), 'sse': metrics.SumSquaredError()},\n",
    "            'sem':{'acc': metrics.RightSideAccuracy(), 'sse': metrics.SumSquaredError()},\n",
    "    }\n",
    "\n",
    "    def __init__(self, cfg, model):\n",
    "        self.cfg = cfg\n",
    "        self.model = model\n",
    "        \n",
    "    def eval(self, testset_name, task):\n",
    "        df = pd.DataFrame()\n",
    "        ts_path = '/home/jupyter/tf/dataset/testsets'\n",
    "        testset_package = data_wrangling.load_testset(os.path.join(ts_path, f\"{testset_name}.pkl.gz\"))\n",
    "        self.model.set_active_task(task)\n",
    "\n",
    "        # for epoch in tqdm(self.cfg.saved_epoches):\n",
    "        for epoch in tqdm(range(1, 4)):\n",
    "            w = self.cfg.path['weights_checkpoint_fstring'].format(epoch=epoch)\n",
    "            self.model.load_weights(w)\n",
    "            y_pred = self.model([testset_package[modeling.IN_OUT[task][0]]] * self.cfg.n_timesteps)\n",
    "            \n",
    "            for timetick_idx in range(self.cfg.output_ticks):\n",
    "                if task == 'triangle':\n",
    "                    for output_name in ('pho', 'sem'):\n",
    "                        tag = {\n",
    "                                'code_name': self.cfg.code_name,\n",
    "                                'epoch': epoch,\n",
    "                                'testset': testset_name,\n",
    "                                'task': task,\n",
    "                                'output_name': output_name,\n",
    "                                'timetick_idx': timetick_idx,\n",
    "                                'timetick': self.output_idx_to_timetick(timetick_idx),\n",
    "                                'word': testset_package['item']\n",
    "                        }\n",
    "\n",
    "                        df = df.append(self._eval_one(y_pred, y_true, tag), ignore_index=True)\n",
    "\n",
    "                else:\n",
    "                    output_name = modeling.IN_OUT[task][1]\n",
    "                    tag = {\n",
    "                            'code_name': self.cfg.code_name,\n",
    "                            'epoch': epoch,\n",
    "                            'testset': testset_name,\n",
    "                            'task': task,\n",
    "                            'output_name': output_name,\n",
    "                            'timetick_idx': timetick_idx,\n",
    "                            'timetick': self.output_idx_to_timetick(timetick_idx),\n",
    "                            'word': testset_package['item']\n",
    "                        }\n",
    "                    df = df.append(self._eval_one(y_pred, y_true, tag), ignore_index=True)\n",
    "\n",
    "        return df\n",
    "    \n",
    "\n",
    "    def output_idx_to_timetick(self, idx):\n",
    "        # Zero indexing idx to one indexing step\n",
    "        d = self.cfg.n_timesteps - self.cfg.output_ticks\n",
    "        return idx + 1 + d \n",
    "\n",
    "\n",
    "    def _eval_one(self, y_pred, y_true, tag):\n",
    "        \"\"\"\n",
    "        y_pred: predition dictionary, e.g., {'pho': (time ticks, items, output nodes)}\n",
    "        y_true: label dictionary (time invarying), e.g., {'sem': (items, maybe n ans. output nodes)}\n",
    "        \"\"\"\n",
    "        out = pd.DataFrame()\n",
    "        this_y_pred = y_pred[tag['output_name']][tag['timetick_idx']]\n",
    "        # shape: (time ticks, items, output nodes)\n",
    "\n",
    "        this_y_true = y_true[tag['output_name']]\n",
    "        # shape: (item, *maybe n ans, output nodes)\n",
    "\n",
    "        acc = self.METRICS_MAP[tag['output_name']]['acc']\n",
    "\n",
    "        if tf.rank(this_y_true) == 3:\n",
    "            # Multi ans mode\n",
    "            out['acc'] = acc.item_metric_multi_ans(this_y_true, this_y_pred)\n",
    "        else:\n",
    "            # Single ans mode\n",
    "            out['acc'] = acc.item_metric(this_y_true, this_y_pred)\n",
    "\n",
    "        # Write tag to df\n",
    "        for k, v in tag.items():\n",
    "            out[k] = v\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = TestSet(cfg, model)\n",
    "x.eval('strain', 'ort_pho')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model level examine class (After eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class examine:\n",
    "    \n",
    "    def __init__(self, code_name, tf_root=\"/home/jupyter/tf\"):\n",
    "\n",
    "        try:\n",
    "            # Fast load from disk\n",
    "            csv_file = os.path.join(tf_root, 'models', code_name, 'eval', 'strain_mean_df.csv')\n",
    "            self.df = pd.read_csv(csv_file)\n",
    "        except:\n",
    "            # Eval from scratch\n",
    "            self.cfg = meta.ModelConfig.from_json(os.path.join(tf_root, 'models', code_name, 'model_config.json'))\n",
    "            self.data = data_wrangling.MyData()\n",
    "            self.model = modeling.HS04Model(self.cfg)\n",
    "            self.model.build()\n",
    "            self.test_strain = evaluate.EvalOral(self.cfg, self.model, self.data)\n",
    "            self.df = self.test_strain.strain_mean_df\n",
    "\n",
    "    def plot_op_strain(self):\n",
    "        df = self.df\n",
    "\n",
    "        @interact(\n",
    "            use_y=['acc','sse','conditional_sse'],\n",
    "            timetick=(1,12,1),\n",
    "            y_max=(1, 20, 1)\n",
    "            )\n",
    "        def plot(use_y='acc', timetick=12, y_max=1):\n",
    "            sdf = df.loc[(df.timetick==timetick)] \n",
    "            \n",
    "            # Plot by condition\n",
    "            plot_by_cond = alt.Chart(sdf).mark_line().encode(\n",
    "                x=alt.X('epoch:Q', scale=alt.Scale(domain=(0, 100), clamp=True)),\n",
    "                y=alt.Y(f\"{use_y}:Q\", scale=alt.Scale(domain=(0, y_max))),\n",
    "                color='cond:N'\n",
    "            )\n",
    "\n",
    "            # Contrasts\n",
    "            contrasts = {}\n",
    "            contrasts['contrast_frequency'] = \"\"\"(datum.HF_INC + datum.HF_CON - (datum.LF_INC + datum.LF_CON))/2\"\"\" \n",
    "            contrasts['contrast_consistency'] = \"\"\"(datum.LF_CON + datum.HF_CON - (datum.LF_INC + datum.HF_INC))/2\"\"\" \n",
    "\n",
    "            def create_contrast_plot(name):\n",
    "                return plot_by_cond.encode(y=alt.Y(\"difference:Q\", scale=alt.Scale(domain=(-y_max, y_max)))\n",
    "                    ).transform_pivot('cond', value=use_y, groupby=['epoch']\n",
    "                    ).transform_calculate(difference = contrasts[name]\n",
    "                    ).properties(title=name)\n",
    "\n",
    "            return plot_by_cond | create_contrast_plot('contrast_frequency') | create_contrast_plot('contrast_consistency')\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\" Create an interactive plot for strain \"\"\"\n",
    "        df = self.df\n",
    "\n",
    "        @interact(\n",
    "            use_y=['acc','sse','conditional_sse'],\n",
    "            task=['pho_sem', 'sem_pho', 'pho_pho', 'sem_sem'],\n",
    "            timetick=(1,12,1),\n",
    "            y_max=(1, 20, 1)\n",
    "            )\n",
    "        def plot(use_y='acc', timetick=12, task='pho_sem', y_max=1):\n",
    "            sdf = df.loc[(df.timetick==timetick) & (df.task==task)] \n",
    "            \n",
    "            # Plot by condition\n",
    "            plot_by_cond = alt.Chart(sdf).mark_line().encode(\n",
    "                x='epoch:Q',\n",
    "                y=alt.Y(f\"{use_y}:Q\", scale=alt.Scale(domain=(0, y_max))),\n",
    "                color='testset:N'\n",
    "            )\n",
    "\n",
    "            # Plot average\n",
    "            plot_average = plot_by_cond.encode(y=alt.Y(f\"mean({use_y}):Q\", scale=alt.Scale(domain=(0, y_max))), color='task')\n",
    "            plot_average += plot_average.mark_errorband()\n",
    "\n",
    "            # Plot contrasts\n",
    "            contrasts = {}\n",
    "            contrasts['contrast_frequency'] = \"\"\"(datum.strain_hf_con_hi + datum.strain_hf_con_li + datum.strain_hf_inc_hi + datum.strain_hf_inc_li - \n",
    "                (datum.strain_lf_con_hi + datum.strain_lf_con_li + datum.strain_lf_inc_hi + datum.strain_lf_inc_li))/4\"\"\"\n",
    "            contrasts['contrast_consistency'] = \"\"\"(datum.strain_hf_con_hi + datum.strain_hf_con_li + datum.strain_lf_con_hi + datum.strain_lf_con_li - \n",
    "                (datum.strain_hf_inc_hi + datum.strain_hf_inc_li + datum.strain_lf_inc_hi + datum.strain_lf_inc_li))/4\"\"\"\n",
    "            contrasts['contrast_imageability'] = \"\"\"(datum.strain_hf_con_hi + datum.strain_lf_con_hi + datum.strain_hf_inc_hi + datum.strain_lf_inc_hi - \n",
    "                (datum.strain_hf_con_li + datum.strain_lf_con_li + datum.strain_hf_inc_li + datum.strain_lf_inc_li))/4\"\"\"\n",
    "\n",
    "            def create_contrast_plot(name):\n",
    "                return plot_by_cond.encode(y=alt.Y(\"difference:Q\", scale=alt.Scale(domain=(-y_max, y_max)))\n",
    "                    ).transform_pivot('testset', value=use_y, groupby=['epoch']\n",
    "                    ).transform_calculate(difference = contrasts[name]\n",
    "                    ).properties(title=name)\n",
    "\n",
    "            contrast_plots = alt.hconcat()\n",
    "            for c in contrasts.keys():\n",
    "                contrast_plots |= create_contrast_plot(c)\n",
    "\n",
    "\n",
    "            return((plot_by_cond | plot_average) & contrast_plots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = examine('boo')\n",
    "tmp.plot_op_strain()\n",
    "# Full looks familiar... good interaction, fast learning overall (will slow down later, using a fast learning rate to save time on testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = examine('op_half_stationary')\n",
    "tmp.plot_op_strain()\n",
    "# Learn slower... \n",
    "# HF_INC seems a tiny bit lower (more apparant in earlier ticks), maybe HF item has more CON O-P tokens?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = examine('op_half_rank_noclip')\n",
    "tmp.plot_op_strain()\n",
    "# HF_INC further decrease --> CON > F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = examine('op_half_rank_hc_30000')\n",
    "tmp.plot_op_strain()\n",
    "# Strong frequency effect\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half-pretrain (Chang 2019)\n",
    "\n",
    "half_pretrain = examine(\"half_pretrain\")\n",
    "half_pretrain.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chang 2019\n",
    "\n",
    "chang_pretrain = examine(\"chang_pretrain\")\n",
    "chang_pretrain.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full-pretrain \n",
    "full_pretrain = examine(\"full_pretrain\")\n",
    "full_pretrain.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m68"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
