{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Speed\n",
    "- GCP BQ support for batch run\n",
    "- Support for v4 model output dict format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Everything on tensorboard is convienient and fast af. but kind of difficult to customize\n",
    "- Need item level details down the line --> which BigQuery comes into play, but not so important until triangle model v4 is stable\n",
    "- currently I am doing things in between, store data locally per model, then aggregate mean level statistic if batch run (varying h-param or multi runs). \n",
    "- I already almost coded everything in bit and pieces, just need to have a better integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext lab_black\n",
    "import os\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import meta, data_wrangling, modeling, evaluate, testcase_plots\n",
    "from tqdm import tqdm\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(code_name):\n",
    "    cfg = meta.ModelConfig.from_json(\n",
    "        os.path.join(\"models\", code_name, \"model_config.json\")\n",
    "    )\n",
    "    model = modeling.MyModel(cfg)\n",
    "    checkpoint = cfg.path[\"weights_checkpoint_fstring\"].format(epoch=250)\n",
    "    model.load_weights(checkpoint)\n",
    "    data = data_wrangling.MyData()\n",
    "    test = evaluate.TestSet(cfg, model)\n",
    "    return cfg, model, data, test\n",
    "\n",
    "\n",
    "cfg, model, data, test = init(\"triangle_high_time_res_4M_fix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HS04 test cases 1: Overall performance\n",
    "![Overall performance](references/hs04_fig9.png)\n",
    "\n",
    "> The network was trained for 1.5 million word presentations. At the conclusion of training, the network produced the correct semantic representations for 97.3% of the items. For the other 2.7% of the words, it activated an average of 1.6 spurious features and failed to activate an average of 0.8 features. The model produced correct phonological representations for 99.2% of the words. On the remaining 0.8% of the words, it produced an average of 1.1 incorrect phonemes. Figure 9 depicts semantic and phonological accuracy over the course of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation procedure:\n",
    "1. Eval the 1000 training set items (randomly sampled) in each:\n",
    "- saved epoch\n",
    "- output timesteps\n",
    "2. Obtain both acc and sse during the evaluation\n",
    "- pho accuracy = all slots correct phoneme\n",
    "- sem accuracy = correct side of 0.5 (cosine doesn't make sense to me, since magnitude determines whether a node activate or not)\n",
    "3. Plot hs04 fig 9 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sample 1000 items from train set (tmp fix for OOM issue)\n",
    "# TODO eval on batch\n",
    "# reload(data_wrangling)\n",
    "# data = data_wrangling.MyData()\n",
    "# s1000 = data.df_train.sample(1000).index\n",
    "# s1000 = data.create_testset_from_train_idx(s1000)\n",
    "# data_wrangling.save_testset(testset=s1000, file='dataset/testsets/train_r1000.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test1(test):\n",
    "    df = test.eval(\"train_r1000\", \"triangle\")\n",
    "    mdf = testcase_plots.make_mean_df(df)\n",
    "    fig9 = testcase_plots.plot_hs04_fig9(mdf, cfg.n_timesteps)\n",
    "    fig9.save(os.path.join(test.cfg.path[\"plot_folder\"], \"test1.html\"))\n",
    "\n",
    "\n",
    "run_test1(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HS04 test cases 2: Freq x Cons in Taraban\n",
    "![Freq x Cons](references/hs04_fig10.png)\n",
    "\n",
    "> In the present model, the error computed at the end of processing was essentially zero for almost all items. This is because the model incorporates a phonological attractor, which tends to pull unit activities to their external values over time. In order to measure the difficulty the network had in reaching these states, we recorded the integral of the error over the course of processing the item from time step 4 to the final time step, 12 (the summation began with time step 4 because it takes four samples for information to flow to phonology from orthography via all routes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: SSE and ACC are the $integral$ of 4-12 ticks from this points onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Taraban to new testset package format (Run once)\n",
    "# reload(data_wrangling)\n",
    "# data = data_wrangling.MyData()\n",
    "# taraban = data.create_testset_from_words(data.df_taraban.word, data.df_taraban.cond)\n",
    "# data_wrangling.save_testset(taraban, 'dataset/testsets/taraban.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test2(test):\n",
    "    df = test.eval(\"taraban\", \"triangle\")\n",
    "    mdf = testcase_plots.make_cond_mean_df(df)\n",
    "\n",
    "    # TODO: Refractorized testset specific post-processing\n",
    "    mdf = mdf.loc[\n",
    "        mdf.cond.isin(\n",
    "            [\n",
    "                \"High-frequency exception\",\n",
    "                \"Regular control for High-frequency exception\",\n",
    "                \"Low-frequency exception\",\n",
    "                \"Regular control for Low-frequency exception\",\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    mdf[\"freq\"] = mdf.cond.apply(\n",
    "        lambda x: \"High\"\n",
    "        if x\n",
    "        in (\"High-frequency exception\", \"Regular control for High-frequency exception\")\n",
    "        else \"Low\"\n",
    "    )\n",
    "    mdf[\"reg\"] = mdf.cond.apply(\n",
    "        lambda x: \"Regular\" if x.startswith(\"Regular\") else \"Exception\"\n",
    "    )\n",
    "\n",
    "    fig10 = testcase_plots.plot_hs04_fig10(mdf, tick_after=12)\n",
    "    fig10.save(os.path.join(test.cfg.path[\"plot_folder\"], \"test2.html\"))\n",
    "\n",
    "\n",
    "run_test2(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HS04 test cases 3: Glushko Nonword\n",
    "\n",
    "> The model produced correct pronunciations for 93% of the nonwords derived from regular words and 84% of the ones derived from exception words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glushko = {}\n",
    "# glushko['item'] = data.df_glushko.word\n",
    "# glushko['cond'] = data.df_glushko.cond\n",
    "# glushko['ort'] = tf.constant(data.x_glushko, dtype=tf.float32)\n",
    "# glushko['phoneme'] = [data.pho_glushko[word] for word in glushko['item']]\n",
    "# glushko['pho'] = [data.y_glushko[word] for word in glushko['item']]\n",
    "# glushko['sem'] = None\n",
    "# data_wrangling.save_testset(testset=glushko, file='dataset/testsets/glushko.pkl.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test3(test):\n",
    "    df = test.eval(\"glushko\", \"triangle\")\n",
    "    mdf = testcase_plots.make_cond_mean_df(df)\n",
    "    test3 = testcase_plots.plot_conds(mdf, tick_after=12)\n",
    "    test3.save(os.path.join(test.cfg.path[\"plot_folder\"], \"test3.html\"))\n",
    "    # test3\n",
    "\n",
    "\n",
    "run_test3(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HS04 test cases 4: IMG\n",
    "![IMG](references/hs04_fig11.png)\n",
    "\n",
    "> We first performed a median split of all items in the training set along the frequency dimension. All words were then categorized as regular or exception. Finally, we used the imageability norms of the Medical Research Council Psycholinguistic Database (Coltheart, 1981) to code all items in the training set that were in the database and did a median split on these items, categorizing them as high or low in imageability. We then identified words that fit each of the categories formed by crossing frequency, regularity, and imageability. The smallest number of items, 28, was obtained for the low-frequency, low-imageability irregular cell in the design. For each of the other cells in the design we randomly chose 28 of the qualifying words. All words were presented to the model, and its output was analyzed as in the simulation of frequency by consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Making a new test set that loosely follow HS04\n",
    "# t = data.df_train[['word', 'wf']].copy()\n",
    "\n",
    "# # Source surprisal\n",
    "# df_suprisal = pd.read_csv('corpus/noam_surprisal.csv')\n",
    "# op = dict(zip(df_suprisal.word.str.lower(), df_suprisal[\"uncond.surprisal\"]))\n",
    "\n",
    "# # Source MRC imageability\n",
    "# df_img = pd.read_csv('corpus/MRC_img.csv', header=None, names=['word', 'img'])\n",
    "# img = dict(zip(df_img.word.str.lower(), df_img.img))\n",
    "\n",
    "# # Merge\n",
    "# t['img'] = t.word.apply(lambda x: img[x] if x in img.keys() else None)\n",
    "# t['op'] = t.word.apply(lambda x: op[x] if x in op.keys() else None)\n",
    "\n",
    "# t = t.dropna()\n",
    "\n",
    "# t['freq_gp'] = t.wf.apply(lambda x: 'hf' if x > t.wf.median() else 'lf')\n",
    "# t['op_gp'] = t.op.apply(lambda x: 'hs' if x > t.op.median() else 'ls')\n",
    "# t['img_gp'] = t.img.apply(lambda x: 'hi' if x > t.img.median() else 'li')\n",
    "# t['cond'] = t.freq_gp + '_' + t.op_gp + '_' + t.img_gp\n",
    "\n",
    "# print(f\"Word frequency median cutoff = {t.wf.median()}\")\n",
    "# print(f\"Imageability median cutoff = {t.img.median()}\")\n",
    "# print(f\"OP surprisal median cutoff = {t.op.median()}\")\n",
    "\n",
    "# print(\"Count number of word in each condition:\")\n",
    "# print(t.groupby(['cond']).count().word)\n",
    "\n",
    "# Packing\n",
    "# hs04_img = data.create_testset_from_words(words=t.word, conds=t.cond)\n",
    "# data_wrangling.save_testset(hs04_img, 'dataset/testsets/hs04_img.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test4(test):\n",
    "    df = test.eval(\"hs04_img\", \"triangle\")\n",
    "    mdf = testcase_plots.make_cond_mean_df(df)\n",
    "    mdf[\"fc\"] = mdf.cond.apply(lambda x: x[:5])\n",
    "    mdf[\"img\"] = mdf.cond.apply(lambda x: x[-2:])\n",
    "    test4 = testcase_plots.plot_hs04_fig11(mdf, tick_after=12)\n",
    "    test4.save(os.path.join(test.cfg.path[\"plot_folder\"], \"test4.html\"))\n",
    "\n",
    "\n",
    "run_test4(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HS04 test cases 5: Lesion\n",
    "![Lesion](references/hs04_fig14.png)\n",
    "\n",
    "> All words in the training set were presented to the trained reading model. To assess the time course of activity at a more fine grain, we ran the network for 4 units of whole time, as in training, but discretized over 48 samples, rather than 12, giving an integration constant of 0.083. The total input to target phonological units from the orth3phon path was summed at each sample. Similarly, the total input to target semantic units from orth3sem, from phon3sem, and from the semantic cleanup units was measured at each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loopy loop loop...\n",
    "We need to vectorized map functions at these levels, some might not be possible (variable size, ans)\n",
    "- model (1 for now)\n",
    "- epoch (39)\n",
    "- timestep (11)\n",
    "- testset x cond (taraban, glushko, hs04 img)\n",
    "- task (9, 5 main, 4 experimental)\n",
    "- output (2 in triangle, otherwise 1)\n",
    "- maybe multiple answers \n",
    "- metrics (acc, sse, cosine) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEM OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test5a(test):\n",
    "    df_intact = test.eval(\"train_r1000\", \"triangle\")\n",
    "    df_os_lesion = test.eval(\"train_r1000\", \"exp_ops\")\n",
    "    df_ops_lesion = test.eval(\"train_r1000\", \"ort_sem\")\n",
    "\n",
    "    df = pd.concat([df_intact, df_os_lesion, df_ops_lesion])\n",
    "    mdf = testcase_plots.make_mean_df(df)\n",
    "\n",
    "    test5a = testcase_plots.plot_hs04_fig14(mdf, output=\"sem\")\n",
    "    test5a.save(os.path.join(test.cfg.path[\"plot_folder\"], \"test5_sem.html\"))\n",
    "\n",
    "\n",
    "run_test5a(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test5b(test):\n",
    "    df_intact = test.eval(\"train_r1000\", \"triangle\")\n",
    "    df_op_lesion = test.eval(\"train_r1000\", \"exp_osp\")\n",
    "    df_osp_lesion = test.eval(\"train_r1000\", \"ort_pho\")\n",
    "\n",
    "    df = pd.concat([df_intact, df_op_lesion, df_osp_lesion])\n",
    "    mdf = testcase_plots.make_mean_df(df)\n",
    "    testcase_plots.print_unique(mdf)\n",
    "\n",
    "    test5b = testcase_plots.plot_hs04_fig14(mdf, output='pho')\n",
    "    test5b.save(os.path.join(test.cfg.path[\"plot_folder\"], \"test5_pho.html\"))\n",
    "\n",
    "\n",
    "run_test5b(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsets = ('pho_pho', 'pho_sem', 'sem_pho', 'sem_sem')\n",
    "y = map(lambda x: test.eval('train_r1000', x), testsets)\n",
    "pd.concat(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model level examine class (After eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class examine:\n",
    "    \n",
    "    def __init__(self, code_name, tf_root=\"/home/jupyter/tf\"):\n",
    "\n",
    "        try:\n",
    "            # Fast load from disk\n",
    "            csv_file = os.path.join(tf_root, 'models', code_name, 'eval', 'strain_mean_df.csv')\n",
    "            self.df = pd.read_csv(csv_file)\n",
    "        except:\n",
    "            # Eval from scratch\n",
    "            self.cfg = meta.ModelConfig.from_json(os.path.join(tf_root, 'models', code_name, 'model_config.json'))\n",
    "            self.data = data_wrangling.MyData()\n",
    "            self.model = modeling.HS04Model(self.cfg)\n",
    "            self.model.build()\n",
    "            self.test_strain = evaluate.EvalOral(self.cfg, self.model, self.data)\n",
    "            self.df = self.test_strain.strain_mean_df\n",
    "\n",
    "    def plot_op_strain(self):\n",
    "        df = self.df\n",
    "\n",
    "        @interact(\n",
    "            use_y=['acc','sse','conditional_sse'],\n",
    "            timetick=(1,12,1),\n",
    "            y_max=(1, 20, 1)\n",
    "            )\n",
    "        def plot(use_y='acc', timetick=12, y_max=1):\n",
    "            sdf = df.loc[(df.timetick==timetick)] \n",
    "            \n",
    "            # Plot by condition\n",
    "            plot_by_cond = alt.Chart(sdf).mark_line().encode(\n",
    "                x=alt.X('epoch:Q', scale=alt.Scale(domain=(0, 100), clamp=True)),\n",
    "                y=alt.Y(f\"{use_y}:Q\", scale=alt.Scale(domain=(0, y_max))),\n",
    "                color='cond:N'\n",
    "            )\n",
    "\n",
    "            # Contrasts\n",
    "            contrasts = {}\n",
    "            contrasts['contrast_frequency'] = \"\"\"(datum.HF_INC + datum.HF_CON - (datum.LF_INC + datum.LF_CON))/2\"\"\" \n",
    "            contrasts['contrast_consistency'] = \"\"\"(datum.LF_CON + datum.HF_CON - (datum.LF_INC + datum.HF_INC))/2\"\"\" \n",
    "\n",
    "            def create_contrast_plot(name):\n",
    "                return plot_by_cond.encode(y=alt.Y(\"difference:Q\", scale=alt.Scale(domain=(-y_max, y_max)))\n",
    "                    ).transform_pivot('cond', value=use_y, groupby=['epoch']\n",
    "                    ).transform_calculate(difference = contrasts[name]\n",
    "                    ).properties(title=name)\n",
    "\n",
    "            return plot_by_cond | create_contrast_plot('contrast_frequency') | create_contrast_plot('contrast_consistency')\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\" Create an interactive plot for strain \"\"\"\n",
    "        df = self.df\n",
    "\n",
    "        @interact(\n",
    "            use_y=['acc','sse','conditional_sse'],\n",
    "            task=['pho_sem', 'sem_pho', 'pho_pho', 'sem_sem'],\n",
    "            timetick=(1,12,1),\n",
    "            y_max=(1, 20, 1)\n",
    "            )\n",
    "        def plot(use_y='acc', timetick=12, task='pho_sem', y_max=1):\n",
    "            sdf = df.loc[(df.timetick==timetick) & (df.task==task)] \n",
    "            \n",
    "            # Plot by condition\n",
    "            plot_by_cond = alt.Chart(sdf).mark_line().encode(\n",
    "                x='epoch:Q',\n",
    "                y=alt.Y(f\"{use_y}:Q\", scale=alt.Scale(domain=(0, y_max))),\n",
    "                color='testset:N'\n",
    "            )\n",
    "\n",
    "            # Plot average\n",
    "            plot_average = plot_by_cond.encode(y=alt.Y(f\"mean({use_y}):Q\", scale=alt.Scale(domain=(0, y_max))), color='task')\n",
    "            plot_average += plot_average.mark_errorband()\n",
    "\n",
    "            # Plot contrasts\n",
    "            contrasts = {}\n",
    "            contrasts['contrast_frequency'] = \"\"\"(datum.strain_hf_con_hi + datum.strain_hf_con_li + datum.strain_hf_inc_hi + datum.strain_hf_inc_li - \n",
    "                (datum.strain_lf_con_hi + datum.strain_lf_con_li + datum.strain_lf_inc_hi + datum.strain_lf_inc_li))/4\"\"\"\n",
    "            contrasts['contrast_consistency'] = \"\"\"(datum.strain_hf_con_hi + datum.strain_hf_con_li + datum.strain_lf_con_hi + datum.strain_lf_con_li - \n",
    "                (datum.strain_hf_inc_hi + datum.strain_hf_inc_li + datum.strain_lf_inc_hi + datum.strain_lf_inc_li))/4\"\"\"\n",
    "            contrasts['contrast_imageability'] = \"\"\"(datum.strain_hf_con_hi + datum.strain_lf_con_hi + datum.strain_hf_inc_hi + datum.strain_lf_inc_hi - \n",
    "                (datum.strain_hf_con_li + datum.strain_lf_con_li + datum.strain_hf_inc_li + datum.strain_lf_inc_li))/4\"\"\"\n",
    "\n",
    "            def create_contrast_plot(name):\n",
    "                return plot_by_cond.encode(y=alt.Y(\"difference:Q\", scale=alt.Scale(domain=(-y_max, y_max)))\n",
    "                    ).transform_pivot('testset', value=use_y, groupby=['epoch']\n",
    "                    ).transform_calculate(difference = contrasts[name]\n",
    "                    ).properties(title=name)\n",
    "\n",
    "            contrast_plots = alt.hconcat()\n",
    "            for c in contrasts.keys():\n",
    "                contrast_plots |= create_contrast_plot(c)\n",
    "\n",
    "\n",
    "            return((plot_by_cond | plot_average) & contrast_plots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = examine('boo')\n",
    "tmp.plot_op_strain()\n",
    "# Full looks familiar... good interaction, fast learning overall (will slow down later, using a fast learning rate to save time on testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = examine('op_half_stationary')\n",
    "tmp.plot_op_strain()\n",
    "# Learn slower... \n",
    "# HF_INC seems a tiny bit lower (more apparant in earlier ticks), maybe HF item has more CON O-P tokens?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = examine('op_half_rank_noclip')\n",
    "tmp.plot_op_strain()\n",
    "# HF_INC further decrease --> CON > F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = examine('op_half_rank_hc_30000')\n",
    "tmp.plot_op_strain()\n",
    "# Strong frequency effect\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half-pretrain (Chang 2019)\n",
    "\n",
    "half_pretrain = examine(\"half_pretrain\")\n",
    "half_pretrain.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chang 2019\n",
    "\n",
    "chang_pretrain = examine(\"chang_pretrain\")\n",
    "chang_pretrain.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full-pretrain \n",
    "full_pretrain = examine(\"full_pretrain\")\n",
    "full_pretrain.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
