{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import os\n",
    "import altair as alt\n",
    "from ipywidgets import interact\n",
    "import pandas as pd\n",
    "import meta, data_wrangling, modeling, metrics, evaluate\n",
    "\n",
    "# meta.limit_gpu_memory_use(7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_name = \"full_pretrain\"\n",
    "tf_root = \"/home/jupyter/tf\"\n",
    "cfg = meta.ModelConfig.from_json(os.path.join(tf_root, 'models', code_name, 'model_config.json'))\n",
    "data = data_wrangling.MyData()\n",
    "model = modeling.HS04Model(cfg)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = evaluate.EvalOral(cfg, model, data)\n",
    "test.eval(\"strain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half-pretrain (Chang 2019)\n",
    "\n",
    "df2 = test.strain_mean_df.copy()\n",
    "\n",
    "def create_plot(df):\n",
    "    @interact(\n",
    "        use_y=['acc','sse','conditional_sse'],\n",
    "        task=['pho_sem', 'sem_pho', 'pho_pho', 'sem_sem'],\n",
    "        timetick=(1,12,1),\n",
    "        y_max=(1, 20, 1)\n",
    "        )\n",
    "    def plot(use_y='acc', timetick=12, task='pho_sem', y_max=1):\n",
    "        sdf = df.loc[(df.timetick==timetick) & (df.task==task)] \n",
    "        \n",
    "        # Plot by condition\n",
    "        plot_by_cond = alt.Chart(sdf).mark_line().encode(\n",
    "            x='epoch:Q',\n",
    "            y=alt.Y(f\"{use_y}:Q\", scale=alt.Scale(domain=(0, y_max))),\n",
    "            color='testset:N'\n",
    "        )\n",
    "\n",
    "        # Plot average\n",
    "        plot_average = plot_by_cond.encode(y=alt.Y(f\"mean({use_y}):Q\", scale=alt.Scale(domain=(0, y_max))), color='task')\n",
    "        plot_average += plot_average.mark_errorband()\n",
    "\n",
    "        # Plot contrasts\n",
    "        contrasts = {}\n",
    "        contrasts['contrast_frequency'] = \"\"\"(datum.strain_hf_con_hi + datum.strain_hf_con_li + datum.strain_hf_inc_hi + datum.strain_hf_inc_li - \n",
    "            (datum.strain_lf_con_hi + datum.strain_lf_con_li + datum.strain_lf_inc_hi + datum.strain_lf_inc_li))/4\"\"\"\n",
    "        contrasts['contrast_consistency'] = \"\"\"(datum.strain_hf_con_hi + datum.strain_hf_con_li + datum.strain_lf_con_hi + datum.strain_lf_con_li - \n",
    "            (datum.strain_hf_inc_hi + datum.strain_hf_inc_li + datum.strain_lf_inc_hi + datum.strain_lf_inc_li))/4\"\"\"\n",
    "        contrasts['contrast_imageability'] = \"\"\"(datum.strain_hf_con_hi + datum.strain_lf_con_hi + datum.strain_hf_inc_hi + datum.strain_lf_inc_hi - \n",
    "            (datum.strain_hf_con_li + datum.strain_lf_con_li + datum.strain_hf_inc_li + datum.strain_lf_inc_li))/4\"\"\"\n",
    "\n",
    "        def create_contrast_plot(name):\n",
    "            return plot_by_cond.encode(y=alt.Y(\"difference:Q\", scale=alt.Scale(domain=(-y_max, y_max)))\n",
    "                ).transform_pivot('testset', value=use_y, groupby=['epoch']\n",
    "                ).transform_calculate(difference = contrasts[name]\n",
    "                ).properties(title=name)\n",
    "\n",
    "        contrast_plots = alt.hconcat()\n",
    "        for c in contrasts.keys():\n",
    "            contrast_plots |= create_contrast_plot(c)\n",
    "\n",
    "\n",
    "        return((plot_by_cond | plot_average) & contrast_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with full corpus\n",
    "create_plot(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained with half corpus\n",
    "create_plot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m68"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
