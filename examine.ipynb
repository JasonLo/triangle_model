{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- speed\n",
    "- GCP BQ support\n",
    "- support for v4 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Everything on tensorboard is convienient and fast af. \n",
    "- Need item level details down the line --> which BigQuery comes into play, but not so important until triangle model v4 is stable\n",
    "- currently I am doing things in between, store data locally per model, then aggregate mean level statistic if batch run (varying h-param or multi runs). \n",
    "- I already almost coded everything in bit and pieces, just need to have a better integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext lab_black\n",
    "import os\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import meta, data_wrangling, modeling, metrics, evaluate, testcase_plots\n",
    "from tqdm import tqdm\n",
    "from importlib import reload\n",
    "reload(evaluate)\n",
    "reload(data_wrangling)\n",
    "reload(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init(code_name):\n",
    "    cfg = meta.ModelConfig.from_json(os.path.join(\"models\", code_name, \"model_config.json\"))\n",
    "    model = modeling.MyModel(cfg)\n",
    "    checkpoint = cfg.path[\"weights_checkpoint_fstring\"].format(epoch=250)\n",
    "    model.load_weights(checkpoint)\n",
    "    data = data_wrangling.MyData()\n",
    "    return cfg, model, data\n",
    "\n",
    "\n",
    "cfg, model, data = init(\"triangle_with_strain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HS04 test cases 1: Overall performance\n",
    "![Overall performance](references/hs04_fig9.png)\n",
    "\n",
    "> The network was trained for 1.5 million word presentations. At the conclusion of training, the network produced the correct semantic representations for 97.3% of the items. For the other 2.7% of the words, it activated an average of 1.6 spurious features and failed to activate an average of 0.8 features. The model produced correct phonological representations for 99.2% of the words. On the remaining 0.8% of the words, it produced an average of 1.1 incorrect phonemes. Figure 9 depicts semantic and phonological accuracy over the course of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation procedure:\n",
    "1. Eval the entire training set in each:\n",
    "- saved epoch\n",
    "- output timesteps\n",
    "2. Obtain both acc and sse during the evaluation\n",
    "- pho accuracy = all slots correct phoneme\n",
    "- sem accuracy = correct side of 0.5 (cosine doesn't make sense to me, since magnitude determines whether a node activate or not)\n",
    "3. Plot hs04 fig 9 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(evaluate)\n",
    "reload(testcase_plots)\n",
    "x = evaluate.TestSet(cfg, model)\n",
    "df = x.eval('train_r1000', 'triangle')\n",
    "mdf = testcase_plots.make_mean_df(df)\n",
    "fig9 = testcase_plots.plot_hs04_fig9(mdf)\n",
    "fig9.save(os.path.join(cfg.path['plot_folder'], 'fig9.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HS04 test cases 2: Freq x Cons in Taraban\n",
    "![Freq x Cons](references/hs04_fig10.png)\n",
    "\n",
    "> In the present model, the error computed at the end of processing was essentially zero for almost all items. This is because the model incorporates a phonological attractor, which tends to pull unit activities to their external values over time. In order to measure the difficulty the network had in reaching these states, we recorded the integral of the error over the course of processing the item from time step 4 to the final time step, 12 (the summation began with time step 4 because it takes four samples for information to flow to phonology from orthography via all routes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Taraban to new testset package format (Run once)\n",
    "# reload(data_wrangling)\n",
    "# data = data_wrangling.MyData()\n",
    "# taraban = data.create_testset_from_words(data.df_taraban.word, data.df_taraban.cond)\n",
    "# data_wrangling.save_testset(taraban, 'dataset/testsets/taraban.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(testcase_plots)\n",
    "reload(evaluate)\n",
    "df = x.eval('taraban', 'triangle')\n",
    "mdf = testcase_plots.make_cond_mean_df(df)\n",
    "\n",
    "# TODO: Refractorized testset specific post-processing\n",
    "mdf = mdf.loc[mdf.cond.isin(['High-frequency exception', 'Regular control for High-frequency exception',\n",
    "       'Low-frequency exception', 'Regular control for Low-frequency exception'])]\n",
    "mdf['freq'] = mdf.cond.apply(lambda x: 'High' if x in ('High-frequency exception', 'Regular control for High-frequency exception') else 'Low')\n",
    "mdf['reg'] = mdf.cond.apply(lambda x: 'Regular' if x.startswith('Regular') else 'Exception')\n",
    "\n",
    "fig10 = testcase_plots.plot_hs04_fig10(mdf)\n",
    "fig10.save(os.path.join(cfg.path['plot_folder'], 'fig10.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mdf['freq'] = mdf.cond.apply(lambda x: 'high' if x.start_with('High-'))\n",
    "mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taraban = data_wrangling.load_testset('dataset/testsets/grain.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grain = data_wrangling.load_testset('dataset/testsets/grain.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_names = ('ort', 'pho_large_grain', 'pho_small_grain', 'sem', 'pho')\n",
    "for x in rep_names:\n",
    "    grain[x] = tf.cast(grain[x], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wrangling.save_testset(testset=grain, file='dataset/testsets/grain.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sample 1000 items from train set (tmp fix for OOM issue)\n",
    "# TODO eval on batch\n",
    "s1000 = data.df_train.sample(1000).index\n",
    "s1000 = data.create_testset_from_train_idx(s1000)\n",
    "data_wrangling.save_testset(testset=s1000, file='dataset/testsets/train_r1000.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_active_task(\"triangle\")\n",
    "y_pred = model([data.testsets[\"strain\"][\"ort\"]] * cfg.n_timesteps)\n",
    "y_true = {out: data.testsets[\"strain\"][out] for out in ('pho', 'sem')}\n",
    "\n",
    "pho_acc = metrics.PhoAccuracy()\n",
    "pho_sse = metrics.SumSquaredError()\n",
    "sem_acc = metrics.RightSideAccuracy()\n",
    "sem_sse = metrics.SumSquaredError()\n",
    "\n",
    "pho_acc.update_state(y_true['pho'], y_pred['pho'][-1])\n",
    "pho_sse.update_state(y_true['pho'], y_pred['pho'][-1])\n",
    "sem_acc.update_state(y_true['sem'], y_pred['sem'][-1])\n",
    "sem_sse.update_state(y_true['sem'], y_pred['sem'][-1])\n",
    "print(f\"pho accuracy:{pho_acc.out.numpy():04f}, sem accuracy:{sem_acc.out.numpy():04f}\")\n",
    "print(f\"pho sse:{pho_sse.out.numpy():04f}, sem sse:{sem_sse.out.numpy():04f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto type testset implemetation manually\n",
    "We need a vectorized map at these dimensions:\n",
    "- model (1 for now)\n",
    "- epoch (39)\n",
    "- timestep (11)\n",
    "- testset x cond (taraban, glushko, hs04 img)\n",
    "- task (9, 5 main, 4 experimental)\n",
    "- output (2 in triangle, otherwise 1)\n",
    "- metrics (acc, sse, cosine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_active_task(\"ort_sem\")\n",
    "y_pred = model([data.testsets[\"strain\"][\"ort\"]] * cfg.n_timesteps)\n",
    "y_true = data.testsets[\"strain\"][\"sem\"]\n",
    "sem_acc.update_state(y_true, y_pred['sem'][-1])\n",
    "sem_sse.update_state(y_true, y_pred['sem'][-1])\n",
    "print(f\"sem accuracy:{sem_acc.out.numpy():04f}, sse:{sem_sse.out.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_active_task(\"exp_ops\")\n",
    "y_pred = model([data.testsets[\"strain\"][\"ort\"]] * cfg.n_timesteps)\n",
    "y_true = data.testsets[\"strain\"][\"sem\"]\n",
    "sem_acc.update_state(y_true, y_pred['sem'][-1])\n",
    "sem_sse.update_state(y_true, y_pred['sem'][-1])\n",
    "print(f\"sem accuracy:{sem_acc.out.numpy():04f}, sse:{sem_sse.out.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_active_task(\"ort_pho\")\n",
    "y_pred = model([data.testsets[\"strain\"][\"ort\"]] * cfg.n_timesteps)\n",
    "y_true = data.testsets[\"strain\"][\"pho\"]\n",
    "pho_acc.update_state(y_true, y_pred['pho'][-1])\n",
    "pho_sse.update_state(y_true, y_pred['pho'][-1])\n",
    "print(f\"pho accuracy:{pho_acc.out.numpy():04f}, pho sse:{pho_sse.out.numpy():04f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_active_task(\"exp_osp\")\n",
    "y_pred = model([data.testsets[\"strain\"][\"ort\"]] * cfg.n_timesteps)\n",
    "y_true = data.testsets[\"strain\"][\"pho\"]\n",
    "pho_acc.update_state(y_true, y_pred['pho'][-1])\n",
    "pho_sse.update_state(y_true, y_pred['pho'][-1])\n",
    "print(f\"pho accuracy:{pho_acc.out.numpy():04f}, pho sse:{pho_sse.out.numpy():04f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- timestep (11)\n",
    "- testset x cond (taraban, glushko, hs04 img)\n",
    "- task (9, 5 main, 4 experimental)\n",
    "- output (2 in triangle, otherwise 1)\n",
    "- metrics (acc, sse, cosine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = TestSet(cfg, model)\n",
    "x.eval('strain', 'ort_pho')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model level examine class (After eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class examine:\n",
    "    \n",
    "    def __init__(self, code_name, tf_root=\"/home/jupyter/tf\"):\n",
    "\n",
    "        try:\n",
    "            # Fast load from disk\n",
    "            csv_file = os.path.join(tf_root, 'models', code_name, 'eval', 'strain_mean_df.csv')\n",
    "            self.df = pd.read_csv(csv_file)\n",
    "        except:\n",
    "            # Eval from scratch\n",
    "            self.cfg = meta.ModelConfig.from_json(os.path.join(tf_root, 'models', code_name, 'model_config.json'))\n",
    "            self.data = data_wrangling.MyData()\n",
    "            self.model = modeling.HS04Model(self.cfg)\n",
    "            self.model.build()\n",
    "            self.test_strain = evaluate.EvalOral(self.cfg, self.model, self.data)\n",
    "            self.df = self.test_strain.strain_mean_df\n",
    "\n",
    "    def plot_op_strain(self):\n",
    "        df = self.df\n",
    "\n",
    "        @interact(\n",
    "            use_y=['acc','sse','conditional_sse'],\n",
    "            timetick=(1,12,1),\n",
    "            y_max=(1, 20, 1)\n",
    "            )\n",
    "        def plot(use_y='acc', timetick=12, y_max=1):\n",
    "            sdf = df.loc[(df.timetick==timetick)] \n",
    "            \n",
    "            # Plot by condition\n",
    "            plot_by_cond = alt.Chart(sdf).mark_line().encode(\n",
    "                x=alt.X('epoch:Q', scale=alt.Scale(domain=(0, 100), clamp=True)),\n",
    "                y=alt.Y(f\"{use_y}:Q\", scale=alt.Scale(domain=(0, y_max))),\n",
    "                color='cond:N'\n",
    "            )\n",
    "\n",
    "            # Contrasts\n",
    "            contrasts = {}\n",
    "            contrasts['contrast_frequency'] = \"\"\"(datum.HF_INC + datum.HF_CON - (datum.LF_INC + datum.LF_CON))/2\"\"\" \n",
    "            contrasts['contrast_consistency'] = \"\"\"(datum.LF_CON + datum.HF_CON - (datum.LF_INC + datum.HF_INC))/2\"\"\" \n",
    "\n",
    "            def create_contrast_plot(name):\n",
    "                return plot_by_cond.encode(y=alt.Y(\"difference:Q\", scale=alt.Scale(domain=(-y_max, y_max)))\n",
    "                    ).transform_pivot('cond', value=use_y, groupby=['epoch']\n",
    "                    ).transform_calculate(difference = contrasts[name]\n",
    "                    ).properties(title=name)\n",
    "\n",
    "            return plot_by_cond | create_contrast_plot('contrast_frequency') | create_contrast_plot('contrast_consistency')\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\" Create an interactive plot for strain \"\"\"\n",
    "        df = self.df\n",
    "\n",
    "        @interact(\n",
    "            use_y=['acc','sse','conditional_sse'],\n",
    "            task=['pho_sem', 'sem_pho', 'pho_pho', 'sem_sem'],\n",
    "            timetick=(1,12,1),\n",
    "            y_max=(1, 20, 1)\n",
    "            )\n",
    "        def plot(use_y='acc', timetick=12, task='pho_sem', y_max=1):\n",
    "            sdf = df.loc[(df.timetick==timetick) & (df.task==task)] \n",
    "            \n",
    "            # Plot by condition\n",
    "            plot_by_cond = alt.Chart(sdf).mark_line().encode(\n",
    "                x='epoch:Q',\n",
    "                y=alt.Y(f\"{use_y}:Q\", scale=alt.Scale(domain=(0, y_max))),\n",
    "                color='testset:N'\n",
    "            )\n",
    "\n",
    "            # Plot average\n",
    "            plot_average = plot_by_cond.encode(y=alt.Y(f\"mean({use_y}):Q\", scale=alt.Scale(domain=(0, y_max))), color='task')\n",
    "            plot_average += plot_average.mark_errorband()\n",
    "\n",
    "            # Plot contrasts\n",
    "            contrasts = {}\n",
    "            contrasts['contrast_frequency'] = \"\"\"(datum.strain_hf_con_hi + datum.strain_hf_con_li + datum.strain_hf_inc_hi + datum.strain_hf_inc_li - \n",
    "                (datum.strain_lf_con_hi + datum.strain_lf_con_li + datum.strain_lf_inc_hi + datum.strain_lf_inc_li))/4\"\"\"\n",
    "            contrasts['contrast_consistency'] = \"\"\"(datum.strain_hf_con_hi + datum.strain_hf_con_li + datum.strain_lf_con_hi + datum.strain_lf_con_li - \n",
    "                (datum.strain_hf_inc_hi + datum.strain_hf_inc_li + datum.strain_lf_inc_hi + datum.strain_lf_inc_li))/4\"\"\"\n",
    "            contrasts['contrast_imageability'] = \"\"\"(datum.strain_hf_con_hi + datum.strain_lf_con_hi + datum.strain_hf_inc_hi + datum.strain_lf_inc_hi - \n",
    "                (datum.strain_hf_con_li + datum.strain_lf_con_li + datum.strain_hf_inc_li + datum.strain_lf_inc_li))/4\"\"\"\n",
    "\n",
    "            def create_contrast_plot(name):\n",
    "                return plot_by_cond.encode(y=alt.Y(\"difference:Q\", scale=alt.Scale(domain=(-y_max, y_max)))\n",
    "                    ).transform_pivot('testset', value=use_y, groupby=['epoch']\n",
    "                    ).transform_calculate(difference = contrasts[name]\n",
    "                    ).properties(title=name)\n",
    "\n",
    "            contrast_plots = alt.hconcat()\n",
    "            for c in contrasts.keys():\n",
    "                contrast_plots |= create_contrast_plot(c)\n",
    "\n",
    "\n",
    "            return((plot_by_cond | plot_average) & contrast_plots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = examine('boo')\n",
    "tmp.plot_op_strain()\n",
    "# Full looks familiar... good interaction, fast learning overall (will slow down later, using a fast learning rate to save time on testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = examine('op_half_stationary')\n",
    "tmp.plot_op_strain()\n",
    "# Learn slower... \n",
    "# HF_INC seems a tiny bit lower (more apparant in earlier ticks), maybe HF item has more CON O-P tokens?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = examine('op_half_rank_noclip')\n",
    "tmp.plot_op_strain()\n",
    "# HF_INC further decrease --> CON > F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = examine('op_half_rank_hc_30000')\n",
    "tmp.plot_op_strain()\n",
    "# Strong frequency effect\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half-pretrain (Chang 2019)\n",
    "\n",
    "half_pretrain = examine(\"half_pretrain\")\n",
    "half_pretrain.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chang 2019\n",
    "\n",
    "chang_pretrain = examine(\"chang_pretrain\")\n",
    "chang_pretrain.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full-pretrain \n",
    "full_pretrain = examine(\"full_pretrain\")\n",
    "full_pretrain.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m68"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
