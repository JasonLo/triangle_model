{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine a single word  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import altair as alt\n",
    "from tqdm import tqdm\n",
    "import troubleshooting \n",
    "import data_wrangling\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intactive input/act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_name = 'triangle_hope1'\n",
    "testset_name = 'train_r100'\n",
    "d = troubleshooting.Diagnosis(code_name)\n",
    "d.eval(testset_name, task='triangle', epoch=200)\n",
    "\n",
    "@interact(\n",
    "    sel_word=d.testset_package['item'], \n",
    "    layer=['pho', 'sem'], \n",
    "    task=['triangle', 'ort_pho', 'exp_osp', 'ort_sem', 'exp_ops'], \n",
    "    epoch=(10, d.cfg.total_number_of_epoch + 1, d.cfg.save_freq)\n",
    "    )\n",
    "def interactive_plot(sel_word, layer, task, epoch):\n",
    "    d = troubleshooting.Diagnosis(code_name)\n",
    "    d.eval(testset_name, task=task, epoch=epoch)\n",
    "    d.set_target_word(sel_word)\n",
    "    print(f\"Output phoneme over timeticks: {d.list_output_phoneme}\")\n",
    "    return d.plot_one_layer(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare bias init -5 vs. 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"triangle_hope_fix\"\n",
    "b = \"triangle_batch1\"\n",
    "\n",
    "def compare_plot(sel_word:str, layer:str, target_nodes:int, task:str, epoch:int) -> alt.Chart:\n",
    "    d1 = troubleshooting.Diagnosis(a)\n",
    "    d1.eval(testset_name, task=task, epoch=epoch)\n",
    "    d1.set_target_word(sel_word)\n",
    "\n",
    "    d2 = troubleshooting.Diagnosis(b)\n",
    "    d2.eval(testset_name, task=task, epoch=epoch)\n",
    "    d2.set_target_word(sel_word)\n",
    "    # print(f\"Output phoneme over timeticks: {d.list_output_phoneme}\")\n",
    "    plot1 = d1.plot_one_layer_by_target(layer, target_act=target_nodes).properties(title=d1.code_name)\n",
    "    plot2 = d2.plot_one_layer_by_target(layer, target_act=target_nodes).properties(title=d2.code_name)\n",
    "\n",
    "    return plot1 & plot2\n",
    "\n",
    "testset_name = 'train_r100'\n",
    "ts = data_wrangling.load_testset(\n",
    "            os.path.join(\"dataset\", \"testsets\", f\"{testset_name}.pkl.gz\")\n",
    "        )\n",
    "\n",
    "# Generate all plots to files\n",
    "for word in tqdm(ts['item']):\n",
    "    for layer in ['pho', 'sem']:\n",
    "        for target_node in [0, 1]:\n",
    "            clear_output(wait=True)\n",
    "            output_path = os.path.join('issues', 'compare_batchsize_1', f\"{layer}_{word}_node{target_node}_compare.html\")\n",
    "            compare_plot(word, layer, target_node, task='triangle', epoch=780).save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tick 1 checking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_word = 'wasps'\n",
    "d.set_target_word(sel_word)\n",
    "print(f\"All outputs: {d.list_outputs}\\n\")\n",
    "print(f\"All weights: {d.list_weights}\")\n",
    "\n",
    "# Get weights and biases\n",
    "sc = d.get_weight(\"w_sc\")\n",
    "bias = d.get_weight(\"bias_css\")\n",
    "\n",
    "# Manually caluclate tick 1 TAI input \n",
    "sem_init = 0.5 * np.ones(sc.shape[0])\n",
    "manual_css_1 = (np.matmul(sem_init, sc) + bias)/3\n",
    "\n",
    "# Compare against the output of the model at tick 1\n",
    "input_css = d.get_output('input_css')\n",
    "print(f\"From model: \\n {input_css[1]} \\n \\n Checking: \\n {manual_css_1}\")  \n",
    "np.allclose(input_css[1], manual_css_1, atol=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "def act_to_df(activation: np.ndarray) -> pd.DataFrame:\n",
    "    \"\"\"Convert an activation numpy 2d array into a labeled pandas dataframe \"\"\"\n",
    "    df = pd.DataFrame(activation)\n",
    "    df['tick'] = df.index\n",
    "    return df.melt(id_vars=['tick'], var_name='node', value_name='activation')\n",
    "\n",
    "def plot_activation(activation_df: pd.DataFrame) -> alt.Chart:\n",
    "    plot = alt.Chart(activation_df).mark_line().encode(\n",
    "        x='tick:O',\n",
    "        y=alt.Y('activation:Q', scale=alt.Scale(domain=(0,1))),\n",
    "        color='node:N',\n",
    "    )\n",
    "    return plot\n",
    "\n",
    "df = act_to_df(cs)\n",
    "plot_activation(df.loc[df.node==4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_hos_hs = d.get_weight(name=\"w_hos_hs\")\n",
    "w_ss = d.get_weight(name=\"w_ss\")\n",
    "bias_s = d.get_weight(name=\"bias_s\")\n",
    "w_cs = d.get_weight(name=\"w_cs\")\n",
    "\n",
    "data = {\n",
    "    'ss1': 0.5 * np.sum(w_ss, axis=0), # Lazy matmul. \n",
    "    'cs1': 0.5 * np.sum(w_cs, axis=0),\n",
    "    'os1': 0.5 * np.sum(w_hos_hs, axis=0),\n",
    "    'bias1': bias_s\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,6))\n",
    "for i, k in enumerate(data.keys()):\n",
    "    df[k].plot.density(ax=ax[i], title=k)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tick 1 input density at PHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_hop_hp = d.get_weight(name=\"w_hop_hp\")\n",
    "w_pp = d.get_weight(name=\"w_pp\")\n",
    "bias_p = d.get_weight(name=\"bias_p\")\n",
    "w_cp = d.get_weight(name=\"w_cp\")\n",
    "\n",
    "data = {\n",
    "    'pp1': 0.5 * np.sum(w_pp, axis=0), # Lazy matmul. \n",
    "    'cp1': 0.5 * np.sum(w_cp, axis=0),\n",
    "    'op1': 0.5 * np.sum(w_hop_hp, axis=0),\n",
    "    'bias1': bias_p\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,6))\n",
    "for i, k in enumerate(data.keys()):\n",
    "    df[k].plot.density(ax=ax[i], title=k)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
