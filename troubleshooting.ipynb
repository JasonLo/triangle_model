{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine a single word  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import meta, data_wrangling, evaluate, troubleshooting\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modeling_useful_init as modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word options in 100 random\n",
    " - pans, loose, youth, finds, strifes\n",
    " - all others: ['wasps', 'taut', 'lived', 'close', 'side', 'mope', 'loose', 'hocks', 'join', 'shared', 'wort', 'her', 'thanks', 'lee', 'whig', 'lot', 'tie', 'walls', 'fronts', 'plops', 'kill', 'gauze', 'grief', 'block', 'grind', 'homes', 'keep', 'plume', 'fart', 'lien', 'rags', 'flanks', 'wastes', 'true', 'praised', 'cram', 'shed', 'dent', 'breadths', 'pale', 'jeeps', 'peep', 'trades', 'chin', 'read', 'rungs', 'lolled', 'strifes', 'picks', 'braille', 'wailed', 'when', 'thin', 'fit', 'slut', 'cabs', 'grave', 'lights', 'coos', 'pans', 'gripe', 'whip', 'hug', 'squads', 'chip', 'lurked', 'filths', 'theme', 'craze', 'youth', 'watt', 'squid', 'tsars', 'soups', 'string', 'moose', 'zinc', 'class', 'snips', 'sick', 'cleave', 'shone', 'vow', 'wig', 'quakes', 'scram', 'kale', 'mag', 'yawn', 'sup', 'chow', 'pinged', 'seal', 'staffs', 'wage', 'crone', 'finds', 'moats', 'gob', 'feuds']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_name = 'OP'\n",
    "# code_name = 'Refrac3_local'\n",
    "# code_name = 'Refrac3_after6'\n",
    "# code_name = 'Refrac3_after6_nodc'\n",
    "# code_name = 'Refrac3_after6_init_act0'\n",
    "code_name = 'Refrac3_after6_informative'\n",
    "selected_word = 'pans'\n",
    "epoch = 300\n",
    "testset_name = 'train_r100'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Diagnosis class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(troubleshooting)\n",
    "d = troubleshooting.Diagnosis(code_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_wrangling.MyData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = modeling.MyModel(d.cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.build()\n",
    "m.set_active_task('triangle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m([data.np_representations['ort'][:100,:]] * 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intact SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem1 = d.subset_df('sem', 1)\n",
    "plotter = troubleshooting.Plots(df_sem1)\n",
    "plotter.activation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stonge kick from bias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_df = df_sem1.loc[(df_sem1.variable=='bias') & (df_sem1.target_act==1)]\n",
    "\n",
    "alt.Chart(bias_df).mark_bar().encode(\n",
    "    y='mean(value)',\n",
    "    x='unit:N',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.eval(testset_name, task='triangle', epoch=epoch)\n",
    "d.set_target_word(selected_word)\n",
    "intact_sem = d.plot_one_layer('sem')\n",
    "intact_sem.save(os.path.join(d.cfg.plot_folder, f\"intact_sem_{selected_word}.html\"))\n",
    "intact_sem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OS SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.eval(testset_name, task='ort_sem', epoch=epoch)\n",
    "d.set_target_word(selected_word)\n",
    "OS_sem = d.plot_one_layer('sem')\n",
    "OS_sem.save(os.path.join(d.cfg.plot_folder, f\"OS_sem_{selected_word}.html\"))\n",
    "OS_sem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPS SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.eval(testset_name, task='exp_ops', epoch=epoch)\n",
    "d.set_target_word(selected_word)\n",
    "OPS_sem = d.plot_one_layer('sem')\n",
    "OPS_sem.save(os.path.join(d.cfg.plot_folder, f\"OPS_sem_{selected_word}.html\"))\n",
    "OPS_sem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intact PHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.eval(testset_name, task='triangle', epoch=epoch)\n",
    "d.set_target_word(selected_word)\n",
    "print(f\"Output phoneme over timeticks: {d.list_output_phoneme}\")\n",
    "intact_pho = d.plot_one_layer('pho')\n",
    "intact_pho.save(os.path.join(d.cfg.plot_folder, f\"intact_pho_{selected_word}.html\"))\n",
    "intact_pho\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OP PHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.sec\n",
    "troubleshooting.Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.eval(testset_name, task='ort_pho', epoch=epoch)\n",
    "d.set_target_word(selected_word)\n",
    "print(f\"Output phoneme over timeticks: {d.list_output_phoneme}\")\n",
    "OP_pho = d.plot_one_layer('pho')\n",
    "OP_pho.save(os.path.join(d.cfg.plot_folder, f\"OP_pho_{selected_word}.html\"))\n",
    "OP_pho\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSP PHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.eval(testset_name, task='exp_osp', epoch=epoch)\n",
    "d.set_target_word(selected_word)\n",
    "print(f\"Output phoneme over timeticks: {d.list_output_phoneme}\")\n",
    "OSP_pho = d.plot_one_layer('pho')\n",
    "OSP_pho.save(os.path.join(d.cfg.plot_folder, f\"OSP_pho_{selected_word}.html\"))\n",
    "OSP_pho\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intactive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(troubleshooting)\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "\n",
    "@interact(\n",
    "    sel_word=d.testset_package['item'], \n",
    "    layer=['pho', 'sem'], \n",
    "    task=['triangle', 'ort_pho', 'exp_osp', 'ort_sem', 'exp_ops'], \n",
    "    epoch=(10, d.cfg.total_number_of_epoch+1, d.cfg.save_freq)\n",
    "    )\n",
    "def interactive_plot(sel_word, layer, task, epoch):\n",
    "    d = troubleshooting.Diagnosis(code_name)\n",
    "    d.eval(testset_name, task='triangle', epoch=epoch)\n",
    "    d.set_target_word(sel_word)\n",
    "    print(f\"Output phoneme over timeticks: {d.list_output_phoneme}\")\n",
    "    return d.plot_one_layer('pho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(troubleshooting)\n",
    "d = troubleshooting.Diagnosis(code_name)\n",
    "d.eval(testset_name, task='triangle', epoch=epoch)\n",
    "\n",
    "def plot_raw_input_by_target(word:str) -> alt.Chart:\n",
    "    d.set_target_word(word)\n",
    "    print(f\"Output phoneme over timeticks: {d.list_output_phoneme}\")\n",
    "\n",
    "    df = d.subset_df(layer='pho', target_act=1)\n",
    "    plotter = troubleshooting.Plots(df)\n",
    "    raw_input_1 = plotter.raw_inputs()\n",
    "\n",
    "    df = d.subset_df(layer='pho', target_act=0)\n",
    "    plotter = troubleshooting.Plots(df)\n",
    "    raw_input_0 = plotter.raw_inputs()\n",
    "\n",
    "    return (raw_input_1 | raw_input_0).resolve_scale(y=\"shared\").properties(title=word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_words = random.sample(d.testset_package['item'], 10)\n",
    "print(ten_words)\n",
    "\n",
    "ten_plots = alt.hconcat()\n",
    "for w in ten_words:\n",
    "    ten_plots &= plot_raw_input_by_target(w)\n",
    "\n",
    "ten_plots.resolve_scale(y=\"shared\").save(os.path.join(d.cfg.plot_folder, 'ten_raw_inputs_to_PHO.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In an intact OP model, ignoring the non informative ticks, the general pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We found a very weird SS-1 having a very high input in off nodes as compared to on nodes\n",
    "- This pattern is also exist in PHO layer\n",
    "Consider PHO layer in a OP model\n",
    "\n",
    "1) Tick 1 is non-informative (No information from O had propagated to P yet) --> tick 1 is fixed across words\n",
    "2) All input is coming from Act P at 0 (=0.5) matmul w_pp. This fixed value is summarized in below density plot\n",
    "3) Functionally it serve as the knowledge (obtain from pretraining) embedded in w_pp, reflecting some degree of direct (1-to-1) coherence coactivation in the phonological layer\n",
    "4) Put in the more general context, bias, PP, and CP reflects probably(?) reflects -> independent activation likelihood in each node, immediate coherence coactivation (1-to-1), and slightly more complex (because it goes through a hidden layer) (but compressed) coherence coactivation???\n",
    "5) Their relative strength is summarized in below density plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tick 1 input density at SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_hos_hs = d.get_weight(name=\"w_hos_hs\")\n",
    "w_ss = d.get_weight(name=\"w_ss\")\n",
    "bias_s = d.get_weight(name=\"bias_s\")\n",
    "w_cs = d.get_weight(name=\"w_cs\")\n",
    "\n",
    "data = {\n",
    "    'ss1': 0.5 * np.sum(w_ss, axis=0), # Lazy matmul. \n",
    "    'cs1': 0.5 * np.sum(w_cs, axis=0),\n",
    "    'os1': 0.5 * np.sum(w_hos_hs, axis=0),\n",
    "    'bias1': bias_s\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,6))\n",
    "for i, k in enumerate(data.keys()):\n",
    "    df[k].plot.density(ax=ax[i], title=k)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tick 1 input density at PHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_hop_hp = d.get_weight(name=\"w_hop_hp\")\n",
    "w_pp = d.get_weight(name=\"w_pp\")\n",
    "bias_p = d.get_weight(name=\"bias_p\")\n",
    "w_cp = d.get_weight(name=\"w_cp\")\n",
    "\n",
    "data = {\n",
    "    'pp1': 0.5 * np.sum(w_pp, axis=0), # Lazy matmul. \n",
    "    'cp1': 0.5 * np.sum(w_cp, axis=0),\n",
    "    'op1': 0.5 * np.sum(w_hop_hp, axis=0),\n",
    "    'bias1': bias_p\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,6))\n",
    "for i, k in enumerate(data.keys()):\n",
    "    df[k].plot.density(ax=ax[i], title=k)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme case node 1918"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PP1 is very large... compare to other input (CP1, bias1)\n",
    "- All pp1, cp1, bias1 is mostly negative\n",
    "- There are a small number of nodes having a strong positive value "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
