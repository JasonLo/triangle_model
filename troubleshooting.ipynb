{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suspect of too low accuracy in Lesion model\n",
    "Vocabulary: \n",
    "- boardcasting: when adding tensor with different dimension, for example input_p (dim = [batch_size, 250]) and bias_p (dim = [1, 250]), bias_p will automatically \"boardcast\" to (batch_size, 250) during the elementwise addition\n",
    "\n",
    "When input information have not reach a layer, it will assume the first axis (batch_size) = 1 \n",
    "however, the batch_size won't matter... since tf.matmul batch_axis is independent with each other...  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os, meta, modeling, data_wrangling, evaluate\n",
    "from importlib import reload\n",
    "reload(modeling)\n",
    "\n",
    "\n",
    "def init(code_name):\n",
    "    cfg = meta.ModelConfig.from_json(\n",
    "        os.path.join(\"models\", code_name, \"model_config.json\")\n",
    "    )\n",
    "    cfg.output_ticks = 8\n",
    "    \n",
    "    model = modeling.MyModel(cfg, batch_size_override=100)\n",
    "    model.load_weights(cfg.saved_weights_fstring.format(epoch=400))\n",
    "    # data = data_wrangling.MyData()\n",
    "    # test = evaluate.TestSet(cfg, model)\n",
    "    return cfg, model\n",
    "\n",
    "\n",
    "cfg, model = init(\"NS_4M_zer01\")\n",
    "train100 = data_wrangling.load_testset('dataset/testsets/train_r100.pkl.gz')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load testset and evaluate an epoch\n",
    "## y_pred[task][output_name][timetick][tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"exp_os\"]\n",
    "\n",
    "y_pred = {}\n",
    "for task in tasks:\n",
    "    model.set_active_task(task)\n",
    "    y_pred[task] = model([train100[modeling.IN_OUT[task][0]]] * cfg.n_timesteps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Task keys: {y_pred.keys()}\")\n",
    "print(f\"Output keys: {y_pred['exp_os'].keys()}\")\n",
    "print(f\"Weight tensors: {[w.name for w in model.weights]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(y_pred['exp_os']['sem'], axis=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input from O to S, more precisely: tf.matmul(hos, w_hos_hs)  \n",
    "os = y_pred['triangle']['input_hos_hs']\n",
    "\n",
    "# Input from P to S, more precisely: tf.matmul(hps, w_hps_hs)\n",
    "ps = y_pred['triangle']['input_hps_hs']\n",
    "\n",
    "# Input from C to S, more precisely: tf.matmul(css, w_cs)\n",
    "cs = y_pred['triangle']['input_css_cs']\n",
    "\n",
    "# Input from S to S, more precisely: tf.matmul(sem, w_ss)\n",
    "ss = y_pred['triangle']['input_sem_ss']\n",
    "\n",
    "# Input from O to P, more precisely: tf.matmul(hop, w_hop_hp)\n",
    "op = y_pred['triangle']['input_hop_hp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_timesteps = list(range(1, cfg.n_timesteps + 1))\n",
    "all_timesteps[-11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[\"exp_os\"]['sem'][[0,1],:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_unit_input(tensor, mask=None):\n",
    "    \"\"\"Mask with output target, reduce sum on items (axis1), mean on units (axis2)\"\"\"\n",
    "    if mask is not None:\n",
    "        tensor = tf.multiply(tensor, mask)\n",
    "    return tf.reduce_mean(tf.reduce_mean(tensor, axis=-1), axis=-1)\n",
    "\n",
    "results_dict = {k: mean_unit_input(globals()[k], train100['sem']) for k in ('os', 'ps', 'cs', 'ss')}\n",
    "results_dict['op'] = mean_unit_input(op, train100['pho'])\n",
    "dol_df = pd.DataFrame.from_dict(results_dict)\n",
    "dol_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {k: mean_unit_input(globals()[k], 1-train100['sem']) for k in ('os', 'ps', 'cs', 'ss')}\n",
    "results_dict['op'] = mean_unit_input(op, 1-train100['pho'])\n",
    "dol_df = pd.DataFrame.from_dict(results_dict)\n",
    "dol_df.plot(title=\"zero target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_s = [w for w in model.weights if w.name == \"my_model_1/bias_s:0\"]\n",
    "bias_p = [w for w in model.weights if w.name == \"my_model_1/bias_p:0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(bias_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(bias_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(os.path.join(cfg.eval_folder, f'train_r1000_{ts}.csv')) for ts in ('triangle', 'exp_ops', 'ort_sem')]\n",
    "df = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = df.loc[(df.timetick==df.timetick.max()) & (df.epoch==400) & (df.output_name==\"sem\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(sdf.sample(100)).mark_point().encode(\n",
    "    x=\"act1:Q\",\n",
    "    y=alt.Y(\"act0:Q\", scale=alt.Scale(reverse=True)),\n",
    "    color=\"task:N\",\n",
    "    detail=\"word:N\",\n",
    "    column=\"acc:N\",\n",
    "    tooltip=['word', 'acc', 'sse', 'act0', 'act1' ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
