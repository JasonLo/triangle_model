{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully modularized experience object\n",
    "\n",
    "- The purpose of this object is to make a flexible environment that can consist of many stages.\n",
    "- Each stage contains a list of tasks with a smooth transition of task sampling probability.\n",
    "- Each task contain a progress counter that determine the speed of corpus opening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task:\n",
    "    \"\"\" A single task \"\"\"\n",
    "    def __init__(self, name: str, progress_start: float, progress_slope: float):\n",
    "        \"\"\"\n",
    "        progress_start: starting location\n",
    "        progress_slope: slope progress in %/sample\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.progress_start = progress_start\n",
    "        self.progress_slope = progress_slope\n",
    "\n",
    "    def get_progress(self, sample: float) -> float:\n",
    "        \"\"\" Return the progress of a given sample in percentage\"\"\"\n",
    "        progress = self.progress_start + sample * self.progress_slope\n",
    "        return min(progress, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_start = 2\n",
    "p_slope = 1/40000\n",
    "\n",
    "n1 = 1_800_000\n",
    "n2 = 800_000\n",
    "n3 = 52_000_000\n",
    "\n",
    "o_start2 = p_start + n1 * p_slope\n",
    "o_start3 = o_start2 + n2 * p_slope\n",
    "r_start3 = p_start + n2 * p_slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stage 1: Oral\n",
    "pho_sem_1 = Task(name=\"pho_sem\", progress_start=p_start, progress_slope=p_slope)\n",
    "sem_pho_1 = Task(name=\"sem_pho\", progress_start=p_start, progress_slope=p_slope)\n",
    "sem_sem_1 = Task(name=\"sem_sem\", progress_start=p_start, progress_slope=p_slope)\n",
    "pho_pho_1 = Task(name=\"pho_pho\", progress_start=p_start, progress_slope=p_slope)\n",
    "\n",
    "# Stage 2: Transition\n",
    "pho_sem_2 = Task(name=\"pho_sem\", progress_start=o_start2, progress_slope=p_slope)\n",
    "sem_pho_2 = Task(name=\"sem_pho\", progress_start=o_start2, progress_slope=p_slope)\n",
    "sem_sem_2 = Task(name=\"sem_sem\", progress_start=o_start2, progress_slope=p_slope)\n",
    "pho_pho_2 = Task(name=\"pho_pho\", progress_start=o_start2, progress_slope=p_slope)\n",
    "ort_pho_2 = Task(name=\"ort_pho\", progress_start=p_start, progress_slope=p_slope)\n",
    "ort_sem_2 = Task(name=\"ort_sem\", progress_start=p_start, progress_slope=p_slope)\n",
    "triangle_2 = Task(name=\"triangle\", progress_start=p_start, progress_slope=p_slope)\n",
    "\n",
    "# Stage 3: Reading\n",
    "pho_sem_3 = Task(name=\"pho_sem\", progress_start=o_start3, progress_slope=p_slope)\n",
    "sem_pho_3 = Task(name=\"sem_pho\", progress_start=o_start3, progress_slope=p_slope)\n",
    "sem_sem_3 = Task(name=\"sem_sem\", progress_start=o_start3, progress_slope=p_slope)\n",
    "pho_pho_3 = Task(name=\"pho_pho\", progress_start=o_start3, progress_slope=p_slope)\n",
    "ort_pho_3 = Task(name=\"ort_pho\", progress_start=r_start3, progress_slope=p_slope)\n",
    "ort_sem_3 = Task(name=\"ort_sem\", progress_start=r_start3, progress_slope=p_slope)\n",
    "triangle_3 = Task(name=\"triangle\", progress_start=r_start3, progress_slope=p_slope)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Stage:\n",
    "    def __init__(self, name: str, tasks: List[Task], stage_sample: int, task_probability_start: List[float], task_probability_end: List[float]):\n",
    "        self.name = name\n",
    "        self.tasks = tasks\n",
    "        self.stage_sample = stage_sample\n",
    "        self.task_probability_start = task_probability_start\n",
    "        self.task_probability_end = task_probability_end\n",
    "\n",
    "    def get_task_probability(self, sample: int) -> float:\n",
    "        \"\"\" Return the probability of a task at a given sample \"\"\"\n",
    "        interpolate = lambda sample, start, end: np.interp(sample, xp=[0, self.stage_sample], fp=[start, end])\n",
    "        p = [interpolate(sample, start, end) for start, end in zip(self.task_probability_start, self.task_probability_end)]\n",
    "        return p\n",
    "\n",
    "    def draw_task(self, sample:int) -> Task:\n",
    "        \"\"\" Return the task to be executed \"\"\"\n",
    "        p = self.get_task_probability(sample)\n",
    "        task = np.random.choice(self.tasks, p=p)\n",
    "        return task\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oral_stage = Stage(\n",
    "    name=\"oral\", \n",
    "    tasks=[pho_sem_1, sem_pho_1, sem_sem_1, pho_pho_1], \n",
    "    stage_sample=1_800_000, \n",
    "    task_probability_start=[0.4, 0.4, 0.1, 0.1], \n",
    "    task_probability_end=[0.4, 0.4, 0.1, 0.1]\n",
    "    )\n",
    "\n",
    "transition_stage = Stage(\n",
    "    name=\"transition\", \n",
    "    tasks=[pho_sem_2, sem_pho_2, sem_sem_2, pho_pho_2, ort_pho_2, ort_sem_2, triangle_2],\n",
    "    stage_sample=800_000, \n",
    "    task_probability_start=[0.4, 0.4, 0.1, 0.1, 0, 0, 0], \n",
    "    task_probability_end=[0.2, 0.2, 0.05, 0.05, 0.1, 0.1, 0.3]\n",
    "    )\n",
    "    \n",
    "reading_stage = Stage(\n",
    "    name=\"reading\", \n",
    "    tasks=[pho_sem_3, sem_pho_3, sem_sem_3, pho_pho_3, ort_pho_3, ort_sem_3, triangle_3],\n",
    "    stage_sample=52_000_000,\n",
    "    task_probability_start=[0.2, 0.2, 0.05, 0.05, 0.1, 0.1, 0.3],\n",
    "    task_probability_end=[0.2, 0.2, 0.05, 0.05, 0.1, 0.1, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Experience:\n",
    "    def __init__(self, stages: List[Stage]):\n",
    "        self.stages = stages\n",
    "        self.n_stages = len(stages)\n",
    "        self.total_sample = sum(x.stage_sample for x in self.stages)\n",
    "\n",
    "    def plot_corpus(self, scale_x=1000):\n",
    "        \"\"\"Plot the corpus opening progress in each stage\"\"\"\n",
    "        fig, ax = plt.subplots(1, self.n_stages, figsize=(7*self.n_stages,5))\n",
    "\n",
    "        for i, stage in enumerate(self.stages):\n",
    "            samples = stage.stage_sample\n",
    "            for j, task in enumerate(stage.tasks):\n",
    "                y = [task.get_progress(sample*scale_x) for sample in range(int(samples/scale_x))]\n",
    "                ax[i].plot(y, label=task.name)\n",
    "                ax[i].legend(loc=\"lower right\")\n",
    "                ax[i].set_title(f'{j}: Corpus opening progression (%) in {stage.name}')\n",
    "                ax[i].set_xlabel(f'sample x {scale_x}')\n",
    "                ax[i].set_ylabel('Progress (%)')\n",
    "                ax[i].set_ylim([0,101])\n",
    "        \n",
    "    def plot_task_probability(self, scale_x=1000):\n",
    "        \"\"\"Plot task probability in each stage\"\"\"\n",
    "        fig, ax = plt.subplots(1, self.n_stages, figsize=(7*self.n_stages,5))\n",
    "\n",
    "        for i, stage in enumerate(self.stages):\n",
    "            samples = stage.stage_sample\n",
    "            ps = [stage.get_task_probability(sample*scale_x) for sample in range(int(samples/scale_x))]\n",
    "            \n",
    "            for j, task in enumerate(stage.tasks):\n",
    "                task_p = [p[j] for p in ps] \n",
    "                ax[i].plot(task_p, label=task.name)\n",
    "                ax[i].legend(loc=\"lower right\")\n",
    "                ax[i].set_title(f'{j}: Sampling probability in {stage.name}')\n",
    "                ax[i].set_xlabel(f'sample x {scale_x}')\n",
    "                ax[i].set_ylabel('Probability')\n",
    "                ax[i].set_ylim([0,1])\n",
    "\n",
    "\n",
    "    def get_stage(self, sample:int) -> [Stage, int]:\n",
    "        \"\"\"Get the current stage and sample_at_stage by no. sample ingested\n",
    "        Stage: Stage object\n",
    "        sample_at_stage: the no. of sample counted from the start of a stage\n",
    "        \"\"\"\n",
    "        cumulative_sample = 0\n",
    "        sample_at_stage = sample\n",
    "\n",
    "        for stage in self.stages:\n",
    "            if sample <= cumulative_sample + stage.stage_sample:\n",
    "                return stage, sample_at_stage\n",
    "            else:\n",
    "                cumulative_sample += stage.stage_sample\n",
    "                sample_at_stage = sample - cumulative_sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experience([oral_stage, transition_stage, reading_stage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_task_probability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Sampler:\n",
    "    \"\"\"v3 Sampler for modularized environment\n",
    "    Features: Fully modularized envrionment staging\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg, data, experience):\n",
    "\n",
    "        # Get necessary environment config from cfg object\n",
    "        self.cfg = cfg\n",
    "        self.wf_clip_low = cfg.wf_clip_low\n",
    "        self.wf_clip_high = cfg.wf_clip_high\n",
    "        self.wf_compression = cfg.wf_compression\n",
    "        self.batch_size = cfg.batch_size\n",
    "        self.n_timesteps = cfg.n_timesteps\n",
    "        self.inject_error_ticks = cfg.inject_error_ticks\n",
    "        \n",
    "        np.random.seed(cfg.rng_seed)\n",
    "        \n",
    "        self.data = data\n",
    "        self.current_sample = 0\n",
    "\n",
    "        self.experience = experience\n",
    "\n",
    "        # Basic convienient variables\n",
    "        self._calculate_aux_variables()\n",
    "\n",
    "\n",
    "    def _calculate_aux_variables(self):\n",
    "\n",
    "        # Word frequency related\n",
    "        if self.wf_clip_low is None:\n",
    "            self.wf_clip_low = 0\n",
    "        \n",
    "        if self.wf_clip_high is None:\n",
    "            self.wf_clip_high = 999999999            \n",
    "            \n",
    "        clip_wf = self.data.df_train.wf.clip(self.wf_clip_low, self.wf_clip_high).copy()\n",
    "        self.rank_pct_wf = clip_wf.rank(pct=True, ascending=False)\n",
    "        self.rank_pct_wf_dict = dict(zip(self.data.df_train.word, self.rank_pct_wf))\n",
    "\n",
    "        assert self.wf_compression in ('log', 'root')\n",
    "        self.compressed_wf = np.log(clip_wf + 1) if self.wf_compression == 'log' else np.sqrt(clip_wf)\n",
    "\n",
    "\n",
    "    def wf_to_ps(self, wf):\n",
    "        \"\"\"convert squashed compressed word frequncy to probabilty\"\"\"\n",
    "        return np.array(wf/np.sum(wf), dtype=\"float32\")\n",
    "\n",
    "    def sample_to_batch(self, sample):\n",
    "        \"\"\"Convert sample to batch in 0-indexing format\"\"\"\n",
    "        return int(sample/self.batch_size)\n",
    "\n",
    "    def get_sampling_p(self, task, stage_sample):\n",
    "        \"\"\"Get sampling probability for a task\"\"\"\n",
    "        progress = task.get_progress(stage_sample)\n",
    "        print(f\"Current progress is: {progress}\")      \n",
    "        # Create selection mask\n",
    "        mask = self.rank_pct_wf < progress\n",
    "        return self.wf_to_ps(self.compressed_wf * mask)\n",
    "\n",
    "    def generator(self):\n",
    "        \"\"\" Generator that draw task and sample idx \n",
    "        \"\"\"\n",
    "        x_ticks = self.n_timesteps\n",
    "        y_ticks = self.inject_error_ticks\n",
    "        \n",
    "        while True:\n",
    "            stage, stage_sample = self.experience.get_stage(self.current_sample)\n",
    "            task = stage.draw_task(stage_sample)\n",
    "            idx = np.random.choice(self.data.df_train.index, self.batch_size, p=self.get_sampling_p(task, stage_sample))\n",
    "            \n",
    "            x, y = modeling.IN_OUT[task.name]\n",
    "            batch_x = [self.data.np_representations[x][idx]] * x_ticks\n",
    "\n",
    "            # Check if multiple output or not\n",
    "            if type(y) is list:\n",
    "                    batch_y = {yi: [self.data.np_representations[yi][idx]] * y_ticks for yi in y}\n",
    "            else:\n",
    "                batch_y = [self.data.np_representations[y][idx]] * y_ticks\n",
    "            \n",
    "            self.current_sample += self.batch_size\n",
    "            yield task.name, idx, batch_x, batch_y\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meta, data_wrangling, modeling\n",
    "data = data_wrangling.MyData()\n",
    "cfg = meta.ModelConfig.from_json(\"./models/triangle_hope1/model_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sampler(cfg, data, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sampler.generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(g)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
