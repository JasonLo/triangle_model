{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Task:\n",
    "    \"\"\" A single task \"\"\"\n",
    "    def __init__(self, name: str, progress_start: float, progress_slope: float):\n",
    "        self.name = name\n",
    "        self.progress_start = progress_start\n",
    "        self.progress_slope = progress_slope\n",
    "\n",
    "    def get_progress(self, sample: float) -> float:\n",
    "        \"\"\" Return the progress of a given sample \"\"\"\n",
    "        return self.progress_start + sample * self.progress_slope\n",
    "\n",
    "\n",
    "class Stage:\n",
    "    def __init__(self, name: str, tasks: List[Task], total_sample: int, task_probability_start: List[float], task_probability_end: List[float]):\n",
    "        self.name = name\n",
    "        self.tasks = tasks\n",
    "        self.task_probability_start = task_probability_start\n",
    "        self.task_probability_end = task_probability_end\n",
    "\n",
    "    def draw_task(self, sample:int) -> Task:\n",
    "        \"\"\" Return the task to be executed \"\"\"\n",
    "        task = np.random.choice(self.tasks, p=self.task_ps[current_batch]) if type(self.tasks) is tuple or list else self.tasks\n",
    "        idx = np.random.choice(self.data.df_train.index, self.batch_size, p=self.get_sampling_p(self.current_sample, task))  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Experience:\n",
    "    def __init__(self, stages):\n",
    "        self.stages = stages\n",
    "\n",
    "    def get_stage(self, sample:int) -> Stage:\n",
    "        \"\"\"Get the current stage by no. sample ingested\"\"\"\n",
    "        cumulative_sample = 0\n",
    "        for stage in self.stages:\n",
    "            if sample < cumulative_sample + stage.total_sample:\n",
    "                return stage\n",
    "            else:\n",
    "                cumulative_sample += stage.total_sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle = Task(\"triangle\", 0, 1/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle.get_progress(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Sampler:\n",
    "    \"\"\"v2 Sampler for tf model v4\n",
    "    Features: \n",
    "    1) Smooth non-stationary environment\n",
    "    2) Visualizing enviroment change with plot_env()\n",
    "    3) Visualizing relative testset exposure with plot_testset_on_env()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg, data):\n",
    "\n",
    "        # Get necessary environment config from cfg object\n",
    "        self.cfg = cfg\n",
    "        self.tasks = cfg.tasks\n",
    "        self.wf_clip_low = cfg.wf_clip_low\n",
    "        self.wf_clip_high = cfg.wf_clip_high\n",
    "        self.wf_compression = cfg.wf_compression\n",
    "        self.oral_start_pct = cfg.oral_start_pct\n",
    "        self.oral_end_pct = cfg.oral_end_pct \n",
    "        self.oral_sample = cfg.oral_sample\n",
    "        self.oral_tasks_ps = cfg.oral_tasks_ps\n",
    "        self.transition_sample = cfg.transition_sample\n",
    "        self.reading_sample = cfg.reading_sample\n",
    "        self.reading_tasks_ps = cfg.reading_tasks_ps\n",
    "        self.batch_size = cfg.batch_size\n",
    "        self.n_timesteps = cfg.n_timesteps\n",
    "        self.inject_error_ticks = cfg.inject_error_ticks\n",
    "        \n",
    "        np.random.seed(cfg.rng_seed)\n",
    "        \n",
    "        self.data = data\n",
    "        self.current_sample = 0\n",
    "\n",
    "        # Basic convienient variables\n",
    "        self._calculate_aux_variables()\n",
    "\n",
    "        # Task probability dictionary (batch, ps)\n",
    "        self.ps = {}\n",
    "        self._calculate_task_ps()\n",
    "\n",
    "        # Progress dictionary \n",
    "        self.progress = {}\n",
    "        self._calculate_progress_dict()\n",
    "\n",
    "    def plot_env(self, ax=None):\n",
    "\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(7,5))\n",
    "\n",
    "        \"\"\"Plot an easy to understand environment progression figure\"\"\"\n",
    "        ax.plot(self.progress['oral'], label='oral corpus')\n",
    "        ax.plot(self.progress['reading'], label='reading corpus')\n",
    "\n",
    "        reading_p = [self.task_ps[i][-1] if type(self.task_ps[i]) is list or tuple else self.task_ps[i] for i in range(self.total_batches)]\n",
    "        # print(reading_p)\n",
    "        ax.plot(reading_p, label='reading_p', linestyle='dashdot', color='black')\n",
    "\n",
    "        ax.axvline(x=self.oral_batches, ymin=0, ymax=1, linestyle = 'dotted', color='red', label='transition start')\n",
    "        ax.axvline(x=self.oral_batches + self.transition_batches, ymin=0, ymax=1, linestyle = 'dotted', color='green', label = 'transition end')\n",
    "        ax.text(x=10, y=0.8, s=f\"oral phase task ps \\n{self.oral_tasks_ps}\")\n",
    "        ax.text(x=self.total_batches*0.5, y=0.8, s=f\"reading phase task ps \\n(after transition) \\n{self.reading_tasks_ps}\")\n",
    "        ax.set_xlabel('batch')\n",
    "        ax.set_ylabel('percetile rank of word frequency')\n",
    "\n",
    "        ax.legend(loc=\"lower right\")\n",
    "        ax.set_title('Corpus opening progression (%)')\n",
    "\n",
    "\n",
    "    def _join_testset_pct(self, testset_name):\n",
    "        \"\"\"Create a temp df for plotting testset on env\"\"\"\n",
    "        f = os.path.join(self.cfg.tf_root, \"dataset\", \"testsets\", f\"{testset_name}.pkl.gz\")\n",
    "        ts = load_testset(f)\n",
    "        ts_sel = {key:ts[key] for key in ('item', 'cond')}\n",
    "        ts_sel['pct'] = [self.rank_pct_wf_dict[x] for x in ts_sel['item']]\n",
    "        return pd.DataFrame(ts_sel)\n",
    "\n",
    "    def _calculate_aux_variables(self):\n",
    "        self.total_sample = self.oral_sample + self.reading_sample\n",
    "\n",
    "        self.total_batches = self.sample_to_batch(self.total_sample)\n",
    "        self.oral_batches = self.sample_to_batch(self.oral_sample)\n",
    "        self.transition_batches = self.sample_to_batch(self.transition_sample)\n",
    "        self.remaining_batches = self.total_batches - self.oral_batches - self.transition_batches\n",
    "\n",
    "        # Word frequency related\n",
    "        if self.wf_clip_low is None:\n",
    "            self.wf_clip_low = 0\n",
    "        \n",
    "        if self.wf_clip_high is None:\n",
    "            self.wf_clip_high = 999999999            \n",
    "            \n",
    "        clip_wf = self.data.df_train.wf.clip(self.wf_clip_low, self.wf_clip_high).copy()\n",
    "        self.rank_pct_wf = clip_wf.rank(pct=True, ascending=False)\n",
    "        self.rank_pct_wf_dict = dict(zip(self.data.df_train.word, self.rank_pct_wf))\n",
    "\n",
    "        assert self.wf_compression in ('log', 'root')\n",
    "        self.compressed_wf = np.log(clip_wf + 1) if self.wf_compression == 'log' else np.sqrt(clip_wf)\n",
    "\n",
    "    def _calculate_task_ps(self):\n",
    "        \"\"\"Task probabililty store all task probabilities in a single dictionary (epoch, ps) \"\"\"\n",
    "\n",
    "        # Oral\n",
    "        self.task_ps = {i:self.oral_tasks_ps for i in range(self.oral_batches)}\n",
    "\n",
    "        # Transition\n",
    "        tps = np.linspace(self.oral_tasks_ps, self.reading_tasks_ps, self.transition_batches)\n",
    "        tran_ps = {i + self.oral_batches: tuple(tps[i]) for i in range(self.transition_batches)}\n",
    "        self.task_ps.update(tran_ps)\n",
    "\n",
    "        # Remaining\n",
    "        remain_ps = {i + self.oral_batches + self.transition_batches: self.reading_tasks_ps for i in range(self.remaining_batches)}\n",
    "        self.task_ps.update(remain_ps)\n",
    "\n",
    "    def _calculate_progress_dict(self):\n",
    "        \"\"\"Progress dictionary storing all %max progress at each epoch in oral and reading stage\"\"\"\n",
    "        # Oral progress\n",
    "        opg = np.linspace(self.oral_start_pct, self.oral_end_pct, self.oral_batches)\n",
    "        self.progress['oral'] = self._extrapolate_ps(opg)\n",
    "\n",
    "        # Reading progress\n",
    "        self.progress['reading'] = self._right_shift_ps(self.progress['oral'])         \n",
    "\n",
    "    def _extrapolate_ps(self, array):\n",
    "        \"\"\"Extrapolate an array to the number of batches long\"\"\"\n",
    "        d = array[1] - array[0]\n",
    "        e = array[-1]\n",
    "        n = len(array)\n",
    "        ex_array = [array[i] if i < n  else e + (i-n) * d for i in range(self.total_batches)]\n",
    "        return np.clip(ex_array, 0, 1)\n",
    "\n",
    "    def _right_shift_ps(self, oral_progress):\n",
    "        \"\"\"Convert oral ps to reading ps\n",
    "        Since reading lag behide oral task by a constant, we just need to shift oral progress to the right\n",
    "        to get reading progress\n",
    "        \"\"\"\n",
    "        n = self.oral_batches\n",
    "        beginning = np.zeros(n)\n",
    "        return np.concatenate([beginning, oral_progress[:-n]])\n",
    "\n",
    "    def wf_to_ps(self, wf):\n",
    "        \"\"\"convert squashed compressed word frequncy to probabilty\"\"\"\n",
    "        return np.array(wf/np.sum(wf), dtype=\"float32\")\n",
    "\n",
    "    def sample_to_batch(self, sample):\n",
    "        \"\"\"Convert sample to batch in 0-indexing format\"\"\"\n",
    "        return int(sample/self.batch_size)\n",
    "\n",
    "    def get_sampling_p(self, current_sample, task):\n",
    "        current_batch = self.sample_to_batch(current_sample)\n",
    "\n",
    "        if task == 'triangle':\n",
    "            progress = self.progress['reading'][current_batch]\n",
    "        else:\n",
    "            progress = self.progress['oral'][current_batch]\n",
    "\n",
    "        # Create selection mask\n",
    "        mask = self.rank_pct_wf < progress\n",
    "    \n",
    "        return self.wf_to_ps(self.compressed_wf * mask)\n",
    "\n",
    "    def generator(self):\n",
    "        \"\"\" Generator that draw task and sample idx \n",
    "        \"\"\"\n",
    "        x_ticks = self.n_timesteps\n",
    "        y_ticks = self.inject_error_ticks\n",
    "        \n",
    "        while True:\n",
    "            current_batch = self.sample_to_batch(self.current_sample)\n",
    "            task = np.random.choice(self.tasks, p=self.task_ps[current_batch]) if type(self.tasks) is tuple or list else self.tasks\n",
    "            idx = np.random.choice(self.data.df_train.index, self.batch_size, p=self.get_sampling_p(self.current_sample, task))\n",
    "            \n",
    "            x, y = modeling.IN_OUT[task]\n",
    "            batch_x = [self.data.np_representations[x][idx]] * x_ticks\n",
    "\n",
    "            if type(y) is list:\n",
    "                    batch_y = {yi: [self.data.np_representations[yi][idx]] * y_ticks for yi in y}\n",
    "            else:\n",
    "                # Single output\n",
    "                batch_y = [self.data.np_representations[y][idx]] * y_ticks\n",
    "            \n",
    "            \n",
    "            self.current_sample += self.batch_size\n",
    "            yield task, idx, batch_x, batch_y\n",
    "     \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
