{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HS04 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The weights that were obtained at the end of the Phase 1 model were frozen and embedded in the larger reading model. Thus, only the connections from orthography to other units were trained in Phase 2. Freezing the weights is not strictly necessary; earlier work (Harm & Seidenberg, 1997) used a process of intermixing in which comprehension trials were used along with reading trials. Weight freezing has the same effect but is simpler and less computationally burdensome to implement. Intermixing is effective and real- istic but adds substantially to network training time.\n",
    "\n",
    "- *Pretraining is necessary, and freeze in phase 2\n",
    "\n",
    "> One set of 500 hidden units mediated the mapping from these orthographic units to semantics...\n",
    "\n",
    "- *500 sem_hidden_units*\n",
    "\n",
    "> ...a second set of 100 hidden units mediated the orth-phon pathway.\n",
    "\n",
    "- *100 pho_hidden_units*\n",
    "\n",
    "> To computationally instantiate the principle that the reading system is under pressure to perform rapidly as well as accurately, we injected error into the semantic and phonological representa- tions early, from time samples 2 to 12. \n",
    "- *11 output_ticks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modeling individual differences\n",
    "- Simulating ERPs\n",
    "- Link to reliance of OP vs OS\n",
    "- Use equation to model semantic / phonetic input to P/S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext lab_black\n",
    "import pickle, os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/jupyter/tf/src\")\n",
    "import meta, data_wrangling, modeling, metrics, evaluate\n",
    "\n",
    "meta.set_gpu_mem_cap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters block (for papermill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "code_name = \"hs04_phase2_test2\"\n",
    "tf_root = \"/home/jupyter/tf\"\n",
    "\n",
    "# Model architechture\n",
    "ort_units = 119\n",
    "pho_units = 250\n",
    "sem_units = 2446\n",
    "\n",
    "hidden_os_units = 500  # P2\n",
    "hidden_op_units = 100  # P2\n",
    "hidden_ps_units = 500\n",
    "hidden_sp_units = 500\n",
    "\n",
    "pho_cleanup_units = 50\n",
    "sem_cleanup_units = 50\n",
    "\n",
    "pho_noise_level = 0.0  # P3\n",
    "sem_noise_level = 0.0  # P3\n",
    "\n",
    "activation = \"sigmoid\"\n",
    "tau = 1 / 3\n",
    "max_unit_time = 4.0\n",
    "output_ticks = 11\n",
    "\n",
    "# Pretraining\n",
    "pretrained_checkpoint = (\n",
    "    \"/home/jupyter/tf/models/hs04_phase1_selected_fix_attractor/weights/ep0200\"\n",
    ")\n",
    "\n",
    "# Training\n",
    "sample_name = \"hs04\"\n",
    "\n",
    "rng_seed = 53797\n",
    "learning_rate = 0.01\n",
    "n_mil_sample = 2.0\n",
    "batch_size = 100\n",
    "save_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = meta.ModelConfig.from_json(os.path.join(\"models\", code_name, \"model_config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {}\n",
    "\n",
    "# Load global cfg variables into a dictionary for feeding into ModelConfig()\n",
    "for v in meta.CORE_CONFIGS:\n",
    "    try:\n",
    "        config_dict[v] = globals()[v]\n",
    "    except:\n",
    "        raise\n",
    "\n",
    "for v in meta.OPTIONAL_CONFIGS:\n",
    "    try:\n",
    "        config_dict[v] = globals()[v]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Construct ModelConfig object\n",
    "cfg = meta.ModelConfig(**config_dict)\n",
    "cfg.save()\n",
    "del config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model and all supporting components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(cfg.rng_seed)\n",
    "data = data_wrangling.MyData()\n",
    "model = modeling.HS04Model(cfg)\n",
    "\n",
    "sampler = data_wrangling.FastSampling(cfg, data)\n",
    "generators = {\"triangle\": sampler.sample_generator(x=\"ort\", y=[\"pho\", \"sem\"])}\n",
    "optimizers = {\"triangle\": tf.keras.optimizers.Adam(learning_rate=cfg.learning_rate)}\n",
    "loss_fns = {\"triangle\": tf.keras.losses.BinaryCrossentropy()}\n",
    "\n",
    "# Mean loss (for TensorBoard)\n",
    "train_losses = {\n",
    "    \"triangle\": tf.keras.metrics.Mean(\"train_loss_triangle\", dtype=tf.float32)\n",
    "}\n",
    "\n",
    "# Train metrics\n",
    "train_acc = {\n",
    "    \"triangle_pho\": metrics.PhoAccuracy(\"acc_triangle_pho\"),\n",
    "    \"triangle_sem\": metrics.RightSideAccuracy(\"acc_triangle_sem\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train step for triangle model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle model (Phase 2 in HS04) specific train step\n",
    "Because we have both P and S output, the trainstep need to cater for this dual output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_triangle(\n",
    "    x,\n",
    "    y,\n",
    "    model,\n",
    "    task,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    train_metric_pho,\n",
    "    train_metric_sem,\n",
    "    train_losses,\n",
    "):\n",
    "\n",
    "    train_weights_name = [x + \":0\" for x in modeling.WEIGHTS_AND_BIASES[task]]\n",
    "    train_weights = [x for x in model.weights if x.name in train_weights_name]\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        pho_pred, sem_pred = model(x, training=True)\n",
    "        loss_value_pho = loss_fn(y[0], pho_pred)\n",
    "        loss_value_sem = loss_fn(y[1], sem_pred)\n",
    "        loss_value = loss_value_pho + loss_value_sem\n",
    "\n",
    "    grads = tape.gradient(loss_value, train_weights)\n",
    "    optimizer.apply_gradients(zip(grads, train_weights))\n",
    "\n",
    "    # Mean loss for Tensorboard\n",
    "    train_losses.update_state(loss_value)\n",
    "\n",
    "    # Metric for last time step (output first dimension is time ticks, from -cfg.output_ticks to end)\n",
    "    train_metric_pho.update_state(tf.cast(y[0][-1], tf.float32), pho_pred[-1])\n",
    "    train_metric_sem.update_state(tf.cast(y[1][-1], tf.float32), sem_pred[-1])\n",
    "\n",
    "\n",
    "train_steps = {\"triangle\": train_step_triangle}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model.build()\n",
    "model.load_weights(pretrained_checkpoint)\n",
    "task = \"triangle\"\n",
    "model.set_active_task(task)\n",
    "\n",
    "\n",
    "# TensorBoard writer\n",
    "train_summary_writer = tf.summary.create_file_writer(cfg.path[\"tensorboard_folder\"])\n",
    "\n",
    "for epoch in range(cfg.total_number_of_epoch):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for step in range(cfg.steps_per_epoch):\n",
    "\n",
    "        x_batch_train, y_batch_train = next(generators[task])\n",
    "\n",
    "        train_steps[task](\n",
    "            x_batch_train,\n",
    "            y_batch_train,\n",
    "            model,\n",
    "            task,\n",
    "            loss_fns[task],\n",
    "            optimizers[task],\n",
    "            train_acc[\"triangle_pho\"],\n",
    "            train_acc[\"triangle_sem\"],\n",
    "            train_losses[task],\n",
    "        )\n",
    "\n",
    "    # End of epoch operations\n",
    "\n",
    "    ## Log all scalar metrics (losses and metrics)and histogram (weights and biases) to tensorboard\n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        [\n",
    "            tf.summary.scalar(f\"loss_{x}\", train_losses[x].result(), step=epoch)\n",
    "            for x in train_losses.keys()\n",
    "        ]\n",
    "        [\n",
    "            tf.summary.scalar(f\"acc_{x}\", train_acc[x].result(), step=epoch)\n",
    "            for x in train_acc.keys()\n",
    "        ]\n",
    "        [tf.summary.histogram(f\"{x.name}\", x, step=epoch) for x in model.weights]\n",
    "\n",
    "    ## Print status\n",
    "    compute_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch + 1} trained for {compute_time:.0f}s\")\n",
    "    print(f\"Losses: {train_losses[task].result().numpy()}\")\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    ## Save weights\n",
    "    if (epoch < 10) or ((epoch + 1) % 10 == 0):\n",
    "        weight_path = cfg.path[\"weights_checkpoint_fstring\"].format(epoch=epoch + 1)\n",
    "        model.save_weights(weight_path, overwrite=True, save_format=\"tf\")\n",
    "\n",
    "    ## Reset metric and loss\n",
    "    [train_losses[x].reset_states() for x in train_losses.keys()]\n",
    "    [train_acc[x].reset_states() for x in train_acc.keys()]\n",
    "\n",
    "# End of training ops\n",
    "# model.save(cfg.path[\"save_model_folder\"])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class testset:\n",
    "    \"\"\"Universal test set object for evaluating model results\n",
    "    1. Single condition, single metric, single value output for maximum capatibility\n",
    "    2. Model level info should be stored at separate table, and merge it at the end\n",
    "    \"\"\"\n",
    "    def __init__(self, name, cfg, model, task, testitems, x_test, y_test, metric, triangle_out=None):\n",
    "        self.name = name\n",
    "        self.cfg = cfg\n",
    "        self.model = model\n",
    "        self.task = task\n",
    "        self.model.set_active_task(self.task)\n",
    "        self.testitems = testitems\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.metric = metric\n",
    "        self.triangle_out = triangle_out\n",
    "\n",
    "    def _convert_dict_to_df(self, x):\n",
    "\n",
    "        self.flat_dict = {\n",
    "            (epoch, timetick, item): {metric: x[epoch][timetick][metric][item]}\n",
    "            for epoch in x.keys()\n",
    "            for timetick in x[epoch].keys()\n",
    "            for metric in x[epoch][timetick].keys()\n",
    "            for item in x[epoch][timetick][metric].keys()\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame.from_dict(self.flat_dict, orient=\"index\")\n",
    "        df.index.rename([\"epoch\", \"timeticks\", \"item\"], inplace=True)\n",
    "        df.reset_index(inplace=True)\n",
    "        return df\n",
    "\n",
    "    def eval_all(self, label_dict=None):\n",
    "        output = {}\n",
    "        for epoch in tqdm(self.cfg.saved_epoches):\n",
    "            output[epoch] = self._eval_one_epoch(epoch)\n",
    "\n",
    "        df = self._convert_dict_to_df(output)\n",
    "        df[\"code_name\"] = self.cfg.code_name\n",
    "        df[\"testset\"] = self.name\n",
    "        df[\"task\"] = self.task\n",
    "\n",
    "        try:\n",
    "            df[\"triangle_out\"] = self.triangle_out\n",
    "            for k, v in label_dict.items():\n",
    "                df[k] = v\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        self.result = df\n",
    "\n",
    "\n",
    "\n",
    "    def _eval_one_epoch(self, epoch):\n",
    "        checkpoint = self.cfg.path[\"weights_checkpoint_fstring\"].format(epoch=epoch)\n",
    "        self.model.load_weights(checkpoint)\n",
    "\n",
    "        pred_y = self.model([self.x_test] * self.cfg.n_timesteps)\n",
    "\n",
    "        if self.triangle_out is not None:\n",
    "            if self.triangle_out == \"pho\":\n",
    "                pred_y = pred_y[0]\n",
    "            elif self.triangle_out == \"sem\":\n",
    "                pred_y = pred_y[1]\n",
    "\n",
    "        output = {}\n",
    "        if type(pred_y) is list:\n",
    "            for i, pred_y_at_this_time in enumerate(pred_y):\n",
    "                tick = self.cfg.n_timesteps - self.cfg.output_ticks + i + 1\n",
    "                output[tick] = self._eval_one_timetick(pred_y_at_this_time)\n",
    "        else:\n",
    "            output[self.cfg.n_timesteps] = self._eval_one_timetick(pred_y)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "    def _eval_one_timetick(self, y_pred):\n",
    "        \n",
    "        output = {}\n",
    "        output[self.metric.name] = dict(\n",
    "            zip(self.testitems, self.metric.item_metric(self.y_test, y_pred))\n",
    "        )\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(data_wrangling)\n",
    "data = data_wrangling.MyData()\n",
    "model = modeling.HS04Model(cfg)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(metrics)\n",
    "\n",
    "train_pho_acc = testset(\n",
    "    name=\"train\",\n",
    "    cfg=cfg,\n",
    "    model=model,\n",
    "    task=\"triangle\",\n",
    "    triangle_out=\"sem\",\n",
    "    testitems=data.testsets[\"train\"][\"item\"],\n",
    "    x_test=data.testsets[\"train\"][\"ort\"],\n",
    "    y_test=data.testsets[\"train\"][\"sem\"],\n",
    "    metric=metrics.RightSideAccuracy(\"acc\")\n",
    ")\n",
    "\n",
    "train_pho_acc.eval_all()\n",
    "\n",
    "train_pho_acc = testset(\n",
    "    name=\"train\",\n",
    "    cfg=cfg,\n",
    "    model=model,\n",
    "    task=\"triangle\",\n",
    "    triangle_out=\"pho\",\n",
    "    testitems=data.testsets[\"train\"][\"item\"],\n",
    "    x_test=data.testsets[\"train\"][\"ort\"],\n",
    "    y_test=data.testsets[\"train\"][\"pho\"],\n",
    "    metric=metrics.PhoAccuracy(\"acc\")\n",
    ")\n",
    "\n",
    "x = t.eval_all(label_dict={\"output\": \"pho\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv('tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.loc[x.timeticks == x.timeticks.max(),].groupby('epoch').mean().plot(y=\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Instantiate metrics\n",
    "ps_homophone_acc = metrics.RightSideAccuracy(\"ps_homophone_acc\")\n",
    "ps_non_homophone_acc = metrics.RightSideAccuracy(\"ps_non_homophone_acc\")\n",
    "ps_train_acc = metrics.RightSideAccuracy(\"ps_train_acc\")\n",
    "\n",
    "\n",
    "def my_eval(model, cfg, x, y, metrics):\n",
    "    pred_y = model([x] * cfg.n_timesteps)\n",
    "\n",
    "    output = []\n",
    "    for metric in metrics:\n",
    "        metric.update_state(y, pred_y[-1])\n",
    "        output.append(metric.result().numpy())\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def eval_oral_phase_ps(checkpoint):\n",
    "\n",
    "    model.load_weights(checkpoint)\n",
    "\n",
    "    non_homophone = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.testsets[\"non_homophone\"][\"pho\"],\n",
    "        data.testsets[\"non_homophone\"][\"sem\"],\n",
    "        [ps_non_homophone_acc],\n",
    "    )\n",
    "\n",
    "    homophone = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.testsets[\"homophone\"][\"pho\"],\n",
    "        data.testsets[\"homophone\"][\"sem\"],\n",
    "        [ps_homophone_acc],\n",
    "    )\n",
    "\n",
    "    all_train = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.pho_train,\n",
    "        data.sem_train,\n",
    "        [ps_train_acc],\n",
    "    )\n",
    "\n",
    "    return non_homophone[0], homophone[0], all_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "for chkpt in tqdm(cfg.path[\"weights_list\"]):\n",
    "    results.append(eval_oral_phase_ps(chkpt))\n",
    "\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"non_homophone\", \"homophone\", \"total\"]\n",
    "saved_n = len(cfg.path[\"weights_list\"])\n",
    "df[\"epoch\"] = np.concatenate(\n",
    "    [np.linspace(1, 10, 10), np.linspace(20, cfg.total_number_of_epoch, saved_n - 10)]\n",
    ")\n",
    "\n",
    "df.plot(x=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SP performance during oral phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_wrangling.MyData()\n",
    "model = modeling.HS04Model(cfg)\n",
    "model.build()\n",
    "model.set_active_task(\"sem_pho\")\n",
    "\n",
    "# Instantiate metrics\n",
    "sp_homophone_acc = metrics.RightSideAccuracy(\"sp_homophone_acc\")\n",
    "sp_non_homophone_acc = metrics.RightSideAccuracy(\"sp_non_homophone_acc\")\n",
    "sp_train_acc = metrics.RightSideAccuracy(\"sp_train_acc\")\n",
    "\n",
    "\n",
    "def eval_oral_phase_sp(checkpoint):\n",
    "\n",
    "    model.load_weights(checkpoint)\n",
    "\n",
    "    non_homophone = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.testsets[\"non_homophone\"][\"sem\"],\n",
    "        data.testsets[\"non_homophone\"][\"pho\"],\n",
    "        [sp_non_homophone_acc],\n",
    "    )\n",
    "\n",
    "    homophone = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.testsets[\"homophone\"][\"sem\"],\n",
    "        data.testsets[\"homophone\"][\"pho\"],\n",
    "        [sp_homophone_acc],\n",
    "    )\n",
    "\n",
    "    all_train = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.sem_train,\n",
    "        data.pho_train,\n",
    "        [sp_train_acc],\n",
    "    )\n",
    "\n",
    "    return non_homophone[0], homophone[0], all_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "for chkpt in tqdm(cfg.path[\"weights_list\"]):\n",
    "    results.append(eval_oral_phase_sp(chkpt))\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "df.columns = [\"non_homophone\", \"homophone\", \"total\"]\n",
    "saved_n = len(cfg.path[\"weights_list\"])\n",
    "df[\"epoch\"] = np.concatenate(\n",
    "    [np.linspace(1, 10, 10), np.linspace(20, cfg.total_number_of_epoch, saved_n - 10)]\n",
    ")\n",
    "\n",
    "df.plot(x=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local ssh to cloud tensorboard\n",
    "# gcloud compute ssh tensorflow-2-4-20210120-000018 --zone us-east4-b -- -L 6006:localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard dev upload --logdir tensorboard_log"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
