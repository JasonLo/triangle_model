{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HS04 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The weights that were obtained at the end of the Phase 1 model were frozen and embedded in the larger reading model. Thus, only the connections from orthography to other units were trained in Phase 2. Freezing the weights is not strictly necessary; earlier work (Harm & Seidenberg, 1997) used a process of intermixing in which comprehension trials were used along with reading trials. Weight freezing has the same effect but is simpler and less computationally burdensome to implement. Intermixing is effective and real- istic but adds substantially to network training time.\n",
    "\n",
    "- *Pretraining is necessary, and freeze in phase 2\n",
    "\n",
    "> One set of 500 hidden units mediated the mapping from these orthographic units to semantics...\n",
    "\n",
    "- *500 sem_hidden_units*\n",
    "\n",
    "> ...a second set of 100 hidden units mediated the orth-phon pathway.\n",
    "\n",
    "- *100 pho_hidden_units*\n",
    "\n",
    "> To computationally instantiate the principle that the reading system is under pressure to perform rapidly as well as accurately, we injected error into the semantic and phonological representa- tions early, from time samples 2 to 12. \n",
    "- *11 output_ticks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modeling individual differences\n",
    "- Simulating ERPs\n",
    "- Link to reliance of OP vs OS\n",
    "- Use equation to model semantic / phonetic input to P/S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "%reload_ext lab_black\n",
    "import pickle, os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/jupyter/tf/src\")\n",
    "import meta, data_wrangling, modeling, metrics, evaluate\n",
    "\n",
    "meta.set_gpu_mem_cap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters block (for papermill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "code_name = \"hs04_phase2_test2\"\n",
    "tf_root = \"/home/jupyter/tf\"\n",
    "\n",
    "# Model architechture\n",
    "ort_units = 119\n",
    "pho_units = 250\n",
    "sem_units = 2446\n",
    "\n",
    "hidden_os_units = 500  # P2\n",
    "hidden_op_units = 100  # P2\n",
    "hidden_ps_units = 500\n",
    "hidden_sp_units = 500\n",
    "\n",
    "pho_cleanup_units = 50\n",
    "sem_cleanup_units = 50\n",
    "\n",
    "pho_noise_level = 0.0  # P3\n",
    "sem_noise_level = 0.0  # P3\n",
    "\n",
    "activation = \"sigmoid\"\n",
    "tau = 1 / 3\n",
    "max_unit_time = 4.0\n",
    "output_ticks = 11\n",
    "\n",
    "# Pretraining\n",
    "pretrained_checkpoint = (\n",
    "    \"/home/jupyter/tf/models/hs04_phase1_selected_fix_attractor/weights/ep0200\"\n",
    ")\n",
    "\n",
    "# Training\n",
    "sample_name = \"hs04\"\n",
    "\n",
    "rng_seed = 53797\n",
    "learning_rate = 0.01\n",
    "n_mil_sample = 2.0\n",
    "batch_size = 100\n",
    "save_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init from scratch\n",
      "Saved config json to /home/jupyter/tf/models/hs04_phase2_test2/model_config.json\n"
     ]
    }
   ],
   "source": [
    "config_dict = {}\n",
    "\n",
    "# Load global cfg variables into a dictionary for feeding into ModelConfig()\n",
    "for v in meta.CORE_CONFIGS:\n",
    "    try:\n",
    "        config_dict[v] = globals()[v]\n",
    "    except:\n",
    "        raise\n",
    "\n",
    "for v in meta.OPTIONAL_CONFIGS:\n",
    "    try:\n",
    "        config_dict[v] = globals()[v]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Construct ModelConfig object\n",
    "cfg = meta.ModelConfig(**config_dict)\n",
    "cfg.save()\n",
    "del config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model and all supporting components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Orthographic representation==========\n",
      "ort_train shape: (5861, 119)\n",
      "ort_strain shape: (160, 119)\n",
      "ort_grain shape: (120, 119)\n",
      "ort_taraban shape: (192, 119)\n",
      "ort_glushko shape: (86, 119)\n",
      "\n",
      "==========Phonological representation==========\n",
      "38  phonemes:  dict_keys(['_', 'p', 'b', 't', 'd', 'k', 'g', 'f', 'v', 'T', 'D', 's', 'z', 'S', 'Z', 'h', 'C', 'J', 'm', 'n', 'l', 'r', 'w', 'y', 'i', 'I', 'e', 'E', 'a', '@', 'u', 'U', 'o', '^', 'Y', 'A', 'W', 'O'])\n",
      "pho_train shape: (5861, 250)\n",
      "pho_strain shape: (160, 250)\n",
      "pho_large_grain shape: (120, 250)\n",
      "pho_small_grain shape: (120, 250)\n",
      "pho_taraban shape: (192, 250)\n",
      "pho_glushko shape: (86, 250)\n",
      "\n",
      "==========Semantic representation==========\n",
      "sem_train shape: (5861, 2446)\n",
      "sem_strain shape: (160, 2446)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(cfg.rng_seed)\n",
    "data = data_wrangling.MyData()\n",
    "model = modeling.HS04Model(cfg)\n",
    "\n",
    "sampler = data_wrangling.FastSampling(cfg, data)\n",
    "generators = {\"triangle\": sampler.sample_generator(x=\"ort\", y=[\"pho\", \"sem\"])}\n",
    "optimizers = {\"triangle\": tf.keras.optimizers.Adam(learning_rate=cfg.learning_rate)}\n",
    "loss_fns = {\"triangle\": tf.keras.losses.BinaryCrossentropy()}\n",
    "\n",
    "# Mean loss (for TensorBoard)\n",
    "train_losses = {\n",
    "    \"triangle\": tf.keras.metrics.Mean(\"train_loss_triangle\", dtype=tf.float32)\n",
    "}\n",
    "\n",
    "# Train metrics\n",
    "train_acc = {\n",
    "    \"triangle_pho\": metrics.PhoAccuracy(\"acc_triangle_pho\"),\n",
    "    \"triangle_sem\": metrics.RightSideAccuracy(\"acc_triangle_sem\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train step for triangle model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle model (Phase 2 in HS04) specific train step\n",
    "Because we have both P and S output, the trainstep need to cater for this dual output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_triangle(\n",
    "    x,\n",
    "    y,\n",
    "    model,\n",
    "    task,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    train_metric_pho,\n",
    "    train_metric_sem,\n",
    "    train_losses,\n",
    "):\n",
    "\n",
    "    train_weights_name = [x + \":0\" for x in modeling.WEIGHTS_AND_BIASES[task]]\n",
    "    train_weights = [x for x in model.weights if x.name in train_weights_name]\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        pho_pred, sem_pred = model(x, training=True)\n",
    "        loss_value_pho = loss_fn(y[0], pho_pred)\n",
    "        loss_value_sem = loss_fn(y[1], sem_pred)\n",
    "        loss_value = loss_value_pho + loss_value_sem\n",
    "\n",
    "    grads = tape.gradient(loss_value, train_weights)\n",
    "    optimizer.apply_gradients(zip(grads, train_weights))\n",
    "\n",
    "    # Mean loss for Tensorboard\n",
    "    train_losses.update_state(loss_value)\n",
    "\n",
    "    # Metric for last time step (output first dimension is time ticks, from -cfg.output_ticks to end)\n",
    "    train_metric_pho.update_state(tf.cast(y[0][-1], tf.float32), pho_pred[-1])\n",
    "    train_metric_sem.update_state(tf.cast(y[1][-1], tf.float32), sem_pred[-1])\n",
    "\n",
    "\n",
    "train_steps = {\"triangle\": train_step_triangle}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model.build()\n",
    "model.load_weights(pretrained_checkpoint)\n",
    "task = \"triangle\"\n",
    "model.set_active_task(task)\n",
    "\n",
    "\n",
    "# TensorBoard writer\n",
    "train_summary_writer = tf.summary.create_file_writer(cfg.path[\"tensorboard_folder\"])\n",
    "\n",
    "for epoch in range(cfg.total_number_of_epoch):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for step in range(cfg.steps_per_epoch):\n",
    "\n",
    "        x_batch_train, y_batch_train = next(generators[task])\n",
    "\n",
    "        train_steps[task](\n",
    "            x_batch_train,\n",
    "            y_batch_train,\n",
    "            model,\n",
    "            task,\n",
    "            loss_fns[task],\n",
    "            optimizers[task],\n",
    "            train_acc[\"triangle_pho\"],\n",
    "            train_acc[\"triangle_sem\"],\n",
    "            train_losses[task],\n",
    "        )\n",
    "\n",
    "    # End of epoch operations\n",
    "\n",
    "    ## Log all scalar metrics (losses and metrics)and histogram (weights and biases) to tensorboard\n",
    "    with train_summary_writer.as_default():\n",
    "\n",
    "        [\n",
    "            tf.summary.scalar(f\"loss_{x}\", train_losses[x].result(), step=epoch)\n",
    "            for x in train_losses.keys()\n",
    "        ]\n",
    "        [\n",
    "            tf.summary.scalar(f\"acc_{x}\", train_acc[x].result(), step=epoch)\n",
    "            for x in train_acc.keys()\n",
    "        ]\n",
    "        [tf.summary.histogram(f\"{x.name}\", x, step=epoch) for x in model.weights]\n",
    "\n",
    "    ## Print status\n",
    "    compute_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch + 1} trained for {compute_time:.0f}s\")\n",
    "    print(f\"Losses: {train_losses[task].result().numpy()}\")\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    ## Save weights\n",
    "    if (epoch < 10) or ((epoch + 1) % 10 == 0):\n",
    "        weight_path = cfg.path[\"weights_checkpoint_fstring\"].format(epoch=epoch + 1)\n",
    "        model.save_weights(weight_path, overwrite=True, save_format=\"tf\")\n",
    "\n",
    "    ## Reset metric and loss\n",
    "    [train_losses[x].reset_states() for x in train_losses.keys()]\n",
    "    [train_acc[x].reset_states() for x in train_acc.keys()]\n",
    "\n",
    "# End of training ops\n",
    "# model.save(cfg.path[\"save_model_folder\"])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS performance during oral phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_wrangling.MyData()\n",
    "model = modeling.HS04Model(cfg)\n",
    "model.build()\n",
    "model.set_active_task(\"pho_sem\")\n",
    "\n",
    "# Instantiate metrics\n",
    "ps_homophone_acc = metrics.RightSideAccuracy(\"ps_homophone_acc\")\n",
    "ps_non_homophone_acc = metrics.RightSideAccuracy(\"ps_non_homophone_acc\")\n",
    "ps_train_acc = metrics.RightSideAccuracy(\"ps_train_acc\")\n",
    "\n",
    "\n",
    "def my_eval(model, cfg, x, y, metrics):\n",
    "    pred_y = model([x] * cfg.n_timesteps)\n",
    "\n",
    "    output = []\n",
    "    for metric in metrics:\n",
    "        metric.update_state(y, pred_y[-1])\n",
    "        output.append(metric.result().numpy())\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def eval_oral_phase_ps(checkpoint):\n",
    "\n",
    "    model.load_weights(checkpoint)\n",
    "\n",
    "    non_homophone = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.testsets[\"non_homophone\"][\"pho\"],\n",
    "        data.testsets[\"non_homophone\"][\"sem\"],\n",
    "        [ps_non_homophone_acc],\n",
    "    )\n",
    "\n",
    "    homophone = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.testsets[\"homophone\"][\"pho\"],\n",
    "        data.testsets[\"homophone\"][\"sem\"],\n",
    "        [ps_homophone_acc],\n",
    "    )\n",
    "\n",
    "    all_train = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.pho_train,\n",
    "        data.sem_train,\n",
    "        [ps_train_acc],\n",
    "    )\n",
    "\n",
    "    return non_homophone[0], homophone[0], all_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "for chkpt in tqdm(cfg.path[\"weights_list\"]):\n",
    "    results.append(eval_oral_phase_ps(chkpt))\n",
    "\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"non_homophone\", \"homophone\", \"total\"]\n",
    "saved_n = len(cfg.path[\"weights_list\"])\n",
    "df[\"epoch\"] = np.concatenate(\n",
    "    [np.linspace(1, 10, 10), np.linspace(20, cfg.total_number_of_epoch, saved_n - 10)]\n",
    ")\n",
    "\n",
    "df.plot(x=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SP performance during oral phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_wrangling.MyData()\n",
    "model = modeling.HS04Model(cfg)\n",
    "model.build()\n",
    "model.set_active_task(\"sem_pho\")\n",
    "\n",
    "# Instantiate metrics\n",
    "sp_homophone_acc = metrics.RightSideAccuracy(\"sp_homophone_acc\")\n",
    "sp_non_homophone_acc = metrics.RightSideAccuracy(\"sp_non_homophone_acc\")\n",
    "sp_train_acc = metrics.RightSideAccuracy(\"sp_train_acc\")\n",
    "\n",
    "\n",
    "def eval_oral_phase_sp(checkpoint):\n",
    "\n",
    "    model.load_weights(checkpoint)\n",
    "\n",
    "    non_homophone = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.testsets[\"non_homophone\"][\"sem\"],\n",
    "        data.testsets[\"non_homophone\"][\"pho\"],\n",
    "        [sp_non_homophone_acc],\n",
    "    )\n",
    "\n",
    "    homophone = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.testsets[\"homophone\"][\"sem\"],\n",
    "        data.testsets[\"homophone\"][\"pho\"],\n",
    "        [sp_homophone_acc],\n",
    "    )\n",
    "\n",
    "    all_train = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.sem_train,\n",
    "        data.pho_train,\n",
    "        [sp_train_acc],\n",
    "    )\n",
    "\n",
    "    return non_homophone[0], homophone[0], all_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "for chkpt in tqdm(cfg.path[\"weights_list\"]):\n",
    "    results.append(eval_oral_phase_sp(chkpt))\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "df.columns = [\"non_homophone\", \"homophone\", \"total\"]\n",
    "saved_n = len(cfg.path[\"weights_list\"])\n",
    "df[\"epoch\"] = np.concatenate(\n",
    "    [np.linspace(1, 10, 10), np.linspace(20, cfg.total_number_of_epoch, saved_n - 10)]\n",
    ")\n",
    "\n",
    "df.plot(x=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local ssh to cloud tensorboard\n",
    "# gcloud compute ssh tensorflow-2-4-20210120-000018 --zone us-east4-b -- -L 6006:localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard dev upload --logdir tensorboard_log"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
