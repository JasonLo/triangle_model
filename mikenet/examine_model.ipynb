{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine model\n",
    "We want to examine how the mikenet model works by checking:\n",
    "1. Whether Chang's weights produce HS04 fig. 12 result\n",
    "2. What are the Input **direction** and **magnitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import meta, modeling, evaluate\n",
    "os.chdir(os.environ.get(\"TF_ROOT\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore to Chang's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = meta.Config.from_json('models/surgery/model_config.json')\n",
    "model = modeling.MyModel(cfg)\n",
    "model.build()\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore(os.path.join(cfg.checkpoint_folder,'epoch-1'))\n",
    "[print(f'{w.name} mean: {w.numpy().mean()}') for w in model.weights]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with mn_r100 testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_r100 = evaluate.load_testset('mn_r100')\n",
    "model.set_active_task('triangle')\n",
    "y_pred = model([mn_r100['ort']] * 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HS04 figure 12](/triangle_model/references/hs04_fig12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_r100['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the sparse representation still looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_sparse(dense: np.array) -> list:\n",
    "    \"\"\"Convert dense representation to sparse representation.\"\"\"\n",
    "    sparse = []\n",
    "    for i, unit in enumerate(dense):\n",
    "        if unit == 1:\n",
    "            sparse.append(i)\n",
    "    return sparse\n",
    "\n",
    "def word_to_sparse(testset: dict, word: str) -> dict:\n",
    "    \"\"\"Convert word to sparse representation.\"\"\"\n",
    "    word_idx = testset['item'].index(word)\n",
    "    return {f\"{x}: {dense_to_sparse(mn_r100[x][word_idx])}\" for x in ['ort', 'pho', 'sem']}\n",
    "\n",
    "\n",
    "word_to_sparse(mn_r100, 'close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF style naming to HS04 naming for reference\n",
    "\n",
    "name_map = {\n",
    "    'input_hos_hs': 'OS',\n",
    "    'input_hop_hp': 'OP',\n",
    "    'input_hps_hs': 'PS',\n",
    "    'input_css_cs': 'CS'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_over_time(x, n_times):\n",
    "    \"\"\"Expand representation to n_times to axis 0\"\"\"\n",
    "    x = tf.Variable(x, dtype=tf.float32)\n",
    "    x = tf.expand_dims(x, axis=0)\n",
    "    x = tf.tile(x, [n_times, 1, 1])\n",
    "    return x\n",
    "\n",
    "sem = expand_over_time(mn_r100['sem'], 13)\n",
    "pho = expand_over_time(mn_r100['pho'], 13)\n",
    "\n",
    "# Checking\n",
    "[tf.assert_equal(sem[i], tf.cast(mn_r100['sem'], dtype=tf.float32)) for i in range(13)]\n",
    "[tf.assert_equal(pho[i], tf.cast(mn_r100['pho'], dtype=tf.float32)) for i in range(13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(y: tf.Tensor, mask: tf.Tensor) -> list:\n",
    "    \"\"\"Get the input over time tick.\n",
    "    Assumed dimensions equal between y and mask:\n",
    "        y: (timetick, word, unit)\n",
    "    \"\"\"\n",
    "    assert y.shape == mask.shape\n",
    "    masked_y = mask * y\n",
    "    mean_y = tf.reduce_sum(masked_y, axis=2) / tf.reduce_sum(mask, axis=2)  # Average over unit dimension among on nodes\n",
    "    return tf.reduce_mean(mean_y, axis=1).numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import CosineSemanticAccuracy\n",
    "acc = CosineSemanticAccuracy()\n",
    "acc(y_true=tf.cast(mn_r100['sem'], tf.float32), y_pred=y_pred['sem'][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw input before TAI\n",
    "op = get_inputs(y_pred['input_hop_hp'], mask=pho)\n",
    "os = get_inputs(y_pred['input_hos_hs'], mask=sem)\n",
    "ps = get_inputs(y_pred['input_hps_hs'], mask=sem)\n",
    "cs = get_inputs(y_pred['input_css_cs'], mask=sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(op, label='O->P')\n",
    "plt.plot(os, label='O->S')\n",
    "plt.plot(ps, label='P->S')\n",
    "plt.plot(cs, label='C->S')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double check with troubleshooting module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from troubleshooting import Diagnosis\n",
    "\n",
    "d = Diagnosis(\"surgery\")\n",
    "d.eval('mn_r100', task=\"triangle\", epoch=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNDiagnosis(Diagnosis):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From old codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "layer = 'sem'\n",
    "target_word = 'close'\n",
    "target_word_idx = mn_r100['item'].index(target_word)\n",
    "bias_name = 'bias_s'\n",
    "\n",
    "df_dict = {}\n",
    "df_dict[\"target_act\"] = mn_r100[layer][target_word_idx, :]\n",
    "df_dict[\"bias\"] = [w.numpy() for w in model.weights if w.name.startswith(bias_name)][0]\n",
    "df_time_invar = pd.DataFrame.from_dict(df_dict)\n",
    "df_time_invar[\"unit\"] = df_time_invar.index\n",
    "df_time_invar[\"word\"] = target_word\n",
    "df_time_invar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEM_NAME_MAP = {\n",
    "    \"input_hps_hs\": \"PS\",\n",
    "    \"input_css_cs\": \"CS\",\n",
    "    \"input_sem\": \"SS\",\n",
    "    \"input_hos_hs\": \"OS\",\n",
    "    \"input_sem\": \"input\",\n",
    "    \"sem\": \"act\",\n",
    "}\n",
    "PHO_NAME_MAP = {\n",
    "    \"input_hsp_hp\": \"SP\",\n",
    "    \"input_cpp_cp\": \"CP\",\n",
    "    \"input_pho_pp\": \"PP\",\n",
    "    \"input_hop_hp\": \"OP\",\n",
    "    \"input_pho\": \"input\",\n",
    "    \"pho\": \"act\",\n",
    "}\n",
    "\n",
    "name_map = SEM_NAME_MAP\n",
    "\n",
    "df_time_varying = pd.DataFrame()\n",
    "\n",
    "for i, model_output_name in enumerate(name_map.keys()):\n",
    "    this_output_df = pd.DataFrame()\n",
    "    for t in range(13):\n",
    "        df_dict = {}\n",
    "        name = name_map[model_output_name]\n",
    "        df_dict[name] = y_pred[model_output_name][t, target_word_idx, :]\n",
    "        this_step_df = pd.DataFrame.from_dict(df_dict)\n",
    "        this_step_df[\"timetick\"] = t\n",
    "        this_step_df[\"unit\"] = this_step_df.index\n",
    "        this_output_df = pd.concat([this_output_df, this_step_df], ignore_index=True)\n",
    "\n",
    "    if i == 0:\n",
    "        df_time_varying = this_output_df\n",
    "    else:\n",
    "        df_time_varying = pd.merge(\n",
    "            df_time_varying, this_output_df, on=[\"timetick\", \"unit\"]\n",
    "        )\n",
    "\n",
    "df_time_varying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and export\n",
    "df = df_time_varying.merge(df_time_invar, on=\"unit\", how=\"left\")\n",
    "df[\"unit_acc\"] = abs(df.target_act - df.act) < 0.5\n",
    "df = df[\n",
    "    [\"word\", \"unit\", \"unit_acc\", \"timetick\", \"target_act\", \"bias\"]\n",
    "    + list(name_map.values())\n",
    "]\n",
    "\n",
    "# Restructure\n",
    "melt_value_vars = [\"bias\"] + list(name_map.values())\n",
    "df = df.melt(\n",
    "    id_vars=[\"word\", \"unit\", \"timetick\", \"target_act\", \"unit_acc\"],\n",
    "    value_vars=melt_value_vars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_on_nodes = df.loc[df.target_act == 1, \"unit\"].unique()\n",
    "all_off_nodes = df.loc[df.target_act == 0, \"unit\"].unique()\n",
    "print(f\"On: {all_on_nodes} \\nOff: {np.random.choice(all_off_nodes, 10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "sel_node = all_on_nodes\n",
    "node_df = df.loc[df.unit.isin(sel_node)]\n",
    "plot_df = node_df.loc[~node_df.variable.isin(['act', 'input', 'SS', 'PP'])]\n",
    "\n",
    "alt.Chart(plot_df).mark_line().encode(\n",
    "    y='mean(value):Q', \n",
    "    x='timetick:Q', \n",
    "    color='variable:N'\n",
    "    ).properties(title=f\"word: {target_word} at nodes: {sel_node}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EoT acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_wrangling\n",
    "def min_cosine_distance_idx(all_reps, pred):\n",
    "    \"\"\"return the index of word that has min cosine distance\"\"\"\n",
    "    all_cosine_dist = [cosine(pred, rep) for rep in all_reps]\n",
    "    return np.argmin(all_cosine_dist) \n",
    "\n",
    "def cosine_accuracy(all_reps, pred, target):\n",
    "    \"\"\"Check whether the prediction is the min cosine distance word\"\"\"\n",
    "    target_idx = min_cosine_distance_idx(all_reps, target)\n",
    "    pred_idx = min_cosine_distance_idx(all_reps, pred)\n",
    "    return target_idx == pred_idx\n",
    "\n",
    "def all_cosine_accuracy(all_reps, preds, targets):\n",
    "    return np.mean([cosine_accuracy(all_reps, pred, target) for pred, target in zip(preds, targets)])\n",
    "\n",
    "def binary_accuracy(pred, target):\n",
    "    \"\"\"Calculate correct side accuracy\"\"\"\n",
    "    d = abs(pred - target)\n",
    "    max_d = np.max(d, axis = 1)\n",
    "    # print(max_d)\n",
    "    return np.mean(max_d < 0.5)\n",
    "\n",
    "def get_all_acc(y_pred):\n",
    "    \"\"\"Calculate accuracy of all outputs\"\"\"\n",
    "    mn_train = data_wrangling.load_testset('mn_r100')\n",
    "    sem_acc = all_cosine_accuracy(all_reps=mn_train['sem'], preds=y_pred['sem'][-1].numpy(), targets=mn_train['sem'])\n",
    "    pho_acc = binary_accuracy(mn_r100['pho'], y_pred['pho'][-1, :, :].numpy())\n",
    "    return {\n",
    "        \"pho\": pho_acc,\n",
    "        \"sem\": sem_acc\n",
    "    }\n",
    "\n",
    "def get_task_acc(task):\n",
    "    \"\"\"Get task acc\"\"\"\n",
    "    model.set_active_task(task)\n",
    "    input_name = modeling.IN_OUT[task][0]\n",
    "    y_pred = model([mn_r100[input_name]] * cfg.n_timesteps)\n",
    "    return get_all_acc(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_task_acc('triangle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
