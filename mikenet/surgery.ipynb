{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surgery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move all the weight and biases from MikeNet to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Keys: ['Phono -> psh', 'Con -> csh', 'psh -> Semantics', 'csh -> Semantics', 'Semantics -> SemCleanup', 'SemCleanup -> Semantics', 'Bias -> Semantics', 'Bias -> SemCleanup', 'Bias -> psh', 'Bias -> csh', 'Semantics -> sph', 'sph -> Phono', 'Phono -> PhoCleanup', 'PhoCleanup -> Phono', 'Bias -> Phono', 'Bias -> sph', 'Bias -> PhoCleanup', 'Ortho -> oph', 'Ortho -> osh', 'oph -> Phono', 'osh -> Semantics', 'Bias -> oph', 'Bias -> osh']\n",
      "\n",
      "Non-weight Keys: ['SimulatorSeed 425840429', 'TAOS Phono', 'DELAYS Phono', 'TAOS psh', 'DELAYS psh', 'TAOS sph', 'DELAYS sph', 'TAOS Semantics', 'DELAYS Semantics', 'TAOS SemCleanup', 'DELAYS SemCleanup', 'TAOS PhoCleanup', 'DELAYS PhoCleanup', 'TAOS Bias', 'DELAYS Bias', 'TAOS Ortho', 'DELAYS Ortho', 'TAOS oph', 'DELAYS oph', 'TAOS osh', 'DELAYS osh', 'TAOS Con', 'DELAYS Con', 'TAOS csh', 'DELAYS csh']\n",
      "\n",
      "Shapes of weights:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Phono -> psh': (200, 300),\n",
       " 'psh -> Semantics': (300, 2446),\n",
       " 'Semantics -> SemCleanup': (2446, 50),\n",
       " 'SemCleanup -> Semantics': (50, 2446),\n",
       " 'Semantics -> sph': (2446, 300),\n",
       " 'sph -> Phono': (300, 200),\n",
       " 'Phono -> PhoCleanup': (200, 50),\n",
       " 'PhoCleanup -> Phono': (50, 200),\n",
       " 'Ortho -> oph': (364, 500),\n",
       " 'Ortho -> osh': (364, 500),\n",
       " 'oph -> Phono': (500, 200),\n",
       " 'osh -> Semantics': (500, 2446),\n",
       " 'Bias -> oph': (500,),\n",
       " 'Bias -> osh': (500,),\n",
       " 'Bias -> Semantics': (2446,),\n",
       " 'Bias -> Phono': (200,),\n",
       " 'Bias -> psh': (300,),\n",
       " 'Bias -> sph': (300,),\n",
       " 'Bias -> SemCleanup': (50,),\n",
       " 'Bias -> PhoCleanup': (50,)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mnutil import MikeNetWeight\n",
    "mn_weight = MikeNetWeight(\"Reading_Weight_v1\")\n",
    "\n",
    "print('\\nShapes of weights:')\n",
    "mn_weight.create_weights_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_name = \"surgery\"\n",
    "batch_name = None\n",
    "tf_root = \"/home/jupyter/triangle_model\"\n",
    "\n",
    "# Model configs\n",
    "ort_units = 364\n",
    "pho_units = 200\n",
    "sem_units = 2446\n",
    "hidden_os_units = 500\n",
    "hidden_op_units = 500\n",
    "hidden_ps_units = 300\n",
    "hidden_sp_units = 300\n",
    "pho_cleanup_units = 50\n",
    "sem_cleanup_units = 50\n",
    "pho_noise_level = 0.\n",
    "sem_noise_level = 0.\n",
    "activation = \"sigmoid\"\n",
    "\n",
    "tau = 1 / 3\n",
    "max_unit_time = 4.0\n",
    "output_ticks = 13\n",
    "inject_error_ticks = 11\n",
    "\n",
    "### Parameter below doesn't matter, because we don't train the model\n",
    "\n",
    "# Training configs\n",
    "learning_rate = 0.005\n",
    "zero_error_radius = 0.1\n",
    "save_freq = 20\n",
    "\n",
    "# Environment configs\n",
    "task_names = [\"pho_sem\", \"sem_pho\", \"pho_pho\", \"sem_sem\", \"ort_pho\", \"ort_sem\", \"triangle\"]\n",
    "wf_compression = \"log\"\n",
    "wf_clip_low = 0\n",
    "wf_clip_high = 999_999_999\n",
    "oral_start_pct = 1.0\n",
    "oral_end_pct = 1.0\n",
    "\n",
    "total_sample = 1_800_000\n",
    "tasks_ps = (0.2, 0.2, 0.05, 0.05, .1, .1, .3)\n",
    "\n",
    "batch_size = 100\n",
    "rng_seed = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UUID not found, regenerating.\n",
      "Saved config json to /triangle_model/models/surgery/model_config.json\n"
     ]
    }
   ],
   "source": [
    "import meta, modeling\n",
    "cfg = meta.Config.from_dict(**globals())\n",
    "model = modeling.MyModel(cfg)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grafting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafted w_hsp_sh from mikenet to TensorFlow\n",
      "Grafted w_hsp_hp from mikenet to TensorFlow\n",
      "Grafted w_pc from mikenet to TensorFlow\n",
      "Grafted w_cp from mikenet to TensorFlow\n",
      "Grafted bias_hsp from mikenet to TensorFlow\n",
      "Grafted bias_p from mikenet to TensorFlow\n",
      "Grafted bias_cpp from mikenet to TensorFlow\n",
      "Grafted w_hps_ph from mikenet to TensorFlow\n",
      "Grafted w_hps_hs from mikenet to TensorFlow\n",
      "Grafted w_sc from mikenet to TensorFlow\n",
      "Grafted w_cs from mikenet to TensorFlow\n",
      "Grafted bias_hps from mikenet to TensorFlow\n",
      "Grafted bias_s from mikenet to TensorFlow\n",
      "Grafted bias_css from mikenet to TensorFlow\n",
      "Grafted w_hos_oh from mikenet to TensorFlow\n",
      "Grafted w_hos_hs from mikenet to TensorFlow\n",
      "Grafted bias_hos from mikenet to TensorFlow\n",
      "Grafted w_hop_oh from mikenet to TensorFlow\n",
      "Grafted w_hop_hp from mikenet to TensorFlow\n",
      "Grafted bias_hop from mikenet to TensorFlow\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "for weight in model.weights:\n",
    "    try:\n",
    "        name = weight.name[:-2]\n",
    "        weight.assign(mn_weight.weights_tf[name])\n",
    "        print(f\"Grafted {name} from mikenet to TensorFlow\")\n",
    "\n",
    "        # Post-load weight sanity check\n",
    "        tf.debugging.assert_equal(mn_weight.weights_tf[name], weight)\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"Missing weight {name} in mikenet\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save grafted weights model into TF checkpoint format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/triangle_model/models/surgery/checkpoints/epoch-1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(\n",
    "    ckpt,\n",
    "    cfg.checkpoint_folder,\n",
    "    max_to_keep=None,  # Keep all checkpoints\n",
    "    checkpoint_name=\"epoch\",\n",
    ")\n",
    "\n",
    "ckpt_manager.save(1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
