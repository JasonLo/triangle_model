{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbgouQwZ1Y1f"
   },
   "source": [
    "# OSP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes:\n",
    "- Absolute path\n",
    "- Flexible zero-error-radius\n",
    "- Examine output by teaching signal and slots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "\n",
    "import h5py, pickle, os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import meta, data_wrangling, modeling, evaluate\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters block for Papermill\n",
    "- Instead of using model_cfg directly, this extra step is needed for batch run using Papermill\n",
    "- Consider carefully the variable type in each cfg setting (Probably automatically check it later...)\n",
    "    - Do not use integer (e.g., 1, 2, 3, 0) in variables that can be float32 (e.g., w_oh_noise, tau...)\n",
    "    - Use integer with a dot instead (e.g., 1., 2., 3., 0.)\n",
    "- To use attractor, two params must be config, \n",
    "    - 1) embed_attractor_cfg --> json cfg file of the pretrain attractor \n",
    "    - 2) embed_attractor_h5 --> h5 file of the exact weight (e.g. ep0500.h5 #epoch or c90.h5 #correct rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "code_name = \"booo2\"\n",
    "\n",
    "sample_name = \"jay\"\n",
    "rng_seed = 53797\n",
    "use_semantic = False\n",
    "\n",
    "# Model architechture\n",
    "input_dim = 4\n",
    "output_dim = 4\n",
    "hidden_units = 100\n",
    "cleanup_units = 20\n",
    "\n",
    "pretrain_attractor = False  # Load pretrained or not\n",
    "\n",
    "# embed_attractor_cfg = 'models/Attractor_{0:02d}/model_config.json'.format(\n",
    "#     cleanup_units\n",
    "# )\n",
    "# embed_attractor_h5 = 'c00.h5'\n",
    "\n",
    "rnn_activation = \"sigmoid\"\n",
    "regularizer_const = None\n",
    "w_initializer = 0.1  # range of uniform random\n",
    "zero_error_radius = 0.5  # When True, zer value = 0.1, hardcoded in modeling.zer_bce()\n",
    "\n",
    "\n",
    "p_noise = 0.0\n",
    "tau = 1 / 3\n",
    "max_unit_time = 4.0\n",
    "output_ticks = 2\n",
    "\n",
    "# Training\n",
    "optimizer = \"adam\"\n",
    "n_mil_sample = 0.1\n",
    "batch_size = 32\n",
    "learning_rate = 0.005\n",
    "save_freq = 10\n",
    "\n",
    "bq_dataset = None\n",
    "batch_unique_setting_string = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for v in meta.model_cfg.minimal_cfgs:\n",
    "    d[v] = globals()[v]\n",
    "\n",
    "for v in meta.model_cfg.aux_cfgs:\n",
    "    try:\n",
    "        d[v] = globals()[v]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "cfg = meta.model_cfg(**d)\n",
    "\n",
    "tf.random.set_seed(cfg.rng_seed)\n",
    "data = data_wrangling.my_data(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace data module by toy data\n",
    "- Input set to 1, 0, 0, 1\n",
    "- Output is 0, 1, 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_input = np.random.choice([0, 1], size=[128, 4])\n",
    "data.x_train = toy_input.astype(\"float32\")\n",
    "not_x = 1 - toy_input\n",
    "data.y_train = not_x.astype(\"float32\")\n",
    "data.sample_p = np.tile(1, 128) / 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0IwxbE29_0yx"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom metrics (in development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Out0(tf.keras.metrics.Metric):\n",
    "    \"\"\"Export last slot average output in last batch of a epoch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"output0\", **kwargs):\n",
    "        super(Out0, self).__init__(name=name, **kwargs)\n",
    "        self.out = self.add_weight(name=\"out0\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.out.assign(tf.reduce_mean(y_pred[y_true == 0]))\n",
    "\n",
    "    def result(self):\n",
    "        return self.out\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.out.assign(0.0)\n",
    "\n",
    "\n",
    "class Out1(tf.keras.metrics.Metric):\n",
    "    \"\"\"Export last slot average output in last batch of a epoch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"output1\", **kwargs):\n",
    "        super(Out1, self).__init__(name=name, **kwargs)\n",
    "        self.out = self.add_weight(name=\"out1\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.out.assign(tf.reduce_mean(y_pred[y_true == 1]))\n",
    "\n",
    "    def result(self):\n",
    "        return self.out\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.out.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Input, concatenate, multiply, RepeatVector\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "\n",
    "def build_model(cfg, training=True):\n",
    "\n",
    "    # Select training or testing mode\n",
    "    cfg.noise_on() if training else cfg.noise_off()\n",
    "\n",
    "    input_o = Input(shape=(cfg.input_dim,), name=\"Input_O\")\n",
    "    input_o_t = RepeatVector(cfg.n_timesteps, name=\"Input_Ot\")(input_o)\n",
    "\n",
    "    rnn_model = modeling.rnn(cfg)(input_o_t)\n",
    "    model = Model(input_o, rnn_model)\n",
    "\n",
    "    op = Adam(learning_rate=cfg.learning_rate, beta_1=0.0, beta_2=0.999, amsgrad=False)\n",
    "    me = [\"BinaryAccuracy\", \"mse\", Out0(), Out1()]\n",
    "\n",
    "    if cfg.zero_error_radius is not None:\n",
    "        print(f\"Using zero-error-radius of {cfg.zero_error_radius}\")\n",
    "\n",
    "        model.compile(\n",
    "            loss=modeling.CustomBCE(radius=cfg.zero_error_radius),\n",
    "            optimizer=op,\n",
    "            metrics=me,\n",
    "        )\n",
    "\n",
    "    elif cfg.zero_error_radius is None:\n",
    "        print(f\"No zero-error-radius\")\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=op, metrics=me)\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKUOoZkP8QiA"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tboard = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=f\"batch_log/{cfg.code_name}\", histogram_freq=1\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    data_wrangling.sample_generator(cfg, data),\n",
    "    steps_per_epoch=1,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[tboard],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir $cfg.path_log_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "basicO2P_master.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-1.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
