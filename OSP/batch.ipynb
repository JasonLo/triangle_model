{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook uses Papermill to batch run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import papermill as pm\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seeds = [int(random.random() * 1e5) for x in range(10)]\n",
    "\n",
    "batch_name = \"O2P_noreg\"\n",
    "\n",
    "# Create batch cfgs\n",
    "batch_cfgs = []\n",
    "i = 0\n",
    "\n",
    "for noise in [0., 4.]:\n",
    "    for h in [25, 100]:\n",
    "        i += 1\n",
    "        code_name = batch_name + \"_model_{:04d}\".format(i)\n",
    "\n",
    "        batch_cfg = dict(\n",
    "            sn=i,\n",
    "            in_notebook=\"OSP_master.ipynb\",\n",
    "            code_name=code_name,\n",
    "            model_folder=\"models/\" + code_name + \"/\",\n",
    "            out_notebook=\"models/\" + code_name + \"/output.ipynb\",\n",
    "            params=dict(\n",
    "                code_name=code_name,\n",
    "                sample_name='hs04',\n",
    "                sample_rng_seed=4321,\n",
    "                tf_rng_seed=4444,\n",
    "                use_semantic=False,\n",
    "                input_dim=119,\n",
    "                hidden_units=h,\n",
    "                output_dim=250,\n",
    "                cleanup_units=50,\n",
    "                use_attractor=False,\n",
    "                rnn_activation='sigmoid',\n",
    "                regularizer_const=5e-6,\n",
    "                p_noise=noise,\n",
    "                tau=0.2,\n",
    "                max_unit_time=4.,\n",
    "                n_mil_sample=2.,\n",
    "                batch_size=128,\n",
    "                learning_rate=0.005,\n",
    "                save_freq=5,\n",
    "                bq_dataset=batch_name\n",
    "            )\n",
    "        )\n",
    "        batch_cfgs.append(batch_cfg)\n",
    "\n",
    "\n",
    "# Run\n",
    "def run_batch(cfg):\n",
    "    try:\n",
    "        print(\"Running model {}\".format(cfg['sn']))\n",
    "\n",
    "        if not os.path.exists(cfg['model_folder']):\n",
    "            os.mkdir(cfg['model_folder'])\n",
    "\n",
    "        pm.execute_notebook(\n",
    "            cfg['in_notebook'],\n",
    "            cfg['out_notebook'],\n",
    "            parameters=cfg['params'],\n",
    "        )\n",
    "\n",
    "    except:\n",
    "        print(\"Error occur in {}\".format(cfg['code_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in parallel pool\n",
    "with Pool(4) as pool:\n",
    "    pool.map(run_batch, batch_cfgs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push results to BQ\n",
    "from meta import model_cfg, connect_gbq\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Make connection to bq\n",
    "bq = connect_gbq()\n",
    "\n",
    "for sn in tqdm(range(len(batch_cfgs))):\n",
    "\n",
    "    model_folder = 'models/{0:s}_model_{1:04d}'.format(batch_name, sn + 1)\n",
    "    strain_i_hist = pd.read_csv(model_folder + '/result_strain_item.csv')\n",
    "    grain_i_hist = pd.read_csv(model_folder + '/result_grain_item.csv')\n",
    "\n",
    "    bq.push_all(\n",
    "        batch_name, batch_cfgs[sn]['params'], strain_i_hist, grain_i_hist\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shutdown compute engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "sleep(30)\n",
    "!sudo poweroff  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "from meta import connect_gbq\n",
    "from evaluate import vis\n",
    "from tqdm import tqdm\n",
    "\n",
    "conn = connect_gbq()\n",
    "cfgs = conn.read_bq_cfg(batch_name)\n",
    "\n",
    "# Read cfg files from BQ\n",
    "print('===== Batch level hyperparams (columns that have >1 unique value) =====')\n",
    "for i, x in enumerate(cfgs.columns):\n",
    "    if not x in ['code_name', 'uuid']:\n",
    "        if len(cfgs[x].unique()) > 1:\n",
    "            print(\n",
    "                'Column <{}> has these unique values: {}'.format(\n",
    "                    x, cfgs[x].unique()\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Parse each run by batch_eval, which aggregate item level data to condition level\n",
    "# and merge Grain and Strain into one single file (Using local files instead of BQ,\n",
    "# may use BQ for way way more data... >5Gbs I guess)\n",
    "\n",
    "models_path = []\n",
    "for i in range(len(cfgs)):\n",
    "    models_path.append('models/' + batch_name + '_model_{0:04d}'.format(i + 1))\n",
    "\n",
    "batch_acc = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(len(cfgs))):\n",
    "\n",
    "    model_path = 'models/' + batch_name + '_model_{0:04d}'.format(i + 1)\n",
    "\n",
    "    this_eval = vis(\n",
    "        model_path, 'result_strain_item.csv', 'result_grain_item.csv'\n",
    "    )  # Eval lesion and grain\n",
    "    this_eval.parse_cond_df()\n",
    "    batch_acc = pd.concat([batch_acc, this_eval.cdf], ignore_index=True)\n",
    "\n",
    "df = pd.merge(batch_acc, cfgs, 'left', 'code_name')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to h5 format\n",
    "df.to_hdf('batch_eval/{}_cdf.h5'.format(batch_name), key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tmp_check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_hdf('batch_eval/{}_cdf.h5'.format(batch_name), 'df')\n",
    "\n",
    "# Plotting results\n",
    "import altair as alt\n",
    "from evaluate import make_df_wnw\n",
    "\n",
    "alt.data_transformers.enable(\"default\")\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# Selectors for interactions\n",
    "sel_run = alt.selection(type=\"multi\", on=\"click\", fields=[\"code_name\"])\n",
    "sel_cond = alt.selection(\n",
    "    type=\"multi\", on=\"click\", fields=[\"cond\"], bind=\"legend\"\n",
    ")\n",
    "\n",
    "# Heatmap for final epoch & timestep (Overview)\n",
    "plot_timestep = df.timestep.max()\n",
    "# plot_timestep = 19\n",
    "\n",
    "# Plot strain\n",
    "\n",
    "df_ov = df[(df.epoch == df.epoch.max()) & (df.timestep == plot_timestep)]\n",
    "\n",
    "overview = (\n",
    "    alt.Chart(df_ov).mark_rect().encode(\n",
    "        x=\"hidden_units:O\",\n",
    "        y=\"p_noise:O\",\n",
    "        column='cond',\n",
    "        row='exp',\n",
    "        color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_run).properties(title=\"Overall Strain accuracy\")\n",
    ")\n",
    "\n",
    "# df_ov_strain = df[(df.epoch == df.epoch.max()) &\n",
    "#                   (df.timestep == plot_timestep) & (df.exp == 'strain')]\n",
    "\n",
    "# overview_strain = (\n",
    "#     alt.Chart(df_ov_strain).mark_rect().encode(\n",
    "#         x=\"hidden_units:O\",\n",
    "#         y=\"p_noise:O\",\n",
    "#         column='cond',\n",
    "#         color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "#         opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "#         tooltip=[\"code_name\", \"acc\"],\n",
    "#     ).add_selection(sel_run).properties(title=\"Overall Strain accuracy\")\n",
    "# )\n",
    "\n",
    "# df_ov_grain = df[(df.epoch == df.epoch.max()) & (df.timestep == plot_timestep) &\n",
    "#                  (df.exp == 'grain')]\n",
    "\n",
    "# overview_grain = (\n",
    "#     alt.Chart(df_ov_grain).mark_rect().encode(\n",
    "#         x=\"hidden_units:O\",\n",
    "#         y=\"p_noise:O\",\n",
    "#         column='cond',\n",
    "#         color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "#         opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "#         tooltip=[\"code_name\", \"acc\"],\n",
    "#     ).add_selection(sel_run).properties(title=\"Overall Grain accuracy\")\n",
    "# )\n",
    "\n",
    "# Accuracy over epoch at last time step for selected model\n",
    "last_time_point = df[df.timestep == df.timestep.max()]\n",
    "\n",
    "acc_plot = (\n",
    "    alt.Chart(last_time_point).mark_line(point=True).encode(\n",
    "        y=alt.Y(\"acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=\"epoch\",\n",
    "        color=\"cond\",\n",
    "        opacity=alt.condition(sel_cond, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_cond).transform_filter(sel_run).properties(\n",
    "        title=\"Full model at final time step\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Accuracy Word (HF-INC) vs. Nonwords\n",
    "wnw_df = make_df_wnw(df, selected_cond=['INC_HF', 'ambiguous', 'unambiguous'])\n",
    "\n",
    "wnw_plot = (\n",
    "    alt.Chart(wnw_df).mark_point().encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        color=alt.Color(\"epoch\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        tooltip=[\"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "    ).transform_filter(sel_run).properties(\n",
    "        title=\"Word vs. Nonword accuracy at final time step\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot diagonal\n",
    "diagline = alt.Chart(pd.DataFrame({\n",
    "    'x': [0, 1],\n",
    "    'y': [0, 1]\n",
    "})).mark_line().encode(x='x', y='y')\n",
    "\n",
    "wnw_with_diag = wnw_plot + diagline\n",
    "\n",
    "# overview = overview_strain & overview_grain\n",
    "mainplots = acc_plot & wnw_with_diag\n",
    "plot = overview | mainplots\n",
    "plot\n",
    "\n",
    "# plot.save('batch_eval/O2P_main_all_HFINC_NW.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_dict = {\n",
    "    'O2P_noreg_model_0001': 'Hidden 25, noise 0',\n",
    "    'O2P_noreg_model_0002': 'Hidden 100, noise 0',\n",
    "    'O2P_noreg_model_0003': 'Hidden 25, noise 4',\n",
    "    'O2P_noreg_model_0004': 'Hidden 100, noise 4',\n",
    "}\n",
    "\n",
    "# Better label\n",
    "wnw_df['group'] = wnw_df.code_name.map(lambda x: cov_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnw_for_epoch_plot = wnw_df.melt(\n",
    "    id_vars=['group', 'epoch'],\n",
    "    value_vars=['word_acc', 'nonword_acc'],\n",
    "    var_name='wnw',\n",
    "    value_name='acc'\n",
    ")\n",
    "\n",
    "wnw_for_epoch_plot['group_wnw'\n",
    "                  ] = wnw_for_epoch_plot.group + wnw_for_epoch_plot.wnw\n",
    "\n",
    "sel_group = alt.selection(\n",
    "    type=\"multi\", on=\"click\", fields=[\"group_wnw\"], bind=\"legend\"\n",
    ")\n",
    "\n",
    "plot_epoch = alt.Chart(wnw_for_epoch_plot).mark_line(point=True).encode(\n",
    "    y=alt.Y(\"acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "    x=\"epoch:Q\",\n",
    "    color=\"group_wnw:N\",\n",
    "    shape=\"wnw\",\n",
    "    opacity=alt.condition(sel_group, alt.value(1), alt.value(0.1)),\n",
    "    tooltip=[\"epoch\", \"acc\"],\n",
    ").add_selection(sel_group).properties(\n",
    "    title=\"Plot word and nonword accuracy by epoch\"\n",
    ")\n",
    "\n",
    "plot_epoch.save('batch_eval/combined4runs_plot_epoch.html')\n",
    "plot_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Word vs. Nonword across 4 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "sel_group = alt.selection(\n",
    "    type=\"multi\", on=\"click\", fields=[\"group\"], bind=\"legend\"\n",
    ")\n",
    "\n",
    "plot_wnw = alt.Chart(wnw_df).mark_line(point=True).encode(\n",
    "    y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "    x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "    color=\"group:N\",\n",
    "    opacity=alt.condition(sel_group, alt.value(1), alt.value(0.1)),\n",
    "    tooltip=[\"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    ").add_selection(sel_group).properties(\n",
    "    title=\"Word vs. Nonword accuracy at final time step\"\n",
    ")\n",
    "\n",
    "plot_wnw.save('batch_eval/combined4runs_plot_wnw.html')\n",
    "\n",
    "plot_wnw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta import model_cfg\n",
    "from evaluate import vis\n",
    "\n",
    "code_name = '{0:}_model_{1:04d}'.format(batch_name, 47)\n",
    "\n",
    "# Load cfg from json\n",
    "cfg = model_cfg(None)\n",
    "cfg.load_cfg_json('models/' + code_name + '/model_config.json')\n",
    "\n",
    "vis = vis(\n",
    "    cfg.path_model_folder, 'result_strain_item.csv', 'result_grain_item.csv'\n",
    ")\n",
    "\n",
    "vis.parse_cond_df()\n",
    "\n",
    "full = vis.plot_dev_interactive('acc').properties(title='Full input')\n",
    "\n",
    "full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible development plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_dev('acc', exp=None, condition='cond', timestep=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible time plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_time('acc', exp='strain', condition='cond', epoch=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
