{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook uses Papermill to batch run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import papermill as pm\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = \"O2P_main\"\n",
    "\n",
    "# Create batch cfgs\n",
    "batch_cfgs = []\n",
    "i = 0\n",
    "\n",
    "for noise in [0., 1., 2., 4., 8.]:\n",
    "    for h in [25, 50, 100, 250]:\n",
    "        for c_unit in [25, 50]:\n",
    "            if c_unit == 25:\n",
    "                for c_stage in [0, 195, 300]:\n",
    "                    # Clean up unit = 25\n",
    "                    i += 1\n",
    "                    code_name = batch_name + \"_model_{:04d}\".format(i)\n",
    "                    batch_cfg = dict(\n",
    "                        sn=i,\n",
    "                        in_notebook=\"basicOSP_master.ipynb\",\n",
    "                        code_name=code_name,\n",
    "                        model_folder=\"models/\" + code_name + \"/\",\n",
    "                        out_notebook=\"models/\" + code_name + \"/output.ipynb\",\n",
    "                        params=dict(\n",
    "                            code_name=code_name,\n",
    "                            sample_name='hs04',\n",
    "                            sample_rng_seed=329,\n",
    "                            tf_rng_seed=123,\n",
    "                            use_semantic=False,\n",
    "                            sem_param_gf=0.,\n",
    "                            sem_param_gi=0.,\n",
    "                            sem_param_kf=0.,\n",
    "                            sem_param_ki=0.,\n",
    "                            sem_param_hf=0.,\n",
    "                            sem_param_hi=0.,\n",
    "                            o_input_dim=119,\n",
    "                            hidden_units=h,\n",
    "                            pho_units=250,\n",
    "                            cleanup_units=c_unit,\n",
    "                            rnn_activation='sigmoid',\n",
    "                            regularizer_const=5e-6,\n",
    "                            embed_attractor_cfg=\n",
    "                            'models/Attractor_{}/model_config.json'.\n",
    "                            format(c_unit),\n",
    "                            embed_attractor_h5='ep{0:04d}.h5'.format(c_stage),\n",
    "                            p_noise=noise,  # i.e. w_pp, w_pc, and w_cp noise\n",
    "                            tau=0.2,\n",
    "                            max_unit_time=4.,\n",
    "                            n_mil_sample=.04,\n",
    "                            batch_size=128,\n",
    "                            learning_rate=0.005,\n",
    "                            save_freq=1,\n",
    "                            bq_dataset=batch_name\n",
    "                        )\n",
    "                    )\n",
    "                    batch_cfgs.append(batch_cfg)\n",
    "\n",
    "            if c_unit == 50:\n",
    "                for c_stage in [0, 70, 125]:\n",
    "                    i += 1\n",
    "                    code_name = batch_name + \"_model_{:04d}\".format(i)\n",
    "                    batch_cfg = dict(\n",
    "                        sn=i,\n",
    "                        in_notebook=\"basicOSP_master.ipynb\",\n",
    "                        code_name=code_name,\n",
    "                        model_folder=\"models/\" + code_name + \"/\",\n",
    "                        out_notebook=\"models/\" + code_name + \"/output.ipynb\",\n",
    "                        params=dict(\n",
    "                            code_name=code_name,\n",
    "                            sample_name='hs04',\n",
    "                            sample_rng_seed=329,\n",
    "                            tf_rng_seed=123,\n",
    "                            use_semantic=False,\n",
    "                            sem_param_gf=0.,\n",
    "                            sem_param_gi=0.,\n",
    "                            sem_param_kf=0.,\n",
    "                            sem_param_ki=0.,\n",
    "                            sem_param_hf=0.,\n",
    "                            sem_param_hi=0.,\n",
    "                            o_input_dim=119,\n",
    "                            hidden_units=h,\n",
    "                            pho_units=250,\n",
    "                            cleanup_units=c_unit,\n",
    "                            rnn_activation='sigmoid',\n",
    "                            regularizer_const=5e-6,\n",
    "                            embed_attractor_cfg=\n",
    "                            'models/Attractor_{}/model_config.json'.\n",
    "                            format(c_unit),\n",
    "                            embed_attractor_h5='ep{0:04d}.h5'.format(c_stage),\n",
    "                            p_noise=noise,  # i.e. w_pp, w_pc, and w_cp noise\n",
    "                            tau=0.2,\n",
    "                            max_unit_time=4.,\n",
    "                            n_mil_sample=.04,\n",
    "                            batch_size=128,\n",
    "                            learning_rate=0.005,\n",
    "                            save_freq=1,\n",
    "                            bq_dataset=batch_name\n",
    "                        )\n",
    "                    )\n",
    "                    batch_cfgs.append(batch_cfg)\n",
    "\n",
    "\n",
    "# Run\n",
    "def run_batch(cfg):\n",
    "    try:\n",
    "        print(\"Running model {}\".format(cfg['sn']))\n",
    "\n",
    "        if not os.path.exists(cfg['model_folder']):\n",
    "            os.mkdir(cfg['model_folder'])\n",
    "\n",
    "        pm.execute_notebook(\n",
    "            cfg['in_notebook'],\n",
    "            cfg['out_notebook'],\n",
    "            parameters=cfg['params'],\n",
    "        )\n",
    "\n",
    "    except:\n",
    "        print(\"Error occur in {}\".format(cfg['code_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in parallel pool\n",
    "# with Pool(4) as pool:\n",
    "#     pool.map(run_batch, batch_cfgs)\n",
    "\n",
    "# Push results to BQ\n",
    "from meta import model_cfg, connect_gbq\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Make connection to bq\n",
    "bq = connect_gbq()\n",
    "\n",
    "for sn in tqdm(range(len(batch_cfgs) + 1)):\n",
    "\n",
    "    model_folder = 'models/{0:s}_model_{1:04d}'.format(batch_name, sn + 1)\n",
    "\n",
    "    # Load model config \n",
    "    cfg = model_cfg(None)\n",
    "    cfg.load_cfg_json(model_folder + '/model_config.json')\n",
    "    cfg.bq_dataset = batch_name\n",
    "\n",
    "    # Load Strain and Grain\n",
    "    strain_i_hist = pd.read_csv(model_folder + '/result_strain_item.csv')\n",
    "    grain_i_hist = pd.read_csv(model_folder + '/result_grain_item.csv')\n",
    "\n",
    "#     bq.push_all(cfg, strain_i_hist, grain_i_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shutdown compute engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "sleep(30)\n",
    "!sudo poweroff  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 120/120 [00:00<00:00, 229.71rows/s]\n",
      "  0%|          | 0/120 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Batch level hyperparams (columns that have >1 unique value) =====\n",
      "Column <hidden_units> has these unique values: [ 50 100 250  25]\n",
      "Column <cleanup_units> has these unique values: [50 25]\n",
      "Column <embed_attractor_cfg> has these unique values: ['models/Attractor_50/model_config.json'\n",
      " 'models/Attractor_25/model_config.json']\n",
      "Column <embed_attractor_h5> has these unique values: ['ep0070.h5' 'ep0195.h5' 'ep0300.h5' 'ep0000.h5' 'ep0125.h5']\n",
      "Column <w_pp_noise> has these unique values: [8. 2. 4. 0. 1.]\n",
      "Column <w_pc_noise> has these unique values: [8. 2. 4. 0. 1.]\n",
      "Column <w_cp_noise> has these unique values: [8. 2. 4. 0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:55<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "from meta import connect_gbq\n",
    "from evaluate import vis\n",
    "from tqdm import tqdm\n",
    "\n",
    "conn = connect_gbq()\n",
    "cfgs = conn.read_bq_cfg(batch_name)\n",
    "\n",
    "# Read cfg files from BQ\n",
    "print('===== Batch level hyperparams (columns that have >1 unique value) =====')\n",
    "for i, x in enumerate(cfgs.columns):\n",
    "    if not x == 'code_name':\n",
    "        if not x == 'uuid':\n",
    "            if len(cfgs[x].unique()) > 1:\n",
    "                print(\n",
    "                    'Column <{}> has these unique values: {}'.format(\n",
    "                        x, cfgs[x].unique()\n",
    "                    )\n",
    "                )\n",
    "\n",
    "# Parse each run by batch_eval, which aggregate item level data to condition level\n",
    "# and merge Grain and Strain into one single file (Using local files instead of BQ,\n",
    "# may use BQ for way way more data... >5Gbs I guess)\n",
    "\n",
    "models_path = []\n",
    "for i in range(len(cfgs)):\n",
    "    models_path.append('models/' + batch_name + '_model_{0:04d}'.format(i + 1))\n",
    "\n",
    "batch_acc = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(len(cfgs))):\n",
    "\n",
    "    model_path = 'models/' + batch_name + '_model_{0:04d}'.format(i + 1)\n",
    "\n",
    "    this_eval = vis(\n",
    "        model_path, 'result_strain_item.csv', 'result_grain_item.csv'\n",
    "    )  # Eval lesion and grain\n",
    "    this_eval.parse_cond_df()\n",
    "    batch_acc = pd.concat([batch_acc, this_eval.cdf], ignore_index=True)\n",
    "\n",
    "df = pd.merge(batch_acc, cfgs, 'left', 'code_name')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/' + batch_name + '_model_{0:04d}'.format(10)\n",
    "\n",
    "this_eval = vis(\n",
    "    model_path, 'result_strain_item.csv', 'result_grain_item.csv'\n",
    ")  # Eval lesion and grain\n",
    "this_eval.parse_cond_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_attractor_acc(cleanup_units, embed_attractor_h5):\n",
    "    if cleanup_units == 25:\n",
    "        if embed_attractor_h5 == 'ep0000.h5':\n",
    "            acc = 0.\n",
    "        if embed_attractor_h5 == 'ep0195.h5':\n",
    "            acc = 0.6\n",
    "        if embed_attractor_h5 == 'ep0300.h5':\n",
    "            acc = 0.9\n",
    "\n",
    "    if cleanup_units == 50:\n",
    "        if embed_attractor_h5 == 'ep0000.h5':\n",
    "            acc = 0.\n",
    "        if embed_attractor_h5 == 'ep0070.h5':\n",
    "            acc = 0.6\n",
    "        if embed_attractor_h5 == 'ep0125.h5':\n",
    "            acc = 0.9\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_acc = []\n",
    "\n",
    "for i in df.index:\n",
    "    tmp_acc.append(\n",
    "        cal_attractor_acc(df.cleanup_units[i], df.embed_attractor_h5[i])\n",
    "    )\n",
    "\n",
    "df['attactor_acc'] = tmp_acc\n",
    "\n",
    "# Save to h5 format\n",
    "df.to_hdf('batch_eval/{}_cdf.h5'.format(batch_name), key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('batch_eval/{}_cdf.h5'.format(batch_name), 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['code_name', 'epoch', 'timestep', 'condition_pf', 'sample_mil',\n",
       "       'unit_time', 'input_s', 'acc', 'sse', 'cond', 'exp', 'condition',\n",
       "       'acc_small_grain', 'sse_small_grain', 'acc_large_grain',\n",
       "       'sse_large_grain', 'uuid', 'sample_name', 'sample_rng_seed',\n",
       "       'tf_rng_seed', 'use_semantic', 'sem_param_gf', 'sem_param_gi',\n",
       "       'sem_param_kf', 'sem_param_ki', 'sem_param_hf', 'sem_param_hi',\n",
       "       'o_input_dim', 'hidden_units', 'pho_units', 'cleanup_units',\n",
       "       'embed_attractor_cfg', 'embed_attractor_h5', 'w_oh_noise', 'w_hp_noise',\n",
       "       'w_pp_noise', 'w_pc_noise', 'w_cp_noise', 'tau', 'max_unit_time',\n",
       "       'n_timesteps', 'n_mil_sample', 'nEpo', 'batch_size', 'steps_per_epoch',\n",
       "       'rnn_activation', 'w_initializer', 'regularizer_const', 'learning_rate',\n",
       "       'save_freq', 'save_freq_sample', 'eval_freq', 'bq_dataset',\n",
       "       'attactor_acc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind = df.loc[(df.timestep == df.timestep.max()) &\n",
    "                (df.cond.isin(['INC_LF', 'ambiguous', 'unambiguous'])), [\n",
    "                    'code_name', 'epoch', 'hidden_units', 'cleanup_units',\n",
    "                    'w_pp_noise', 'attactor_acc', 'acc', 'exp'\n",
    "                ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">attactor_acc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">cleanup_units</th>\n",
       "      <th colspan=\"2\" halign=\"left\">hidden_units</th>\n",
       "      <th colspan=\"2\" halign=\"left\">w_pp_noise</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>grain</th>\n",
       "      <th>strain</th>\n",
       "      <th>grain</th>\n",
       "      <th>strain</th>\n",
       "      <th>grain</th>\n",
       "      <th>strain</th>\n",
       "      <th>grain</th>\n",
       "      <th>strain</th>\n",
       "      <th>grain</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code_name</th>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">O2P_main_model_0001</th>\n",
       "      <th>1</th>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.095833</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.191667</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">O2P_main_model_0120</th>\n",
       "      <th>60</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                acc         attactor_acc        cleanup_units  \\\n",
       "exp                           grain  strain        grain strain         grain   \n",
       "code_name           epoch                                                       \n",
       "O2P_main_model_0001 1      0.004167  0.0125          0.0    0.0            25   \n",
       "                    2      0.095833  0.1000          0.0    0.0            25   \n",
       "                    3      0.191667  0.1125          0.0    0.0            25   \n",
       "                    4      0.254167  0.1250          0.0    0.0            25   \n",
       "                    5      0.600000  0.3250          0.0    0.0            25   \n",
       "...                             ...     ...          ...    ...           ...   \n",
       "O2P_main_model_0120 60     0.000000  0.0000          0.9    0.9            50   \n",
       "                    65     0.000000  0.0250          0.9    0.9            50   \n",
       "                    70     0.000000  0.0250          0.9    0.9            50   \n",
       "                    75     0.033333  0.0250          0.9    0.9            50   \n",
       "                    80     0.033333  0.0500          0.9    0.9            50   \n",
       "\n",
       "                                 hidden_units        w_pp_noise         \n",
       "exp                       strain        grain strain      grain strain  \n",
       "code_name           epoch                                               \n",
       "O2P_main_model_0001 1         25           25     25        0.0    0.0  \n",
       "                    2         25           25     25        0.0    0.0  \n",
       "                    3         25           25     25        0.0    0.0  \n",
       "                    4         25           25     25        0.0    0.0  \n",
       "                    5         25           25     25        0.0    0.0  \n",
       "...                          ...          ...    ...        ...    ...  \n",
       "O2P_main_model_0120 60        50          250    250        8.0    8.0  \n",
       "                    65        50          250    250        8.0    8.0  \n",
       "                    70        50          250    250        8.0    8.0  \n",
       "                    75        50          250    250        8.0    8.0  \n",
       "                    80        50          250    250        8.0    8.0  \n",
       "\n",
       "[2400 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ind.pivot_table(index=['code_name', 'epoch'], columns='exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "import altair as alt\n",
    "\n",
    "alt.data_transformers.enable(\"default\")\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# Selectors for interactions\n",
    "sel_run = alt.selection(type=\"multi\", on=\"click\", fields=[\"code_name\"])\n",
    "sel_cond = alt.selection(\n",
    "    type=\"multi\", on=\"click\", fields=[\"cond\"], bind=\"legend\"\n",
    ")\n",
    "\n",
    "# Heatmap for final epoch & timestep (Overview)\n",
    "plot_timestep = df.timestep.max()\n",
    "# plot_timestep = 19\n",
    "\n",
    "# Plot strain\n",
    "\n",
    "df_ov_strain = df[(df.epoch == df.epoch.max()) &\n",
    "                  (df.timestep == plot_timestep) & (df.exp == 'strain')]\n",
    "\n",
    "overview_strain = (\n",
    "    alt.Chart(df_ov_strain).mark_rect().encode(\n",
    "        x=\"hidden_units:O\",\n",
    "        y=\"w_pp_noise:O\",\n",
    "        column='attactor_acc',\n",
    "        row='cleanup_units',\n",
    "        color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_run)\n",
    ")\n",
    "\n",
    "df_ov_grain = df[(df.epoch == df.epoch.max()) & (df.timestep == plot_timestep) &\n",
    "                 (df.exp == 'grain')]\n",
    "\n",
    "overview_grain = (\n",
    "    alt.Chart(df_ov_grain).mark_rect().encode(\n",
    "        x=\"hidden_units:O\",\n",
    "        y=\"w_pp_noise:O\",\n",
    "        column='attactor_acc',\n",
    "        row='cleanup_units',\n",
    "        color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_run)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy over epoch at last time step for selected model\n",
    "last_time_point = df[df.timestep == df.timestep.max()]\n",
    "\n",
    "acc_plot = (\n",
    "    alt.Chart(last_time_point).mark_line().encode(\n",
    "        y=alt.Y(\"acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=\"epoch\",\n",
    "        color=\"cond\",\n",
    "        opacity=alt.condition(sel_cond, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_cond).transform_filter(sel_run).properties(\n",
    "        title=\"Full model at final time step\"\n",
    "    )\n",
    ")\n",
    "overview = overview_strain & overview_grain\n",
    "plot = overview | acc_plot\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.save('batch_eval/O2P_l2reg.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta import model_cfg\n",
    "from evaluate import vis\n",
    "\n",
    "code_name = '{0:}_model_{1:04d}'.format(batch_name, 47)\n",
    "\n",
    "# Load cfg from json\n",
    "cfg = model_cfg(None)\n",
    "cfg.load_cfg_json('models/' + code_name + '/model_config.json')\n",
    "\n",
    "vis = vis(\n",
    "    cfg.path_model_folder, 'result_strain_item.csv', 'result_grain_item.csv'\n",
    ")\n",
    "\n",
    "vis.parse_cond_df()\n",
    "\n",
    "full = vis.plot_dev_interactive('acc').properties(title='Full input')\n",
    "\n",
    "full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible development plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_dev('acc', exp=None, condition='cond', timestep=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible time plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_time('acc', exp='strain', condition='cond', epoch=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
