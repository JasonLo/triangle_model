{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook uses Papermill to batch run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import papermill as pm\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = \"O2P_main\"\n",
    "\n",
    "# Create batch cfgs\n",
    "batch_cfgs = []\n",
    "i = 0\n",
    "\n",
    "for noise in [0., 1., 2., 4., 8.]:\n",
    "    for h in [25, 50, 100, 250]:\n",
    "        for c_unit in [25, 50]:\n",
    "            if c_unit == 25:\n",
    "                for c_stage in [0, 195, 300]:\n",
    "                    # Clean up unit = 25\n",
    "                    i += 1\n",
    "                    code_name = batch_name + \"_model_{:04d}\".format(i)\n",
    "                    batch_cfg = dict(\n",
    "                        sn=i,\n",
    "                        in_notebook=\"basicOSP_master.ipynb\",\n",
    "                        code_name=code_name,\n",
    "                        model_folder=\"models/\" + code_name + \"/\",\n",
    "                        out_notebook=\"models/\" + code_name + \"/output.ipynb\",\n",
    "                        params=dict(\n",
    "                            code_name=code_name,\n",
    "                            sample_name='hs04',\n",
    "                            sample_rng_seed=329,\n",
    "                            tf_rng_seed=123,\n",
    "                            use_semantic=False,\n",
    "                            sem_param_gf=0.,\n",
    "                            sem_param_gi=0.,\n",
    "                            sem_param_kf=0.,\n",
    "                            sem_param_ki=0.,\n",
    "                            sem_param_hf=0.,\n",
    "                            sem_param_hi=0.,\n",
    "                            o_input_dim=119,\n",
    "                            hidden_units=h,\n",
    "                            pho_units=250,\n",
    "                            cleanup_units=c_unit,\n",
    "                            rnn_activation='sigmoid',\n",
    "                            regularizer_const=5e-6,\n",
    "                            embed_attractor_cfg=\n",
    "                            'models/Attractor_{}/model_config.json'.\n",
    "                            format(c_unit),\n",
    "                            embed_attractor_h5='ep{0:04d}.h5'.format(c_stage),\n",
    "                            p_noise=noise,  # i.e. w_pp, w_pc, and w_cp noise\n",
    "                            tau=0.2,\n",
    "                            max_unit_time=4.,\n",
    "                            n_mil_sample=1.,\n",
    "                            batch_size=128,\n",
    "                            learning_rate=0.005,\n",
    "                            save_freq=5,\n",
    "                            bq_dataset=batch_name\n",
    "                        )\n",
    "                    )\n",
    "                    batch_cfgs.append(batch_cfg)\n",
    "\n",
    "            if c_unit == 50:\n",
    "                for c_stage in [0, 70, 125]:\n",
    "                    i += 1\n",
    "                    code_name = batch_name + \"_model_{:04d}\".format(i)\n",
    "                    batch_cfg = dict(\n",
    "                        sn=i,\n",
    "                        in_notebook=\"basicOSP_master.ipynb\",\n",
    "                        code_name=code_name,\n",
    "                        model_folder=\"models/\" + code_name + \"/\",\n",
    "                        out_notebook=\"models/\" + code_name + \"/output.ipynb\",\n",
    "                        params=dict(\n",
    "                            code_name=code_name,\n",
    "                            sample_name='hs04',\n",
    "                            sample_rng_seed=329,\n",
    "                            tf_rng_seed=123,\n",
    "                            use_semantic=False,\n",
    "                            sem_param_gf=0.,\n",
    "                            sem_param_gi=0.,\n",
    "                            sem_param_kf=0.,\n",
    "                            sem_param_ki=0.,\n",
    "                            sem_param_hf=0.,\n",
    "                            sem_param_hi=0.,\n",
    "                            o_input_dim=119,\n",
    "                            hidden_units=h,\n",
    "                            pho_units=250,\n",
    "                            cleanup_units=c_unit,\n",
    "                            rnn_activation='sigmoid',\n",
    "                            regularizer_const=5e-6,\n",
    "                            embed_attractor_cfg=\n",
    "                            'models/Attractor_{}/model_config.json'.\n",
    "                            format(c_unit),\n",
    "                            embed_attractor_h5='ep{0:04d}.h5'.format(c_stage),\n",
    "                            p_noise=noise,  # i.e. w_pp, w_pc, and w_cp noise\n",
    "                            tau=0.2,\n",
    "                            max_unit_time=4.,\n",
    "                            n_mil_sample=1.,\n",
    "                            batch_size=128,\n",
    "                            learning_rate=0.005,\n",
    "                            save_freq=5,\n",
    "                            bq_dataset=batch_name\n",
    "                        )\n",
    "                    )\n",
    "                    batch_cfgs.append(batch_cfg)\n",
    "\n",
    "\n",
    "# Run\n",
    "def run_batch(cfg):\n",
    "    try:\n",
    "        print(\"Running model {}\".format(cfg['sn']))\n",
    "\n",
    "        if not os.path.exists(cfg['model_folder']):\n",
    "            os.mkdir(cfg['model_folder'])\n",
    "\n",
    "        pm.execute_notebook(\n",
    "            cfg['in_notebook'],\n",
    "            cfg['out_notebook'],\n",
    "            parameters=cfg['params'],\n",
    "        )\n",
    "\n",
    "    except:\n",
    "        print(\"Error occur in {}\".format(cfg['code_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in parallel pool\n",
    "# with Pool(4) as pool:\n",
    "#     pool.map(run_batch, batch_cfgs)\n",
    "\n",
    "# Push results to BQ\n",
    "from meta import model_cfg, connect_gbq\n",
    "import pandas as pd\n",
    "\n",
    "# Make connection to bq\n",
    "bq = connect_gbq()\n",
    "\n",
    "for sn in range(1, len(batch_cfgs) + 1):\n",
    "\n",
    "    model_folder = 'models/{0:s}_model_{1:04d}'.format(batch_name, sn)\n",
    "    \n",
    "    # Load model config\n",
    "    cfg = model_cfg(None)\n",
    "    cfg.load_cfg_json(model_folder + '/model_config.json')\n",
    "    cfg.bq_dataset = batch_name\n",
    "    \n",
    "    # Load Strain and Grain\n",
    "    strain_i_hist = pd.read_csv(model_folder + '/result_strain_item.csv')\n",
    "    grain_i_hist = pd.read_csv(model_folder + '/result_grain_item.csv')\n",
    "    bq.push_all(cfg, strain_i_hist, grain_i_hist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shutdown compute engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo poweroff  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "from meta import read_bq_cfg\n",
    "from evaluate import vis\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# batch_name = 'O2P_weightdecay'\n",
    "save_fig = None\n",
    "cfgs = read_bq_cfg(batch_name)\n",
    "\n",
    "# Read cfg files from BQ\n",
    "print('===== Batch level hyperparams (columns that have >1 unique value) =====')\n",
    "for i, x in enumerate(cfgs.columns):\n",
    "    if not x == 'code_name':\n",
    "        if not x == 'uuid':\n",
    "            if len(cfgs[x].unique()) > 1:\n",
    "                print(\n",
    "                    'Column <{}> has these unique values: {}'.format(\n",
    "                        x, cfgs[x].unique()\n",
    "                    )\n",
    "                )\n",
    "\n",
    "# Parse each run by batch_eval, which aggregate item level data to condition level \n",
    "# and merge Grain and Strain into one single file (Using local files instead of BQ, \n",
    "# may use BQ for way way more data... >5Gbs I guess)\n",
    "\n",
    "models_path = [\n",
    "    'models/' + batch_name + '_model_{0:04d}'.format(i)\n",
    "    for i in range(1,\n",
    "                   len(cfgs) + 1)\n",
    "]\n",
    "batch_acc = pd.DataFrame()\n",
    "\n",
    "for i, name in enumerate(models_path):\n",
    "    this_eval = vis(\n",
    "        name, 'result_strain_item.csv', 'result_grain_item.csv'\n",
    "    )  # Eval lesion and grain\n",
    "    this_eval.parse_cond_df()\n",
    "    batch_acc = pd.concat([batch_acc, this_eval.cdf], ignore_index=True)\n",
    "\n",
    "df = pd.merge(batch_acc, cfgs, 'left', 'code_name')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_attractor_acc(cleanup_units, embed_attractor_h5):\n",
    "    if cleanup_units == 25:\n",
    "        if embed_attractor_h5 == 'ep0000.h5':\n",
    "            acc = 0.\n",
    "        if embed_attractor_h5 == 'ep0195.h5':\n",
    "            acc = 0.6\n",
    "        if embed_attractor_h5 == 'ep0300.h5':\n",
    "            acc = 0.9\n",
    "\n",
    "    if cleanup_units == 50:\n",
    "        if embed_attractor_h5 == 'ep0000.h5':\n",
    "            acc = 0.\n",
    "        if embed_attractor_h5 == 'ep0070.h5':\n",
    "            acc = 0.6\n",
    "        if embed_attractor_h5 == 'ep0125.h5':\n",
    "            acc = 0.9\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_acc = []\n",
    "\n",
    "for i in df.index:\n",
    "    tmp_acc.append(\n",
    "        cal_attractor_acc(df.cleanup_units[i], df.embed_attractor_h5[i])\n",
    "    )\n",
    "\n",
    "df['attactor_acc'] = tmp_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "import altair as alt\n",
    "\n",
    "alt.data_transformers.enable(\"default\")\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# Selectors for interactions\n",
    "sel_run = alt.selection(type=\"multi\", on=\"click\", fields=[\"code_name\"])\n",
    "sel_cond = alt.selection(\n",
    "    type=\"multi\", on=\"click\", fields=[\"cond\"], bind=\"legend\"\n",
    ")\n",
    "\n",
    "# Heatmap for final epoch & timestep (Overview)\n",
    "plot_timestep = df.timestep.max()\n",
    "# plot_timestep = 19\n",
    "\n",
    "# Plot strain\n",
    "\n",
    "df_epo_time = df[(df.epoch == df.epoch.max()) & (df.timestep == plot_timestep) &\n",
    "                 (df.exp == 'strain')]\n",
    "\n",
    "overview = (\n",
    "    alt.Chart(df_epo_time).mark_rect().encode(\n",
    "        x=\"hidden_units:O\",\n",
    "        y=\"w_pp_noise:O\",\n",
    "        column='attactor_acc',\n",
    "        row='cleanup_units',\n",
    "        color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_run)\n",
    ")\n",
    "\n",
    "# Accuracy over epoch at last time step for selected model\n",
    "last_time_point = df[df.timestep == df.timestep.max()]\n",
    "\n",
    "acc_plot = (\n",
    "    alt.Chart(last_time_point).mark_line().encode(\n",
    "        y=alt.Y(\"acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=\"epoch\",\n",
    "        color=\"cond\",\n",
    "        opacity=alt.condition(sel_cond, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_cond).transform_filter(sel_run).properties(\n",
    "        title=\"Full model at final time step\"\n",
    "    )\n",
    ")\n",
    "\n",
    "plot = overview | acc_plot\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.save('batch_eval/O2P_l2reg.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta import model_cfg\n",
    "from evaluate import vis\n",
    "\n",
    "code_name = '{0:}_model_{1:04d}'.format(batch_name, 47)\n",
    "\n",
    "# Load cfg from json\n",
    "cfg = model_cfg(None)\n",
    "cfg.load_cfg_json('models/' + code_name + '/model_config.json')\n",
    "\n",
    "vis = vis(\n",
    "    cfg.path_model_folder, 'result_strain_item.csv', 'result_grain_item.csv'\n",
    ")\n",
    "\n",
    "vis.parse_cond_df()\n",
    "\n",
    "full = vis.plot_dev_interactive('acc').properties(title='Full input')\n",
    "\n",
    "full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible development plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_dev('acc', exp=None, condition='cond', timestep=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible time plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_time('acc', exp='strain', condition='cond', epoch=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive for other batches (for record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## semantic_lr_batch\n",
    "- Purpose: Examine learning rate effect interaction with g and k\n",
    "- Hyperparams: lr, g, k\n",
    "- Modeling branch: OSP (Feedforward)\n",
    "- Total models: 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "from meta import read_bq_cfg\n",
    "from evaluate import vis\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# batch_name = 'over_ride_batch_name_here'\n",
    "save_fig = None\n",
    "cfgs = read_bq_cfg(batch_name)\n",
    "\n",
    "# Read cfg files from BQ\n",
    "print('===== Batch level hyperparams (columns that have >1 unique value) =====')\n",
    "for i, x in enumerate(cfgs.columns):\n",
    "    if not x == 'code_name':\n",
    "        if not x == 'uuid':\n",
    "            if len(cfgs[x].unique()) > 1:\n",
    "                print(\n",
    "                    'Column <{}> has these unique values: {}'.format(\n",
    "                        x, cfgs[x].unique()\n",
    "                    )\n",
    "                )\n",
    "\n",
    "# Parse each run by batch_eval, which aggregate item level data to condition level and merge Grain and Strain into one single file (Using local files instead of BQ, may use BQ for way way more data... >5Gbs I guess)\n",
    "\n",
    "models_path = ['models/' + batch_name + '_model_{0:04d}'.format(i) for i in range(1, 13)]\n",
    "batch_acc = pd.DataFrame()\n",
    "\n",
    "for i, name in enumerate(models_path):\n",
    "    # for i, name in enumerate(os.listdir(\"models/\")):\n",
    "    this_eval = vis(name, 'result_strain_ns_item.csv', 'result_grain_item.csv') # Eval lesion and grain\n",
    "    this_eval.parse_cond_df()\n",
    "    batch_acc = pd.concat(\n",
    "        [batch_acc, this_eval.cdf], ignore_index=True\n",
    "    )\n",
    "\n",
    "df = pd.merge(batch_acc, cfgs, 'left', 'code_name')\n",
    "print('Done')\n",
    "\n",
    "# Plotting results\n",
    "import altair as alt\n",
    "\n",
    "alt.data_transformers.enable(\"default\")\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# Selectors for interactions\n",
    "sel_run = alt.selection(type=\"multi\", on=\"click\", fields=[\"code_name\"])\n",
    "sel_cond = alt.selection(\n",
    "    type=\"multi\", on=\"click\", fields=[\"cond\"], bind=\"legend\"\n",
    ")\n",
    "\n",
    "# Heatmap for final epoch & timestep (Overview)\n",
    "final_epo_time = df[(df.epoch == df.epoch.max()) &\n",
    "                    (df.timestep == df.timestep.max())]\n",
    "\n",
    "overview = (\n",
    "    alt.Chart(final_epo_time).mark_rect().encode(\n",
    "        y=\"sem_param_kf:O\",\n",
    "        x=\"sem_param_gf:O\",\n",
    "        column=\"learning_rate:Q\",\n",
    "        row = 'exp',\n",
    "        color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_run)\n",
    ")\n",
    "\n",
    "# Accuracy over epoch at last time step for selected model\n",
    "last_time_point = df[df.timestep == df.timestep.max()]\n",
    "\n",
    "acc_plot = (\n",
    "    alt.Chart(last_time_point).mark_line().encode(\n",
    "        y=\"acc:Q\",\n",
    "        x=\"epoch\",\n",
    "        color=\"cond\",\n",
    "        opacity=alt.condition(sel_cond, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_cond).transform_filter(sel_run).properties(\n",
    "        title=\"At final time step\"\n",
    "    )\n",
    ")\n",
    "\n",
    "plot = overview | acc_plot\n",
    "plot.save('batch_eval/batch_lr_g_k_12.html')\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch 3\n",
    "- Purpose: Extra plotting for Pretrain attractor\n",
    "- Hyperparams: hidden, pretrain or not\n",
    "- Modeling branch: OSP\n",
    "- Total models: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "from meta import batch_eval, read_bq_cfg\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# batch_name = 'over_ride_batch_name_here'\n",
    "save_fig = None\n",
    "cfgs = read_bq_cfg(batch_name)\n",
    "\n",
    "# Read cfg files from BQ\n",
    "print('===== Batch level hyperparams (columns that have >1 unique value) =====')\n",
    "for i, x in enumerate(cfgs.columns):\n",
    "    if not x == 'code_name':\n",
    "        if not x == 'uuid':\n",
    "            if len(cfgs[x].unique()) > 1:\n",
    "                print(\n",
    "                    'Column <{}> has these unique values: {}'.format(\n",
    "                        x, cfgs[x].unique()\n",
    "                    )\n",
    "                )\n",
    "\n",
    "# Parse each run by batch_eval, which aggregate item level data to condition level and merge Grain and Strain into one single file (Using local files instead of BQ, may use BQ for way way more data... >5Gbs I guess)\n",
    "\n",
    "models_path = [batch_name + '_model_{0:04d}'.format(i) for i in range(1, 9)]\n",
    "batch_acc = pd.DataFrame()\n",
    "\n",
    "for i, name in enumerate(models_path):\n",
    "    # for i, name in enumerate(os.listdir(\"models/\")):\n",
    "    if name.startswith(batch_name):\n",
    "        this_eval = batch_eval(name)\n",
    "        batch_acc = pd.concat(\n",
    "            [batch_acc, this_eval.export_result()], ignore_index=True\n",
    "        )\n",
    "\n",
    "df = pd.merge(batch_acc, cfgs, 'left', 'code_name')\n",
    "print('Done')\n",
    "\n",
    "# Plotting results\n",
    "import altair as alt\n",
    "\n",
    "alt.data_transformers.enable(\"default\")\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# Selectors for interactions\n",
    "sel_run = alt.selection(type=\"multi\", on=\"click\", fields=[\"code_name\"])\n",
    "sel_cond = alt.selection(\n",
    "    type=\"multi\", on=\"click\", fields=[\"cond\"], bind=\"legend\"\n",
    ")\n",
    "\n",
    "# Heatmap for final epoch & timestep (Overview)\n",
    "final_epo_time = df[(df.epoch == df.epoch.max()) &\n",
    "                    (df.timestep == df.timestep.max())]\n",
    "\n",
    "overview = (\n",
    "    alt.Chart(final_epo_time).mark_rect().encode(\n",
    "        y=\"cond:N\",\n",
    "        x=\"regularizer_const:O\",\n",
    "        color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_run)\n",
    ")\n",
    "\n",
    "# Accuracy over epoch at last time step for selected model\n",
    "last_time_point = df[df.timestep == df.timestep.max()]\n",
    "\n",
    "acc_plot = (\n",
    "    alt.Chart(last_time_point).mark_line().encode(\n",
    "        y=\"acc:Q\",\n",
    "        x=\"epoch\",\n",
    "        color=\"cond\",\n",
    "        opacity=alt.condition(sel_cond, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_cond).transform_filter(sel_run).properties(\n",
    "        title=\"At final time step\"\n",
    "    )\n",
    ")\n",
    "\n",
    "plot = overview | acc_plot\n",
    "if save_fig is not None:\n",
    "    plot.save(save_fig)\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch 2\n",
    "- Purpose: Replicate OP models result\n",
    "- Hyperparams: p-noise, hidden, and clean up\n",
    "- Modeling branch: OSP\n",
    "- Total models: 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "alt.data_transformers.enable(\"default\")\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "sel_run = alt.selection(type=\"multi\", on=\"click\", fields=[\"code_name\"])\n",
    "sel_cond = alt.selection(\n",
    "    type=\"multi\", on=\"click\", fields=[\"cond\"], bind=\"legend\"\n",
    ")\n",
    "\n",
    "final_epo_time = df[(df.epoch == df.epoch.max()) &\n",
    "                    (df.timestep == df.timestep.max())]\n",
    "\n",
    "overview = (\n",
    "    alt.Chart(final_epo_time).mark_rect().encode(\n",
    "        y=\"hidden_units:O\",\n",
    "        x=\"cleanup_units:O\",\n",
    "        column=\"w_pp_noise\",\n",
    "        row=\"exp\",\n",
    "        color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_run)\n",
    ")\n",
    "\n",
    "last_time_point = df[df.timestep == df.timestep.max()]\n",
    "\n",
    "acc_plot = (\n",
    "    alt.Chart(last_time_point).mark_line().encode(\n",
    "        y=\"acc:Q\",\n",
    "        x=\"epoch\",\n",
    "        color=\"cond\",\n",
    "        opacity=alt.condition(sel_cond, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_cond).transform_filter(sel_run).properties(\n",
    "        title=\"At final time step\"\n",
    "    )\n",
    ")\n",
    "\n",
    "plot = overview | acc_plot\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch 1\n",
    "- Purpose: Initial testing\n",
    "- Hyperparams: p-noise, hidden, and clean up\n",
    "- Modeling branch: OP\n",
    "- Total models: 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a eval script snapshot for batch1 eval\n",
    "# Put in OSP folder to run\n",
    "# Use meta eval block for development\n",
    "\n",
    "batch_name = \"batch_v1\"\n",
    "\n",
    "from meta import read_bq_cfg\n",
    "cfgs = read_bq_cfg('batch_test')\n",
    "\n",
    "# Read cfg files from BQ\n",
    "print('===== Check columns that has multiple unique values =====')\n",
    "for i, x in enumerate(cfgs.columns):\n",
    "    if not x == 'code_name':\n",
    "        if not x == 'uuid':\n",
    "            if len(cfgs[x].unique()) > 1:\n",
    "                print('Column: {} has these unique values: {}'.format(\n",
    "                    x, cfgs[x].unique()))\n",
    "\n",
    "import os, json\n",
    "import pandas as pd\n",
    "from meta import batch_eval\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Read all local results\n",
    "batch_acc = pd.DataFrame()\n",
    "\n",
    "from meta import model_cfg\n",
    "\n",
    "class batch_eval():\n",
    "    def __init__(self, model_folder):\n",
    "        from evaluate import training_history, strain_eval, grain_eval, plot_development\n",
    "        from data_wrangling import my_data\n",
    "        import altair as plt\n",
    "\n",
    "        self.model_folder = 'models/' + model_folder\n",
    "        self.load_config()\n",
    "        self.read_eval_from_file()\n",
    "        self.max_epoch = self.strain_i_hist['epoch'].max()\n",
    "\n",
    "    def load_config(self):\n",
    "        self.cfg = model_cfg(None)\n",
    "        self.cfg.load_cfg_json(self.model_folder + '/model_config.json')\n",
    "\n",
    "    def training_hist(self):\n",
    "        self.t_hist = training_history(self.cfg.path_history_pickle)\n",
    "        return self.t_hist.plot_all()\n",
    "\n",
    "    def read_eval_from_file(self):\n",
    "        self.strain_i_hist = pd.read_csv(self.model_folder +\n",
    "                                         '/result_strain_item.csv')\n",
    "        self.grain_i_hist = pd.read_csv(self.model_folder +\n",
    "                                        '/result_grain_item.csv')\n",
    "\n",
    "    def parse_strain_cond_df(self, cond):\n",
    "        self.strain_i_hist['code_name'] = self.strain_i_hist.model_version\n",
    "        self.scdf = self.strain_i_hist[[\n",
    "            'code_name', 'epoch', 'sample_mil', 'timestep', 'unit_time', cond,\n",
    "            'input_s', 'acc', 'sse'\n",
    "        ]]\n",
    "        self.scdf = self.scdf.groupby(['code_name', 'epoch', 'timestep', cond],\n",
    "                                      as_index=False).mean()\n",
    "        self.scdf['cond'] = self.scdf[cond]\n",
    "        self.scdf['exp'] = 'strain'\n",
    "\n",
    "    def parse_grain_cond_df(self, cond):\n",
    "        self.grain_i_hist['code_name'] = self.grain_i_hist.model_version\n",
    "        self.gcdf = self.grain_i_hist[[\n",
    "            'code_name', 'epoch', 'sample_mil', 'timestep', 'unit_time', cond,\n",
    "            'input_s', 'acc_acceptable', 'sse_acceptable'\n",
    "        ]]\n",
    "        self.gcdf = self.gcdf.rename(columns={\n",
    "            'acc_acceptable': 'acc',\n",
    "            'sse_acceptable': 'sse'\n",
    "        })\n",
    "        self.gcdf = self.gcdf.groupby(['code_name', 'epoch', 'timestep', cond],\n",
    "                                      as_index=False).mean()\n",
    "        self.gcdf['cond'] = self.gcdf[cond]\n",
    "        self.gcdf['exp'] = 'grain'\n",
    "\n",
    "    def parse_cond_df(self,\n",
    "                      cond_strain='condition_pf',\n",
    "                      cond_grain='condition'):\n",
    "        self.parse_strain_cond_df(cond_strain)\n",
    "        self.parse_grain_cond_df(cond_grain)\n",
    "        self.cdf = pd.concat([self.scdf, self.gcdf], sort=False)\n",
    "\n",
    "    def plot_dev(self, y, time_step=None):\n",
    "\n",
    "        if time_step == None: time_step = self.cfg.n_timesteps - 1\n",
    "\n",
    "        title = '{} at timestep {} / unit time {}'.format(\n",
    "            y, plot_time_step + 1, self.cfg.unit_time)\n",
    "        sel = alt.selection(type='single',\n",
    "                            on='click',\n",
    "                            fields=['cond'],\n",
    "                            empty='all')\n",
    "        plot = alt.Chart(\n",
    "            self.cdf[lambda x: x['timestep'] == time_step]).mark_line(\n",
    "                point=True).encode(\n",
    "                    y=y,\n",
    "                    x='epoch:Q',\n",
    "                    color='cond',\n",
    "                    opacity=alt.condition(sel, alt.value(1), alt.value(0)),\n",
    "                    tooltip=[\n",
    "                        'epoch', 'timestep', 'sample_mil', 'acc', 'sse'\n",
    "                    ]).add_selection(sel).interactive().properties(title=title)\n",
    "\n",
    "        return plot\n",
    "\n",
    "    def plot_time(self, y, epoch=None):\n",
    "        if epoch == None: epoch = self.max_epoch\n",
    "        title = '{} at epoch {} '.format(y, epoch)\n",
    "        sel = alt.selection(type='single',\n",
    "                            on='click',\n",
    "                            fields=['cond'],\n",
    "                            empty='all')\n",
    "\n",
    "        plot = alt.Chart(self.cdf[lambda x: x['epoch'] == epoch]).mark_line(\n",
    "            point=True).encode(\n",
    "                y=y,\n",
    "                x='unit_time:Q',\n",
    "                color='cond',\n",
    "                opacity=alt.condition(sel, alt.value(1), alt.value(0)),\n",
    "                tooltip=[\n",
    "                    'epoch', 'timestep', 'sample_mil', 'acc', 'sse'\n",
    "                ]).add_selection(sel).interactive().properties(title=title)\n",
    "\n",
    "        return plot\n",
    "\n",
    "    def plots(self,\n",
    "              mode,\n",
    "              ys,\n",
    "              cond_strain='condition_pf',\n",
    "              cond_grain='condition'):\n",
    "        # Mode = dev(d) / time(t)\n",
    "        self.parse_cond_df(cond_strain, cond_grain)\n",
    "\n",
    "        plots = alt.hconcat()\n",
    "        for y in ys:\n",
    "            if mode == 'd':\n",
    "                plots |= self.plot_dev(y, cond_strain, cond_grain)\n",
    "            elif mode == 't':\n",
    "                plots |= self.plot_time(y, self.max_epoch, cond_strain,\n",
    "                                        cond_grain)\n",
    "            else:\n",
    "                print('Use d for development plot, use t for time plot')\n",
    "\n",
    "        return plots\n",
    "\n",
    "    def export_result(self):\n",
    "        self.parse_cond_df()\n",
    "        return self.cdf.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Parse each run by batch_eval, which aggregate item level data to condition level and merge Grain and Strain into one single file\n",
    "\n",
    "for i, name in enumerate(\n",
    "    ['batch_v1_model_{0:04d}'.format(i) for i in range(1, 36 + 1)]):\n",
    "    # for i, name in enumerate(os.listdir(\"models/\")):\n",
    "    if name.startswith(batch_name):\n",
    "        this_eval = batch_eval(name)\n",
    "        batch_acc = pd.concat([batch_acc, this_eval.export_result()],\n",
    "                              ignore_index=True)\n",
    "\n",
    "df = pd.merge(batch_acc, cfgs, 'left', 'code_name')\n",
    "clear_output()\n",
    "print('Done')\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "alt.data_transformers.enable(\"default\")\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "sel_run = alt.selection(type=\"multi\", on=\"click\", fields=[\"code_name\"])\n",
    "sel_cond = alt.selection(type=\"multi\",\n",
    "                         on=\"click\",\n",
    "                         fields=[\"cond\"],\n",
    "                         bind=\"legend\")\n",
    "\n",
    "final_epo_time = df[(df.epoch == df.epoch.max())\n",
    "                    & (df.timestep == df.timestep.max())]\n",
    "\n",
    "overview = (alt.Chart(final_epo_time).mark_rect().encode(\n",
    "    y=\"hidden_units:O\",\n",
    "    x=\"cleanup_units:O\",\n",
    "    column=\"w_pp_noise\",\n",
    "    row=\"exp\",\n",
    "    color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "    opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "    tooltip=[\"code_name\", \"acc\"],\n",
    ").add_selection(sel_run))\n",
    "\n",
    "last_time_point = df[df.timestep == df.timestep.max()]\n",
    "\n",
    "acc_plot = (alt.Chart(last_time_point).mark_line().encode(\n",
    "    y=\"acc:Q\",\n",
    "    x=\"epoch\",\n",
    "    color=\"cond\",\n",
    "    opacity=alt.condition(sel_cond, alt.value(1), alt.value(0.1)),\n",
    "    tooltip=[\"code_name\", \"acc\"],\n",
    ").add_selection(sel_cond).transform_filter(sel_run).properties(\n",
    "    title=\"At final time step\"))\n",
    "\n",
    "plot = overview | acc_plot\n",
    "plot.save('batch_eval.html')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
