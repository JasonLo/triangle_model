{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook uses Papermill to batch run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import papermill as pm\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = \"O2P_main\"\n",
    "\n",
    "# Create batch cfgs\n",
    "batch_cfgs = []\n",
    "i = 0\n",
    "\n",
    "for noise in [0., 1., 2., 4., 8.]:\n",
    "    for h in [25, 50, 100, 250]:\n",
    "        for c_unit in [25, 50]:\n",
    "            if c_unit == 25:\n",
    "                for c_stage in [0, 195, 300]:\n",
    "                    # Clean up unit = 25\n",
    "                    i += 1\n",
    "                    code_name = batch_name + \"_model_{:04d}\".format(i)\n",
    "                    batch_cfg = dict(\n",
    "                        sn=i,\n",
    "                        in_notebook=\"basicOSP_master.ipynb\",\n",
    "                        code_name=code_name,\n",
    "                        model_folder=\"models/\" + code_name + \"/\",\n",
    "                        out_notebook=\"models/\" + code_name + \"/output.ipynb\",\n",
    "                        params=dict(\n",
    "                            code_name=code_name,\n",
    "                            sample_name='hs04',\n",
    "                            sample_rng_seed=329,\n",
    "                            tf_rng_seed=123,\n",
    "                            use_semantic=False,\n",
    "                            sem_param_gf=0.,\n",
    "                            sem_param_gi=0.,\n",
    "                            sem_param_kf=0.,\n",
    "                            sem_param_ki=0.,\n",
    "                            sem_param_hf=0.,\n",
    "                            sem_param_hi=0.,\n",
    "                            o_input_dim=119,\n",
    "                            hidden_units=h,\n",
    "                            pho_units=250,\n",
    "                            cleanup_units=c_unit,\n",
    "                            rnn_activation='sigmoid',\n",
    "                            regularizer_const=5e-6,\n",
    "                            embed_attractor_cfg=\n",
    "                            'models/Attractor_{}/model_config.json'.\n",
    "                            format(c_unit),\n",
    "                            embed_attractor_h5='ep{0:04d}.h5'.format(c_stage),\n",
    "                            p_noise=noise,  # i.e. w_pp, w_pc, and w_cp noise\n",
    "                            tau=0.2,\n",
    "                            max_unit_time=4.,\n",
    "                            n_mil_sample=.04,\n",
    "                            batch_size=128,\n",
    "                            learning_rate=0.005,\n",
    "                            save_freq=1,\n",
    "                            bq_dataset=batch_name\n",
    "                        )\n",
    "                    )\n",
    "                    batch_cfgs.append(batch_cfg)\n",
    "\n",
    "            if c_unit == 50:\n",
    "                for c_stage in [0, 70, 125]:\n",
    "                    i += 1\n",
    "                    code_name = batch_name + \"_model_{:04d}\".format(i)\n",
    "                    batch_cfg = dict(\n",
    "                        sn=i,\n",
    "                        in_notebook=\"basicOSP_master.ipynb\",\n",
    "                        code_name=code_name,\n",
    "                        model_folder=\"models/\" + code_name + \"/\",\n",
    "                        out_notebook=\"models/\" + code_name + \"/output.ipynb\",\n",
    "                        params=dict(\n",
    "                            code_name=code_name,\n",
    "                            sample_name='hs04',\n",
    "                            sample_rng_seed=329,\n",
    "                            tf_rng_seed=123,\n",
    "                            use_semantic=False,\n",
    "                            sem_param_gf=0.,\n",
    "                            sem_param_gi=0.,\n",
    "                            sem_param_kf=0.,\n",
    "                            sem_param_ki=0.,\n",
    "                            sem_param_hf=0.,\n",
    "                            sem_param_hi=0.,\n",
    "                            o_input_dim=119,\n",
    "                            hidden_units=h,\n",
    "                            pho_units=250,\n",
    "                            cleanup_units=c_unit,\n",
    "                            rnn_activation='sigmoid',\n",
    "                            regularizer_const=5e-6,\n",
    "                            embed_attractor_cfg=\n",
    "                            'models/Attractor_{}/model_config.json'.\n",
    "                            format(c_unit),\n",
    "                            embed_attractor_h5='ep{0:04d}.h5'.format(c_stage),\n",
    "                            p_noise=noise,  # i.e. w_pp, w_pc, and w_cp noise\n",
    "                            tau=0.2,\n",
    "                            max_unit_time=4.,\n",
    "                            n_mil_sample=.04,\n",
    "                            batch_size=128,\n",
    "                            learning_rate=0.005,\n",
    "                            save_freq=1,\n",
    "                            bq_dataset=batch_name\n",
    "                        )\n",
    "                    )\n",
    "                    batch_cfgs.append(batch_cfg)\n",
    "\n",
    "\n",
    "# Run\n",
    "def run_batch(cfg):\n",
    "    try:\n",
    "        print(\"Running model {}\".format(cfg['sn']))\n",
    "\n",
    "        if not os.path.exists(cfg['model_folder']):\n",
    "            os.mkdir(cfg['model_folder'])\n",
    "\n",
    "        pm.execute_notebook(\n",
    "            cfg['in_notebook'],\n",
    "            cfg['out_notebook'],\n",
    "            parameters=cfg['params'],\n",
    "        )\n",
    "\n",
    "    except:\n",
    "        print(\"Error occur in {}\".format(cfg['code_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in parallel pool\n",
    "with Pool(4) as pool:\n",
    "    pool.map(run_batch, batch_cfgs)\n",
    "    \n",
    "# Push results to BQ\n",
    "from meta import model_cfg, connect_gbq\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Make connection to bq\n",
    "bq = connect_gbq()\n",
    "\n",
    "for sn in tqdm(range(len(batch_cfgs))):\n",
    "\n",
    "    model_folder = 'models/{0:s}_model_{1:04d}'.format(batch_name, sn + 1)\n",
    "\n",
    "    # Load model config \n",
    "    cfg = model_cfg(None)\n",
    "    cfg.load_cfg_json(model_folder + '/model_config.json')\n",
    "    cfg.bq_dataset = batch_name\n",
    "\n",
    "    # Load Strain and Grain\n",
    "    strain_i_hist = pd.read_csv(model_folder + '/result_strain_item.csv')\n",
    "    grain_i_hist = pd.read_csv(model_folder + '/result_grain_item.csv')\n",
    "\n",
    "    bq.push_all(cfg, strain_i_hist, grain_i_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shutdown compute engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "sleep(30)\n",
    "!sudo poweroff  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "from meta import connect_gbq\n",
    "from evaluate import vis\n",
    "from tqdm import tqdm\n",
    "\n",
    "conn = connect_gbq()\n",
    "cfgs = conn.read_bq_cfg(batch_name)\n",
    "\n",
    "# Read cfg files from BQ\n",
    "print('===== Batch level hyperparams (columns that have >1 unique value) =====')\n",
    "for i, x in enumerate(cfgs.columns):\n",
    "    if not x == 'code_name':\n",
    "        if not x == 'uuid':\n",
    "            if len(cfgs[x].unique()) > 1:\n",
    "                print(\n",
    "                    'Column <{}> has these unique values: {}'.format(\n",
    "                        x, cfgs[x].unique()\n",
    "                    )\n",
    "                )\n",
    "\n",
    "# Parse each run by batch_eval, which aggregate item level data to condition level\n",
    "# and merge Grain and Strain into one single file (Using local files instead of BQ,\n",
    "# may use BQ for way way more data... >5Gbs I guess)\n",
    "\n",
    "models_path = []\n",
    "for i in range(len(cfgs)):\n",
    "    models_path.append('models/' + batch_name + '_model_{0:04d}'.format(i + 1))\n",
    "\n",
    "batch_acc = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(len(cfgs))):\n",
    "\n",
    "    model_path = 'models/' + batch_name + '_model_{0:04d}'.format(i + 1)\n",
    "\n",
    "    this_eval = vis(\n",
    "        model_path, 'result_strain_item.csv', 'result_grain_item.csv'\n",
    "    )  # Eval lesion and grain\n",
    "    this_eval.parse_cond_df()\n",
    "    batch_acc = pd.concat([batch_acc, this_eval.cdf], ignore_index=True)\n",
    "\n",
    "df = pd.merge(batch_acc, cfgs, 'left', 'code_name')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_attractor_acc(cleanup_units, embed_attractor_h5):\n",
    "    if cleanup_units == 25:\n",
    "        if embed_attractor_h5 == 'ep0000.h5':\n",
    "            acc = 0.\n",
    "        if embed_attractor_h5 == 'ep0195.h5':\n",
    "            acc = 0.6\n",
    "        if embed_attractor_h5 == 'ep0300.h5':\n",
    "            acc = 0.9\n",
    "\n",
    "    if cleanup_units == 50:\n",
    "        if embed_attractor_h5 == 'ep0000.h5':\n",
    "            acc = 0.\n",
    "        if embed_attractor_h5 == 'ep0070.h5':\n",
    "            acc = 0.6\n",
    "        if embed_attractor_h5 == 'ep0125.h5':\n",
    "            acc = 0.9\n",
    "\n",
    "    return acc\n",
    "\n",
    "tmp_acc = []\n",
    "\n",
    "for i in df.index:\n",
    "    tmp_acc.append(\n",
    "        cal_attractor_acc(df.cleanup_units[i], df.embed_attractor_h5[i])\n",
    "    )\n",
    "\n",
    "df['attactor_acc'] = tmp_acc\n",
    "\n",
    "# Save to h5 format\n",
    "df.to_hdf('batch_eval/{}_cdf.h5'.format(batch_name), key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('batch_eval/{}_cdf.h5'.format(batch_name), 'df')\n",
    "\n",
    "# Plotting results\n",
    "import altair as alt\n",
    "from evaluate import make_df_wnw\n",
    "\n",
    "alt.data_transformers.enable(\"default\")\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# Selectors for interactions\n",
    "sel_run = alt.selection(type=\"multi\", on=\"click\", fields=[\"code_name\"])\n",
    "sel_cond = alt.selection(\n",
    "    type=\"multi\", on=\"click\", fields=[\"cond\"], bind=\"legend\"\n",
    ")\n",
    "\n",
    "# Heatmap for final epoch & timestep (Overview)\n",
    "plot_timestep = df.timestep.max()\n",
    "# plot_timestep = 19\n",
    "\n",
    "# Plot strain\n",
    "\n",
    "df_ov_strain = df[(df.epoch == df.epoch.max()) &\n",
    "                  (df.timestep == plot_timestep) & (df.exp == 'strain')]\n",
    "\n",
    "overview_strain = (\n",
    "    alt.Chart(df_ov_strain).mark_rect().encode(\n",
    "        x=\"hidden_units:O\",\n",
    "        y=\"w_pp_noise:O\",\n",
    "        column='attactor_acc',\n",
    "        row='cleanup_units',\n",
    "        color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_run).properties(title=\"Overall Strain accuracy\")\n",
    ")\n",
    "\n",
    "df_ov_grain = df[(df.epoch == df.epoch.max()) & (df.timestep == plot_timestep) &\n",
    "                 (df.exp == 'grain')]\n",
    "\n",
    "overview_grain = (\n",
    "    alt.Chart(df_ov_grain).mark_rect().encode(\n",
    "        x=\"hidden_units:O\",\n",
    "        y=\"w_pp_noise:O\",\n",
    "        column='attactor_acc',\n",
    "        row='cleanup_units',\n",
    "        color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_run).properties(title=\"Overall Grain accuracy\")\n",
    ")\n",
    "\n",
    "# Accuracy over epoch at last time step for selected model\n",
    "last_time_point = df[df.timestep == df.timestep.max()]\n",
    "\n",
    "acc_plot = (\n",
    "    alt.Chart(last_time_point).mark_line(point=True).encode(\n",
    "        y=alt.Y(\"acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=\"epoch\",\n",
    "        color=\"cond\",\n",
    "        opacity=alt.condition(sel_cond, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_cond).transform_filter(sel_run).properties(\n",
    "        title=\"Full model at final time step\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Accuracy Word (HF-INC) vs. Nonwords\n",
    "wnw_df = make_df_wnw(df, selected_cond=['INC_HF', 'ambiguous', 'unambiguous'])\n",
    "\n",
    "wnw_plot = (\n",
    "    alt.Chart(wnw_df).mark_line(point=True).encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        color=alt.Color(\"epoch\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        tooltip=[\"code_name\", \"word_acc\", \"nonword_acc\"],\n",
    "    ).transform_filter(sel_run).properties(\n",
    "        title=\"Word vs. Nonword accuracy at final time step\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot diagonal\n",
    "diagline = alt.Chart(pd.DataFrame({\n",
    "    'x': [0, 1],\n",
    "    'y': [0, 1]\n",
    "})).mark_line().encode(x=alt.X('x', axis=alt.Axis(labels=False)), y=alt.Y('y', axis=alt.Axis(labels=False)))\n",
    "\n",
    "wnw_with_diag = diagline + wnw_plot\n",
    "\n",
    "overview = overview_strain & overview_grain\n",
    "mainplots = acc_plot & wnw_with_diag\n",
    "plot = overview | mainplots\n",
    "plot\n",
    "\n",
    "plot.save('batch_eval/O2P_main_all_HFINC_NW.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.save('batch_eval/O2P_l2reg.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta import model_cfg\n",
    "from evaluate import vis\n",
    "\n",
    "code_name = '{0:}_model_{1:04d}'.format(batch_name, 47)\n",
    "\n",
    "# Load cfg from json\n",
    "cfg = model_cfg(None)\n",
    "cfg.load_cfg_json('models/' + code_name + '/model_config.json')\n",
    "\n",
    "vis = vis(\n",
    "    cfg.path_model_folder, 'result_strain_item.csv', 'result_grain_item.csv'\n",
    ")\n",
    "\n",
    "vis.parse_cond_df()\n",
    "\n",
    "full = vis.plot_dev_interactive('acc').properties(title='Full input')\n",
    "\n",
    "full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible development plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_dev('acc', exp=None, condition='cond', timestep=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible time plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_time('acc', exp='strain', condition='cond', epoch=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
