{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook uses Papermill to batch run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import papermill as pm\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = \"O2P_main\"\n",
    "\n",
    "# Create batch cfgs\n",
    "batch_cfgs = []\n",
    "i = 0\n",
    "\n",
    "for noise in [0., 1., 2., 4., 8.]:\n",
    "    for h in [25, 50, 100, 250]:\n",
    "        for c_unit in [25, 50]:\n",
    "            if c_unit == 25:\n",
    "                for c_stage in [0, 195, 300]:\n",
    "                    # Clean up unit = 25\n",
    "                    i += 1\n",
    "                    code_name = batch_name + \"_model_{:04d}\".format(i)\n",
    "                    batch_cfg = dict(\n",
    "                        sn=i,\n",
    "                        in_notebook=\"basicOSP_master.ipynb\",\n",
    "                        code_name=code_name,\n",
    "                        model_folder=\"models/\" + code_name + \"/\",\n",
    "                        out_notebook=\"models/\" + code_name + \"/output.ipynb\",\n",
    "                        params=dict(\n",
    "                            code_name=code_name,\n",
    "                            sample_name='hs04',\n",
    "                            sample_rng_seed=329,\n",
    "                            tf_rng_seed=123,\n",
    "                            use_semantic=False,\n",
    "                            sem_param_gf=0.,\n",
    "                            sem_param_gi=0.,\n",
    "                            sem_param_kf=0.,\n",
    "                            sem_param_ki=0.,\n",
    "                            sem_param_hf=0.,\n",
    "                            sem_param_hi=0.,\n",
    "                            o_input_dim=119,\n",
    "                            hidden_units=h,\n",
    "                            pho_units=250,\n",
    "                            cleanup_units=c_unit,\n",
    "                            rnn_activation='sigmoid',\n",
    "                            regularizer_const=5e-6,\n",
    "                            embed_attractor_cfg=\n",
    "                            'models/Attractor_{}/model_config.json'.\n",
    "                            format(c_unit),\n",
    "                            embed_attractor_h5='ep{0:04d}.h5'.format(c_stage),\n",
    "                            p_noise=noise,  # i.e. w_pp, w_pc, and w_cp noise\n",
    "                            tau=0.2,\n",
    "                            max_unit_time=4.,\n",
    "                            n_mil_sample=.04,\n",
    "                            batch_size=128,\n",
    "                            learning_rate=0.005,\n",
    "                            save_freq=1,\n",
    "                            bq_dataset=batch_name\n",
    "                        )\n",
    "                    )\n",
    "                    batch_cfgs.append(batch_cfg)\n",
    "\n",
    "            if c_unit == 50:\n",
    "                for c_stage in [0, 70, 125]:\n",
    "                    i += 1\n",
    "                    code_name = batch_name + \"_model_{:04d}\".format(i)\n",
    "                    batch_cfg = dict(\n",
    "                        sn=i,\n",
    "                        in_notebook=\"basicOSP_master.ipynb\",\n",
    "                        code_name=code_name,\n",
    "                        model_folder=\"models/\" + code_name + \"/\",\n",
    "                        out_notebook=\"models/\" + code_name + \"/output.ipynb\",\n",
    "                        params=dict(\n",
    "                            code_name=code_name,\n",
    "                            sample_name='hs04',\n",
    "                            sample_rng_seed=329,\n",
    "                            tf_rng_seed=123,\n",
    "                            use_semantic=False,\n",
    "                            sem_param_gf=0.,\n",
    "                            sem_param_gi=0.,\n",
    "                            sem_param_kf=0.,\n",
    "                            sem_param_ki=0.,\n",
    "                            sem_param_hf=0.,\n",
    "                            sem_param_hi=0.,\n",
    "                            o_input_dim=119,\n",
    "                            hidden_units=h,\n",
    "                            pho_units=250,\n",
    "                            cleanup_units=c_unit,\n",
    "                            rnn_activation='sigmoid',\n",
    "                            regularizer_const=5e-6,\n",
    "                            embed_attractor_cfg=\n",
    "                            'models/Attractor_{}/model_config.json'.\n",
    "                            format(c_unit),\n",
    "                            embed_attractor_h5='ep{0:04d}.h5'.format(c_stage),\n",
    "                            p_noise=noise,  # i.e. w_pp, w_pc, and w_cp noise\n",
    "                            tau=0.2,\n",
    "                            max_unit_time=4.,\n",
    "                            n_mil_sample=.04,\n",
    "                            batch_size=128,\n",
    "                            learning_rate=0.005,\n",
    "                            save_freq=1,\n",
    "                            bq_dataset=batch_name\n",
    "                        )\n",
    "                    )\n",
    "                    batch_cfgs.append(batch_cfg)\n",
    "\n",
    "\n",
    "# Run\n",
    "def run_batch(cfg):\n",
    "    try:\n",
    "        print(\"Running model {}\".format(cfg['sn']))\n",
    "\n",
    "        if not os.path.exists(cfg['model_folder']):\n",
    "            os.mkdir(cfg['model_folder'])\n",
    "\n",
    "        pm.execute_notebook(\n",
    "            cfg['in_notebook'],\n",
    "            cfg['out_notebook'],\n",
    "            parameters=cfg['params'],\n",
    "        )\n",
    "\n",
    "    except:\n",
    "        print(\"Error occur in {}\".format(cfg['code_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in parallel pool\n",
    "with Pool(12) as pool:\n",
    "    pool.map(run_batch, batch_cfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push results to BQ\n",
    "from meta import model_cfg, connect_gbq\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Make connection to bq\n",
    "bq = connect_gbq()\n",
    "\n",
    "for sn in tqdm(range(len(batch_cfgs))):\n",
    "\n",
    "    model_folder = 'models/{0:s}_model_{1:04d}'.format(batch_name, sn + 1)\n",
    "\n",
    "    # Load model config \n",
    "    cfg = model_cfg(None)\n",
    "    cfg.load_cfg_json(model_folder + '/model_config.json')\n",
    "    cfg.bq_dataset = batch_name\n",
    "\n",
    "    # Load Strain and Grain\n",
    "    strain_i_hist = pd.read_csv(model_folder + '/result_strain_item.csv')\n",
    "    grain_i_hist = pd.read_csv(model_folder + '/result_grain_item.csv')\n",
    "\n",
    "    bq.push_all(cfg, strain_i_hist, grain_i_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shutdown compute engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "sleep(30)\n",
    "!sudo poweroff  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 120/120 [00:00<00:00, 213.98rows/s]\n",
      "  0%|          | 0/120 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Batch level hyperparams (columns that have >1 unique value) =====\n",
      "Column <hidden_units> has these unique values: [ 25  50 100 250]\n",
      "Column <cleanup_units> has these unique values: [25 50]\n",
      "Column <embed_attractor_cfg> has these unique values: ['models/Attractor_25/model_config.json'\n",
      " 'models/Attractor_50/model_config.json']\n",
      "Column <embed_attractor_h5> has these unique values: ['ep0300.h5' 'ep0195.h5' 'ep0000.h5' 'ep0125.h5' 'ep0070.h5']\n",
      "Column <w_pp_noise> has these unique values: [0. 1. 2. 8. 4.]\n",
      "Column <w_pc_noise> has these unique values: [0. 1. 2. 8. 4.]\n",
      "Column <w_cp_noise> has these unique values: [0. 1. 2. 8. 4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:12<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "from meta import connect_gbq\n",
    "from evaluate import vis\n",
    "from tqdm import tqdm\n",
    "\n",
    "conn = connect_gbq()\n",
    "cfgs = conn.read_bq_cfg(batch_name)\n",
    "\n",
    "# Read cfg files from BQ\n",
    "print('===== Batch level hyperparams (columns that have >1 unique value) =====')\n",
    "for i, x in enumerate(cfgs.columns):\n",
    "    if not x == 'code_name':\n",
    "        if not x == 'uuid':\n",
    "            if len(cfgs[x].unique()) > 1:\n",
    "                print(\n",
    "                    'Column <{}> has these unique values: {}'.format(\n",
    "                        x, cfgs[x].unique()\n",
    "                    )\n",
    "                )\n",
    "\n",
    "# Parse each run by batch_eval, which aggregate item level data to condition level\n",
    "# and merge Grain and Strain into one single file (Using local files instead of BQ,\n",
    "# may use BQ for way way more data... >5Gbs I guess)\n",
    "\n",
    "models_path = []\n",
    "for i in range(len(cfgs)):\n",
    "    models_path.append('models/' + batch_name + '_model_{0:04d}'.format(i + 1))\n",
    "\n",
    "batch_acc = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(len(cfgs))):\n",
    "\n",
    "    model_path = 'models/' + batch_name + '_model_{0:04d}'.format(i + 1)\n",
    "\n",
    "    this_eval = vis(\n",
    "        model_path, 'result_strain_item.csv', 'result_grain_item.csv'\n",
    "    )  # Eval lesion and grain\n",
    "    this_eval.parse_cond_df()\n",
    "    batch_acc = pd.concat([batch_acc, this_eval.cdf], ignore_index=True)\n",
    "\n",
    "df = pd.merge(batch_acc, cfgs, 'left', 'code_name')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_attractor_acc(cleanup_units, embed_attractor_h5):\n",
    "    if cleanup_units == 25:\n",
    "        if embed_attractor_h5 == 'ep0000.h5':\n",
    "            acc = 0.\n",
    "        if embed_attractor_h5 == 'ep0195.h5':\n",
    "            acc = 0.6\n",
    "        if embed_attractor_h5 == 'ep0300.h5':\n",
    "            acc = 0.9\n",
    "\n",
    "    if cleanup_units == 50:\n",
    "        if embed_attractor_h5 == 'ep0000.h5':\n",
    "            acc = 0.\n",
    "        if embed_attractor_h5 == 'ep0070.h5':\n",
    "            acc = 0.6\n",
    "        if embed_attractor_h5 == 'ep0125.h5':\n",
    "            acc = 0.9\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_acc = []\n",
    "\n",
    "for i in df.index:\n",
    "    tmp_acc.append(\n",
    "        cal_attractor_acc(df.cleanup_units[i], df.embed_attractor_h5[i])\n",
    "    )\n",
    "\n",
    "df['attactor_acc'] = tmp_acc\n",
    "\n",
    "# Save to h5 format\n",
    "df.to_hdf('batch_eval/{}_cdf.h5'.format(batch_name), key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('batch_eval/{}_cdf.h5'.format(batch_name), 'df')\n",
    "\n",
    "df_ind = df.loc[(df.timestep == df.timestep.max()) &\n",
    "                (df.cond.isin(['INC_HF', 'ambiguous', 'unambiguous'])), [\n",
    "                    'code_name', 'epoch', 'hidden_units', 'cleanup_units',\n",
    "                    'w_pp_noise', 'attactor_acc', 'acc', 'exp'\n",
    "                ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvt = df_ind.pivot_table(index=['code_name', 'epoch'],\n",
    "                         columns='exp').reset_index()\n",
    "\n",
    "plt_df = pd.DataFrame()\n",
    "plt_df['code_name'] = pvt.code_name\n",
    "plt_df['epoch'] = pvt.epoch\n",
    "plt_df['nonword_acc'] = pvt.acc.grain\n",
    "plt_df['word_acc'] = pvt.acc.strain\n",
    "plt_df['hidden_units'] = pvt.hidden_units.strain\n",
    "plt_df['w_pp_noise'] = pvt.w_pp_noise.strain\n",
    "plt_df['hidden_units'] = pvt.hidden_units.strain\n",
    "plt_df['hidden_units'] = pvt.hidden_units.strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check all pivot align correctly\n",
    "print(all(pvt.attactor_acc.grain == pvt.attactor_acc.strain))\n",
    "print(all(pvt.cleanup_units.grain == pvt.cleanup_units.strain))\n",
    "print(all(pvt.hidden_units.grain == pvt.hidden_units.strain))\n",
    "print(all(pvt.w_pp_noise.grain == pvt.w_pp_noise.strain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_name</th>\n",
       "      <th>epoch</th>\n",
       "      <th>nonword_acc</th>\n",
       "      <th>word_acc</th>\n",
       "      <th>hidden_units</th>\n",
       "      <th>w_pp_noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O2P_main_model_0001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O2P_main_model_0001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O2P_main_model_0001</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O2P_main_model_0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O2P_main_model_0001</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.025</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>O2P_main_model_0120</td>\n",
       "      <td>80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>O2P_main_model_0120</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>250</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>O2P_main_model_0120</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>250</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>O2P_main_model_0120</td>\n",
       "      <td>95</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.025</td>\n",
       "      <td>250</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>O2P_main_model_0120</td>\n",
       "      <td>100</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.050</td>\n",
       "      <td>250</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2880 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                code_name  epoch  nonword_acc  word_acc  hidden_units  \\\n",
       "0     O2P_main_model_0001      1     0.000000     0.000            25   \n",
       "1     O2P_main_model_0001      2     0.000000     0.000            25   \n",
       "2     O2P_main_model_0001      3     0.000000     0.000            25   \n",
       "3     O2P_main_model_0001      4     0.000000     0.000            25   \n",
       "4     O2P_main_model_0001      5     0.008333     0.025            25   \n",
       "...                   ...    ...          ...       ...           ...   \n",
       "2875  O2P_main_model_0120     80     0.000000     0.000           250   \n",
       "2876  O2P_main_model_0120     85     0.000000     0.025           250   \n",
       "2877  O2P_main_model_0120     90     0.000000     0.025           250   \n",
       "2878  O2P_main_model_0120     95     0.033333     0.025           250   \n",
       "2879  O2P_main_model_0120    100     0.033333     0.050           250   \n",
       "\n",
       "      w_pp_noise  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "...          ...  \n",
       "2875         8.0  \n",
       "2876         8.0  \n",
       "2877         8.0  \n",
       "2878         8.0  \n",
       "2879         8.0  \n",
       "\n",
       "[2880 rows x 6 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "import altair as alt\n",
    "\n",
    "alt.data_transformers.enable(\"default\")\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# Selectors for interactions\n",
    "sel_run = alt.selection(type=\"multi\", on=\"click\", fields=[\"code_name\"])\n",
    "sel_cond = alt.selection(\n",
    "    type=\"multi\", on=\"click\", fields=[\"cond\"], bind=\"legend\"\n",
    ")\n",
    "\n",
    "# Heatmap for final epoch & timestep (Overview)\n",
    "plot_timestep = df.timestep.max()\n",
    "# plot_timestep = 19\n",
    "\n",
    "# Plot strain\n",
    "\n",
    "df_ov_strain = df[(df.epoch == df.epoch.max()) &\n",
    "                  (df.timestep == plot_timestep) & (df.exp == 'strain')]\n",
    "\n",
    "overview_strain = (\n",
    "    alt.Chart(df_ov_strain).mark_rect().encode(\n",
    "        x=\"hidden_units:O\",\n",
    "        y=\"w_pp_noise:O\",\n",
    "        column='attactor_acc',\n",
    "        row='cleanup_units',\n",
    "        color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_run)\n",
    ")\n",
    "\n",
    "df_ov_grain = df[(df.epoch == df.epoch.max()) & (df.timestep == plot_timestep) &\n",
    "                 (df.exp == 'grain')]\n",
    "\n",
    "overview_grain = (\n",
    "    alt.Chart(df_ov_grain).mark_rect().encode(\n",
    "        x=\"hidden_units:O\",\n",
    "        y=\"w_pp_noise:O\",\n",
    "        column='attactor_acc',\n",
    "        row='cleanup_units',\n",
    "        color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_run)\n",
    ")\n",
    "\n",
    "wnw_plot = (\n",
    "    alt.Chart(plt_df).mark_line().encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        color=\"epoch\",\n",
    "        opacity=alt.condition(sel_cond, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"word_acc\", \"nonword_acc\"],\n",
    "    ).transform_filter(sel_run).properties(\n",
    "        title=\"Full model at final time step\"\n",
    "    )\n",
    ")\n",
    "\n",
    "wnw_plot\n",
    "\n",
    "# Accuracy over epoch at last time step for selected model\n",
    "last_time_point = df[df.timestep == df.timestep.max()]\n",
    "\n",
    "acc_plot = (\n",
    "    alt.Chart(last_time_point).mark_line().encode(\n",
    "        y=alt.Y(\"acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=\"epoch\",\n",
    "        color=\"cond\",\n",
    "        opacity=alt.condition(sel_cond, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).transform_filter(sel_run).properties(\n",
    "        title=\"Word vs. Nonword at final time step\"\n",
    "    )\n",
    ")\n",
    "overview = overview_strain & overview_grain\n",
    "mainplots = acc_plot & wnw_plot\n",
    "plot = overview | mainplots\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.save('batch_eval/O2P_l2reg.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta import model_cfg\n",
    "from evaluate import vis\n",
    "\n",
    "code_name = '{0:}_model_{1:04d}'.format(batch_name, 47)\n",
    "\n",
    "# Load cfg from json\n",
    "cfg = model_cfg(None)\n",
    "cfg.load_cfg_json('models/' + code_name + '/model_config.json')\n",
    "\n",
    "vis = vis(\n",
    "    cfg.path_model_folder, 'result_strain_item.csv', 'result_grain_item.csv'\n",
    ")\n",
    "\n",
    "vis.parse_cond_df()\n",
    "\n",
    "full = vis.plot_dev_interactive('acc').properties(title='Full input')\n",
    "\n",
    "full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible development plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_dev('acc', exp=None, condition='cond', timestep=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible time plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_time('acc', exp='strain', condition='cond', epoch=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
