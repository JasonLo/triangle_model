{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch run models\n",
    "1. Running model\n",
    "2. Evaluating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import os, itertools, json, multiprocessing\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import papermill as pm\n",
    "from time import sleep\n",
    "from meta import model_cfg, batch_cfgs_to_df, parse_batch_results, check_cfgs_params\n",
    "from evaluate import make_df_wnw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run batch\n",
    "Make configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# seeds = [int(random.random() * 1e5) for x in range(10)]\n",
    "\n",
    "batch_name = \"O2P_rr2019\"\n",
    "\n",
    "batch_output_dir = 'batch_eval/{}/'.format(batch_name)\n",
    "os.makedirs(batch_output_dir, exist_ok=True)\n",
    "\n",
    "param_grid = {\n",
    "    'p_noise': [0., 1., 2., 3.],\n",
    "    'hidden_units': [50, 100, 150, 200],\n",
    "    'learning_rate': [.001, .005, .01],\n",
    "    'cleanup_units': [10, 50]\n",
    "}\n",
    "\n",
    "static_hpar = {\n",
    "    'sample_name': 'jay',\n",
    "    'rng_seed': 4321,\n",
    "    'use_semantic': False,\n",
    "    'input_dim': 119,\n",
    "    'output_dim': 250,\n",
    "    'use_attractor': False,\n",
    "    'rnn_activation': 'sigmoid',\n",
    "    'regularizer_const': None,\n",
    "    'w_initializer': 'glorot_uniform',\n",
    "    'tau': 0.2,\n",
    "    'max_unit_time': 4.,\n",
    "    'optimizer': 'adam',\n",
    "    'n_mil_sample': 1.,\n",
    "    'batch_size': 1,\n",
    "    'save_freq': 10,\n",
    "    'bq_dataset': batch_name\n",
    "}\n",
    "\n",
    "# Check duplicate keys\n",
    "for key in static_hpar.keys():\n",
    "    if key in param_grid.keys():\n",
    "        raise ValueError('Key duplicate: {}'.format(key))\n",
    "\n",
    "# Iterate and create batch level super object: batch_cfgs\n",
    "batch_cfgs = []\n",
    "varying_hpar_names, varying_hpar_values = zip(*param_grid.items())\n",
    "for i, v in enumerate(itertools.product(*varying_hpar_values)):\n",
    "    code_name = batch_name + \"_r{:04d}\".format(i)\n",
    "\n",
    "    this_hpar = dict(zip(varying_hpar_names, v))\n",
    "    this_hpar.update(static_hpar)\n",
    "\n",
    "    # Add identifier params into param dict\n",
    "    this_hpar['code_name'] = code_name\n",
    "\n",
    "    # Pass into model_cfg to catch error early\n",
    "    model_cfg(**this_hpar)\n",
    "\n",
    "    batch_cfg = dict(\n",
    "        sn=i,\n",
    "        in_notebook=\"OSP_master.ipynb\",\n",
    "        code_name=code_name,\n",
    "        model_folder=\"models/\" + code_name + \"/\",\n",
    "        out_notebook=\"models/\" + code_name + \"/output.ipynb\",\n",
    "        params=this_hpar\n",
    "    )\n",
    "\n",
    "    batch_cfgs.append(batch_cfg)\n",
    "\n",
    "# Save cfgs\n",
    "with open(batch_output_dir + 'batch_config.json', 'w') as f:\n",
    "    json.dump(batch_cfgs, f)\n",
    "    \n",
    "n = len(batch_cfgs)\n",
    "print('There are {} models in this batch'.format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "def run_batch(cfg):\n",
    "    \"\"\"\n",
    "    Using papermill to run parameterized notebook\n",
    "    \"\"\"\n",
    "    print(\"Running model {}\".format(cfg['sn']))\n",
    "    os.makedirs(cfg['model_folder'], exist_ok=True)\n",
    "    pm.execute_notebook(\n",
    "        cfg['in_notebook'],\n",
    "        cfg['out_notebook'],\n",
    "        parameters=cfg['params'],\n",
    "    )\n",
    "\n",
    "\n",
    "# Run in parallel pool\n",
    "with multiprocessing.Pool(4) as pool:\n",
    "    pool.map(run_batch, batch_cfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_batch_results(cfgs)\n",
    "df.to_csv(batch_output_dir + 'bcdf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shutdown compute engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_mail(batch_name)\n",
    "sleep(30)\n",
    "!sudo poweroff  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = model_cfg('models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the batch structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_cfgs_params(cfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create re-useable overview heatmap and word vs. nonword df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.enable(\"default\")\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# Selectors for interactions\n",
    "sel_run = alt.selection(type=\"multi\", on=\"click\", fields=[\"code_name\"])\n",
    "sel_cond = alt.selection(\n",
    "    type=\"multi\", on=\"click\", fields=[\"cond\"], bind=\"legend\"\n",
    ")\n",
    "\n",
    "# df for overview\n",
    "df_ov = df[(df.epoch == df.epoch.max()) & (df.timestep == df.timestep.max())]\n",
    "\n",
    "# Shared master over-view\n",
    "overview = (\n",
    "    alt.Chart(df_ov).mark_rect().encode(\n",
    "        x=\"p_noise:O\",\n",
    "        y=\"hidden_units:O\",\n",
    "        row=\"learning_rate:O\",\n",
    "        column=\"cleanup_units:O\",\n",
    "        color=alt.Color(\"acc\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        opacity=alt.condition(sel_run, alt.value(1), alt.value(0)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_run).properties(title=\"Overall accuracy\")\n",
    ")\n",
    "\n",
    "# Accuracy Word (HF-INC) vs. Nonwords\n",
    "df_wnw = make_df_wnw(df, selected_cond=['INC_HF', 'ambiguous', 'unambiguous'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single run plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy over epoch at last time step for selected model\n",
    "df_laststep = df[df.timestep == df.timestep.max()]\n",
    "\n",
    "acc_plot = (\n",
    "    alt.Chart(df_laststep).mark_line(point=True).encode(\n",
    "        y=alt.Y(\"acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=\"epoch\",\n",
    "        color=\"cond\",\n",
    "        opacity=alt.condition(sel_cond, alt.value(1), alt.value(0)),\n",
    "        tooltip=[\"code_name\", \"acc\"],\n",
    "    ).add_selection(sel_cond).transform_filter(sel_run).properties(\n",
    "        title=\"Full model at final time step\"\n",
    "    )\n",
    ")\n",
    "\n",
    "wnw_plot = (\n",
    "    alt.Chart(df_wnw).mark_point().encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        color=alt.Color(\"epoch\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        tooltip=[\"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "    ).transform_filter(sel_run).properties(\n",
    "        title=\"Word vs. Nonword accuracy at final time step\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot diagonal\n",
    "diagline = alt.Chart(pd.DataFrame({\n",
    "    'x': [0, 1],\n",
    "    'y': [0, 1]\n",
    "})).mark_line(color='black').encode(x='x', y='y')\n",
    "\n",
    "wnw_with_diag = wnw_plot + diagline\n",
    "\n",
    "# overview = overview_strain & overview_grain\n",
    "mainplots = acc_plot & wnw_with_diag\n",
    "splot = overview | mainplots\n",
    "\n",
    "splot.save(batch_output_dir + 'single_run.html')\n",
    "splot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi runs plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnw_mdf = df_wnw.melt(\n",
    "    id_vars=['code_name', 'epoch'],\n",
    "    value_vars=['word_acc', 'nonword_acc'],\n",
    "    var_name='wnw',\n",
    "    value_name='acc'\n",
    ")\n",
    "\n",
    "plot_epoch = alt.Chart(wnw_mdf).mark_point(size=80).encode(\n",
    "    y=alt.Y(\"acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "    x=\"epoch:Q\",\n",
    "    color=\"code_name:N\",\n",
    "    shape=\"wnw:N\",\n",
    "    opacity=alt.condition(sel_run, alt.value(1), alt.value(0)),\n",
    "    tooltip=[\"code_name\", \"epoch\", \"acc\"],\n",
    ").add_selection(sel_run).transform_filter(sel_run).properties(\n",
    "    title=\"Plot word and nonword accuracy by epoch\"\n",
    ")\n",
    "\n",
    "plot_wnw = alt.Chart(df_wnw).mark_line(point=True).encode(\n",
    "    y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "    x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "    color=\"code_name:N\",\n",
    "    opacity=alt.condition(sel_run, alt.value(1), alt.value(0)),\n",
    "    tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    ").add_selection(sel_run).properties(\n",
    "    title=\"Word vs. Nonword accuracy at final time step\"\n",
    ")\n",
    "\n",
    "plot_wnw_diag = plot_wnw + diagline\n",
    "\n",
    "multi_plot = overview | (plot_epoch & plot_wnw_diag)\n",
    "multi_plot.save(batch_output_dir + 'multi_runs.html')\n",
    "multi_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --output-dir=$batch_output_dir --to html batch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual hand pick experiment parallel run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext lab_black\n",
    "import os, itertools, json, multiprocessing\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import papermill as pm\n",
    "from time import sleep\n",
    "from meta import model_cfg, batch_cfgs_to_df, parse_batch_results, check_cfgs_params\n",
    "from evaluate import make_df_wnw\n",
    "\n",
    "batch_name = \"O2P_batchsize_opt_test\"\n",
    "\n",
    "batch_output_dir = 'batch_eval/{}/'.format(batch_name)\n",
    "os.makedirs(batch_output_dir, exist_ok=True)\n",
    "\n",
    "# import random\n",
    "# seeds = [int(random.random() * 1e5) for x in range(10)]\n",
    "\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'batch_size': [1, 32, 128],\n",
    "}\n",
    "\n",
    "static_hpar = {\n",
    "    'sample_name': 'jay',\n",
    "    'rng_seed': 4321,\n",
    "    'use_semantic': False,\n",
    "    'input_dim': 119,\n",
    "    'output_dim': 250,\n",
    "    'use_attractor': False,\n",
    "    'rnn_activation': 'sigmoid',\n",
    "    'regularizer_const': None,\n",
    "    'w_initializer': 'glorot_uniform',\n",
    "    'tau': 0.2,\n",
    "    'max_unit_time': 4.,\n",
    "    'n_mil_sample': 1.,\n",
    "    'save_freq': 10,\n",
    "    'bq_dataset': None,\n",
    "    'p_noise': 0.,\n",
    "    'hidden_units': 100,\n",
    "    'learning_rate': .008,\n",
    "    'cleanup_units': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate and create batch level super object: batch_cfgs\n",
    "batch_cfgs = []\n",
    "varying_hpar_names, varying_hpar_values = zip(*param_grid.items())\n",
    "for i, v in enumerate(itertools.product(*varying_hpar_values)):\n",
    "    code_name = batch_name + \"_r{:04d}\".format(i)\n",
    "\n",
    "    this_hpar = dict(zip(varying_hpar_names, v))\n",
    "    this_hpar.update(static_hpar)\n",
    "\n",
    "    # Add identifier params into param dict\n",
    "    this_hpar['code_name'] = code_name\n",
    "\n",
    "    # Pass into model_cfg to catch error early\n",
    "    model_cfg(**this_hpar)\n",
    "\n",
    "    batch_cfg = dict(\n",
    "        sn=i,\n",
    "        in_notebook=\"OSP_master.ipynb\",\n",
    "        code_name=code_name,\n",
    "        model_folder=\"models/\" + code_name + \"/\",\n",
    "        out_notebook=\"models/\" + code_name + \"/output.ipynb\",\n",
    "        params=this_hpar\n",
    "    )\n",
    "\n",
    "    batch_cfgs.append(batch_cfg)\n",
    "\n",
    "# Save cfgs\n",
    "cfgs = batch_cfgs_to_df(batch_cfgs)\n",
    "cfgs.to_csv(batch_output_dir + 'cfgs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "def run_batch(cfg):\n",
    "    \"\"\"\n",
    "    Using papermill to run parameterized notebook\n",
    "    \"\"\"\n",
    "    print(\"Running model {}\".format(cfg['sn']))\n",
    "    os.makedirs(cfg['model_folder'], exist_ok=True)\n",
    "    pm.execute_notebook(\n",
    "        cfg['in_notebook'],\n",
    "        cfg['out_notebook'],\n",
    "        parameters=cfg['params'],\n",
    "    )\n",
    "\n",
    "\n",
    "# Run in parallel pool\n",
    "with multiprocessing.Pool(4) as pool:\n",
    "    pool.map(run_batch, batch_cfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_batch_results(cfgs)\n",
    "df.to_csv(batch_output_dir + 'bcdf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_mail(batch_name)\n",
    "sleep(30)\n",
    "!sudo poweroff  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
