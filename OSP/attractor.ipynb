{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain attractor network OSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "code_name = 'Attractor_50_noise2'\n",
    "sample_name = 'hs04'\n",
    "sample_rng_seed = 329\n",
    "tf_rng_seed = 1234\n",
    "\n",
    "# Model architechture\n",
    "output_dim = 250\n",
    "cleanup_units = 50\n",
    "rnn_activation = 'sigmoid'\n",
    "tau = 0.2\n",
    "max_unit_time = 4.\n",
    "p_noise = 2.\n",
    "\n",
    "# Training\n",
    "n_mil_sample = 5.  # 1 mil can only reach 50-60% correct\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "save_freq = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta import model_cfg\n",
    "# cfg = model_cfg(code_name=None)\n",
    "# cfg.load_cfg_json('models/Attractor_100/model_config.json')\n",
    "cfg = model_cfg(\n",
    "    code_name=code_name,\n",
    "    sample_name=sample_name,\n",
    "    sample_rng_seed=sample_rng_seed,\n",
    "    tf_rng_seed=tf_rng_seed,\n",
    "    output_dim=output_dim,\n",
    "    w_pp_noise=p_noise,\n",
    "    w_pc_noise=p_noise,\n",
    "    w_cp_noise=p_noise,\n",
    "    cleanup_units=cleanup_units,\n",
    "    tau=tau,\n",
    "    max_unit_time=max_unit_time,\n",
    "    n_mil_sample=n_mil_sample,\n",
    "    batch_size=batch_size,\n",
    "    rnn_activation=rnn_activation,\n",
    "    learning_rate=learning_rate,\n",
    "    save_freq=save_freq\n",
    ")\n",
    "\n",
    "# Global TF seed (Sampling is out of TF scope...)\n",
    "tf.random.set_seed(cfg.tf_rng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 250)]             0         \n",
      "_________________________________________________________________\n",
      "rnn (attractor_rnn)          [(None, 250), (None, 250) 87800     \n",
      "=================================================================\n",
      "Total params: 87,800\n",
      "Trainable params: 87,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Input\n",
    "from modeling import attractor_rnn\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "clamp_steps = 14\n",
    "\n",
    "input_o = Input(shape=(cfg.output_dim, ))\n",
    "rnn_model = attractor_rnn(cfg, clamp_steps)(input_o)\n",
    "model = Model(input_o, rnn_model)\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(\n",
    "        learning_rate=cfg.learning_rate,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        amsgrad=False\n",
    "    ),\n",
    "    metrics=['BinaryAccuracy', 'mse']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(cfg.path_weight_folder + 'ep0000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Orthographic representation==========\n",
      "x_train shape: (5832, 119)\n",
      "x_strain shape: (160, 119)\n",
      "x_grain shape: (120, 119)\n",
      "\n",
      "==========Phonological representation==========\n",
      "38  phonemes:  dict_keys(['a', 'W', 'D', '_', '^', 'U', 'm', 'o', 'k', 's', 'g', 'p', 't', 'w', 'Z', 'z', 'n', 'T', 'e', 'S', 'J', 'A', 'r', 'l', 'h', 'f', 'b', 'v', 'E', 'C', 'Y', 'y', 'I', 'O', 'i', 'u', '@', 'd'])\n",
      "y_train shape: (5832, 250)\n",
      "y_strain shape: (160, 250)\n",
      "y_large_grain shape: (120, 250)\n",
      "y_small_grain shape: (120, 250)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import h5py, pickle, os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from data_wrangling import my_data\n",
    "data = my_data(cfg)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    cfg.path_weights_checkpoint,\n",
    "    verbose=1,\n",
    "    period=cfg.save_freq,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "\n",
    "def sample_gen4attractor(\n",
    "    x_set, y_set, n_timesteps, batch_size, sample_p, rng_seed\n",
    "):\n",
    "    # Get <batch_size> of data from <x_set>, <y_set> based on the probability of <sample_p>\n",
    "    np.random.seed(rng_seed)\n",
    "    while 1:\n",
    "        idx = np.random.choice(range(len(sample_p)), batch_size, p=sample_p)\n",
    "        batch_x = x_set[idx]\n",
    "        batch_y = []\n",
    "\n",
    "        for i in range(n_timesteps):\n",
    "            batch_y.append(y_set[idx])\n",
    "        yield (batch_x, batch_y)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    sample_gen4attractor(\n",
    "        data.y_train, data.y_train, cfg.n_timesteps - 14, cfg.batch_size,\n",
    "        data.sample_p, cfg.sample_rng_seed\n",
    "    ),\n",
    "    steps_per_epoch=cfg.steps_per_epoch,\n",
    "    epochs=cfg.nEpo,\n",
    "    verbose=0,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "# Saving history and model\n",
    "pickle_out = open(cfg.path_history_pickle, \"wb\")\n",
    "pickle.dump(history.history, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "clear_output()\n",
    "print('Training done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import training_history\n",
    "\n",
    "hist = training_history(cfg.path_history_pickle)\n",
    "hist.plot_all(cfg.path_plot_folder + 'history.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import plot_variables\n",
    "plot_variables(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import get_all_pronunciations_fast\n",
    "\n",
    "\n",
    "def attractor_acc(model, data, timestep, verbose):\n",
    "    # Timestep is counting from the first unclapped time point\n",
    "    y_pred_matrix = model.predict(data.y_strain)\n",
    "    y_pred = get_all_pronunciations_fast(\n",
    "        y_pred_matrix[-1], data.phon_key\n",
    "    )  # Prediction at last time step\n",
    "    y_true = get_all_pronunciations_fast(data.y_strain, data.phon_key)\n",
    "\n",
    "    correct = []\n",
    "    incorrect = []\n",
    "    incorrect_ans = []\n",
    "    for i, x in enumerate(y_pred):\n",
    "        if y_pred[i] == y_true[i]:\n",
    "            correct.append(y_pred[i])\n",
    "        else:\n",
    "            incorrect.append(y_pred[i])\n",
    "            incorrect_ans.append(y_true[i])\n",
    "\n",
    "    c_rate = len(correct) / len(y_pred)\n",
    "\n",
    "    if verbose == True:\n",
    "        print(\n",
    "            'Correct preditions {} % \\n They are: {} \\n'.format(\n",
    "                100 * c_rate, correct\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            'Incorrect preditions {} % \\n They are {} \\n'.format(\n",
    "                100 * len(incorrect) / len(y_pred), incorrect\n",
    "            )\n",
    "        )\n",
    "        print('Correct answer should be: {}'.format(incorrect_ans))\n",
    "\n",
    "    return len(correct) / len(y_pred)\n",
    "\n",
    "\n",
    "def attractor_dev(model, cfg, data):\n",
    "    acc = []\n",
    "    for weights_h5 in cfg.path_weights_list:\n",
    "        model.load_weights(weights_h5)\n",
    "        acc.append(attractor_acc(model, data, cfg.n_timesteps - 1, False))\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def get_epoch_where_p_more_than(epoch_list, acc_list, x):\n",
    "    return epoch_list[np.min(np.where(np.array(acc_list) > x))]\n",
    "\n",
    "\n",
    "acc = attractor_dev(model, cfg, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(cfg.saved_epoch_list, acc)\n",
    "plt.title('Attractor accuracy on Strain set over training')\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    'Accuracy reach 0.6 at epoch: {}'.format(\n",
    "        get_epoch_where_p_more_than(cfg.saved_epoch_list, acc, 0.6)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    'Accuracy reach 0.8 at epoch: {}'.format(\n",
    "        get_epoch_where_p_more_than(cfg.saved_epoch_list, acc, 0.8)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    'Accuracy reach 0.9 at epoch: {}'.format(\n",
    "        get_epoch_where_p_more_than(cfg.saved_epoch_list, acc, 0.9)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    'Accuracy reach 0.95 at epoch: {}'.format(\n",
    "        get_epoch_where_p_more_than(cfg.saved_epoch_list, acc, 0.95)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html --output-dir=$cfg.path_model_folder train_attractor.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
