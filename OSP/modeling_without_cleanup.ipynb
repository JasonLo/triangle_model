{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile modeling_without_cleanup.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import activations, initializers, regularizers\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class rnn_no_cleanup(Layer):\n",
    "    # In plaut version (rnn_v1), input are identical in O-->H path over timestep\n",
    "    # Use keras copy layer seems more efficient\n",
    "    def __init__(self, cfg, **kwargs):\n",
    "        super(rnn_no_cleanup, self).__init__(**kwargs)\n",
    "\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.rnn_activation = activations.get(cfg.rnn_activation)\n",
    "        self.weight_regularizer = regularizers.l2(cfg.regularizer_const)\n",
    "\n",
    "        self.w_oh = self.add_weight(\n",
    "            name='w_oh',\n",
    "            shape=(self.cfg.o_input_dim, self.cfg.hidden_units),\n",
    "            initializer=self.cfg.w_initializer,\n",
    "            regularizer=self.weight_regularizer,\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        self.w_hp = self.add_weight(\n",
    "            name='w_hp',\n",
    "            shape=(self.cfg.hidden_units, self.cfg.pho_units),\n",
    "            initializer=self.cfg.w_initializer,\n",
    "            regularizer=self.weight_regularizer,\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        self.w_pp = self.add_weight(\n",
    "            name='w_pp',\n",
    "            shape=(self.cfg.pho_units, self.cfg.pho_units),\n",
    "            initializer=self.cfg.w_initializer,\n",
    "            regularizer=self.weight_regularizer,\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        self.bias_h = self.add_weight(\n",
    "            shape=(self.cfg.hidden_units, ),\n",
    "            name='bias_h',\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        self.bias_p = self.add_weight(\n",
    "            shape=(self.cfg.pho_units, ),\n",
    "            name='bias_p',\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Hack for complying keras.layers.concatenate() format\n",
    "        # Dimension note: (batch, timestep, input_dim)\n",
    "        # Spliting input_dim below (index = 2)\n",
    "        if self.cfg.use_semantic == True:\n",
    "            o_input, s_input = tf.split(\n",
    "                inputs, [self.cfg.o_input_dim, self.cfg.pho_units], 2\n",
    "            )\n",
    "        else:\n",
    "            o_input = inputs\n",
    "\n",
    "        ### Trial level init ###\n",
    "        self.input_h_list = []\n",
    "        self.input_p_list = []\n",
    "\n",
    "        self.act_h_list = []\n",
    "        self.act_p_list = []\n",
    "\n",
    "        # Set input to 0\n",
    "        self.input_h_list.append(\n",
    "            tf.zeros((1, self.cfg.hidden_units), dtype=tf.float32)\n",
    "        )\n",
    "        self.input_p_list.append(\n",
    "            tf.zeros((1, self.cfg.pho_units), dtype=tf.float32)\n",
    "        )\n",
    "\n",
    "        # Set activations to 0.5\n",
    "        self.act_h_list.append(self.input_h_list[0] + 0.5)\n",
    "        self.act_p_list.append(self.input_p_list[0] + 0.5)\n",
    "\n",
    "        for t in range(1, self.cfg.n_timesteps + 1):\n",
    "            # print(f'Time step = {t}')\n",
    "\n",
    "            # Inject noise to weights in each time step\n",
    "            if self.cfg.w_oh_noise != 0:\n",
    "                w_oh = self.inject_noise(self.w_oh, self.cfg.w_oh_noise)\n",
    "            else:\n",
    "                w_oh = self.w_oh\n",
    "\n",
    "            if self.cfg.w_hp_noise != 0:\n",
    "                w_hp = self.inject_noise(self.w_hp, self.cfg.w_hp_noise)\n",
    "            else:\n",
    "                w_hp = self.w_hp\n",
    "\n",
    "            if self.cfg.w_pp_noise != 0:\n",
    "                w_pp = self.inject_noise(self.w_pp, self.cfg.w_pp_noise)\n",
    "            else:\n",
    "                w_pp = self.w_pp\n",
    "\n",
    "            ##### Hidden layer #####\n",
    "            oh = tf.matmul(o_input[:, t - 1, :], w_oh)\n",
    "            mem_h = self.input_h_list[t - 1]\n",
    "            h = self.cfg.tau * (oh + self.bias_h) + (1 - self.cfg.tau) * mem_h\n",
    "\n",
    "            self.input_h_list.append(h)\n",
    "            self.act_h_list.append(self.rnn_activation(h))\n",
    "\n",
    "            ##### Phonology layer #####\n",
    "            hp = tf.matmul(self.act_h_list[t - 1], w_hp)\n",
    "            pp = tf.matmul(\n",
    "                self.act_p_list[t - 1],\n",
    "                tf.linalg.set_diag(w_pp, tf.zeros(self.cfg.pho_units))\n",
    "            )  # Zero diagonal lock\n",
    "\n",
    "            mem_p = self.input_p_list[t - 1]\n",
    "\n",
    "            p = self.cfg.tau * (hp + pp +\n",
    "                                self.bias_p) + (1 - self.cfg.tau) * mem_p\n",
    "\n",
    "            if self.cfg.use_semantic == True:\n",
    "                p += s_input[:, t - 1, :]  # Inject semantic input\n",
    "\n",
    "            self.input_p_list.append(p)\n",
    "            self.act_p_list.append(self.rnn_activation(p))\n",
    "\n",
    "        return self.act_p_list[1:]\n",
    "\n",
    "    def inject_noise(self, x, noise_sd):\n",
    "        noise = K.random_normal(shape=K.shape(x), mean=0., stddev=noise_sd)\n",
    "        return x + noise\n",
    "\n",
    "    def compute_output_shape(self):\n",
    "        return tensor_shape.as_shape([1, cfg.pho_units] + cfg.n_timesteps)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'custom_cfg': self.cfg, 'name': 'rnn'}\n",
    "        base_config = super(rnn_pho_task, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class rnn_no_cleanup_no_pp(Layer):\n",
    "    # In plaut version (rnn_v1), input are identical in O-->H path over timestep\n",
    "    # Use keras copy layer seems more efficient\n",
    "    def __init__(self, cfg, **kwargs):\n",
    "        super(rnn_no_cleanup_no_pp, self).__init__(**kwargs)\n",
    "\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.rnn_activation = activations.get(cfg.rnn_activation)\n",
    "        self.weight_regularizer = regularizers.l2(cfg.regularizer_const)\n",
    "\n",
    "        self.w_oh = self.add_weight(\n",
    "            name='w_oh',\n",
    "            shape=(self.cfg.o_input_dim, self.cfg.hidden_units),\n",
    "            initializer=self.cfg.w_initializer,\n",
    "            regularizer=self.weight_regularizer,\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        self.w_hp = self.add_weight(\n",
    "            name='w_hp',\n",
    "            shape=(self.cfg.hidden_units, self.cfg.pho_units),\n",
    "            initializer=self.cfg.w_initializer,\n",
    "            regularizer=self.weight_regularizer,\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        self.w_pp = self.add_weight(\n",
    "            name='w_pp',\n",
    "            shape=(self.cfg.pho_units, self.cfg.pho_units),\n",
    "            initializer=self.cfg.w_initializer,\n",
    "            regularizer=self.weight_regularizer,\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        self.bias_h = self.add_weight(\n",
    "            shape=(self.cfg.hidden_units, ),\n",
    "            name='bias_h',\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        self.bias_p = self.add_weight(\n",
    "            shape=(self.cfg.pho_units, ),\n",
    "            name='bias_p',\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Hack for complying keras.layers.concatenate() format\n",
    "        # Dimension note: (batch, timestep, input_dim)\n",
    "        # Spliting input_dim below (index = 2)\n",
    "        if self.cfg.use_semantic == True:\n",
    "            o_input, s_input = tf.split(\n",
    "                inputs, [self.cfg.o_input_dim, self.cfg.pho_units], 2\n",
    "            )\n",
    "        else:\n",
    "            o_input = inputs\n",
    "\n",
    "        ### Trial level init ###\n",
    "        self.input_h_list = []\n",
    "        self.input_p_list = []\n",
    "\n",
    "        self.act_h_list = []\n",
    "        self.act_p_list = []\n",
    "\n",
    "        # Set input to 0\n",
    "        self.input_h_list.append(\n",
    "            tf.zeros((1, self.cfg.hidden_units), dtype=tf.float32)\n",
    "        )\n",
    "        self.input_p_list.append(\n",
    "            tf.zeros((1, self.cfg.pho_units), dtype=tf.float32)\n",
    "        )\n",
    "\n",
    "        # Set activations to 0.5\n",
    "        self.act_h_list.append(self.input_h_list[0] + 0.5)\n",
    "        self.act_p_list.append(self.input_p_list[0] + 0.5)\n",
    "\n",
    "        for t in range(1, self.cfg.n_timesteps + 1):\n",
    "            # print(f'Time step = {t}')\n",
    "\n",
    "            # Inject noise to weights in each time step\n",
    "            if self.cfg.w_oh_noise != 0:\n",
    "                w_oh = self.inject_noise(self.w_oh, self.cfg.w_oh_noise)\n",
    "            else:\n",
    "                w_oh = self.w_oh\n",
    "\n",
    "            if self.cfg.w_hp_noise != 0:\n",
    "                w_hp = self.inject_noise(self.w_hp, self.cfg.w_hp_noise)\n",
    "            else:\n",
    "                w_hp = self.w_hp\n",
    "\n",
    "            if self.cfg.w_pp_noise != 0:\n",
    "                w_pp = self.inject_noise(self.w_pp, self.cfg.w_pp_noise)\n",
    "            else:\n",
    "                w_pp = self.w_pp\n",
    "\n",
    "            ##### Hidden layer #####\n",
    "            oh = tf.matmul(o_input[:, t - 1, :], w_oh)\n",
    "            mem_h = self.input_h_list[t - 1]\n",
    "            h = self.cfg.tau * (oh + self.bias_h) + (1 - self.cfg.tau) * mem_h\n",
    "\n",
    "            self.input_h_list.append(h)\n",
    "            self.act_h_list.append(self.rnn_activation(h))\n",
    "\n",
    "            ##### Phonology layer #####\n",
    "            hp = tf.matmul(self.act_h_list[t - 1], w_hp)\n",
    "\n",
    "            mem_p = self.input_p_list[t - 1]\n",
    "\n",
    "            p = self.cfg.tau * (hp + self.bias_p) + (1 - self.cfg.tau) * mem_p\n",
    "\n",
    "            if self.cfg.use_semantic == True:\n",
    "                p += s_input[:, t - 1, :]  # Inject semantic input\n",
    "\n",
    "            self.input_p_list.append(p)\n",
    "            self.act_p_list.append(self.rnn_activation(p))\n",
    "\n",
    "        return self.act_p_list[1:]\n",
    "\n",
    "    def inject_noise(self, x, noise_sd):\n",
    "        noise = K.random_normal(shape=K.shape(x), mean=0., stddev=noise_sd)\n",
    "        return x + noise\n",
    "\n",
    "    def compute_output_shape(self):\n",
    "        return tensor_shape.as_shape([1, cfg.pho_units] + cfg.n_timesteps)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'custom_cfg': self.cfg, 'name': 'rnn'}\n",
    "        base_config = super(rnn_pho_task, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
