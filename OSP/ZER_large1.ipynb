{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbgouQwZ1Y1f"
   },
   "source": [
    "# OSP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes:\n",
    "- Absolute path\n",
    "- Flexible zero-error-radius\n",
    "- Examine output by teaching signal and slots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import h5py, pickle, os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import meta, data_wrangling, modeling, evaluate\n",
    "from IPython.display import clear_output\n",
    "\n",
    "meta.gpu_mem_cap(2048)  # Put memory cap to allow parallel runs\n",
    "meta.check_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters block for Papermill\n",
    "- Instead of using model_cfg directly, this extra step is needed for batch run using Papermill\n",
    "- Consider carefully the variable type in each cfg setting (Probably automatically check it later...)\n",
    "    - Do not use integer (e.g., 1, 2, 3, 0) in variables that can be float32 (e.g., w_oh_noise, tau...)\n",
    "    - Use integer with a dot instead (e.g., 1., 2., 3., 0.)\n",
    "- To use attractor, two params must be config, \n",
    "    - 1) embed_attractor_cfg --> json cfg file of the pretrain attractor \n",
    "    - 2) embed_attractor_h5 --> h5 file of the exact weight (e.g. ep0500.h5 #epoch or c90.h5 #correct rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "code_name = \"large1\"\n",
    "\n",
    "sample_name = \"jay\"\n",
    "rng_seed = 53797\n",
    "use_semantic = False\n",
    "\n",
    "# Model architechture\n",
    "input_dim = 119\n",
    "output_dim = 250\n",
    "hidden_units = 100\n",
    "cleanup_units = 20\n",
    "\n",
    "pretrain_attractor = False  # Load pretrained or not\n",
    "\n",
    "# embed_attractor_cfg = 'models/Attractor_{0:02d}/model_config.json'.format(\n",
    "#     cleanup_units\n",
    "# )\n",
    "# embed_attractor_h5 = 'c00.h5'\n",
    "\n",
    "rnn_activation = \"sigmoid\"\n",
    "regularizer_const = None\n",
    "w_initializer = 0.1  # range of uniform random\n",
    "zero_error_radius = 0.1  # When True, zer value = 0.1, hardcoded in modeling.zer_bce()\n",
    "\n",
    "\n",
    "p_noise = 0.0\n",
    "tau = 1 / 3\n",
    "max_unit_time = 4.0\n",
    "output_ticks = 2\n",
    "\n",
    "# Training\n",
    "optimizer = \"adam\"\n",
    "n_mil_sample = 1.0\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "save_freq = 10\n",
    "\n",
    "bq_dataset = None\n",
    "batch_unique_setting_string = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for v in meta.model_cfg.minimal_cfgs:\n",
    "    d[v] = globals()[v]\n",
    "\n",
    "for v in meta.model_cfg.aux_cfgs:\n",
    "    try:\n",
    "        d[v] = globals()[v]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "cfg = meta.model_cfg(**d)\n",
    "\n",
    "tf.random.set_seed(cfg.rng_seed)\n",
    "data = data_wrangling.my_data(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0IwxbE29_0yx"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom metrics (in development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Out0(tf.keras.metrics.Metric):\n",
    "    \"\"\"Export last slot average output in last batch of a epoch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"output0\", **kwargs):\n",
    "        super(Out0, self).__init__(name=name, **kwargs)\n",
    "        self.out = self.add_weight(name=\"out0\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.out.assign(tf.reduce_mean(y_pred[y_true == 0]))\n",
    "\n",
    "    def result(self):\n",
    "        return self.out\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.out.assign(0.0)\n",
    "\n",
    "\n",
    "class Out1(tf.keras.metrics.Metric):\n",
    "    \"\"\"Export last slot average output in last batch of a epoch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"output1\", **kwargs):\n",
    "        super(Out1, self).__init__(name=name, **kwargs)\n",
    "        self.out = self.add_weight(name=\"out1\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.out.assign(tf.reduce_mean(y_pred[y_true == 1]))\n",
    "\n",
    "    def result(self):\n",
    "        return self.out\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.out.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanOutputSlot10(tf.keras.metrics.Metric):\n",
    "    \"\"\"Export last slot average output in last batch of a epoch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"mean_output_slot10\", **kwargs):\n",
    "        super(MeanOutputSlot10, self).__init__(name=name, **kwargs)\n",
    "        self.out10 = self.add_weight(name=\"out10\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_slots = tf.split(y_pred, 10, axis=-1)\n",
    "        self.out10.assign(tf.reduce_mean(y_pred_slots[9]))\n",
    "\n",
    "    def result(self):\n",
    "        return self.out10\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.out10.assign(0.0)\n",
    "\n",
    "\n",
    "class MeanOutputSlot4(tf.keras.metrics.Metric):\n",
    "    \"\"\"Export last slot average output in last batch of a epoch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"mean_output_slot4\", **kwargs):\n",
    "        super(MeanOutputSlot4, self).__init__(name=name, **kwargs)\n",
    "        self.out4 = self.add_weight(name=\"out4\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_slots = tf.split(y_pred, 10, axis=-1)\n",
    "        self.out4.assign(tf.reduce_mean(y_pred_slots[3]))\n",
    "\n",
    "    def result(self):\n",
    "        return self.out4\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.out4.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Input, concatenate, multiply, RepeatVector\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "\n",
    "def build_model(training=True):\n",
    "    \"\"\"\n",
    "    Create Keras model\n",
    "    Note that:\n",
    "    For structural things, such as repeat vector, should build within the model\n",
    "    For Static calculation of input, it is easier to modify, should build within sample generator\n",
    "    \"\"\"\n",
    "\n",
    "    cfg.noise_on() if training else cfg.noise_off()\n",
    "\n",
    "    input_o = Input(shape=(cfg.input_dim,), name=\"Input_O\")\n",
    "    input_o_t = RepeatVector(cfg.n_timesteps, name=\"Input_Ot\")(input_o)\n",
    "\n",
    "    # Construct semantic input\n",
    "    if cfg.use_semantic == True:\n",
    "        raw_s_t = Input(shape=(cfg.n_timesteps, cfg.output_dim), name=\"Plaut_St\")\n",
    "\n",
    "        input_p = Input(shape=(cfg.output_dim,), name=\"input_P\")\n",
    "        input_p_t = RepeatVector(cfg.n_timesteps, name=\"Teaching_Pt\")(input_p)\n",
    "\n",
    "        input_s_t = multiply([raw_s_t, input_p_t], name=\"Input_St\")\n",
    "\n",
    "        combined = concatenate([input_o_t, input_s_t], name=\"Combined_input\")\n",
    "        rnn_model = rnn(cfg)(combined)\n",
    "        model = Model([input_o, raw_s_t, input_p], rnn_model)\n",
    "\n",
    "    else:\n",
    "        rnn_model = modeling.rnn(cfg)(input_o_t)\n",
    "        model = Model(input_o, rnn_model)\n",
    "\n",
    "    # Select optimizer\n",
    "    if cfg.optimizer == \"adam\":\n",
    "        op = Adam(\n",
    "            learning_rate=cfg.learning_rate, beta_1=0.0, beta_2=0.999, amsgrad=False\n",
    "        )\n",
    "\n",
    "    elif cfg.optimizer == \"sgd\":\n",
    "        op = SGD(cfg.learning_rate)\n",
    "\n",
    "    # Select zero error radius (by chossing custom loss function zer_bce())\n",
    "\n",
    "    me = [\n",
    "        \"BinaryAccuracy\",\n",
    "        \"mse\",\n",
    "        Out0(),\n",
    "        Out1(),\n",
    "        MeanOutputSlot4(),\n",
    "        MeanOutputSlot10(),\n",
    "    ]\n",
    "\n",
    "    if cfg.zero_error_radius is not None:\n",
    "        print(f\"Using zero-error-radius of {zero_error_radius}\")\n",
    "        model.compile(\n",
    "            loss=modeling.CustomBCE(radius=cfg.zero_error_radius),\n",
    "            optimizer=op,\n",
    "            metrics=me,\n",
    "        )\n",
    "\n",
    "    elif cfg.zero_error_radius is None:\n",
    "        print(f\"No zero-error-radius\")\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=op, metrics=me)\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arming attractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.pretrain_attractor is True:\n",
    "    print(\"Found attractor info in config (cfg), arming attractor...\")\n",
    "    attractor_cfg = meta.model_cfg(cfg.embed_attractor_cfg, bypass_chk=True)\n",
    "    attractor_obj = modeling.attractor(attractor_cfg, cfg.embed_attractor_h5)\n",
    "    model = modeling.arm_attractor(model, attractor_obj)\n",
    "    evaluate.plot_variables(model)\n",
    "else:\n",
    "    print(\"Config indicates no attractor, I have do nothing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKUOoZkP8QiA"
   },
   "source": [
    "## Training\n",
    "- ball (id = 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.df_train.loc[\n",
    "    96,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_input = np.tile(data.x_train[96,], [1, 1])\n",
    "one_input = one_input.astype(\"float32\")\n",
    "\n",
    "one_target = np.tile(data.y_train[96,], [1, 1])\n",
    "one_target = one_target.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tboard = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=f\"batch_log/{cfg.code_name}\", histogram_freq=1\n",
    ")\n",
    "\n",
    "history = model.fit(x=one_input, y=one_target, epochs=10, verbose=1, callbacks=[tboard])\n",
    "\n",
    "\n",
    "clear_output()\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=one_input, y=one_target, epochs=50, verbose=1, callbacks=[tboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintAllIO:\n",
    "    \"\"\"A Convienient class for printing out all input and activation in layer rnn\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def get_rnn(self, name):\n",
    "        return np.asarray(\n",
    "            [x.numpy() for x in getattr(model.get_layer(\"rnn\"), name)]\n",
    "        ).squeeze()\n",
    "\n",
    "    def print_all(self):\n",
    "\n",
    "        print(\"Input h:\")\n",
    "        print(self.get_rnn(\"input_h_list\"))\n",
    "        print(\"Activation h:\")\n",
    "        print(self.get_rnn(\"act_h_list\"))\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print(\"Input c:\")\n",
    "        print(self.get_rnn(\"input_c_list\"))\n",
    "        print(\"Activation c:\")\n",
    "        print(self.get_rnn(\"act_c_list\"))\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print(\"Input p:\")\n",
    "        print(self.get_rnn(\"input_p_list\"))\n",
    "        print(\"Activation p:\")\n",
    "        print(self.get_rnn(\"act_p_list\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(one_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk0 = PrintAllIO(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last 2 timesteps activation p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When target is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last1 = chk0.get_rnn(\"act_p_list\")[-1, :]\n",
    "last1[one_target[0] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last2 = chk0.get_rnn(\"act_p_list\")[-2, :]\n",
    "last2[one_target[0] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When target is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last1[one_target[0] == 0] > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last2[one_target[0] == 0] > 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- None of the targe == 1 nodes has injected error\n",
    "- Many target == 0 node still has injected error\n",
    "- Perhaps sparsity explain the punching throught learning ... same as last expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "basicO2P_master.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
