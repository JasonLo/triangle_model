{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbgouQwZ1Y1f"
   },
   "source": [
    "# OSP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes:\n",
    "- Absolute path\n",
    "- Flexible zero-error-radius\n",
    "- Examine output by teaching signal and slots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import h5py, pickle, os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import meta, data_wrangling, modeling, evaluate\n",
    "from IPython.display import clear_output\n",
    "\n",
    "meta.gpu_mem_cap(2048)  # Put memory cap to allow parallel runs\n",
    "meta.check_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters block for Papermill\n",
    "- Instead of using model_cfg directly, this extra step is needed for batch run using Papermill\n",
    "- Consider carefully the variable type in each cfg setting (Probably automatically check it later...)\n",
    "    - Do not use integer (e.g., 1, 2, 3, 0) in variables that can be float32 (e.g., w_oh_noise, tau...)\n",
    "    - Use integer with a dot instead (e.g., 1., 2., 3., 0.)\n",
    "- To use attractor, two params must be config, \n",
    "    - 1) embed_attractor_cfg --> json cfg file of the pretrain attractor \n",
    "    - 2) embed_attractor_h5 --> h5 file of the exact weight (e.g. ep0500.h5 #epoch or c90.h5 #correct rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "code_name = \"boox\"\n",
    "\n",
    "sample_name = \"jay\"\n",
    "rng_seed = 53797\n",
    "use_semantic = False\n",
    "\n",
    "# Model architechture\n",
    "input_dim = 119\n",
    "output_dim = 250\n",
    "hidden_units = 100\n",
    "cleanup_units = 20\n",
    "\n",
    "pretrain_attractor = False  # Load pretrained or not\n",
    "\n",
    "# embed_attractor_cfg = 'models/Attractor_{0:02d}/model_config.json'.format(\n",
    "#     cleanup_units\n",
    "# )\n",
    "# embed_attractor_h5 = 'c00.h5'\n",
    "\n",
    "rnn_activation = \"sigmoid\"\n",
    "regularizer_const = None\n",
    "w_initializer = 0.1  # range of uniform random\n",
    "zero_error_radius = 0.5  # When True, zer value = 0.1, hardcoded in modeling.zer_bce()\n",
    "\n",
    "\n",
    "p_noise = 0.0\n",
    "tau = 1 / 3\n",
    "max_unit_time = 4.0\n",
    "output_ticks = 2\n",
    "\n",
    "# Training\n",
    "optimizer = \"adam\"\n",
    "n_mil_sample = 1.0\n",
    "batch_size = 128\n",
    "learning_rate = 0.05\n",
    "save_freq = 10\n",
    "\n",
    "bq_dataset = None\n",
    "batch_unique_setting_string = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for v in meta.model_cfg.minimal_cfgs:\n",
    "    d[v] = globals()[v]\n",
    "\n",
    "for v in meta.model_cfg.aux_cfgs:\n",
    "    try:\n",
    "        d[v] = globals()[v]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "cfg = meta.model_cfg(**d)\n",
    "\n",
    "tf.random.set_seed(cfg.rng_seed)\n",
    "data = data_wrangling.my_data(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0IwxbE29_0yx"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom metrics (in development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanOutputSlot10(tf.keras.metrics.Metric):\n",
    "    \"\"\"Export last slot average output in last batch of a epoch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"mean_output_slot10\", **kwargs):\n",
    "        super(MeanOutputSlot10, self).__init__(name=name, **kwargs)\n",
    "        self.out10 = self.add_weight(name=\"out10\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_slots = tf.split(y_pred, 10, axis=-1)\n",
    "        self.out10.assign(tf.reduce_mean(y_pred_slots[9]))\n",
    "\n",
    "    def result(self):\n",
    "        return self.out10\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.out10.assign(0.0)\n",
    "\n",
    "\n",
    "class MeanOutputSlot4(tf.keras.metrics.Metric):\n",
    "    \"\"\"Export last slot average output in last batch of a epoch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"mean_output_slot4\", **kwargs):\n",
    "        super(MeanOutputSlot4, self).__init__(name=name, **kwargs)\n",
    "        self.out4 = self.add_weight(name=\"out4\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_slots = tf.split(y_pred, 10, axis=-1)\n",
    "        self.out4.assign(tf.reduce_mean(y_pred_slots[3]))\n",
    "\n",
    "    def result(self):\n",
    "        return self.out4\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.out4.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Input, concatenate, multiply, RepeatVector\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "\n",
    "def build_model(training=True):\n",
    "    \"\"\"\n",
    "    Create Keras model\n",
    "    Note that:\n",
    "    For structural things, such as repeat vector, should build within the model\n",
    "    For Static calculation of input, it is easier to modify, should build within sample generator\n",
    "    \"\"\"\n",
    "\n",
    "    cfg.noise_on() if training else cfg.noise_off()\n",
    "\n",
    "    input_o = Input(shape=(cfg.input_dim,), name=\"Input_O\")\n",
    "    input_o_t = RepeatVector(cfg.n_timesteps, name=\"Input_Ot\")(input_o)\n",
    "\n",
    "    # Construct semantic input\n",
    "    if cfg.use_semantic == True:\n",
    "        raw_s_t = Input(shape=(cfg.n_timesteps, cfg.output_dim), name=\"Plaut_St\")\n",
    "\n",
    "        input_p = Input(shape=(cfg.output_dim,), name=\"input_P\")\n",
    "        input_p_t = RepeatVector(cfg.n_timesteps, name=\"Teaching_Pt\")(input_p)\n",
    "\n",
    "        input_s_t = multiply([raw_s_t, input_p_t], name=\"Input_St\")\n",
    "\n",
    "        combined = concatenate([input_o_t, input_s_t], name=\"Combined_input\")\n",
    "        rnn_model = rnn(cfg)(combined)\n",
    "        model = Model([input_o, raw_s_t, input_p], rnn_model)\n",
    "\n",
    "    else:\n",
    "        rnn_model = modeling.rnn(cfg)(input_o_t)\n",
    "        model = Model(input_o, rnn_model)\n",
    "\n",
    "    # Select optimizer\n",
    "    if cfg.optimizer == \"adam\":\n",
    "        op = Adam(\n",
    "            learning_rate=cfg.learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False\n",
    "        )\n",
    "\n",
    "    elif cfg.optimizer == \"sgd\":\n",
    "        op = SGD(cfg.learning_rate)\n",
    "\n",
    "    # Select zero error radius (by chossing custom loss function zer_bce())\n",
    "\n",
    "    me = [\"BinaryAccuracy\", \"mse\", MeanOutputSlot4(), MeanOutputSlot10()]\n",
    "\n",
    "    if cfg.zero_error_radius is not None:\n",
    "        print(f\"Using zero-error-radius of {zero_error_radius}\")\n",
    "        model.compile(\n",
    "            loss=modeling.CustomBCE(radius=cfg.zero_error_radius),\n",
    "            optimizer=op,\n",
    "            metrics=me,\n",
    "        )\n",
    "\n",
    "    elif cfg.zero_error_radius is None:\n",
    "        print(f\"No zero-error-radius\")\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=op, metrics=me)\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arming attractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.pretrain_attractor is True:\n",
    "    print(\"Found attractor info in config (cfg), arming attractor...\")\n",
    "    attractor_cfg = meta.model_cfg(cfg.embed_attractor_cfg, bypass_chk=True)\n",
    "    attractor_obj = modeling.attractor(attractor_cfg, cfg.embed_attractor_h5)\n",
    "    model = modeling.arm_attractor(model, attractor_obj)\n",
    "    evaluate.plot_variables(model)\n",
    "else:\n",
    "    print(\"Config indicates no attractor, I have do nothing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKUOoZkP8QiA"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = modeling.ModelCheckpoint_custom(\n",
    "    cfg.path_weights_checkpoint, save_weights_only=True, period=cfg.save_freq,\n",
    ")\n",
    "\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "#     cfg.path_log_folder, histogram_freq=1\n",
    "# )\n",
    "\n",
    "history = model.fit(\n",
    "    data_wrangling.sample_generator(cfg, data),\n",
    "    steps_per_epoch=cfg.steps_per_epoch,\n",
    "    epochs=cfg.nEpo,\n",
    "    verbose=0,\n",
    "    callbacks=[checkpoint],\n",
    ")\n",
    "\n",
    "\n",
    "# Saving history and model\n",
    "pickle_out = open(cfg.path_history_pickle, \"wb\")\n",
    "pickle.dump(history.history, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "clear_output()\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMmNcbJdcPMh"
   },
   "source": [
    "# Parse results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse item level stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must turn training mode off before evaluation\n",
    "model = build_model(training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strain full model\n",
    "strain = evaluate.strain_eval(cfg, data, model)\n",
    "strain.start_evaluate(\n",
    "    test_use_semantic=False, output=cfg.path_model_folder + \"result_strain_item.csv\"\n",
    ")\n",
    "\n",
    "# Semantic lesion in Strain\n",
    "# if cfg.use_semantic == True:\n",
    "#     strain_ns = strain_eval(cfg, data, model)\n",
    "#     strain_ns.start_evaluate(\n",
    "#         test_use_semantic=False,\n",
    "#         output=cfg.path_model_folder + 'result_strain_ns_item.csv'\n",
    "#     )\n",
    "\n",
    "# Grain\n",
    "grain = evaluate.grain_eval(cfg, data, model)\n",
    "grain.start_evaluate(output=cfg.path_model_folder + \"result_grain_item.csv\")\n",
    "\n",
    "# Taraban\n",
    "taraban = evaluate.taraban_eval(cfg, data, model)\n",
    "taraban.start_evaluate(\n",
    "    test_use_semantic=False, output=cfg.path_model_folder + \"result_taraban_item.csv\"\n",
    ")\n",
    "\n",
    "# Glushko\n",
    "glushko = evaluate.glushko_eval(cfg, data, model)\n",
    "glushko.start_evaluate(False, cfg.path_model_folder + \"result_glushko_item.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack results into visualization class\n",
    "vis = evaluate.vis(cfg.path_model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.training_hist().save(cfg.path_plot_folder + \"training_history.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output at slot 4 & 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = evaluate.training_history(cfg.path_history_pickle)\n",
    "x.plot(\"rnn_1_mean_output_slot10\", \"output10\").save(\n",
    "    cfg.path_plot_folder + \"output_slot10.html\"\n",
    ")\n",
    "\n",
    "x.plot(\"rnn_1_mean_output_slot4\", \"output4\").save(\n",
    "    cfg.path_plot_folder + \"output_slot4.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KnxCNzMyWah"
   },
   "source": [
    "### Strain and Grain plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis_ns = vis(\n",
    "#     cfg.path_model_folder, 'result_strain_ns_item.csv', 'result_grain_item.csv'\n",
    "# )\n",
    "# vis_ns.parse_cond_df()\n",
    "# lesion = vis_ns.plot_dev('acc').properties(title='Semantic lesion')\n",
    "# strain_plot = full | lesion\n",
    "# strain_plot\n",
    "\n",
    "sg = vis.plot_dev_interactive(\"acc\", [\"strain\", \"grain\"]).properties(\n",
    "    title=\"Accuracy in Strain and Grain\"\n",
    ")\n",
    "sg.save(cfg.path_plot_folder + \"development_sg.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesion development deep dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_inter = vis.plot_dev_interactive('acc')\n",
    "# dev_inter.save(cfg.path_plot_folder + 'interactive_strain_dev_full.html')\n",
    "# dev_inter\n",
    "\n",
    "# dev_inter = vis_ns.plot_dev_interactive('acc')\n",
    "# dev_inter.save(cfg.path_plot_folder + 'interactive_strain_dev_lesion.html')\n",
    "# dev_inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesion time plot deep dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_inter = vis.plot_time_interactive('acc')\n",
    "# time_inter.save(cfg.path_plot_folder + 'interactive_strain_time.html')\n",
    "# time_inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grain plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = vis.plot_dev_interactive(\"acc_small_grain\", exp=[\"grain\"]).properties(\n",
    "    title=\"Small Grain Response\"\n",
    ")\n",
    "large = vis.plot_dev_interactive(\"acc_large_grain\", exp=[\"grain\"]).properties(\n",
    "    title=\"Large Grain Response\"\n",
    ")\n",
    "grain_plot = (small | large).properties(\n",
    "    title=\"Accuracy of Grain by response and condition\"\n",
    ")\n",
    "grain_plot.save(cfg.path_plot_folder + \"development_grain_by_response.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taraban and Glushko plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = vis.plot_dev_interactive(\"acc\", [\"taraban\", \"glushko\"]).properties(\n",
    "    title=\"Accuracy in Taraban and Glushko by condition\"\n",
    ")\n",
    "tb.save(cfg.path_plot_folder + \"development_tg.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words vs. Nonwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnw_zr = vis.plot_wnw([\"INC_HF\"], [\"unambiguous\"]).properties(\n",
    "    title=\"Strain (INC_HF) vs. Grain (UN)\"\n",
    ")\n",
    "\n",
    "all_taraban_conds = list(vis.cdf.loc[vis.cdf.exp == \"taraban\", \"cond\"].unique())\n",
    "wnw_tg = vis.plot_wnw(all_taraban_conds, [\"Exception\", \"Regular\"]).properties(\n",
    "    title=\"Taraban (all) vs. Glushko (NW)\"\n",
    ")\n",
    "wnw_plot = wnw_zr | wnw_tg\n",
    "wnw_plot.save(cfg.path_plot_folder + \"wnw.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.weight(cfg.path_weights_list[-1]).violinplot(\n",
    "    cfg.path_plot_folder + \"weight_violin.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.weight(cfg.path_weights_list[-1]).heatmap(\n",
    "    cfg.path_plot_folder + \"weight_heatmap.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --output-dir=$cfg.path_model_folder --to html OSP_master.ipynb"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "basicO2P_master.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
