{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling probability analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, training set data is being feed by a custom data_wrangling.sample_generator() function, what it do basically are:\n",
    "1. Set random seed (line 4)\n",
    "2. Randomly generate n item ids (where n=batch_size) by sampling probability (data.sample_p) (line 10-12)\n",
    "3. Retrieve actual data from data.x_train by idx (line 20)\n",
    "4. Fill it to a n_timesteps dataframe (to clamp input over timesteps) (line 18-20)\n",
    "5. Repeat 2-5 while being called\n",
    "\n",
    "For simplicity, below showing a version without semantic input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_generator(cfg, data):\n",
    "    # Dimension guide: (batch_size, timesteps, nodes)\n",
    "\n",
    "    np.random.seed(cfg.rng_seed)\n",
    "    epoch = 0\n",
    "    batch = 0\n",
    "\n",
    "    while True:\n",
    "        batch += 1\n",
    "        idx = np.random.choice(\n",
    "            range(len(data.sample_p)), cfg.batch_size, p=data.sample_p\n",
    "        )\n",
    "\n",
    "        # Preallocate for easier indexing: (batch_size, time_step, input_dim)\n",
    "        batch_s = np.zeros((cfg.batch_size, cfg.n_timesteps, cfg.output_dim))\n",
    "        batch_y = []\n",
    "\n",
    "        for t in range(cfg.n_timesteps):\n",
    "\n",
    "            batch_y.append(data.y_train[idx])\n",
    "\n",
    "        if batch % cfg.steps_per_epoch == 0:\n",
    "            epoch += 1  # Counting epoch for ramping up input S\n",
    "\n",
    "        yield (data.x_train[idx], batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, data.sample_p control how often the model see a given word during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample_p\n",
    "There are two implementations in calculating sample_p\n",
    "1. HS04\n",
    "2. Jay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In HS04 implementation:\n",
    "    \n",
    "\n",
    "> The frequency of each item was coded using a square-root compression of the Wall Street Journal (WSJ) corpus (Marcus, Santorini, & Marcinkiewicz, 1993) according to the formula\n",
    "> $p_i=\\frac{\\sqrt{f_i}}{\\sqrt{m}}$ ... (6)\n",
    "> where fi is the WSJ frequency of the ith item and m is 30,000 (a reasonable cutoff frequency). Values over 1.0 were set to 1.0; those less than 0.05 were set to 0.05.\n",
    "\n",
    "\n",
    "In Jay implementation:\n",
    "``` python\n",
    "> # generate frequency proportions (probably could be a separate function)\n",
    "> train[4] = [min(x, 10000) for x in train[3]]  # cap frequency at 10k\n",
    "> train[5] = np.sqrt(train[4])  # take the SQRT of the capped frequency\n",
    "> train[6] = train[5] / train[5].sum()  # generate proportion for sampling\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wf_manager():\n",
    "    # Note: the probability must sum to 1 when passing it to np.random.choice()\n",
    "    def __init__(self, wf):\n",
    "        self.wf = np.array(wf)\n",
    "\n",
    "    def to_p(self, x):\n",
    "        \"\"\"\n",
    "        Calculate proportion p, i.e. Sum(p) = 1 in training set\n",
    "        \"\"\"\n",
    "        return x / np.sum(x)\n",
    "    \n",
    "    def root_freq(self):\n",
    "        return np.sqrt(self.wf)\n",
    "\n",
    "    def samp_hs04(self):\n",
    "        \"\"\"\n",
    "        HS04 sampling p implementation\n",
    "        \"\"\"\n",
    "        root = np.sqrt(self.wf) / np.sqrt(30000)  # Formula 6 (HS04)\n",
    "        clip = root.clip(0.05, 1.0)               # Values over 1.0 were set to 1.0; those less than 0.05 were set to 0.05.\n",
    "        return self.to_p(clip)                    # generate proportion for sampling\n",
    "    \n",
    "    def samp_jay(self):\n",
    "        \"\"\"\n",
    "        Jay's sampling p implementation\n",
    "        Identical to script from Jay (support.py)\n",
    "        \"\"\"\n",
    "        cap = self.wf.clip(0, 10000)              # cap frequency at 10k\n",
    "        root = np.sqrt(cap)                       # take the SQRT of the capped frequency\n",
    "        return self.to_p(root)                    # generate proportion for sampling\n",
    "    \n",
    "    def samp_jay_in_hs04_style(self):\n",
    "        \"\"\"\n",
    "        Jay's sampling p in HS04 style\n",
    "        \"\"\"\n",
    "        root = np.sqrt(self.wf) / np.sqrt(10000)\n",
    "        clip = root.clip(0., 1.)\n",
    "        return self.to_p(clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the current pipeline to generate sampling_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_train = pd.read_csv('../common/input/df_train.csv', index_col=0)\n",
    "wf = wf_manager(df_train['wf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minor Checking: samp_jay == samp_jay_in_hs04_style, upto 1e-16..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert any(wf.samp_jay() - wf.samp_jay_in_hs04_style() > 1e-16) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data file for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd \n",
    "alt.data_transformers.enable(\"default\")\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "df = pd.DataFrame({'p_jay': wf.samp_jay(), 'p_hs04': wf.samp_hs04(), 'root_wf': wf.root_freq()})\n",
    "df = df.melt(id_vars='root_wf', var_name='sample', value_name='p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a peek at the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of root frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_area().encode(\n",
    "    alt.X('root_wf', bin=alt.Bin(step=10)),\n",
    "    alt.Y('count()')\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Root frequency is still heavily skewed to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pchart = alt.Chart(df).mark_line().encode(x='root_wf', y='p', color='sample').interactive()\n",
    "pchart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Actually it is the same graph I shown last time... but x-axis changed to root for easier scaling\n",
    "    - when x = 0-7 (approximately), p_hs04 > p_jay \n",
    "    - when x = 7 to 125, p_jay > p_hs04\n",
    "    - when x = 125 to inf, p_hs04 > p_jay\n",
    "- Cuminative probability should be == 1 \n",
    "    - Yes, but hard to see, since x-axis is very skewed... \n",
    "    - proof:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sum of all p in jay: {} and hs04: {}'.format(sum(wf.samp_jay()), sum(wf.samp_hs04())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aera under the curve won't be equal, since x-axis is weighted (low end is heavier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strain = pd.read_csv('../common/input/df_strain.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive of root frequency in High frequency (HF) condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(df_strain.loc[df_strain.frequency=='HF','wf'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive of root frequency in Low frequency (LF) condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(df_strain.loc[df_strain.frequency=='LF','wf'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High-light 25-75 percentile on the chart for easier viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_df = [{\n",
    "            \"start\": 41.5,\n",
    "            \"end\": 104.7,\n",
    "            \"condition\": \"HF\"\n",
    "          },\n",
    "          {\n",
    "            \"start\": 9.2,\n",
    "            \"end\": 22.1,\n",
    "            \"condition\": \"LF\"\n",
    "          }]\n",
    "\n",
    "anno_df = pd.DataFrame(anno_df)\n",
    "\n",
    "rect = alt.Chart(anno_df).mark_rect().encode(\n",
    "    x='start',\n",
    "    x2='end',\n",
    "    color='condition:N',\n",
    "    opacity=alt.value(0.8)\n",
    ").interactive()\n",
    "\n",
    "rect + pchart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- p_jay > p_hs04 most of the time in Strain data set\n",
    "    - discrepancy increase as word frequency increase (until it hit the clipping point of p_jay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --output-dir=. --to html sampling_check.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
