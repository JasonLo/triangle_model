{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declarator for counting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(func, *args, **kwargs):\n",
    "    def wrapper():\n",
    "        counter = {}\n",
    "        words = func(*args, **kwargs)\n",
    "        for word in words:\n",
    "            if word in counter:\n",
    "                counter[word] += 1\n",
    "            else:\n",
    "                counter[word] = 1\n",
    "        return func(*args, **kwargs), counter\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stitching altair plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import benchmark_hs04, meta\n",
    "import os\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot1(test_obj, null, metric, timetick=12):\n",
    "    \"\"\"Plot metric over training epoch\"\"\"\n",
    "    code_name = test_obj.cfg.code_name\n",
    "    df = test_obj.eval(\"train_r100\", \"triangle\")\n",
    "    mean_df = benchmark_hs04.make_mean_df(df)\n",
    "\n",
    "    metric_specific_scale = alt.Scale(domain=(0, 1)) if metric == \"acc\" else alt.Scale()\n",
    "    plot_title = f\"{code_name}: (batch size: {test_obj.cfg.batch_size}; learning rate: {test_obj.cfg.learning_rate})\"\n",
    "    return (\n",
    "        alt.Chart(mean_df.loc[mean_df.timetick==timetick])\n",
    "        .mark_line(point=True)\n",
    "        .encode(\n",
    "            x=\"epoch:Q\",\n",
    "            y=alt.Y(f\"mean({metric}):Q\", scale=metric_specific_scale),\n",
    "            color=\"output_name:N\",\n",
    "        )\n",
    "    ).properties(title=plot_title)\n",
    "\n",
    "def plot2(test_obj, epoch_selector, metric, timetick=range(4, 13)):\n",
    "    \"\"\"Plot metric over training epoch\"\"\"\n",
    "    code_name = test_obj.cfg.code_name\n",
    "    df = test_obj.eval(\"taraban\", \"triangle\")\n",
    "    mean_df = benchmark_hs04.make_cond_mean_df(df)\n",
    "    mean_df = mean_df.loc[mean_df.timetick.isin(timetick)]\n",
    "    mean_df = mean_df.loc[mean_df.output_name == \"pho\"]\n",
    "    mean_df = mean_df.loc[\n",
    "        mean_df.cond.isin(\n",
    "            [\n",
    "                \"High-frequency exception\",\n",
    "                \"Regular control for High-frequency exception\",\n",
    "                \"Low-frequency exception\",\n",
    "                \"Regular control for Low-frequency exception\",\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    mean_df[\"freq\"] = mean_df.cond.apply(\n",
    "        lambda x: \"High\"\n",
    "        if x\n",
    "        in (\"High-frequency exception\", \"Regular control for High-frequency exception\")\n",
    "        else \"Low\"\n",
    "    )\n",
    "    mean_df[\"reg\"] = mean_df.cond.apply(\n",
    "        lambda x: \"Regular\" if x.startswith(\"Regular\") else \"Exception\"\n",
    "    )\n",
    "\n",
    "\n",
    "    metric_specific_scale = alt.Scale(domain=(0, 1)) if metric == \"acc\" else alt.Scale()\n",
    "    plot_title = f\"{code_name}: (batch size: {test_obj.cfg.batch_size}; learning rate: {test_obj.cfg.learning_rate})\"\n",
    "\n",
    "    epoch_selection = (\n",
    "        alt.Chart(mean_df).mark_rect().encode(x=\"epoch:Q\").add_selection(epoch_selector)\n",
    "    ).properties(width=400)\n",
    "\n",
    "    plot_fxc_interact = (\n",
    "        alt.Chart(mean_df)\n",
    "        .mark_line()\n",
    "        .encode(\n",
    "            x=alt.X(\"freq:N\", scale=alt.Scale(reverse=True),axis=alt.Axis(labels=False)),\n",
    "            y=alt.Y(f\"mean({metric}):Q\", scale=metric_specific_scale),\n",
    "            color=\"reg:N\",\n",
    "        )\n",
    "        .transform_filter(epoch_selector)\n",
    "        .properties(width=400)\n",
    "    )\n",
    "\n",
    "    return (epoch_selection & plot_fxc_interact).properties(title=plot_title)\n",
    "\n",
    "\n",
    "def plot4(test_obj, epoch_selector, metric, timetick=range(4, 13)):\n",
    "    code_name = test_obj.cfg.code_name\n",
    "\n",
    "    df = test_obj.eval(\"hs04_img_240\", \"triangle\")\n",
    "    mean_df = benchmark_hs04.make_cond_mean_df(df)\n",
    "\n",
    "    mean_df = mean_df.loc[mean_df.timetick.isin(timetick)]\n",
    "    mean_df = mean_df.loc[mean_df.output_name == \"pho\"]\n",
    "    \n",
    "    mean_df[\"fc\"] = mean_df.cond.apply(lambda x: x[:5])\n",
    "    mean_df[\"img\"] = mean_df.cond.apply(lambda x: x[-2:])\n",
    "\n",
    "    metric_specific_scale = alt.Scale(domain=(0, 1)) if metric == \"acc\" else alt.Scale()\n",
    "\n",
    "    epoch_selection = (\n",
    "        alt.Chart(mean_df).mark_rect().encode(x=\"epoch:Q\").add_selection(epoch_selector)\n",
    "    ).properties(width=300)\n",
    "\n",
    "    bar = (\n",
    "        alt.Chart(mean_df)\n",
    "        .mark_bar()\n",
    "        .encode(\n",
    "            x=\"img:N\",\n",
    "            y=alt.Y(f\"mean({metric}):Q\", scale=metric_specific_scale),\n",
    "            column=alt.Column(\"fc:N\", sort=['hf_ls', 'lf_ls', 'hf_hs', 'lf_hs']),\n",
    "            color=\"img:N\",\n",
    "        )\n",
    "        .transform_filter(epoch_selector)\n",
    "    ).properties(height=200)\n",
    "\n",
    "    plot_title = f\"{code_name}: (batch size: {test_obj.cfg.batch_size}; learning rate: {test_obj.cfg.learning_rate})\"\n",
    "    return (epoch_selection & bar).properties(title=plot_title)\n",
    "\n",
    "def plot6(test_obj, null, metric, cond='hf', timetick=12, testset='train_r100'):\n",
    "    code_name = test_obj.cfg.code_name\n",
    "\n",
    "    df_intact = test_obj.eval(testset, \"triangle\", save_file_prefix=\"cos\")\n",
    "    df_os_lesion = test_obj.eval(testset, \"exp_ops\", save_file_prefix=\"cos\")\n",
    "    df_ops_lesion = test_obj.eval(testset, \"ort_sem\", save_file_prefix=\"cos\")\n",
    "    df_sem = pd.concat([df_intact, df_os_lesion, df_ops_lesion], ignore_index=True)\n",
    "    mean_df = benchmark_hs04.make_cond_mean_df(df_sem)\n",
    "\n",
    "    mean_df = mean_df.loc[mean_df.timetick.isin([timetick])]\n",
    "    mean_df = mean_df.loc[mean_df.output_name == \"sem\"]\n",
    "    mean_df = mean_df.loc[mean_df.cond == cond]\n",
    "    \n",
    "    metric_specific_scale = alt.Scale(domain=(0, 1)) if metric == \"acc\" else alt.Scale()\n",
    "\n",
    "    plot_title = f\"{code_name}: (batch size: {test_obj.cfg.batch_size}; learning rate: {test_obj.cfg.learning_rate})\"\n",
    "\n",
    "    return alt.Chart(mean_df).mark_line(point=True).encode(\n",
    "            x=\"epoch:Q\",\n",
    "            y=alt.Y(f\"mean({metric}):Q\", scale=metric_specific_scale),\n",
    "            color=\"task:N\",\n",
    "        ).properties(title=plot_title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchPlot:\n",
    "\n",
    "    BENCHMARKS = {1: \"Accuracy\", 2: \"Taraban\", 4: \"HS04-IMG\", 6: \"Cosine lesion in SEM\"}\n",
    "    PLOTTER = {1: plot1, 2: plot2, 4: plot4, 6: plot6}\n",
    "\n",
    "    def __init__(self, batch_name: str, tf_root: str):\n",
    "        self.batch_name = batch_name\n",
    "        self.json = os.path.join(\"models\", batch_name, \"batch_config.json\")\n",
    "        self.tf_root = tf_root\n",
    "        self.cfg_df = self.parse_batch_config()\n",
    "        self.interval_epoch = alt.selection_interval(init={\"epoch\": (100, 200)})\n",
    "\n",
    "    def parse_batch_config(self):\n",
    "        df = meta.batch_json_to_df(self.json, tf_root=self.tf_root)\n",
    "        assert (\n",
    "            self.batch_name == \"task_effect\"\n",
    "        )  # Just in case I forgot to change below line in other batches\n",
    "        df[\"task\"] = [\n",
    "            \"OP\",\n",
    "            \"OS\",\n",
    "            \"Triangle\",\n",
    "        ] * 12  # Caution: this is a hack to get around list type config, only works for this batch\n",
    "        return df[[\"code_name\", \"batch_size\", \"learning_rate\", \"task\"]]\n",
    "\n",
    "    def plot(self, code_name, plot_fn, **kwargs):\n",
    "        \"\"\"Plot an acc in a run\"\"\"\n",
    "\n",
    "        test = benchmark_hs04.init(code_name, batch_name=self.batch_name)\n",
    "        test.cfg.tf_root = self.tf_root\n",
    "        return plot_fn(test, self.interval_epoch, **kwargs)\n",
    "\n",
    "    def find_code_name(self, criteria: dict) -> str:\n",
    "        \"\"\"Return a code_name from a dictionary of criteria.\"\"\"\n",
    "        mask = []\n",
    "        for k, v in criteria.items():\n",
    "            hit = (self.cfg_df[k] == v).to_list()\n",
    "            if len(mask) > 0:\n",
    "                mask = [a and b for a, b in zip(mask, hit)]\n",
    "            else:\n",
    "                mask = hit\n",
    "\n",
    "        return self.cfg_df.code_name.loc[mask].to_string(index=False)\n",
    "\n",
    "    def plot_grid(\n",
    "        self,\n",
    "        benchmark_id: int,\n",
    "        metric: str,\n",
    "        col: str = \"learning_rate\",\n",
    "        row: str = \"batch_size\",\n",
    "        task: str = \"Triangle\",\n",
    "    ) -> alt.Chart:\n",
    "        \"\"\"Plot grid of plots\"\"\"\n",
    "        plotter = self.PLOTTER[benchmark_id]\n",
    "\n",
    "        cols_val = sorted(self.cfg_df[col].unique())\n",
    "        rows_val = sorted(self.cfg_df[row].unique())\n",
    "\n",
    "        fig = alt.hconcat()\n",
    "        for vr in rows_val:\n",
    "            this_row = alt.vconcat()\n",
    "            for vc in cols_val:\n",
    "                criterion = {col: vc, row: vr, \"task\": task}\n",
    "                code_name = self.find_code_name(criterion)\n",
    "                this_row |= self.plot(code_name, plot_fn=plotter, metric=metric)\n",
    "            fig &= this_row\n",
    "\n",
    "        return fig\n",
    "\n",
    "\n",
    "bp = BatchPlot(batch_name=\"task_effect\", tf_root=\"/home/jupyter/triangle_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.plot_grid(1, metric=\"acc\").save('interactive_1_acc.html')\n",
    "bp.plot_grid(1, metric=\"sse\").save('interactive_1_sse.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.plot_grid(2, metric=\"acc\").save('interactive_2_acc.html')\n",
    "bp.plot_grid(2, metric=\"csse\").save('interactive_2_csse.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.plot_grid(4, metric=\"acc\").save('interactive_4_acc.html')\n",
    "bp.plot_grid(4, metric=\"csse\").save('interactive_4_csse.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting random100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import benchmark_hs04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = benchmark_hs04.init('task_effect/task_effect_r0017')\n",
    "test.cfg.tf_root = \"/home/jupyter/triangle_model\"\n",
    "import metrics\n",
    "\n",
    "# Override semantic accuracy with cosine accuracy\n",
    "test.METRICS_MAP[\"acc\"][\"sem\"] = metrics.CosineSemanticAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "    csv_full_path = [\n",
    "        os.path.join(tf_root, \"models\", batch_name, code_name, \"eval\", f)\n",
    "        for f in csv_to_be_patch\n",
    "    ]\n",
    "benchmark_hs04.run_test6_cosine_split('task_effect/task_effect_r0017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_hs04.run_test6_cosine('task_effect/task_effect_r0017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patching evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_wrangling\n",
    "import pandas as pd\n",
    "r100 = data_wrangling.load_testset('train_r100')\n",
    "mapper = {word: cond for word, cond in zip(r100['item'], r100['cond'])}\n",
    "\n",
    "def patch_random100(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df['cond'] = df['word'].map(mapper)\n",
    "    df.to_csv(file, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meta\n",
    "tf_root = '/home/jupyter/triangle_model'\n",
    "batch_name = \"task_effect\"\n",
    "batch_json = os.path.join(tf_root, 'models', batch_name, 'batch_config.json')\n",
    "batch_df = meta.batch_json_to_df(batch_json, tf_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_names = batch_df.code_name.unique().tolist()\n",
    "csv_to_be_patch = ('cos_train_r100_exp_ops.csv', 'cos_train_r100_ort_sem.csv', 'cos_train_r100_triangle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code_name in tqdm(code_names):\n",
    "    csv_full_path = [os.path.join(tf_root, 'models', batch_name, code_name, \"eval\", f) for f in csv_to_be_patch]\n",
    "    [patch_random100(x) for x in csv_full_path]\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
