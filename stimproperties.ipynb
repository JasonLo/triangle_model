{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Align with accuracy instead of epoch\n",
    "- One epoch that closest to 80% accuracy on PHO\n",
    "2. Plot individual “network” difference beta over grid\n",
    "- Taraban : y~lm(freq x cons)\n",
    "- IMG-HS04 : y~lm(fxcximg)\n",
    "- Nonword Glushko overall: just acc\n",
    "3. Big stat model on the entire grid\n",
    "- Y ~ batch_size  or epsilon check same dimensions or not… \n",
    "- y ~ lm/lmer(batch_size  or epsilon * stimprop)  | testset x\n",
    "4. Also summarize DoL within the same grid [raw, same epoch at 1]\n",
    "- P: intact, OP, OSP\n",
    "- S: intact, OS, OPS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meta\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats.mstats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"\"\"Batch object that take cares of the data manipulation in the results of a batch.\"\"\"\n",
    "\n",
    "    def __init__(self, batch_name: str, tf_root: str = None):\n",
    "        self.batch_name = batch_name\n",
    "        self.json = os.path.join(\"models\", batch_name, \"batch_config.json\")\n",
    "        self.tf_root = tf_root if tf_root else \"./\"\n",
    "        self.cfg_df = self.parse_batch_config()\n",
    "        self.code_names = self.cfg_df.code_name.unique().tolist()\n",
    "\n",
    "        # Dataframe to be loaded\n",
    "        self.df = None\n",
    "        self.backup_df = None\n",
    "\n",
    "    def mount_testset(self, csv: list):\n",
    "        self.df = self.parse_df(csv)\n",
    "        self.checkpoint_df()\n",
    "\n",
    "    def checkpoint_df(self):\n",
    "        \"\"\"Make a df checkpoint copy\"\"\"\n",
    "        self.backup_df = self.df.copy()\n",
    "\n",
    "    def restore_df(self):\n",
    "        \"\"\"Restore self.df to the original dataframe.\"\"\"\n",
    "        self.df = self.backup_df\n",
    "\n",
    "    def subset_df(\n",
    "        self,\n",
    "        code_name: str = None,\n",
    "        epoch: int = None,\n",
    "        output_name: str = None,\n",
    "        timetick: list = None,\n",
    "        cond: list = None,\n",
    "        train_task: str = None,\n",
    "    ):\n",
    "        \"\"\"Subset self.df to spec.\"\"\"\n",
    "        df = self.df\n",
    "        df = df.loc[df.code_name == code_name] if code_name is not None else df\n",
    "        df = df.loc[df.epoch == epoch] if epoch is not None else df\n",
    "        df = df.loc[df.output_name == output_name] if output_name is not None else df\n",
    "        df = df.loc[df.timetick.isin(timetick)] if timetick is not None else df\n",
    "        df = df.loc[df.cond.isin(cond)] if cond is not None else df\n",
    "        df = df.loc[df.train_task == train_task] if train_task is not None else df\n",
    "        return df\n",
    "\n",
    "    def subset_by_epoch_dict(self, sel_epoch: dict):\n",
    "        \"\"\"Return a subset of the dataframe using a epoch dictionary.\n",
    "        args:\n",
    "            sel_epoch: dictionary of epochs to select with k=code_name, v=epoch\n",
    "        \"\"\"\n",
    "        dfs = [self.subset_df(code_name=k, epoch=v) for k, v in sel_epoch.items()]\n",
    "        return self.concat_dfs(dfs)\n",
    "\n",
    "    def parse_batch_config(self):\n",
    "        df = meta.batch_json_to_df(self.json, tf_root=self.tf_root)\n",
    "        assert (\n",
    "            self.batch_name == \"task_effect\"\n",
    "        )  # Just in case I forgot to change below line in other batches\n",
    "        df[\"train_task\"] = [\n",
    "            \"OP\",\n",
    "            \"OS\",\n",
    "            \"Triangle\",\n",
    "        ] * 12  # Caution: this is a hack to get around list type config, only works for this batch\n",
    "        return df[[\"code_name\", \"batch_size\", \"learning_rate\", \"train_task\"]]\n",
    "\n",
    "    def parse_df(self, csv: list) -> pd.DataFrame:\n",
    "        files = chain.from_iterable([self.get_eval_file_names(x) for x in csv])\n",
    "        df = self.merge_from_file_names(files)\n",
    "        return df.merge(self.cfg_df, on=\"code_name\", how=\"left\")\n",
    "\n",
    "    def get_eval_file_names(self, csv_name: str) -> list:\n",
    "        \"\"\"Return a list of dataframes from a list of csvs.\"\"\"\n",
    "        return [\n",
    "            os.path.join(\n",
    "                self.tf_root, \"models\", self.batch_name, code_name, \"eval\", csv_name\n",
    "            )\n",
    "            for code_name in self.code_names\n",
    "        ]\n",
    "\n",
    "    def find_code_name(self, criteria: dict) -> str:\n",
    "        \"\"\"Return a code_name from a dictionary of criteria.\"\"\"\n",
    "        mask = None\n",
    "        for k, v in criteria.items():\n",
    "            hit = (self.cfg_df[k].isin(v)).to_list()\n",
    "            mask = hit if mask is None else (a & b for a, b in zip(mask, hit))\n",
    "\n",
    "        return self.cfg_df.code_name.loc[mask].tolist()\n",
    "\n",
    "    def find_epoch_by_acc(self, code_name: str, acc: float) -> int:\n",
    "        \"\"\"Return an epoch number from an accuracy.\"\"\"\n",
    "        df = self.df.loc[self.df.code_name == code_name]\n",
    "        df = df.groupby(\"epoch\").mean().reset_index()  # Group by epoch\n",
    "        idx = self.find_nearest(df.acc, acc)  # Find nearest accuracy\n",
    "        return df.iloc[\n",
    "            idx,\n",
    "        ].epoch  # Return epoch\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_from_file_names(filenames: list) -> list:\n",
    "        \"\"\"Merge a list of dataframes into one.\"\"\"\n",
    "        dfs = [pd.read_csv(f) for f in filenames]\n",
    "        return Batch.concat_dfs(dfs)\n",
    "\n",
    "    @staticmethod\n",
    "    def concat_dfs(dfs: list) -> pd.DataFrame:\n",
    "        \"\"\"Return a dataframe from a list of dataframes.\"\"\"\n",
    "        return pd.concat(dfs, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def find_nearest(array, value):\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        return idx\n",
    "\n",
    "    @staticmethod\n",
    "    def get_acc_based_df(self, acc: float) -> pd.DataFrame:\n",
    "        \"\"\"Return a dataframe of accuracy for a code_name.\"\"\"\n",
    "\n",
    "        df = self.df.loc[self.df.code_name == code_name].copy()\n",
    "        # Subset to nearest accuracy epoch\n",
    "        sel_epoch = self.find_epoch_by_acc(code_name, 0.8)\n",
    "        df = df.loc[df.epoch == sel_epoch]\n",
    "        return df\n",
    "\n",
    "\n",
    "b = Batch(\"task_effect\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find epoch that are closest to 80% accuracy in each network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define by Taraban\n",
    "- at 8-12 ticks\n",
    "- Train task: Triangle\n",
    "- Output at PHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.mount_testset(['taraban_triangle.csv'])\n",
    "\n",
    "sel_conds = [\n",
    "    \"High-frequency exception\",\n",
    "    \"Regular control for High-frequency exception\",\n",
    "    \"Low-frequency exception\",\n",
    "    \"Regular control for Low-frequency exception\",\n",
    "    ]\n",
    "\n",
    "b.df = b.subset_df(output_name=\"pho\", timetick=range(8, 13), cond=sel_conds, train_task=\"Triangle\")\n",
    "b.checkpoint_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for epoch that is closest to 80% accuracy\n",
    "sel_epoch = {x:b.find_epoch_by_acc(x, 0.8) for x in tqdm(b.df.code_name.unique())}\n",
    "print(sel_epoch)\n",
    "\n",
    "\n",
    "df = b.subset_by_epoch_dict(sel_epoch)\n",
    "df[\"freq\"] = df.cond.apply(\n",
    "    lambda x: \"High\"\n",
    "    if x\n",
    "    in (\"High-frequency exception\", \"Regular control for High-frequency exception\")\n",
    "    else \"Low\"\n",
    ")\n",
    "df[\"reg\"] = df.cond.apply(\n",
    "    lambda x: \"Regular\" if x.startswith(\"Regular\") else \"Exception\"\n",
    ")\n",
    "df = df[['batch_size', 'learning_rate', 'code_name', 'epoch', 'timetick', 'freq', 'reg', 'word', 'acc', 'sse']]\n",
    "df.to_csv(os.path.join('issues', '0_batchsize_lr', 'taraban80.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc_txt = alt.Chart(mdf).mark_text(dy=6).encode(\n",
    "    x='learning_rate:O',\n",
    "    y=alt.Y('batch_size:O'),\n",
    "    text=alt.Text('mean(acc):Q', format='.2f'),\n",
    ").properties(title = f\"Selected epoch and mean accuracy in Taranban testset\", width=200, height=200)\n",
    "\n",
    "epoch_txt = acc_txt.mark_text(dy=-6).encode(\n",
    "    text=alt.Text('mean(epoch):Q', format='.0f'),\n",
    ")\n",
    "\n",
    "heatmap = acc_txt.mark_rect().encode(\n",
    "    color=\"mean(acc):Q\"\n",
    ")\n",
    "\n",
    "heatmap + acc_txt + epoch_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reg_num'] = df.reg.apply(lambda x: 0.5 if x == 'Regular' else -0.5)\n",
    "df['freq_num'] = df.freq.apply(lambda x: 0.5 if x == 'High' else -0.5)\n",
    "\n",
    "mdf = df.groupby(['batch_size', 'learning_rate', 'code_name', 'freq', 'reg']).mean().reset_index()\n",
    "\n",
    "def plot_taraban(df, metric: str = 'acc'):\n",
    "    metric_specific_scale = alt.Scale(domain=(0, 1)) if metric == \"acc\" else alt.Scale()\n",
    "    return alt.Chart(df).mark_line().encode(\n",
    "            x=alt.X(\"freq:N\", scale=alt.Scale(reverse=True)),\n",
    "            y=alt.Y(f\"mean({metric}):Q\", scale=metric_specific_scale),\n",
    "            row=\"batch_size:O\",\n",
    "            column=\"learning_rate:O\",\n",
    "            color=\"reg:N\",\n",
    "        ).properties(width=150, height=150)\n",
    "\n",
    "\n",
    "plot_taraban(mdf, 'acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferential statistics on mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = smf.glm(formula='zscore(acc) ~ zscore(learning_rate) * zscore(batch_size) * reg_num * freq_num', data=mdf).fit()\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize beta on grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taraban_params(df, code_name):\n",
    "    m = smf.glm(formula=\"acc ~ freq_num * reg_num\", data=df.loc[df.code_name == code_name], family=sm.families.Binomial()).fit()\n",
    "    p = m.params\n",
    "    p['code_name'] = code_name\n",
    "    return pd.DataFrame(p).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all betas\n",
    "setting_map = mdf[['code_name', 'batch_size', 'learning_rate']].groupby(['code_name']).mean().reset_index()\n",
    "params = [get_taraban_params(df, code_name=x) for x in tqdm(df.code_name.unique())]\n",
    "taraban_beta = pd.concat(params, ignore_index=True)\n",
    "taraban_beta = taraban_beta.merge(setting_map, on='code_name')\n",
    "taraban_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taraban_beta.columns = ['intercept', 'freq_effect', 'reg_effect', 'interactions', 'code_name', 'batch_size', 'epsilon']\n",
    "taraban_beta = taraban_beta.melt(id_vars=['code_name', 'batch_size', 'epsilon'], value_vars=['intercept', 'freq_effect', 'reg_effect', 'interactions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(taraban_beta).mark_rect().encode(\n",
    "    x='epsilon:O',\n",
    "    y='batch_size:O',\n",
    "    color=alt.Color('value:Q', scale=alt.Scale(domain=(-25, 25), scheme='redblue')),\n",
    "    column='variable:N',\n",
    ").properties(width=200, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.mount_testset(['glushko_triangle.csv'])\n",
    "b.df = b.subset_df(output_name=\"pho\", timetick=range(8, 13), train_task=\"Triangle\")\n",
    "b.checkpoint_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = b.subset_by_epoch_dict(sel_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = df.groupby(['batch_size', 'learning_rate', 'code_name', 'cond']).mean().reset_index()\n",
    "mdf['cond_num'] = mdf.cond.apply(lambda x: 0.5 if x == 'Regular' else -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(mdf).mark_rect().encode(\n",
    "    x='learning_rate:O',\n",
    "    y='batch_size:O',\n",
    "    color=alt.Color('acc:Q', scale=alt.Scale(domain=(0, 1))),\n",
    "    column='cond:N',\n",
    ").properties(width=200, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = smf.glm(formula='zscore(acc) ~ zscore(learning_rate) * zscore(batch_size) * cond_num ', data=mdf).fit()\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Img-HS04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.mount_testset(['hs04_img_240_triangle.csv'])\n",
    "b.df = b.subset_df(output_name=\"pho\", timetick=range(8, 13), train_task=\"Triangle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = b.subset_by_epoch_dict(sel_epoch)\n",
    "b.checkpoint_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['freq', 'op', 'img']] = df.cond.str.split('_', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['freq_num'] = df.freq.apply(lambda x: 0.5 if x == 'hf' else -0.5)\n",
    "df['op_num'] = df.op.apply(lambda x: 0.5 if x == 'ls' else -0.5)\n",
    "df['img_num'] = df.img.apply(lambda x: 0.5 if x == 'hi' else -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = df.groupby(['batch_size', 'learning_rate', 'code_name', 'cond']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(mdf).mark_rect().encode(\n",
    "    x='learning_rate:O',\n",
    "    y='batch_size:O',\n",
    "    color=alt.Color('mean(acc):Q', scale=alt.Scale(domain=(0, 1))),\n",
    ").properties(title=\"Mean accuracy in IMG testset\", width=200, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = smf.glm(formula='zscore(acc) ~ zscore(learning_rate) * zscore(batch_size) * freq_num * op_num * img_num ', data=mdf).fit()\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(m.summary().tables[1][1:], columns=['lable', 'coef', 'se', 'z', 'p', 'lci', 'uci'])\n",
    "x.to_csv('tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_params(df, code_name):\n",
    "    m = smf.glm(formula=\"acc ~ freq_num * op_num * img_num\", data=df.loc[df.code_name == code_name], family=sm.families.Binomial()).fit()\n",
    "    p = m.params\n",
    "    p['code_name'] = code_name\n",
    "    return pd.DataFrame(p).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [get_img_params(df, code_name=x) for x in tqdm(df.code_name.unique())]\n",
    "img_beta = pd.concat(params, ignore_index=True)\n",
    "setting_map = mdf[['code_name', 'batch_size', 'learning_rate']].groupby(['code_name']).mean().reset_index()\n",
    "img_beta = img_beta.merge(setting_map, on='code_name')\n",
    "img_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_beta.columns = ['intercept', 'freq_effect', 'reg_effect', 'fxr', 'img_effect', 'fxi', 'rxi', 'fxrxi', 'code_name', 'batch_size', 'epsilon']\n",
    "img_beta = img_beta.melt(id_vars=['code_name', 'batch_size', 'epsilon'], value_vars=['intercept', 'freq_effect', 'reg_effect', 'fxr', 'img_effect', 'fxi', 'rxi', 'fxrxi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(img_beta).mark_rect().encode(\n",
    "    x='epsilon:O',\n",
    "    y='batch_size:O',\n",
    "    color=alt.Color('value:Q', scale=alt.Scale(domain=(-25, 25), scheme='redblue')),\n",
    "    column='variable:N',\n",
    ").properties(width=200, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PHO output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.mount_testset(['train_r100_ort_pho.csv', 'train_r100_exp_osp.csv', 'train_r100_triangle.csv'])\n",
    "b.df = b.subset_df(timetick=range(8, 13), output_name='pho', train_task=\"Triangle\")\n",
    "df = b.subset_by_epoch_dict(sel_epoch)\n",
    "b.checkpoint_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dol_pho_mdf = df.groupby(['batch_size', 'learning_rate', 'code_name', 'task']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(dol_pho_mdf).mark_rect().encode(\n",
    "    x='learning_rate:O',\n",
    "    y='batch_size:O',\n",
    "    color=alt.Color('acc:Q', scale=alt.Scale(domain=(0, 1))),\n",
    "    column='task:N',\n",
    ").properties(width=200, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.mount_testset(['cos_train_r100_ort_sem.csv', 'cos_train_r100_exp_ops.csv', 'cos_train_r100_triangle.csv'])\n",
    "b.df = b.subset_df(timetick=range(8, 13), output_name='sem', train_task=\"Triangle\")\n",
    "df = b.subset_by_epoch_dict(sel_epoch)\n",
    "b.checkpoint_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dol_sem_mdf = df.groupby(['batch_size', 'learning_rate', 'code_name', 'task']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(dol_sem_mdf).mark_rect().encode(\n",
    "    x='learning_rate:O',\n",
    "    y='batch_size:O',\n",
    "    color=alt.Color('acc:Q', scale=alt.Scale(domain=(0, 1))),\n",
    "    column='task:N',\n",
    ").properties(width=200, height=200)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
