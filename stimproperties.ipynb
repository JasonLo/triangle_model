{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Align with accuracy instead of epoch\n",
    "- One epoch that closest to 80% accuracy on PHO\n",
    "2. Plot individual “network” difference beta over grid\n",
    "- Taraban : y~lm(freq x cons)\n",
    "- IMG-HS04 : y~lm(fxcximg)\n",
    "- Nonword Glushko overall: just acc\n",
    "3. Big stat model on the entire grid\n",
    "- Y ~ batch_size  or epsilon check same dimensions or not… \n",
    "- y ~ lm/lmer(batch_size  or epsilon * stimprop)  | testset x\n",
    "4. Also summarize DoL within the same grid [raw, same epoch at 1]\n",
    "- P: intact, OP, OSP\n",
    "- S: intact, OS, OPS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meta\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from itertools import chain\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, batch_name: str, tf_root: str = None):\n",
    "        self.batch_name = batch_name\n",
    "        self.json = os.path.join(\"models\", batch_name, \"batch_config.json\")\n",
    "        self.tf_root = tf_root if tf_root else \"./\"\n",
    "        self.cfg_df = self.parse_batch_config()\n",
    "        self.code_names = self.cfg_df.code_name.unique().tolist()\n",
    "        self.df = self.parse_df(['train_r100_triangle.csv'])\n",
    "\n",
    "    def mount_testset(self, csv: list):\n",
    "        self.df = self.parse_df(csv)\n",
    "\n",
    "    def subset_df(self, code_name:str=None, epoch:int=None, output_name:str=None, timetick:list=None, cond:list=None):\n",
    "        \"\"\"Return a subset of the dataframe.\"\"\"\n",
    "        df = self.df\n",
    "        df = df.loc[df.code_name == code_name] if code_name is not None else df\n",
    "        df = df.loc[df.epoch == epoch] if epoch is not None else df \n",
    "        df = df.loc[df.output_name == output_name] if output_name is not None else df\n",
    "        df = df.loc[df.timetick.isin(timetick)] if timetick is not None else df\n",
    "        df = df.loc[df.cond.isin(cond)] if cond is not None else df\n",
    "        return df\n",
    "\n",
    "    def subset_by_epoch_dict(self, sel_epoch:dict):\n",
    "        \"\"\"Return a subset of the dataframe using a epoch dictionary.\n",
    "        args:\n",
    "            sel_epoch: dictionary of epochs to select with k=code_name, v=epoch\n",
    "        \"\"\"\n",
    "        dfs = [self.subset_df(code_name=k, epoch=v) for k, v in sel_epoch.items()]\n",
    "        return self.concat_dfs(dfs)\n",
    "\n",
    "    def parse_batch_config(self):\n",
    "        df = meta.batch_json_to_df(self.json, tf_root=self.tf_root)\n",
    "        assert (\n",
    "            self.batch_name == \"task_effect\"\n",
    "        )  # Just in case I forgot to change below line in other batches\n",
    "        df[\"train_task\"] = [\n",
    "            \"OP\",\n",
    "            \"OS\",\n",
    "            \"Triangle\",\n",
    "        ] * 12  # Caution: this is a hack to get around list type config, only works for this batch\n",
    "        return df[[\"code_name\", \"batch_size\", \"learning_rate\", \"train_task\"]]\n",
    "\n",
    "    def parse_df(self, csv: list) -> pd.DataFrame:\n",
    "        files = chain.from_iterable([self.get_eval_file_names(x) for x in csv])\n",
    "        df = self.merge_from_file_names(files)\n",
    "        return df.merge(self.cfg_df, on=\"code_name\", how=\"left\")\n",
    "\n",
    "\n",
    "    def get_eval_file_names(self, csv_name: str) -> list:\n",
    "        \"\"\"Return a list of dataframes from a list of csvs.\"\"\"\n",
    "        return [\n",
    "            os.path.join(\n",
    "                self.tf_root, \"models\", self.batch_name, code_name, \"eval\", csv_name\n",
    "            )\n",
    "            for code_name in self.code_names\n",
    "        ]\n",
    "\n",
    "    def find_code_name(self, criteria: dict) -> str:\n",
    "        \"\"\"Return a code_name from a dictionary of criteria.\"\"\"\n",
    "        mask = None\n",
    "        for k, v in criteria.items():\n",
    "            hit = (self.cfg_df[k].isin(v)).to_list()\n",
    "            mask = hit if mask is None else (a & b for a, b in zip(mask, hit))\n",
    "\n",
    "        return self.cfg_df.code_name.loc[mask].tolist()\n",
    "\n",
    "    def find_epoch_by_acc(self, code_name: str, acc: float) -> int:\n",
    "        \"\"\"Return an epoch number from an accuracy.\"\"\"\n",
    "        df = self.df.loc[self.df.code_name == code_name]\n",
    "        df = df.loc[df.output_name == 'pho'] # PHO as criteria\n",
    "        df = df.loc[df.timetick.isin(range(8, 13))] # Selecting 8-12 ticks\n",
    "        df = df.groupby('epoch').mean().reset_index() # Group by epoch\n",
    "        idx = self.find_nearest(df.acc, acc) # Find nearest accuracy\n",
    "        return df.iloc[idx,].epoch # Return epoch\n",
    "        \n",
    "    @staticmethod\n",
    "    def merge_from_file_names(filenames: list) -> list:\n",
    "        \"\"\"Merge a list of dataframes into one.\"\"\"\n",
    "        dfs = [pd.read_csv(f) for f in filenames]\n",
    "        return Batch.concat_dfs(dfs)\n",
    "\n",
    "    @staticmethod\n",
    "    def concat_dfs(dfs: list) -> pd.DataFrame:\n",
    "        \"\"\"Return a dataframe from a list of dataframes.\"\"\"\n",
    "        return pd.concat(dfs, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def find_nearest(array, value):\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        return idx\n",
    "\n",
    "    @staticmethod\n",
    "    def get_acc_based_df(self, acc: float) -> pd.DataFrame:\n",
    "        \"\"\"Return a dataframe of accuracy for a code_name.\"\"\"\n",
    "\n",
    "        df = self.df.loc[self.df.code_name == code_name].copy()\n",
    "        # Subset to nearest accuracy epoch\n",
    "        sel_epoch = self.find_epoch_by_acc(code_name, 0.8)\n",
    "        df = df.loc[df.epoch == sel_epoch]\n",
    "        return df\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "b = Batch(\"task_effect\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find epoch that are closest to 80% accuracy in each network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define by train_r100 testset\n",
    "- at 8-12 ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.mount_testset(['taraban_triangle.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_epoch = {x:b.find_epoch_by_acc(x, 0.8) for x in tqdm(b.code_names)}\n",
    "print(sel_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = b.subset_by_epoch_dict(sel_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_conds = [\n",
    "    \"High-frequency exception\",\n",
    "    \"Regular control for High-frequency exception\",\n",
    "    \"Low-frequency exception\",\n",
    "    \"Regular control for Low-frequency exception\",\n",
    "    ]\n",
    "\n",
    "df = df.loc[df.cond.isin(sel_conds)] # Select conditions\n",
    "df = df.loc[df.output_name == 'pho'] # P output\n",
    "df = df.loc[df.timetick.isin(range(8, 13))] # timetick 8-12\n",
    "df = df.loc[df.train_task == 'Triangle'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('issues/0_batchsize_lr/taraban80.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['batch_size', 'learning_rate', 'code_name', 'epoch', 'cond']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try inferential statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats.mstats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = smf.glm(formula='zscore(acc) ~ zscore(learning_rate) + zscore(batch_size) + C(reg)  + C(freq)', data=mdf).fit()\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_text().encode(\n",
    "    x='learning_rate:O',\n",
    "    y='batch_size:O',\n",
    "    text='mean(acc):Q'\n",
    "    ).properties(width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taraban dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.mount_testset(['taraban_triangle.csv'])\n",
    "df = b.subset_by_epoch_dict(sel_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_conds = [\"High-frequency exception\",\n",
    "            \"Regular control for High-frequency exception\",\n",
    "            \"Low-frequency exception\",\n",
    "            \"Regular control for Low-frequency exception\",\n",
    "            ]\n",
    "\n",
    "df = df.loc[df.cond.isin(sel_conds)] # Select conditions\n",
    "df = df.loc[df.output_name == 'pho'] # P output\n",
    "df = df.loc[df.timetick.isin(range(8, 13))] # timetick 8-12\n",
    "df = df.loc[df.train_task == 'Triangle'] \n",
    "    \n",
    "df[\"freq\"] = df.cond.apply(\n",
    "    lambda x: \"High\"\n",
    "    if x\n",
    "    in (\"High-frequency exception\", \"Regular control for High-frequency exception\")\n",
    "    else \"Low\"\n",
    ")\n",
    "df[\"reg\"] = df.cond.apply(\n",
    "    lambda x: \"Regular\" if x.startswith(\"Regular\") else \"Exception\"\n",
    ")\n",
    "\n",
    "\n",
    "df = df[['batch_size', 'learning_rate', 'code_name', 'epoch', 'timetick', 'freq', 'reg', 'word', 'acc', 'sse']]\n",
    "df.to_csv(os.path.join('issues', '0_batchsize_lr', 'taraban80.csv'))\n",
    "mdf = df.groupby(['batch_size', 'learning_rate', 'freq', 'reg']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = df.groupby(['batch_size', 'learning_rate', 'code_name', 'freq', 'reg']).mean().reset_index()\n",
    "\n",
    "def plot_taraban(df, metric: str = 'acc'):\n",
    "    metric_specific_scale = alt.Scale(domain=(0, 1)) if metric == \"acc\" else alt.Scale()\n",
    "    return alt.Chart(df).mark_line().encode(\n",
    "            x=alt.X(\"freq:N\", scale=alt.Scale(reverse=True)),\n",
    "            y=alt.Y(f\"mean({metric}):Q\", scale=metric_specific_scale),\n",
    "            row=\"batch_size:O\",\n",
    "            column=\"learning_rate:O\",\n",
    "            color=\"reg:N\",\n",
    "        ).properties(width=150, height=150)\n",
    "\n",
    "\n",
    "plot_taraban(mdf, 'acc').save('taraban_acc.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('taraban_at_80.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select PHO accuracy at last time tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "heat = alt.Chart(acc_df).mark_rect().encode(\n",
    "    x='learning_rate:O',\n",
    "    y=alt.Y('batch_size:O'),\n",
    "    color=alt.Color('acc:Q', scale=alt.Scale(domain=[0, 1])),\n",
    ")\n",
    "\n",
    "heat.mark_text().encode(\n",
    "    text=alt.Text('acc:Q', format='.2f')\n",
    ").properties(width=300, height=300).configure_text(fontSize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat.mark_text().encode(\n",
    "    text=alt.Text('epoch:Q', format='.0f')\n",
    ").properties(width=300, height=300).configure_text(fontSize=20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
