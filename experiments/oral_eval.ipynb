{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import sqlite3\n",
    "import os, json\n",
    "import evaluate, meta, modeling, data_wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import TestSet\n",
    "class EvalOral:\n",
    "    \"\"\"Bundle of testsets\"\"\"\n",
    "\n",
    "    TESTSETS_NAME = (\"strain\", \"grain\", \"taraban\")\n",
    "\n",
    "    def __init__(self, cfg, model, data):\n",
    "        self.cfg = cfg\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "\n",
    "        self.train_mean_df = None\n",
    "        self.strain_mean_df = None\n",
    "        self.grain_mean_df = None\n",
    "        self.taraban_mean_df = None\n",
    "        self.cortese_mean_df = None\n",
    "        \n",
    "        # Setup database\n",
    "        if self.cfg.batch_name is not None:\n",
    "            \n",
    "            sqlite_file = os.path.join(self.cfg.path[\"batch_folder\"], \"batch_results.sqlite\")\n",
    "            self.con = sqlite3.connect(sqlite_file)\n",
    "            self.cur = self.con.cursor()\n",
    "        \n",
    "        # Load eval results from file\n",
    "        for _testset_name in self.TESTSETS_NAME:\n",
    "            try:\n",
    "                _file = os.path.join(\n",
    "                    self.cfg.path[\"model_folder\"],\n",
    "                    \"eval\",\n",
    "                    f\"{_testset_name}_mean_df.csv\",\n",
    "                )\n",
    "                setattr(self, f\"{_testset_name}_mean_df\", pd.read_csv(_file))\n",
    "            except (FileNotFoundError, IOError):\n",
    "                pass\n",
    "\n",
    "        # Bundle testsets into dictionary\n",
    "        self.run_eval = {\n",
    "            \"strain\": self._eval_strain,\n",
    "            \"taraban\": self._eval_taraban\n",
    "        }\n",
    "        \n",
    "    def eval(self, testset_name):\n",
    "        \"\"\"Run eval and push to dat\"\"\"\n",
    "        if getattr(self, f\"{testset_name}_mean_df\") is None:\n",
    "            results = self.run_eval[testset_name]()\n",
    "            try:\n",
    "                results.to_sql(testset_name, self.con, if_exists=\"append\")\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            print(\"Evaluation results found, loaded from file.\")\n",
    "\n",
    "\n",
    "    def _eval_strain(self):\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        testsets = (\n",
    "            \"strain_hf_con_hi\",\n",
    "            \"strain_hf_inc_hi\",\n",
    "            \"strain_hf_con_li\",\n",
    "            \"strain_hf_inc_li\",\n",
    "            \"strain_lf_con_hi\",\n",
    "            \"strain_lf_inc_hi\",\n",
    "            \"strain_lf_con_li\",\n",
    "            \"strain_lf_inc_li\"\n",
    "        )\n",
    "\n",
    "        for testset_name in testsets:\n",
    "            t_ps = TestSet(\n",
    "                name=testset_name,\n",
    "                cfg=self.cfg,\n",
    "                model=self.model,\n",
    "                task=\"pho_sem\",\n",
    "                testitems=self.data.testsets[testset_name][\"item\"],\n",
    "                x_test=self.data.testsets[testset_name][\"pho\"],\n",
    "                y_test=self.data.testsets[testset_name][\"sem\"],\n",
    "            )\n",
    "            \n",
    "            t_ps.eval_all()\n",
    "            df = pd.concat([df, t_ps.result])\n",
    "            \n",
    "            t_sp = TestSet(\n",
    "                name=testset_name,\n",
    "                cfg=self.cfg,\n",
    "                model=self.model,\n",
    "                task=\"sem_pho\",\n",
    "                testitems=self.data.testsets[testset_name][\"item\"],\n",
    "                x_test=self.data.testsets[testset_name][\"sem\"],\n",
    "                y_test=self.data.testsets[testset_name][\"pho\"],\n",
    "            )\n",
    "            \n",
    "            t_sp.eval_all()\n",
    "            df = pd.concat([df, t_sp.result])\n",
    "\n",
    "\n",
    "        df.to_csv(\n",
    "            os.path.join(\n",
    "                self.cfg.path[\"model_folder\"], \"eval\", \"strain_item_df.csv\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Condition level aggregate\n",
    "        mean_df = (\n",
    "            df.groupby(\n",
    "                [\n",
    "                    \"code_name\",\n",
    "                    \"task\",\n",
    "                    \"testset\",\n",
    "                    \"epoch\",\n",
    "                    \"timetick\",\n",
    "                    \"y\",\n",
    "                ]\n",
    "            )\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "        mean_df.to_csv(\n",
    "            os.path.join(\n",
    "                self.cfg.path[\"model_folder\"], \"eval\", \"strain_mean_df.csv\"\n",
    "            )\n",
    "        )\n",
    "        self.strain_mean_df = mean_df\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def _eval_taraban(self):\n",
    "\n",
    "        testsets = (\n",
    "            \"taraban_hf-exc\",\n",
    "            \"taraban_hf-reg-inc\",\n",
    "            \"taraban_lf-exc\",\n",
    "            \"taraban_lf-reg-inc\",\n",
    "            \"taraban_ctrl-hf-exc\",\n",
    "            \"taraban_ctrl-hf-reg-inc\",\n",
    "            \"taraban_ctrl-lf-exc\",\n",
    "            \"taraban_ctrl-lf-reg-inc\",\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for testset_name in testsets:\n",
    "\n",
    "            t_ps = TestSet(\n",
    "                name=testset_name,\n",
    "                cfg=self.cfg,\n",
    "                model=self.model,\n",
    "                task=\"pho_sem\",\n",
    "                testitems=self.data.testsets[testset_name][\"item\"],\n",
    "                x_test=self.data.testsets[testset_name][\"pho\"],\n",
    "                y_test=self.data.testsets[testset_name][\"sem\"],\n",
    "            )\n",
    "\n",
    "            t_ps.eval_all()\n",
    "            df = pd.concat([df, t_ps.result])\n",
    "\n",
    "            t_sp = TestSet(\n",
    "                name=testset_name,\n",
    "                cfg=self.cfg,\n",
    "                model=self.model,\n",
    "                task=\"sem_pho\",\n",
    "                testitems=self.data.testsets[testset_name][\"item\"],\n",
    "                x_test=self.data.testsets[testset_name][\"sem\"],\n",
    "                y_test=self.data.testsets[testset_name][\"pho\"],\n",
    "            )\n",
    "\n",
    "            t_sp.eval_all()\n",
    "            df = pd.concat([df, t_sp.result])\n",
    "\n",
    "        df.to_csv(\n",
    "            os.path.join(self.cfg.path[\"model_folder\"], \"eval\", \"taraban_item_df.csv\")\n",
    "        )\n",
    "\n",
    "        mean_df = (\n",
    "            df.groupby([\"code_name\", \"task\", \"testset\", \"epoch\", \"timetick\", \"y\"])\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        mean_df.to_csv(\n",
    "            os.path.join(self.cfg.path[\"model_folder\"], \"eval\", \"taraban_mean_df.csv\")\n",
    "        )\n",
    "\n",
    "        self.taraban_mean_df = mean_df\n",
    "        \n",
    "        return df\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_name = 'high_stress_long_pretraining'\n",
    "tf_root = '/home/jupyter/tf'\n",
    "\n",
    "cfg = meta.ModelConfig.from_json(os.path.join(tf_root, \"models\", code_name, \"model_config.json\"))\n",
    "model = modeling.HS04Model(cfg)\n",
    "data = data_wrangling.MyData()\n",
    "cfg.batch_name = None\n",
    "oral_test = EvalOral(cfg, model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oral_test.eval('strain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oral_test.strain_mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_bigquery(csv_file, dataset_name, table_name):\n",
    "    from google.cloud import bigquery\n",
    "    import json, os\n",
    "    import pandas as pd\n",
    "\n",
    "    # Create connection to BQ and push data\n",
    "    client = bigquery.Client()\n",
    "    dataset = client.create_dataset(dataset_name, exists_ok=True)\n",
    "    table_ref = dataset.table(table_name)\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True\n",
    "    )\n",
    "\n",
    "    with open(csv_file, \"rb\") as f:\n",
    "        job = client.load_table_from_file(f, table_ref, job_config=job_config)\n",
    "\n",
    "    job.result()\n",
    "    print(f\"Loaded {job.output_rows} rows into {dataset_name}:{table_ref.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_bigquery(os.path.join(cfg.path['model_folder'], 'eval', 'oral_strain_item_df.csv'), dataset_name=\"triangle_oral\", table_name=\"strain\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
