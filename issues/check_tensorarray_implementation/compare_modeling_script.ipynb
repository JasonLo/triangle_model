{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, random\n",
    "import meta, modeling, old_modeling, data_wrangling, evaluate, troubleshooting\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(old_modeling)\n",
    "reload(modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_name = \"Refrac2_5M\"\n",
    "cfg = meta.ModelConfig.from_json(os.path.join('/home/jupyter/tf/models', code_name, 'model_config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model = old_modeling.TriangleModel(cfg)\n",
    "new_model = modeling.TriangleModel(cfg, batch_size_override=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model.load_weights(cfg.saved_weights[-1])\n",
    "new_model.load_weights(cfg.saved_weights[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model.build()\n",
    "new_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_same_model(model, task1, task2):\n",
    "    \"\"\"Test model output differences in two given task in the same model equal\n",
    "    Return the maximum difference \n",
    "    \n",
    "    \"\"\"\n",
    "    i_name1, o_name1 = modeling.IN_OUT[task1]\n",
    "    i_name2, o_name2 = modeling.IN_OUT[task2]\n",
    "\n",
    "    assert i_name1 == i_name2\n",
    "    assert o_name1 == o_name2\n",
    "\n",
    "    i_name, o_name = i_name1, o_name1\n",
    "\n",
    "    strain = data_wrangling.load_testset('dataset/testsets/strain_hf_con_hi.pkl.gz')\n",
    "    input_x = [strain[i_name]] * 13\n",
    "\n",
    "    model.set_active_task(task1)\n",
    "    y_pred1 = model(input_x)\n",
    "    \n",
    "    model.set_active_task(task2)\n",
    "    y_pred2 = model(input_x)\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Max difference in {o_name} output:\")\n",
    "    for i in range(13):\n",
    "        print(\n",
    "            tf.reduce_max(\n",
    "                tf.math.abs(\n",
    "                    y_pred1[o_name][i] - y_pred2[o_name][i]\n",
    "                )\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_same_model(new_model, 'exp_os', 'ort_sem')\n",
    "test_same_model(new_model, 'exp_op', 'ort_pho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal implementation of OP (ort_pho) and minimum change implementation (exp_op) are the same. Likewise in ort_sem and exp_os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double check weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check loaded weight equal inside model instances\n",
    "list(map(lambda x: tf.reduce_max(abs(x[0] - x[1])), zip(old_model.weights, new_model.weights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_task(task_name, old_model, new_model, output_name_old=None, output_name_new=None):\n",
    "    \"\"\"Test model output differences in a given task\n",
    "    Return the maximum difference \n",
    "    \"\"\"\n",
    "    i_name, o_name = modeling.IN_OUT[task_name]\n",
    "\n",
    "    strain = data_wrangling.load_testset('dataset/testsets/strain_hf_con_hi.pkl.gz')\n",
    "    input_x = [strain[i_name]] * 13\n",
    "\n",
    "    old_model.set_active_task(task_name)\n",
    "    new_model.set_active_task(task_name)\n",
    "\n",
    "    y_pred_old = old_model(input_x)\n",
    "    y_pred_new = new_model(input_x)\n",
    "\n",
    "    print(f\"Max difference in {output_name_old} output:\")\n",
    "    for i in range(13):\n",
    "        print(\n",
    "            tf.reduce_max(\n",
    "                tf.math.abs(\n",
    "                    y_pred_new[output_name_new][i] - y_pred_old[output_name_old][i]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in ('triangle', 'pho_pho', 'sem_pho'):\n",
    "    print(f'Max abs diff in {task}')\n",
    "    test_task(task, old_model, new_model, 'pho', 'pho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1e-5 max abs differece was found in PHO output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in ('triangle', 'sem_sem', 'pho_sem', 'ort_sem'):\n",
    "    print(f'Max abs diff in {task}')\n",
    "    test_task(task, old_model, new_model, 'sem', 'sem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1e-4 max abs difference was found in sem output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dig deeper in OP task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_task('ort_pho', old_model, new_model, output_name_old='hop', output_name_new='hop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OP is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_task('ort_pho', old_model, new_model, output_name_old='input_p', output_name_new='input_pho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input P is not fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_task('ort_pho', old_model, new_model, output_name_old='input_cpp', output_name_new='input_cpp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPP also not fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hop is fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problematic chunk:\n",
    "\n",
    "Old\n",
    "``` {python}\n",
    "##### Phonology Cleanup layer #####\n",
    "cpp = self.tau * (tf.matmul(act_p_list[t], w_pc) + bias_cpp)\n",
    "cpp += (1 - self.tau) * input_cpp_list[t]\n",
    "```\n",
    "\n",
    "New\n",
    "```\n",
    "##### Phonology Cleanup layer #####\n",
    "self.input_cpp = self.input_cpp.write(\n",
    "    t + 1,\n",
    "    self.tau * (tf.matmul(self.pho.read(t), w_pc) + bias_cpp)\n",
    "    + (1 - self.tau) * self.input_cpp.read(t),\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine piece by piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain = data_wrangling.load_testset('dataset/testsets/strain_hf_con_hi.pkl.gz')\n",
    "input_x = [strain['ort']] * 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.set_active_task('ort_pho')\n",
    "old_model.set_active_task('ort_pho')\n",
    "y_pred_new = new_model(input_x)\n",
    "y_pred_old = old_model(input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_old.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_new.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_eq(a, b, verbose=False):\n",
    "    print(tf.reduce_max(abs(a-b)).numpy() == 0.)\n",
    "    if verbose:\n",
    "        print(a)\n",
    "        print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check time averaged input components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check tau\n",
    "new_model.tau == old_model.tau\n",
    "check_eq(old_model.tau, new_model.tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# act_p_0\n",
    "act_pho_0_old = y_pred_old['pho'][0]\n",
    "act_pho_0_new = y_pred_new['pho'][0]\n",
    "check_eq(act_pho_0_new, act_pho_0_old, verbose=True)\n",
    "\n",
    "# Forced shape batch_size x pho units in new  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check W_PC\n",
    "w_pc_new = [x for x in new_model.weights if x.name.endswith('w_pc:0')][0]\n",
    "w_pc_old = [x for x in old_model.weights if x.name.endswith('w_pc:0')][0]\n",
    "check_eq(w_pc_new, w_pc_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check bias equal\n",
    "bias_cpp_new = [x for x in new_model.weights if x.name.endswith('bias_cpp:0')][0]\n",
    "bias_cpp_old = [x for x in old_model.weights if x.name.endswith('bias_cpp:0')][0]\n",
    "check_eq(bias_cpp_new, bias_cpp_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_new = new_model.tau * (tf.matmul(act_pho_0_new, w_pc_new) + bias_cpp_new)\n",
    "p1_old = old_model.tau * (tf.matmul(act_pho_0_old, w_pc_old) + bias_cpp_old)\n",
    "check_eq(p1_new, p1_old, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- new dim: (20, 50)\n",
    "- old dim: (1, 50)\n",
    "\n",
    "all underlying components are the same, yet, tau * (matmul(act_p * w_pc) + bias_cpp) is not identical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider a reduced example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = [[1., 2., 3.]] # Old implementation of activation \n",
    "a2 = [[1., 2., 3.], [1., 2., 3.], [1., 2., 3.]] # New implementation with batch_size = 3\n",
    "w = [[2., 3. ,2.], [1., 0., 0.], [0., 0., 1.]] # simplified w_pc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = tf.matmul(a1, w)\n",
    "r2 = tf.matmul(a2, w)\n",
    "check_eq(r1, r2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The actual calculation should behave like the toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_eq(p1_old[0], p1_new[0], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = tf.matmul(act_pho_0_new, w_pc_new)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = tf.matmul(act_pho_0_old, w_pc_old)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_np = act_pho_0_new[0].numpy()\n",
    "w_np = w_pc_new.numpy()\n",
    "np_from_new = np.matmul(act_np, w_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_np = act_pho_0_old[0].numpy()\n",
    "w_np = w_pc_old.numpy()\n",
    "np_from_old = np.matmul(act_np, w_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(a,b):\n",
    "    return np.max(np.abs(a-b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae(np_from_new, np_from_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae(np_from_new, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae(np_from_old, old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorArray implementation is not very precise..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
