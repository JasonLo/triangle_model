{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate SSE boundary which leads to ACC = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library from evaluate.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def gen_pkey(p_file=\"../common/patterns/mappingv2.txt\"):\n",
    "    # read phonological patterns from the mapping file\n",
    "    # See Harm & Seidenberg PDF file\n",
    "    mapping = pd.read_table(p_file, header=None, delim_whitespace=True)\n",
    "    m_dict = mapping.set_index(0).T.to_dict(\"list\")\n",
    "    return m_dict\n",
    "\n",
    "\n",
    "def get_pronunciation_fast(act, phon_key):\n",
    "    phonemes = list(phon_key.keys())\n",
    "    act10 = np.tile([v for k, v in phon_key.items()], 10)\n",
    "\n",
    "    d = np.abs(act10 - act)\n",
    "    d_mat = np.reshape(d, (38, 10, 25))\n",
    "    sumd_mat = np.squeeze(np.sum(d_mat, 2))\n",
    "    map_idx = np.argmin(sumd_mat, 0)\n",
    "    out = str()\n",
    "    for x in map_idx:\n",
    "        out += phonemes[x]\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_all_pronunciations_fast(act, phon_key):\n",
    "    return np.apply_along_axis(get_pronunciation_fast, 1, act, phon_key)\n",
    "\n",
    "\n",
    "def get_accuracy(output, target):\n",
    "    return 1 * np.array(output == target)\n",
    "\n",
    "\n",
    "def get_mean_accuracy(output, target):\n",
    "    return np.mean(get_accuracy(output, target))\n",
    "\n",
    "\n",
    "def get_sse(output, target):\n",
    "    \"\"\" Get sum squared error at last axis (item level)\n",
    "    \"\"\"\n",
    "    return np.sum(np.square(output - target), axis=-1)\n",
    "\n",
    "\n",
    "def get_mean_sse(output, target):\n",
    "    return np.mean(get_sse(output, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = get_all_pronunciations_fast(y_strain, pkey)\n",
    "y_noisy = y_strain + 0.51 * np.random.rand(*y_strain.shape)\n",
    "ysn = get_all_pronunciations_fast(y_noisy, pkey)\n",
    "get_accuracy(ys, ysn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Strain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkey = gen_pkey(\"../../common/patterns/mappingv2.txt\")\n",
    "input_path = \"../../common/input/\"\n",
    "df_strain = pd.read_csv(input_path + \"df_strain.csv\", index_col=0)\n",
    "y_strain = np.load(input_path + \"y_strain.npz\")[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main simulation function\n",
    "1. Add noise to teaching signal\n",
    "2. Convert noisy signal to P with mapping.txt\n",
    "3. Calculate SSE and ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sim(noise_lv):\n",
    "    \"\"\" This function evaluate the mean ACC and SSE of Strain dataset when noise is added to the teaching signal\n",
    "    noise_lv: a multiplier for scaling standard normal Gaussian noise (np.random.rand())\n",
    "    acc, see: mean acc and sse of the noisy signal\n",
    "    \"\"\"\n",
    "    noisy_y = y_strain + noise_lv * np.random.rand(*y_strain.shape)\n",
    "    clip_y = np.clip(noisy_y, 0, 1)\n",
    "    yp = get_all_pronunciations_fast(clip_y, pkey)\n",
    "    sse = get_mean_sse(noisy_y, y_strain)\n",
    "    acc = get_mean_accuracy(yp, df_strain.pho)\n",
    "    return acc, sse\n",
    "\n",
    "\n",
    "def my_sim2():\n",
    "    \"\"\" Check Jay's hypothesis... SSE at ZER = 2.5... catch bug in get_mean_sse, fixed\n",
    "    \"\"\"\n",
    "    noisy_y = y_strain * 0.8 + 0.1\n",
    "    yp = get_all_pronunciations_fast(noisy_y, pkey)\n",
    "    sse = get_mean_sse(noisy_y, y_strain)\n",
    "    acc = get_mean_accuracy(yp, df_strain.pho)\n",
    "    return acc, sse\n",
    "\n",
    "\n",
    "def my_sim3(noise_lv):\n",
    "\n",
    "    # Push to almost flipping \n",
    "    uni_noisy = noise_lv * np.random.rand(*y_strain.shape)\n",
    "    tipping_y = y_strain * 0.52 + 0.52 / 2\n",
    "    noisy_y = tipping_y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since too much noise will just wipe out accuracy, sim will keep noise level near 0.5 - 0.51, where near the boundary at each output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_acc = []\n",
    "sims_sse = []\n",
    "for noise in np.linspace(0.5, 0.51, 10000):\n",
    "    sims = my_sim(noise)\n",
    "    sims_acc.append(sims[0])\n",
    "    sims_sse.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sim3(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"acc\"] = sims_acc\n",
    "df[\"sse\"] = sims_sse\n",
    "df.plot.scatter(x=\"sse\", y=\"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "- Simulated max SSE for 100% accuracy in Strain data set = 0.134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.acc == 1, \"sse\"].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.epoch.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSE by ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df = pd.read_csv(\"1250_sims.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_1M_200609.csv\")\n",
    "df.columns = [\n",
    "    \"code_name\",\n",
    "    \"epoch\",\n",
    "    \"hidden\",\n",
    "    \"cleanup\",\n",
    "    \"pnoise\",\n",
    "    \"lr\",\n",
    "    \"cond\",\n",
    "    \"measure\",\n",
    "    \"score\",\n",
    "]\n",
    "\n",
    "sdf = df.loc[\n",
    "    df.measure.isin([\"SSE\", \"CorrSSE\", \"IncorrSSE\"])\n",
    "    & df.code_name.isin(old_df.ID.unique()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The shift in max and min values over training is interesting--relative to the end of training, the sse or both correct and incorrect responses is much larger at the beginning of training.  \n",
    "    - Same as loss... \n",
    "- I was a little surprised by how at the magnitude of SSE for correct responses at the beginning.  \n",
    "- Also the overlap between the SSE distributions for correct and incorrect responses is interesting.   \n",
    "- The max SSE for correct responses is always substantially higher than the min SSE for incorrect responses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSE Mean shift over epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf_mean = sdf.groupby([\"epoch\", \"cond\", \"measure\"]).score.mean().reset_index()\n",
    "\n",
    "alt.Chart(plotdf_mean).mark_line().encode(\n",
    "    x=\"epoch:Q\", y=\"score\", column=\"measure\", color=\"cond\", tooltip=\"score\"\n",
    ").properties(title=\"Mean SSE over epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf_mean = sdf.groupby([\"epoch\", \"pnoise\", \"measure\"]).score.mean().reset_index()\n",
    "\n",
    "alt.Chart(plotdf_mean).mark_line().encode(\n",
    "    x=\"epoch:Q\", y=\"score\", column=\"measure\", color=\"pnoise:O\", tooltip=\"score\"\n",
    ").properties(title=\"Mean SSE over epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf_mean = sdf.groupby([\"epoch\", \"hidden\", \"measure\"]).score.mean().reset_index()\n",
    "\n",
    "alt.Chart(plotdf_mean).mark_line().encode(\n",
    "    x=\"epoch:Q\", y=\"score\", column=\"measure\", color=\"hidden:O\", tooltip=\"score\"\n",
    ").properties(title=\"Mean SSE over epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf_mean = sdf.groupby([\"epoch\", \"lr\", \"measure\"]).score.mean().reset_index()\n",
    "\n",
    "alt.Chart(plotdf_mean).mark_line().encode(\n",
    "    x=\"epoch:Q\", y=\"score\", column=\"measure\", color=\"lr:O\", tooltip=\"score\"\n",
    ").properties(title=\"Mean SSE over epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf_mean = sdf.groupby([\"epoch\", \"cleanup\", \"measure\"]).score.mean().reset_index()\n",
    "\n",
    "alt.Chart(plotdf_mean).mark_line().encode(\n",
    "    x=\"epoch:Q\", y=\"score\", column=\"measure\", color=\"cleanup:O\", tooltip=\"score\"\n",
    ").properties(title=\"Mean SSE over epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf = (\n",
    "    sdf.groupby([\"epoch\", \"measure\"]).score.agg([\"min\", \"max\", \"mean\"]).reset_index()\n",
    ")\n",
    "plotdf = pd.melt(\n",
    "    plotdf, id_vars=[\"epoch\", \"measure\"], value_vars=[\"min\", \"mean\", \"max\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(plotdf).mark_line().encode(\n",
    "    x=\"epoch:Q\", y=\"value\", column=\"measure\", color=\"variable\", tooltip=\"value:Q\",\n",
    ").properties(title=\"Min/Max SSE over epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
