{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "Examine simulated data acc/sse related to word freqeuncy as a function of sigmoid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import ipywidgets as widgets\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull data from BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/jupyter/tf/secret/majestic-camp-303620-e8cb3a12037b.json\"\n",
    "client = bigquery.Client(location=\"US\", project=\"majestic-camp-303620\")\n",
    "\n",
    "def load_raw_data():\n",
    "    \"\"\"Read data from BQ database\"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        epoch,\n",
    "        sample,\n",
    "        word,\n",
    "        AVG(wf) AS wf ,  \n",
    "        AVG(acc) AS acc, \n",
    "        AVG(sse) AS sse, \n",
    "    FROM \n",
    "        slow_op_10.train\n",
    "    WHERE \n",
    "        unit_time=4.0\n",
    "    GROUP BY\n",
    "        epoch,\n",
    "        sample,\n",
    "        word;\n",
    "    \"\"\"\n",
    "    query_job = client.query(query)\n",
    "\n",
    "    return query_job.to_dataframe()\n",
    "\n",
    "# df = load_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better name\n",
    "df.rename({'wf':'wf_dynamic'}, axis=1, inplace=True)\n",
    "\n",
    "# Get OP measure (unconditional surprisal)\n",
    "op = pd.read_csv('noam/supplementary_material.csv')\n",
    "op = op[['word', 'uncond.surprisal']]\n",
    "op.rename({'uncond.surprisal': 'op'}, axis=1, inplace=True)\n",
    "df = df.merge(op, how='left', on='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obsolete, calculate Zipf from WSJ frequency\n",
    "\n",
    "# df_train = pd.read_csv(\"../../dataset/df_train.csv\")\n",
    "# df_train = df_train[['word', 'wf', 'img']]\n",
    "# df_train.rename({'wf':'wf_wsj'}, axis=1, inplace=True)\n",
    "# df = df.merge(df_train, 'left', 'word')\n",
    "\n",
    "# df['zipf_wsj'] = np.log10((df.wf_wsj/1000) + 1)\n",
    "# df['log_wf_wsj'] = np.log10(df.wf_wsj+1)\n",
    "# df['log_wf_dynamic'] = np.log10(df.wf_dynamic+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When converting WSJ to Zipf, Zipf range is 0-3.4, which is a bit off the regular range of 0-7, perhaps WSJ is not a wpm scale in the raw data\n",
    "- To get Zipf scale, I used a [word_freq](https://github.com/LuminosoInsight/wordfreq/) library that based on [exquisite-corpus](https://github.com/LuminosoInsight/exquisite-corpus), which aggregated corpus from Wikipedia, SUBTLEX, News, Books, Web, Twitter, Reddit, and MISC content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Zipf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordfreq\n",
    "\n",
    "def get_zipf(x):\n",
    "    return wordfreq.zipf_frequency(str(x), lang='en', minimum=0)\n",
    "\n",
    "def get_wf(x):\n",
    "    return wordfreq.word_frequency(str(x), lang='en', minimum=0)\n",
    "\n",
    "df['zipf'] = df.word.apply(get_zipf)\n",
    "df['wf'] = df.word.apply(get_wf)\n",
    "\n",
    "# Save\n",
    "df.to_csv(\"parsed_df.csv\")\n",
    "\n",
    "# Peek at 1M sample\n",
    "df.loc[df.epoch==100 ,['wf_dynamic', 'wf', 'zipf', 'op']].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('parsed_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(x_var=['wf_dynamic', 'wf', 'zipf'],\n",
    "                  y_var=['acc', 'sse'],\n",
    "                  epoch=(10,100,10), \n",
    "                  min_op=(0, 10, 0.1), \n",
    "                  max_op=(0, 10, 0.1),\n",
    "                  min_zipf=(0, 8, 0.01),\n",
    "                  max_zipf=(0, 7, 0.01),\n",
    "                  loess_bandwidth=(0,1,0.1))\n",
    "def plot_exploratory(x_var='zipf', y_var='acc', epoch=100, min_op=0, max_op=0, min_zipf=0, max_zipf=8, loess_bandwidth=0.3):\n",
    "    x = df.loc[(df.epoch==epoch) & \n",
    "               (df.op >= min_op) & \n",
    "               (df.op <= max_op) &\n",
    "               (df.zipf >= min_zipf) &\n",
    "               (df.zipf <= max_zipf)]\n",
    "\n",
    "    annotatation = f'Epoch: {epoch}; OP surprisal within: [{min_op}, {max_op}]; Zipf within: [{min_zipf}, {max_zipf}]'\n",
    "\n",
    "    if len(x) > 1000:\n",
    "        x = x.sample(1000)\n",
    "\n",
    "    if y_var == 'acc':\n",
    "        y_obj = alt.Y(\"acc\", scale=alt.Scale(domain=(0,1)))\n",
    "    elif y_var == 'sse':\n",
    "        y_obj = \"sse:Q\"\n",
    "\n",
    "    p = alt.Chart(x).encode(x=x_var, y=y_obj,  tooltip=[\"word\", \"wf\", \"wf_dynamic\", \"zipf\", \"op\"]).mark_point()\n",
    "    l = p.transform_loess(x_var, y_var, bandwidth=loess_bandwidth).mark_line(color='red')\n",
    "\n",
    "    return (p + l).properties(title=annotatation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve fit\n",
    "\n",
    "### Fit accuracy to 2-PL IRT like equation\n",
    "\n",
    "$P(X=1|\\theta, a, b)= \\frac{e^{(a(\\theta -b))}}{1+e^{(a(\\theta -b))}}$\n",
    "\n",
    "where \n",
    "$\\theta$: frequency (zipf scale)\n",
    "\n",
    "$a$: max slope (IRT: discriminability)\n",
    "\n",
    "$b$: x-shift (IRT: difficulty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore parameter effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2pl(theta, a, b):\n",
    "    \"\"\"2PL equation\"\"\"\n",
    "    x = a * (theta - b)\n",
    "    ex = np.exp(x)\n",
    "    return ex/(1+ex)\n",
    "\n",
    "@widgets.interact(a=(0, 10, 0.1),\n",
    "                  b=(-10, 10, 1))\n",
    "def my_plot(a, b):\n",
    "    theta = np.linspace(0, 8, 30)\n",
    "    df = pd.DataFrame({\"theta\":theta, \"p\":f2pl(theta, a, b)})\n",
    "    return alt.Chart(df).mark_line(point=True, color=\"red\").encode(\n",
    "        x=\"theta\",\n",
    "        y=alt.Y(\"p\", scale=alt.Scale(domain=(0,1)))\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit 2PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_df = df.loc[(df.epoch==70) & (df.op==0)]\n",
    "sel_df.wf_dynamic.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(epoch=(10, 100, 10), x_var=['zipf', 'wf', 'wf_dynamic'])\n",
    "def my_2pl_irt(epoch, x_var='zipf'):\n",
    "\n",
    "    # Filter data to selected epoch\n",
    "    sel_df = df.loc[(df.epoch==epoch) & (df.op==0)]\n",
    "\n",
    "    # Curve fit\n",
    "    curve_params, _ = curve_fit(f=f2pl, \n",
    "        xdata=sel_df[x_var], \n",
    "        ydata=sel_df['acc'], \n",
    "        maxfev=10000,\n",
    "        method='trf',\n",
    "        loss='soft_l1',\n",
    "        p0=[3, sel_df[x_var].mean()],\n",
    "        bounds=([0, -6], [10, 14])\n",
    "        )\n",
    "\n",
    "    # Plot (Actual)\n",
    "    sel_df = sel_df.sample(1000) if len(sel_df) > 1000 else sel_df\n",
    "\n",
    "    plot_actual = alt.Chart(sel_df).mark_point().encode(\n",
    "        x=x_var,\n",
    "        y='acc'\n",
    "    )\n",
    "\n",
    "    # Create predicted df\n",
    "    theta = np.linspace(sel_df[x_var].min(), sel_df[x_var].max(), 30)\n",
    "    pred = f2pl(x, *curve_params)\n",
    "    predicted_df = pd.DataFrame({x_var: theta, 'acc': pred})\n",
    "    \n",
    "    # Plot (Predicted)\n",
    "    annotations = f\"2PL curve: a:{curve_params[0]:.2f}, b:{curve_params[1]:.2f}\"\n",
    "\n",
    "    plot_predict = alt.Chart(predicted_df).mark_line(point=True, color=\"red\").encode(\n",
    "        x=x_var,\n",
    "        y='acc'\n",
    "    ).properties(title=annotations)\n",
    "\n",
    "    return plot_actual + plot_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit sse to 4-PL IRT like equation\n",
    "\n",
    "$P(X=1|\\theta, a, b, c, d)= c + (d-c) \\frac{e^{(a(\\theta -b))}}{1+e^{(a(\\theta -b))}}$\n",
    "\n",
    "where \n",
    "$\\theta$: frequency (zipf scale)\n",
    "\n",
    "$a$: max slope (IRT: discriminability)\n",
    "\n",
    "$b$: x-shift (IRT: difficulty)\n",
    "\n",
    "$c$: lower asymptote\n",
    "\n",
    "$d$: upper asymptote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f4pl(theta, a, b, c, d):\n",
    "    \"\"\"4PL equation\"\"\"\n",
    "    x = a * (theta - b)\n",
    "    ex = np.exp(x)\n",
    "    fr = ex / (1 + ex)\n",
    "    return c + (d-c) * fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "name": "python379jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
