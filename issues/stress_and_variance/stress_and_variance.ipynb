{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine effect of error injection timing and rng seed variance\n",
    "I have ran 10 models per (error_injection_timing)\n",
    "- fewer error ticks : 2 (11 - 12 tick)\n",
    "- more error ticks : 11 (2 - 12 tick)\n",
    "- Phase 1 training is done with the same error tick setting\n",
    "\n",
    "\n",
    "static_hpar = {\n",
    "    \"tf_root\": \"/home/jupyter/tf\",\n",
    "    \"ort_units\": 119,\n",
    "    \"pho_units\": 250,\n",
    "    \"sem_units\": 2446,\n",
    "    \"hidden_os_units\": 500,\n",
    "    \"hidden_op_units\": 100,\n",
    "    \"hidden_ps_units\": 500,\n",
    "    \"hidden_sp_units\": 500,\n",
    "    \"pho_cleanup_units\": 20,\n",
    "    \"sem_cleanup_units\": 50,\n",
    "    \"pho_noise_level\": 0.0,\n",
    "    \"sem_noise_level\": 0.0,\n",
    "    \"activation\": \"sigmoid\",\n",
    "    \"tau\": 1 / 3,\n",
    "    \"max_unit_time\": 4.0,\n",
    "    \"output_ticks\": 11,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"zero_error_radius\": 0.1,\n",
    "    \"n_mil_sample\": 2.0,\n",
    "    \"batch_size\": 100,\n",
    "    \"save_freq\": 10,\n",
    "    \"batch_name\": batch_name,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext lab_black\n",
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = \"error_injection_timing_test\"\n",
    "con = sqlite3.connect(\n",
    "    f\"/home/jupyter/tf/models/batch_run/{batch_name}/batch_results.sqlite\"\n",
    ")\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(f'Result tables: {cur.fetchall()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_config = pd.read_sql_query(\"SELECT * FROM batch_config\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT \n",
    "        code_name, \n",
    "        epoch, \n",
    "        timetick, \n",
    "        y, \n",
    "        testset, \n",
    "        AVG(acc) as acc, \n",
    "        AVG(sse) as sse, \n",
    "        AVG(conditional_sse) as conditional_sse\n",
    "    FROM strain\n",
    "    GROUP BY\n",
    "        code_name, \n",
    "        epoch,\n",
    "        timetick,\n",
    "        y,\n",
    "        testset\n",
    "    \"\"\"\n",
    "\n",
    "strain_df = pd.read_sql_query(query, con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caution, there are 4 y_test in grain, ['pho_small_grain', 'pho_large_grain', 'pho', 'sem']\n",
    "# pho is pho_small_grain or pho_large_grain\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        code_name, \n",
    "        epoch, \n",
    "        timetick, \n",
    "        y, \n",
    "        testset, \n",
    "        AVG(acc) as acc, \n",
    "        AVG(sse) as sse, \n",
    "        AVG(conditional_sse) as conditional_sse\n",
    "    FROM grain\n",
    "    WHERE y_test IN ('pho', 'sem')\n",
    "    GROUP BY\n",
    "        code_name, \n",
    "        epoch,\n",
    "        timetick,\n",
    "        y,\n",
    "        testset\n",
    "    \"\"\"\n",
    "\n",
    "grain_df = pd.read_sql_query(query, con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_df['wordness'] = 'word'\n",
    "grain_df['wordness'] = 'nonword'\n",
    "\n",
    "df = pd.concat([strain_df, grain_df])\n",
    "df = df.merge(batch_config[['code_name', 'inject_error_ticks']], \"left\", on=\"code_name\")\n",
    "\n",
    "# Average by wordness\n",
    "mean_df = df.groupby(['code_name', 'epoch', 'timetick', 'y', 'wordness']).mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Phonology output\n",
    "- Similar to what we found in O2P model\n",
    "    - Late timetick --> Similar between inject_error_ticks\n",
    "    - At earlier time tick, inject_error_ticks has more influence on word than nonword\n",
    "- Somewhat differnt from O2P model\n",
    "    - More inject_error_ticks is relatively more stable over time ticks (vs. less inject_error, and vs. O2P model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "stress_contrast_df = mean_df.groupby(['inject_error_ticks', 'epoch', 'timetick', 'wordness', 'y']).mean().reset_index()\n",
    "\n",
    "def stress_plot(df, variable_of_interest):\n",
    "    \"\"\"Plot Hi time stress vs. Low time stress in variable of interest\"\"\"\n",
    "\n",
    "    timetick_selection = alt.selection_single(\n",
    "        bind=alt.binding_range(min=0, max=12, step=1),\n",
    "        fields=[\"timetick\"],\n",
    "        init={\"timetick\": 12},\n",
    "        name=\"timetick\",\n",
    "    )\n",
    "\n",
    "    return alt.Chart(df).mark_line().encode(\n",
    "        x='epoch:Q',\n",
    "        y=f'{variable_of_interest}:Q',\n",
    "        color='wordness:N',\n",
    "        column='inject_error_ticks:N',\n",
    "    ).add_selection(timetick_selection).transform_filter(timetick_selection)\n",
    "\n",
    "stress_plot(stress_contrast_df.loc[stress_contrast_df.y=='pho'], 'acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Semantic output\n",
    "- Less inject_error_tick just kill the accuracy in the timeticks that without error injection (e.g., tick 9: 0%, tick 10: 70%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_plot(stress_contrast_df.loc[(stress_contrast_df.y=='sem') & (stress_contrast_df.wordness=='word')], 'acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_df = df.loc[df.inject_error_ticks==11]\n",
    "\n",
    "mean_df = hs_df.groupby(['code_name', 'epoch', 'timetick', 'wordness', 'y']).mean().reset_index()\n",
    "variance_df = mean_df.groupby(['epoch', 'timetick', 'wordness', 'y']).var().reset_index()\n",
    "\n",
    "\n",
    "alt.Chart(variance_df).mark_rect().encode(\n",
    "        x='epoch:O',\n",
    "        y='timetick:O',\n",
    "        color=alt.Color('acc', scale=alt.Scale(domain=(0, 0.008))),\n",
    "        column='wordness',\n",
    "        row='y',\n",
    "        tooltip=['acc']\n",
    "    ).properties(title='RNG Seed variance: Variance in the mean of wordness over Epoch and Timetick')\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ignore bottom-left panel\n",
    "- similar pattern as O2P, but slightly higher variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoom-in: last timetick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_df = mean_df.loc[mean_df.timetick==12,]\n",
    "\n",
    "alt.Chart(sel_df).mark_line().encode(\n",
    "    x='epoch:Q',\n",
    "    y='acc:Q',\n",
    "    column='wordness',\n",
    "    row='y',\n",
    "    color='code_name'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variance related to accuracy, it is highest when acc near 0.7-0.8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phonology output variance by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = hs_df.groupby(['code_name', 'epoch', 'timetick', 'testset', 'y']).mean().reset_index()\n",
    "variance_df = mean_df.groupby(['epoch', 'timetick', 'testset', 'y']).var().reset_index()\n",
    "\n",
    "alt.Chart(variance_df.loc[variance_df.y=='pho']).mark_rect().encode(\n",
    "    x='epoch:O',\n",
    "    y='timetick:O',\n",
    "    color=alt.Color('acc', scale=alt.Scale(domain=(0, 0.02))),\n",
    "    row='testset',\n",
    "    tooltip=['acc']\n",
    ").properties(title='RNG Seed variance: Variance by condition over Epoch and Timetick')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic output variance by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_subtests = ('strain_hf_con_hi', 'strain_hf_con_li', 'strain_hf_inc_hi', 'strain_hf_inc_li',\n",
    "       'strain_lf_con_hi', 'strain_lf_con_li', 'strain_lf_inc_hi', 'strain_lf_inc_li')\n",
    "\n",
    "sem_variance_plot_df = variance_df.loc[(variance_df.y=='sem') & variance_df.testset.isin(strain_subtests)]\n",
    "\n",
    "\n",
    "alt.Chart(sem_variance_plot_df).mark_rect().encode(\n",
    "    x='epoch:O',\n",
    "    y='timetick:O',\n",
    "    color=alt.Color('acc', scale=alt.Scale(domain=(0, 0.02))),\n",
    "    row='testset',\n",
    "    tooltip=['acc']\n",
    ").properties(title='RNG Seed variance: Variance by condition over Epoch and Timetick')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last timetick phonology by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_df = mean_df.loc[(mean_df.timetick==12) & (mean_df.y==\"pho\"),]\n",
    "\n",
    "alt.Chart(sel_df).mark_line().encode(\n",
    "    x='epoch:Q',\n",
    "    y='acc:Q',\n",
    "    row='testset:N',\n",
    "    color='code_name'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last time tick semantic by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_df = mean_df.loc[(mean_df.timetick==12) & (mean_df.y==\"sem\") & (mean_df.testset.isin(strain_subtests)),]\n",
    "\n",
    "alt.Chart(sel_df).mark_line().encode(\n",
    "    x='epoch:Q',\n",
    "    y='acc:Q',\n",
    "    row='testset:N',\n",
    "    color='code_name'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Semantics has a stonger variance\n",
    "- Maybe need more run per cell than O2P"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
