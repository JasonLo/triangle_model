{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Equation playground\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough test on how each parameter affect semantic input\n",
    "- Purpose: rapid prototype formula and parameter before actual sampling\n",
    "- Target: \n",
    "    - Around 4.5 input in LF, 5.5 in HF at the end of training\n",
    "    - Effect should quickly peak at 0.1M sample at 1.0, and decrease to 0.5 at EoT\n",
    "- Frequency of HF and LF is a rough copy of simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class SemanticExperiment:\n",
    "    \"\"\"Semantic experiment class for evaluating semantic equation\"\"\"\n",
    "    # Mean in each condition in Strain data set (in a perfect world)\n",
    "    strain = {\n",
    "                \"HF_HI\": {\"wf\": 6500., \"img\": 6.},\n",
    "                \"HF_LI\": {\"wf\": 6500., \"img\": 3.5},\n",
    "                \"LF_HI\": {\"wf\": 400., \"img\": 6.},\n",
    "                \"LF_LI\": {\"wf\": 400., \"img\": 3.5}\n",
    "            }\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        # Load tmp cfg and data\n",
    "        import sys\n",
    "        sys.path.append(\"/home/jupyter/tf/src/\")\n",
    "        import meta, data_wrangling\n",
    "        from importlib import reload\n",
    "        reload(data_wrangling)\n",
    "        self.cfg = meta.ModelConfig.from_json(\n",
    "            \"../../models/test_sampling_speed_2/model_config.json\")\n",
    "        self.data = data_wrangling.MyData()\n",
    "        clear_output()\n",
    "        self.semantic_params = kwargs\n",
    "\n",
    "        # Fake data\n",
    "        self.fake_epoch = np.arange(100)\n",
    "        self.fake_cwfhf = np.linspace(0, 650, 100)\n",
    "        self.fake_cwflf = np.concatenate((np.linspace(0, 5, 11),  np.linspace(5, 130, 90)[1:]))\n",
    "\n",
    "        # Instantiate sampler\n",
    "        self.sampler = data_wrangling.Sampling(self.cfg, self.data, debugging=True)\n",
    "        self.sampler.set_semantic_parameters(**self.semantic_params)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def run_sampling(self):\n",
    "        last_epoch = 0\n",
    "        with tqdm(total=100) as progress:\n",
    "            while self.sampler.current_epoch <= 100:\n",
    "\n",
    "                # Progress bar\n",
    "                if last_epoch != self.sampler.current_epoch:\n",
    "                    progress.update(1)\n",
    "                last_epoch = self.sampler.current_epoch\n",
    "\n",
    "                # dry run sampling\n",
    "                next(self.sampler.sample_generator(dryrun=True))\n",
    "\n",
    "        self.df, self.df_mean = self._parse_sampler_results()\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "    def _parse_sampler_results(self):\n",
    "\n",
    "        # Convert dict to df\n",
    "        df_wf = pd.DataFrame(self.sampler.debug_wf).transpose()\n",
    "        df_wf.columns = \"cwf_\" + df_wf.columns.astype(str)\n",
    "        df_wf[\"word\"] = df_wf.index\n",
    "\n",
    "        df_sem = pd.DataFrame(self.sampler.debug_sem).transpose()\n",
    "        df_sem.columns = \"sem_\" + df_sem.columns.astype(str)\n",
    "        df_sem[\"word\"] = df_sem.index\n",
    "\n",
    "        # Merge\n",
    "        df = pd.merge(df_wf, df_sem, \"left\", on=\"word\")\n",
    "\n",
    "        # Subset\n",
    "        df = df.loc[df.word.isin(self.data.df_strain.word)]\n",
    "        df = df.melt(id_vars=['word'],\n",
    "                            var_name='epoch_label', value_name='value')\n",
    "\n",
    "        # Make new columns\n",
    "        df[\"measure\"] = df.epoch_label.str.split(\"_\", expand=True).loc[:, 0]\n",
    "        df[\"epoch\"] = df.epoch_label.str.split(\"_\", expand=True).loc[:, 1]\n",
    "        df.pop(\"epoch_label\")\n",
    "\n",
    "        # Pivot\n",
    "        df = df.pivot_table(index=[\"word\", \"epoch\"], columns=\"measure\").reset_index()\n",
    "        df.columns = ['word', 'epoch', 'cumulative_frequency', 'semantic_input']\n",
    "\n",
    "        # Merge strain conditions\n",
    "        df = pd.merge(df, self.data.df_strain, \"left\", on='word')\n",
    "        df['cond'] = df.frequency + '_' + df.imageability\n",
    "        df.rename(columns={'wf': 'static_wf'}, inplace=True)\n",
    "\n",
    "        # Activation\n",
    "        df[\"activation\"] = df.semantic_input.apply(self.sigmoid)\n",
    "\n",
    "        # Mean df\n",
    "        df_mean = df.pivot_table(index=\"epoch\", columns=\"cond\")\n",
    "        df_mean[\"epoch\"] = df_mean.index.astype(int)\n",
    "        df_mean.reset_index(drop=True, inplace=True)\n",
    "        df_mean.sort_values(\"epoch\", inplace=True)\n",
    "\n",
    "        for measure in [\"semantic_input\", \"activation\"]:\n",
    "            df_mean[f\"frequency_effect_{measure}\"] = df_mean[measure][\"HF_HI\"] + df_mean[measure][\"HF_LI\"] - \\\n",
    "                df_mean[measure][\"LF_HI\"] - df_mean[measure][\"LF_LI\"]\n",
    "\n",
    "            df_mean[f\"imageability_effect_{measure}\"] = df_mean[measure][\"HF_HI\"] + df_mean[measure][\"LF_HI\"] - \\\n",
    "                df_mean[measure][\"HF_LI\"] - df_mean[measure][\"LF_LI\"]\n",
    "\n",
    "            df_mean[f\"fxi_interaction_{measure}\"] = df_mean[measure][\"LF_HI\"] - df_mean[measure][\"LF_LI\"] - \\\n",
    "                df_mean[measure][\"HF_HI\"] + df_mean[measure][\"HF_LI\"]\n",
    "\n",
    "\n",
    "        return (df, df_mean)\n",
    "\n",
    "    def plot_fake_input(self):\n",
    "\n",
    "        # Effects\n",
    "        hf = self.sampler.semantic_input(self.fake_cwfhf)\n",
    "        lf = self.sampler.semantic_input(self.fake_cwflf)\n",
    "        eff = hf-lf\n",
    "\n",
    "        # Plot\n",
    "        ax = plt.subplot()\n",
    "        plt.title(\"Semantic input\")\n",
    "        ax.plot(self.fake_epoch, hf, label=\"HF\")\n",
    "        ax.plot(self.fake_epoch, lf, label=\"LF\")\n",
    "        ax.plot(self.fake_epoch, eff, label=\"frequency effect\")\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_fake_wf(self):\n",
    "        ax = plt.subplot()\n",
    "        plt.title(\"Fake cumulative frequency\")\n",
    "        ax.plot(self.fake_epoch, self.fake_cwfhf, label=\"HF\")\n",
    "        ax.plot(self.fake_epoch, self.fake_cwflf, label=\"LF\")\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_wf(self):\n",
    "        \"\"\"Plot the simulated cumulative frequency\"\"\"\n",
    "\n",
    "        plot_wf = alt.Chart(self.df).mark_line().encode(\n",
    "            x=\"epoch:Q\",\n",
    "            y=\"mean(cumulative_frequency):Q\",\n",
    "            color=\"cond:N\",\n",
    "        )\n",
    "\n",
    "        return plot_wf\n",
    "\n",
    "    def plot_strain(self, df=None):\n",
    "\n",
    "        if df is None:\n",
    "            df = self.df_mean\n",
    "\n",
    "        strain_conds = self.strain.keys()\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "        # Semantic input\n",
    "        ax = fig.add_subplot(221)\n",
    "        ax.title.set_text(\"Semantic input over epoch\")\n",
    "        for condition in strain_conds:\n",
    "            ax.plot(df.epoch, df[\"semantic_input\"][condition], label=condition)\n",
    "        ax.legend()\n",
    "\n",
    "        # Semantic activation\n",
    "        ax = fig.add_subplot(222)\n",
    "        ax.title.set_text(\"Semantic activation over epoch\")\n",
    "        for condition in strain_conds:\n",
    "            ax.plot(df.epoch, df[\"activation\"][condition], label=condition)\n",
    "        ax.legend()\n",
    "\n",
    "        # Contrasts for input\n",
    "        contrasts = [\"frequency_effect\", \"imageability_effect\", \"fxi_interaction\"]\n",
    "\n",
    "        ax = fig.add_subplot(223)\n",
    "        ax.title.set_text(\"Contrasts for input\")\n",
    "        for contrast in contrasts:\n",
    "            ax.plot(df.epoch, df[f\"{contrast}_semantic_input\"], label=contrast)\n",
    "        ax.legend()\n",
    "\n",
    "        # Contrasts for activation\n",
    "        ax = fig.add_subplot(224)\n",
    "        ax.title.set_text(\"Contrasts for activation\")\n",
    "\n",
    "        for contrast in contrasts:\n",
    "            ax.plot(df.epoch, df[f\"{contrast}_activation\"], label=contrast)\n",
    "        ax.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto = SemanticExperiment(**{\"g\":1, \"k\":1, \"h\":1, \"w\":1})\n",
    "proto.run_sampling()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(proto.df.loc[proto.df.epoch==proto.df.epoch.max(),]).mark_circle().encode(\r\n",
    "    x=alt.X(\"static_wf:Q\"),\r\n",
    "    y=alt.Y(\"cumulative_frequency:Q\"),\r\n",
    "    color=\"cond:N\",\r\n",
    "    tooltip=[\"word\", \"cond\", \"cumulative_frequency\", \"static_wf\"]\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto = SemanticExperiment(**{\"g\":5, \"k\":100, \"w\":5})\n",
    "proto.plot_fake_input()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
