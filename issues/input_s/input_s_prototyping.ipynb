{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Equation playground\n",
    "from os import sched_yield\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough test on how each parameter affect semantic input\n",
    "- Purpose: rapid prototype formula and parameter before actual sampling\n",
    "- Target: \n",
    "    - Around 4.5 input in LF, 5.5 in HF at the end of training\n",
    "    - Effect should quickly peak at 0.1M sample at 1.0, and decrease to 0.5 at EoT\n",
    "- Frequency of HF and LF is a rough copy of simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_s(g, k, h, w):\n",
    "    \"\"\" Rapid prototyping of Semantic input equation\n",
    "    \"\"\"\n",
    "\n",
    "    def f(x):\n",
    "        \"\"\"Semantic equation\"\"\"\n",
    "        numer = g * np.log(10**w * x + h)\n",
    "        denom = np.log(10 ** w * x + h) + k\n",
    "        return numer/denom\n",
    "    \n",
    "    # Epoch serie\n",
    "    epoch = np.arange(100)\n",
    "\n",
    "    # Rough cumulative frequency\n",
    "    cwf_hf = np.linspace(0, 650, 100)\n",
    "    cwf_lf = np.concatenate((np.linspace(0, 5, 11),  np.linspace(5, 130, 90)[1:]))\n",
    "\n",
    "    # Effects\n",
    "    hf = f(cwf_hf)\n",
    "    lf = f(cwf_lf)\n",
    "    eff = hf-lf\n",
    "\n",
    "    # Plot\n",
    "    ax = plt.subplot()\n",
    "    plt.title(\"Semantic input\")\n",
    "    ax.plot(epoch, hf, label=\"HF\")\n",
    "    ax.plot(epoch, lf, label=\"LF\")\n",
    "    ax.plot(epoch, eff, label=\"frequency effect\")\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_s(g=5, k=100, h=1, w=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_s(g=50, k=100, h=1, w=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(data_wrangling)\n",
    "\n",
    "\n",
    "class SemanticExperiment:\n",
    "    \"\"\"Semantic experiment class for evaluating semantic equation\"\"\"\n",
    "    # Mean in each condition in Strain data set (in a perfect world)\n",
    "    strain = {\n",
    "                \"HF_HI\": {\"wf\": 6500., \"img\": 6.},\n",
    "                \"HF_LI\": {\"wf\": 6500., \"img\": 3.5},\n",
    "                \"LF_HI\": {\"wf\": 400., \"img\": 6.},\n",
    "                \"LF_LI\": {\"wf\": 400., \"img\": 3.5}\n",
    "            }\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.semantic_params = kwargs\n",
    "        self.sampler = self._run_sampling()\n",
    "        self.df, self.df_mean = self._parse_sampler_results()\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _run_sampling(self):\n",
    "        last_epoch = 0\n",
    "        sampler = data_wrangling.Sampling(cfg, data, debugging=True)\n",
    "        sampler.set_semantic_parameters(**self.semantic_params)\n",
    "\n",
    "        with tqdm(total=100) as progress:\n",
    "            while sampler.current_epoch <= 100:\n",
    "\n",
    "                # Progress bar\n",
    "                if last_epoch != sampler.current_epoch:\n",
    "                    progress.update(1)\n",
    "                last_epoch = sampler.current_epoch\n",
    "\n",
    "                # dry run sampling\n",
    "                next(sampler.sample_generator(dryrun=True))\n",
    "\n",
    "        return sampler\n",
    "\n",
    "    def _parse_sampler_results(self):\n",
    "\n",
    "        # Convert dict to df\n",
    "        df_wf = pd.DataFrame(self.sampler.debug_wf).transpose()\n",
    "        df_wf.columns = \"cwf_\" + df_wf.columns.astype(str)\n",
    "        df_wf[\"word\"] = df_wf.index\n",
    "\n",
    "        df_sem = pd.DataFrame(self.sampler.debug_sem).transpose()\n",
    "        df_sem.columns = \"sem_\" + df_sem.columns.astype(str)\n",
    "        df_sem[\"word\"] = df_sem.index\n",
    "\n",
    "        # Merge\n",
    "        df = pd.merge(df_wf, df_sem, \"left\", on=\"word\")\n",
    "\n",
    "        # Subset\n",
    "        df = df.loc[df.word.isin(data.df_strain.word)]\n",
    "        df = df.melt(id_vars=['word'],\n",
    "                            var_name='epoch_label', value_name='value')\n",
    "\n",
    "        # Make new columns\n",
    "        df[\"measure\"] = df.epoch_label.str.split(\"_\", expand=True).loc[:, 0]\n",
    "        df[\"epoch\"] = df.epoch_label.str.split(\"_\", expand=True).loc[:, 1]\n",
    "        df.pop(\"epoch_label\")\n",
    "\n",
    "        # Pivot\n",
    "        df = df.pivot_table(index=[\"word\", \"epoch\"], columns=\"measure\").reset_index()\n",
    "        df.columns = ['word', 'epoch', 'cumulative_frequency', 'semantic_input']\n",
    "\n",
    "        # Merge strain conditions\n",
    "        df = pd.merge(df, data.df_strain, \"left\", on='word')\n",
    "        df['cond'] = df.frequency + '_' + df.imageability\n",
    "        df.rename(columns={'wf': 'static_wf'}, inplace=True)\n",
    "\n",
    "        # Activation\n",
    "        df[\"activation\"] = df.semantic_input.apply(self.sigmoid)\n",
    "\n",
    "        # Mean df\n",
    "        df_mean = df.pivot_table(index=\"epoch\", columns=\"cond\")\n",
    "        df_mean[\"epoch\"] = df_mean.index.astype(int)\n",
    "        df_mean.reset_index(drop=True, inplace=True)\n",
    "        df_mean.sort_values(\"epoch\", inplace=True)\n",
    "\n",
    "        for measure in [\"semantic_input\", \"activation\"]:\n",
    "            df_mean[f\"frequency_effect_{measure}\"] = df_mean[measure][\"HF_HI\"] + df_mean[measure][\"HF_LI\"] - \\\n",
    "                df_mean[measure][\"LF_HI\"] - df_mean[measure][\"LF_LI\"]\n",
    "\n",
    "            df_mean[f\"imageability_effect_{measure}\"] = df_mean[measure][\"HF_HI\"] + df_mean[measure][\"LF_HI\"] - \\\n",
    "                df_mean[measure][\"HF_LI\"] - df_mean[measure][\"LF_LI\"]\n",
    "\n",
    "            df_mean[f\"fxi_interaction_{measure}\"] = df_mean[measure][\"LF_HI\"] - df_mean[measure][\"LF_LI\"] - \\\n",
    "                df_mean[measure][\"HF_HI\"] + df_mean[measure][\"HF_LI\"]\n",
    "\n",
    "\n",
    "        return (df, df_mean)\n",
    "\n",
    "    def plot_input(self):\n",
    "\n",
    "        plot_sem = alt.Chart(self.df).mark_line().encode(\n",
    "            x=\"epoch:Q\",\n",
    "            y=\"mean(semantic_input):Q\",\n",
    "            color=\"cond:N\",\n",
    "        )\n",
    "\n",
    "        plot_wf = alt.Chart(self.df).mark_line().encode(\n",
    "            x=\"epoch:Q\",\n",
    "            y=\"mean(cumulative_frequency):Q\",\n",
    "            color=\"cond:N\",\n",
    "        )\n",
    "\n",
    "        return plot_wf | plot_sem\n",
    "\n",
    "    def plot_strain(self, df=None):\n",
    "\n",
    "        if df is None:\n",
    "            df = self.df_mean\n",
    "\n",
    "        strain_conds = self.strain.keys()\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "        # Semantic input\n",
    "        ax = fig.add_subplot(221)\n",
    "        ax.title.set_text(\"Semantic input over epoch\")\n",
    "        for condition in strain_conds:\n",
    "            ax.plot(df.epoch, df[\"semantic_input\"][condition], label=condition)\n",
    "        ax.legend()\n",
    "\n",
    "        # Semantic activation\n",
    "        ax = fig.add_subplot(222)\n",
    "        ax.title.set_text(\"Semantic activation over epoch\")\n",
    "        for condition in strain_conds:\n",
    "            ax.plot(df.epoch, df[\"activation\"][condition], label=condition)\n",
    "        ax.legend()\n",
    "\n",
    "        # Contrasts for input\n",
    "        contrasts = [\"frequency_effect\", \"imageability_effect\", \"fxi_interaction\"]\n",
    "\n",
    "        ax = fig.add_subplot(223)\n",
    "        ax.title.set_text(\"Contrasts for input\")\n",
    "        for contrast in contrasts:\n",
    "            ax.plot(df.epoch, df[f\"{contrast}_semantic_input\"], label=contrast)\n",
    "        ax.legend()\n",
    "\n",
    "        # Contrasts for activation\n",
    "        ax = fig.add_subplot(224)\n",
    "        ax.title.set_text(\"Contrasts for activation\")\n",
    "\n",
    "        for contrast in contrasts:\n",
    "            ax.plot(df.epoch, df[f\"{contrast}_activation\"], label=contrast)\n",
    "        ax.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/jupyter/tf/src/\")\n",
    "import meta, data_wrangling\n",
    "\n",
    "cfg = meta.ModelConfig.from_json(\n",
    "    \"../../models/test_sampling_speed_2/model_config.json\")\n",
    "data = data_wrangling.MyData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto8 = SemanticExperiment(**{\"g\":50, \"k\":100, \"h\":1, \"w\":2})\n",
    "proto8.plot_strain()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- w can change the effect size\n",
    "- Due to sampling dynamic cahnge, the early difference is huge as compared to PMSP\n",
    "- Effect still too high... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto9 = SemanticExperiment(**{\"g\":50, \"k\":100, \"h\":1, \"w\":3})\n",
    "proto9.plot_strain()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As w increase, it increase to effect of g... asymptote is higher\n",
    "- need to scale it down a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto10 = SemanticExperiment(**{\"g\":40, \"k\":100, \"h\":1, \"w\":3})\n",
    "proto10.plot_strain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto11 = SemanticExperiment(**{\"g\":30, \"k\":100, \"h\":1, \"w\":4})\n",
    "proto11.plot_strain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto12 = SemanticExperiment(**{\"g\":20, \"k\":100, \"h\":1, \"w\":8})\n",
    "proto12.plot_strain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
