{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "1. Check the bias distribution in a feedforward OS model without cleanup, and see whether it is mostly negative. \n",
    "2. If the bias is related to the probability of activation in a node, we should see (negative) correlation between the two. Where the low activation chance nodes should have a more negative bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/jupyter/tf')\n",
    "\n",
    "import troubleshooting\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_names = ('OS_ff', 'Refrac3_local', 'Refrac3_after6')\n",
    "\n",
    "name_map = {\n",
    "    'OS_ff': 'OS feedforward with no cleanup',\n",
    "    'Refrac3_local': 'Original triangle with 2-12 tick error injection',\n",
    "    'Refrac3_after6': 'Triangle with 7-12 tick error injection'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inputs_sem(code_name):\n",
    "    \"\"\"Plot bias and input density\"\"\"\n",
    "\n",
    "    d = troubleshooting.Diagnosis(code_name)\n",
    "    d.eval('train_r100', task='triangle', epoch=d.cfg.total_number_of_epoch)\n",
    "\n",
    "    data = {\n",
    "        'ss1': 0.5 * np.sum(d.get_weight(name=\"w_ss\"), axis=0), # Lazy matmul. \n",
    "        'cs1': 0.5 * np.sum(d.get_weight(name=\"w_cs\"), axis=0),\n",
    "        'os1': 0.5 * np.sum(d.get_weight(name=\"w_hos_hs\"), axis=0),\n",
    "        'bias1': d.get_weight(name=\"bias_s\") \n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(15,6))\n",
    "    for i, k in enumerate(data.keys()):\n",
    "        df[k].plot.density(ax=ax[i], title=k)\n",
    "\n",
    "    fig.suptitle(name_map[code_name])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og = plot_inputs_sem('Refrac3_local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For inputs, we multiply the initilized state 0.5, to weights. In real representation, the activation will be much lower, which will leads to a lower input. \n",
    "- For bias, it is taken as is.\n",
    "- Bias mean is slightly positive !?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a6 = plot_inputs_sem('Refrac3_after6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In error injection 7-12, the bias mean is near zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ff = plot_inputs_sem('OS_ff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bias in OS feedforward is almost all negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability of activation per slot in semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_wrangling\n",
    "data = data_wrangling.MyData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized log word frequency is the log10 frequency in each word divided by the max log frequency in all words\n",
    "\n",
    "$\\Huge{swf_i = \\frac{\\log(wf_i + 1)}{\\max(\\log(wf + 1))}}$\n",
    "\n",
    "Weighted activation probability in each node\n",
    "\n",
    "$\\Huge{p_j = \\frac{swf_i * act_{ij}}{n_i}}$\n",
    "\n",
    "where i is word index, j is unit index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency weighting\n",
    "wf = np.log10(data.df_train.wf+1)\n",
    "swf = wf/wf.max()\n",
    "\n",
    "# Tile (copy) to fit all 2446 units\n",
    "wf_tile = np.transpose(np.tile(swf, reps=(2446,1)))\n",
    "\n",
    "unweighted_p = data.np_representations['sem']\n",
    "weigthed_activation = unweighted_p * wf_tile\n",
    "\n",
    "# Probability of activation in each node\n",
    "mean_unweighted_p = np.mean(s, axis=0)\n",
    "mean_weighted_p = np.mean(weigthed_activation, axis=0)\n",
    "\n",
    "def pad_sq(x:np.array)->np.array:\n",
    "    \"\"\"Pad the vector into 2500 units and reshape it into shape: (50, 50)\"\"\"\n",
    "    assert len(x) == 2446\n",
    "    return np.concatenate([x, np.zeros((54,))]).reshape(50,50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unweighted activation probabilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pad_sq(mean_unweighted_p), cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.title('Unweighted probability of activation per each semantic node')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sparse\n",
    "- High p nodes exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 nodes having unweighted p > 0.1\n",
    "mean_unweighted_p[mean_unweighted_p>0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted by word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pad_sq(mean_weighted_p), cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.title('Log frequency weighted probability of activation per semantic node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias in OS feedforword model\n",
    "bias_ff_pad_sq = pad_sq(df_ff.bias1)\n",
    "plt.imshow(bias_ff_pad_sq, cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.title('bias in OP feedforward model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation between bias and node activation probabiliity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_units = pd.DataFrame({\n",
    "    \"bias_original\": df_og.bias1,\n",
    "    \"bias_after6\": df_a6.bias1,\n",
    "    \"bias_ff\": df_ff.bias1,\n",
    "    \"unit_act_p_unweighted\": mean_unweighted_p,\n",
    "    \"unit_act_p_weighted\": mean_weighted_p\n",
    "})\n",
    "\n",
    "df_units.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Correlation magnitude is small... \n",
    "- In Feedforward it is negative !?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
