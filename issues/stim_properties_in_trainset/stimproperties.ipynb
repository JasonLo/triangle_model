{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Align with accuracy instead of epoch\n",
    "- One epoch that closest to 80% accuracy on PHO\n",
    "2. Plot individual “network” difference beta over grid\n",
    "- Taraban : y~lm(freq x cons)\n",
    "- IMG-HS04 : y~lm(fxcximg)\n",
    "- Nonword Glushko overall: just acc\n",
    "3. Big stat model on the entire grid\n",
    "- Y ~ batch_size  or epsilon check same dimensions or not… \n",
    "- y ~ lm/lmer(batch_size  or epsilon * stimprop)  | testset x\n",
    "4. Also summarize DoL within the same grid [raw, same epoch at 1]\n",
    "- P: intact, OP, OSP\n",
    "- S: intact, OS, OPS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meta\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats.mstats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"\"\"Batch object that take cares of the data manipulation in the results of a batch.\"\"\"\n",
    "\n",
    "    def __init__(self, batch_name: str, tf_root: str = None):\n",
    "        self.batch_name = batch_name\n",
    "        self.json = os.path.join(\"models\", batch_name, \"batch_config.json\")\n",
    "        self.tf_root = tf_root if tf_root else \"./\"\n",
    "        self.cfg_df = self.parse_batch_config()\n",
    "        self.code_names = self.cfg_df.code_name.unique().tolist()\n",
    "\n",
    "        # Dataframe to be loaded\n",
    "        self.df = None\n",
    "        self.backup_df = None\n",
    "\n",
    "    def mount_testset(self, csv: list):\n",
    "        self.df = self.parse_df(csv)\n",
    "        self.checkpoint_df()\n",
    "\n",
    "    def checkpoint_df(self):\n",
    "        \"\"\"Make a df checkpoint copy\"\"\"\n",
    "        self.backup_df = self.df.copy()\n",
    "\n",
    "    def restore_df(self):\n",
    "        \"\"\"Restore self.df to the original dataframe.\"\"\"\n",
    "        self.df = self.backup_df\n",
    "\n",
    "    def subset_df(\n",
    "        self,\n",
    "        code_name: str = None,\n",
    "        epoch: int = None,\n",
    "        output_name: str = None,\n",
    "        timetick: list = None,\n",
    "        cond: list = None,\n",
    "        train_task: str = None,\n",
    "    ):\n",
    "        \"\"\"Subset self.df to spec.\"\"\"\n",
    "        df = self.df\n",
    "        df = df.loc[df.code_name == code_name] if code_name is not None else df\n",
    "        df = df.loc[df.epoch == epoch] if epoch is not None else df\n",
    "        df = df.loc[df.output_name == output_name] if output_name is not None else df\n",
    "        df = df.loc[df.timetick.isin(timetick)] if timetick is not None else df\n",
    "        df = df.loc[df.cond.isin(cond)] if cond is not None else df\n",
    "        df = df.loc[df.train_task == train_task] if train_task is not None else df\n",
    "        return df\n",
    "\n",
    "    def subset_by_epoch_dict(self, sel_epoch: dict):\n",
    "        \"\"\"Return a subset of the dataframe using a epoch dictionary.\n",
    "        args:\n",
    "            sel_epoch: dictionary of epochs to select with k=code_name, v=epoch\n",
    "        \"\"\"\n",
    "        dfs = [self.subset_df(code_name=k, epoch=v) for k, v in sel_epoch.items()]\n",
    "        return self.concat_dfs(dfs)\n",
    "\n",
    "    def parse_batch_config(self):\n",
    "        df = meta.batch_json_to_df(self.json, tf_root=self.tf_root)\n",
    "        assert (\n",
    "            self.batch_name == \"task_effect\"\n",
    "        )  # Just in case I forgot to change below line in other batches\n",
    "        df[\"train_task\"] = [\n",
    "            \"OP\",\n",
    "            \"OS\",\n",
    "            \"Triangle\",\n",
    "        ] * 12  # Caution: this is a hack to get around list type config, only works for this batch\n",
    "        return df[[\"code_name\", \"batch_size\", \"learning_rate\", \"train_task\"]]\n",
    "\n",
    "    def parse_df(self, csv: list) -> pd.DataFrame:\n",
    "        files = chain.from_iterable([self.get_eval_file_names(x) for x in csv])\n",
    "        df = self.merge_from_file_names(files)\n",
    "        return df.merge(self.cfg_df, on=\"code_name\", how=\"left\")\n",
    "\n",
    "    def get_eval_file_names(self, csv_name: str) -> list:\n",
    "        \"\"\"Return a list of dataframes from a list of csvs.\"\"\"\n",
    "        return [\n",
    "            os.path.join(\n",
    "                self.tf_root, \"models\", self.batch_name, code_name, \"eval\", csv_name\n",
    "            )\n",
    "            for code_name in self.code_names\n",
    "        ]\n",
    "\n",
    "    def find_code_name(self, criteria: dict) -> str:\n",
    "        \"\"\"Return a code_name from a dictionary of criteria.\"\"\"\n",
    "        mask = None\n",
    "        for k, v in criteria.items():\n",
    "            hit = (self.cfg_df[k].isin(v)).to_list()\n",
    "            mask = hit if mask is None else (a & b for a, b in zip(mask, hit))\n",
    "\n",
    "        return self.cfg_df.code_name.loc[mask].tolist()\n",
    "\n",
    "    def find_epoch(self, code_name: str, outputs: list, fn: callable, sse: float = None, acc: float = None) -> int:\n",
    "        \"\"\"Return an epoch number from an accuracy.\"\"\"\n",
    "        assert (sse is None) ^ (acc is None) # Exclusive or (to make sure only sse or acc is set)\n",
    "        df = self.df.loc[self.df.code_name == code_name]\n",
    "        df = df.loc[df.output_name.isin(outputs)]\n",
    "        df = df.groupby(\"epoch\").mean().reset_index()  # Group by epoch\n",
    "\n",
    "        if acc is not None:\n",
    "            idx = fn(df.acc, acc)  # Find nearest accuracy\n",
    "        if sse is not None:\n",
    "            idx = fn(df.sse, sse)  # Find nearest sse\n",
    "\n",
    "        if idx is None:\n",
    "            return None\n",
    "        else:\n",
    "            return df.iloc[idx,].epoch  # Return epoch\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_from_file_names(filenames: list) -> list:\n",
    "        \"\"\"Merge a list of dataframes into one.\"\"\"\n",
    "        dfs = [pd.read_csv(f) for f in filenames]\n",
    "        return Batch.concat_dfs(dfs)\n",
    "\n",
    "    @staticmethod\n",
    "    def concat_dfs(dfs: list) -> pd.DataFrame:\n",
    "        \"\"\"Return a dataframe from a list of dataframes.\"\"\"\n",
    "        return pd.concat(dfs, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def find_nearest(array, value):\n",
    "        \"\"\"Returning the index of an array that is closest to a given value.\"\"\"\n",
    "        array = np.array(array)\n",
    "        return (np.abs(array - value)).argmin()\n",
    "\n",
    "    @staticmethod\n",
    "    def find_first_less_than(array, value):\n",
    "        \"\"\"Returning the first index of an array that has the value lower than a given value\n",
    "        Return None if no value is found.\n",
    "        \"\"\"\n",
    "        array = np.array(array)\n",
    "        test = array < value\n",
    "        return test.argmax() if sum(test) > 0 else None\n",
    "\n",
    "    @staticmethod\n",
    "    def find_first_more_than(array, value):\n",
    "        \"\"\"Returning the first index of an array that has the value higher than a given value\n",
    "        Return None if no value is found.\n",
    "        \"\"\"\n",
    "        array = np.array(array)\n",
    "        test = array > value\n",
    "        return test.argmax() if sum(test) > 0 else None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_acc_based_df(self, acc: float) -> pd.DataFrame:\n",
    "        \"\"\"Return a dataframe of accuracy for a code_name.\"\"\"\n",
    "\n",
    "        df = self.df.loc[self.df.code_name == code_name].copy()\n",
    "        # Subset to nearest accuracy epoch\n",
    "        sel_epoch = self.find_epoch_by_acc(code_name, 0.8)\n",
    "        df = df.loc[df.epoch == sel_epoch]\n",
    "        return df\n",
    "\n",
    "\n",
    "b = Batch(\"task_effect\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the correlation between PHO and SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.mount_testset(['train_r100_triangle.csv'])\n",
    "b.df = b.subset_df(timetick=range(8, 13), train_task=\"Triangle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = b.df.groupby([\"batch_size\", \"learning_rate\", \"word\", \"epoch\", \"output_name\"]).mean().reset_index()\n",
    "df = df[[\"batch_size\", \"learning_rate\", \"epoch\", \"word\", \"output_name\", \"acc\", \"sse\", \"act1\"]]\n",
    "df = df.pivot_table(index=[\"batch_size\", \"learning_rate\", \"epoch\"], columns=\"output_name\", values=\"acc\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "spearmanr(df['pho'], df['sem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the earliest epoch that reach below 0.4 SEM SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_epoch_sem = {x:b.find_epoch(x, outputs=[\"sem\"], fn=b.find_first_less_than, sse=0.4) for x in tqdm(b.df.code_name.unique())}\n",
    "print(sel_epoch_sem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the earliest epoch that reach below 0.05 PHO SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_epoch_pho = {x:b.find_epoch(x, outputs=[\"pho\"], fn=b.find_first_less_than, sse=0.05) for x in tqdm(b.df.code_name.unique())}\n",
    "print(sel_epoch_pho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the epoch that is nearest to 0.9 SEM ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_epoch_sem09 = {x:b.find_epoch(x, outputs=[\"sem\"], fn=b.find_nearest, acc=0.90) for x in tqdm(b.df.code_name.unique())}\n",
    "print(sel_epoch_sem09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TarabanTest:\n",
    "    \n",
    "    def __init__(self, batch: Batch, sel_epoch: dict):\n",
    "        self.batch = batch\n",
    "        self.sel_epoch = sel_epoch\n",
    "        self.df = None # Cleaned dataframe selected to sel_epoch from tidy()\n",
    "        self.mdf = None # mean within cell of self.df from tidy()\n",
    "        self.taraban_beta = {} # beta values from run_glm()\n",
    "        self.tidy()\n",
    "\n",
    "    def tidy(self):\n",
    "        # Tidy up Taraban testset\n",
    "        self.batch.mount_testset(['taraban_triangle.csv'])\n",
    "        sel_conds = [\n",
    "        \"High-frequency exception\",\n",
    "        \"Regular control for High-frequency exception\",\n",
    "        \"Low-frequency exception\",\n",
    "        \"Regular control for Low-frequency exception\",\n",
    "        ]\n",
    "\n",
    "        self.batch.df = self.batch.subset_df(output_name=\"pho\", timetick=range(8, 13), cond=sel_conds, train_task=\"Triangle\")\n",
    "\n",
    "        self.batch.df[\"freq\"] = self.batch.df.cond.apply(\n",
    "            lambda x: \"High\"\n",
    "            if x\n",
    "            in (\"High-frequency exception\", \"Regular control for High-frequency exception\")\n",
    "            else \"Low\"\n",
    "        )\n",
    "\n",
    "        self.batch.df[\"reg\"] = self.batch.df.cond.apply(\n",
    "            lambda x: \"Regular\" if x.startswith(\"Regular\") else \"Exception\"\n",
    "        )\n",
    "\n",
    "        self.batch.checkpoint_df()\n",
    "\n",
    "        # Create different dfs\n",
    "        self.df = self.batch.subset_by_epoch_dict(self.sel_epoch)\n",
    "        self.df = self.df[['batch_size', 'learning_rate', 'code_name', 'epoch', 'timetick', 'freq', 'reg', 'word', 'acc', 'sse']]\n",
    "        self.mdf = self.df.groupby(['batch_size', 'learning_rate', 'code_name', 'freq', 'reg']).mean().reset_index()\n",
    "\n",
    "    def plot_selection_acc(self):\n",
    "    \n",
    "        acc_txt = alt.Chart(self.mdf).mark_text(dy=6).encode(\n",
    "            x='learning_rate:O',\n",
    "            y=alt.Y('batch_size:O'),\n",
    "            text=alt.Text('mean(acc):Q', format='.2f'),\n",
    "        ).properties(title = f\"Selected epoch and mean accuracy in Taraban testset\", width=200, height=200)\n",
    "\n",
    "        epoch_txt = acc_txt.mark_text(dy=-6).encode(\n",
    "            text=alt.Text('mean(epoch):Q', format='.0f'),\n",
    "        )\n",
    "\n",
    "        heatmap = acc_txt.mark_rect().encode(\n",
    "            color=\"mean(acc):Q\"\n",
    "        )\n",
    "\n",
    "        return heatmap + acc_txt + epoch_txt\n",
    "\n",
    "    def plot_interaction(self, metric: str = 'acc'):\n",
    "        metric_specific_scale = alt.Scale(domain=(0, 1)) if metric == \"acc\" else alt.Scale()\n",
    "        return alt.Chart(self.mdf).mark_line().encode(\n",
    "                x=alt.X(\"freq:N\", scale=alt.Scale(reverse=True)),\n",
    "                y=alt.Y(f\"mean({metric}):Q\", scale=metric_specific_scale),\n",
    "                row=\"batch_size:O\",\n",
    "                column=\"learning_rate:O\",\n",
    "                color=\"reg:N\",\n",
    "            ).properties(width=150, height=150)\n",
    "\n",
    "    def run_grid_glm(self, metric: str = 'acc'):\n",
    "\n",
    "        # Numeric condition for lm\n",
    "\n",
    "        self.mdf['reg_num'] = self.mdf.reg.apply(lambda x: 0.5 if x == 'Regular' else -0.5)\n",
    "        self.mdf['freq_num'] = self.mdf.freq.apply(lambda x: 0.5 if x == 'High' else -0.5)\n",
    "\n",
    "        if metric == 'acc':\n",
    "        m = smf.glm(formula=f'zscore({metric}) ~ zscore(learning_rate) * zscore(batch_size) * reg_num * freq_num', data=self.mdf).fit()\n",
    "        elif metric == 'sse':\n",
    "            m = smf.glm(formula='zscore(sse) ~ zscore(learning_rate) * zscore(batch_size) * reg_num * freq_num', data=self.mdf).fit()\n",
    "        \n",
    "        print(f\"===== Grid level GLM on average {metric} =====\")\n",
    "        print(m.summary())\n",
    "\n",
    "\n",
    "    def run_cell_glm(self, metric: str = 'acc'):\n",
    "\n",
    "        assert metric in ['acc', 'sse']\n",
    "        get_beta = self.get_taraban_params_acc if metric == 'acc' else self.get_taraban_params_sse\n",
    "        \n",
    "        self.df['reg_num'] = self.df.reg.apply(lambda x: 0.5 if x == 'Regular' else -0.5)\n",
    "        self.df['freq_num'] = self.df.freq.apply(lambda x: 0.5 if x == 'High' else -0.5)\n",
    "        # Run cell level GLMs\n",
    "\n",
    "        params = [get_beta(self.df, code_name=x) for x in tqdm(self.df.code_name.unique())]\n",
    "        self.taraban_beta[metric] = pd.concat(params, ignore_index=True)\n",
    "        setting_map = self.mdf[['code_name', 'batch_size', 'learning_rate']].groupby(['code_name']).mean().reset_index()\n",
    "        self.taraban_beta[metric] = self.taraban_beta[metric].merge(setting_map, on='code_name')\n",
    "\n",
    "        # Restructure\n",
    "        self.taraban_beta[metric].columns = ['intercept', 'freq_effect', 'reg_effect', 'interactions', 'code_name', 'batch_size', 'epsilon']\n",
    "        self.taraban_beta[metric] = self.taraban_beta[metric].melt(id_vars=['code_name', 'batch_size', 'epsilon'], value_vars=['intercept', 'freq_effect', 'reg_effect', 'interactions'])\n",
    "\n",
    "    def plot_glm_betas(self, metric: str = 'acc', color_range: float = 25):\n",
    "        \"\"\"Plot the betas on grid.\"\"\"\n",
    "\n",
    "        if self.taraban_beta is {}:\n",
    "            raise Exception(\"Run run_glm() first.\")\n",
    "\n",
    "        # Plot betas\n",
    "        return alt.Chart(self.taraban_beta[metric]).mark_rect().encode(\n",
    "            x='epsilon:O',\n",
    "            y='batch_size:O',\n",
    "            color=alt.Color('value:Q', scale=alt.Scale(domain=(-color_range, color_range), scheme='redblue')),\n",
    "            column='variable:N',\n",
    "        ).properties(width=200, height=200)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_taraban_params_acc(df, code_name):\n",
    "        try:\n",
    "            m = smf.glm(formula=\"acc ~ freq_num * reg_num\", data=df.loc[df.code_name == code_name], family=sm.families.Binomial()).fit()\n",
    "            p = m.params\n",
    "            p['code_name'] = code_name\n",
    "            return pd.DataFrame(p).T\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {code_name}\")\n",
    "            pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_taraban_params_sse(df, code_name):\n",
    "        try:\n",
    "            m = smf.glm(formula=\"sse ~ freq_num * reg_num\", data=df.loc[df.code_name == code_name]).fit()\n",
    "            p = m.params\n",
    "            p['code_name'] = code_name\n",
    "            return pd.DataFrame(p).T\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {code_name}\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TarabanTest(b, sel_epoch_sem09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.plot_selection_acc().save('sel_sem09_taraban_acc.html')\n",
    "t.plot_interaction(metric='acc').save('sel_sem09_taraban_acc_interaction.html')\n",
    "t.plot_interaction(metric='sse').save('sel_sem09_taraban_sse_interaction.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.run_grid_glm('acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.run_grid_glm('sse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.run_cell_glm('acc')\n",
    "t.run_cell_glm('sse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.plot_glm_betas('acc',color_range=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.plot_glm_betas('sse', color_range=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find epoch that are closest to 80% accuracy in each network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define by Taraban\n",
    "- at 8-12 ticks\n",
    "- Train task: Triangle\n",
    "- Output at PHO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlushkoTest:\n",
    "    \n",
    "    def __init__(self, batch: Batch, sel_epoch: dict):\n",
    "        self.batch = batch\n",
    "        self.sel_epoch = sel_epoch\n",
    "        self.df = None # Cleaned dataframe selected to sel_epoch from tidy()\n",
    "        self.mdf = None # mean within cell of self.df from tidy()\n",
    "        self.tidy()\n",
    "\n",
    "    def tidy(self):\n",
    "        # Tidy up \n",
    "        self.batch.mount_testset(['glushko_triangle.csv'])\n",
    "        self.batch.df = self.batch.subset_df(output_name=\"pho\", timetick=range(8, 13), train_task=\"Triangle\")\n",
    "        self.batch.checkpoint_df()\n",
    "\n",
    "        # Create different dfs\n",
    "        self.df = self.batch.subset_by_epoch_dict(self.sel_epoch)\n",
    "        self.df['cond_num'] = self.df.cond.apply(lambda x: 0.5 if x == 'Regular' else -0.5)\n",
    "        self.mdf = self.df.groupby(['batch_size', 'learning_rate', 'code_name', 'cond']).mean().reset_index()\n",
    "\n",
    "    def plot_selection_acc(self):\n",
    "    \n",
    "        acc_txt = alt.Chart(self.mdf).mark_text(dy=6).encode(\n",
    "            x='learning_rate:O',\n",
    "            y='batch_size:O',\n",
    "            text=alt.Text('mean(acc):Q', format='.2f'),\n",
    "        ).properties(title = f\"Selected epoch and mean accuracy in Taraban testset\", width=200, height=200)\n",
    "\n",
    "        epoch_txt = acc_txt.mark_text(dy=-6).encode(\n",
    "            text=alt.Text('mean(epoch):Q', format='.0f'),\n",
    "        )\n",
    "\n",
    "        heatmap = acc_txt.mark_rect().encode(\n",
    "            color=\"mean(acc):Q\"\n",
    "        )\n",
    "\n",
    "        return heatmap + acc_txt + epoch_txt\n",
    "\n",
    "    def plot_cond_heatmap(self, metric: str = 'acc'):\n",
    "        metric_specific_scale = alt.Scale(domain=(0, 1)) if metric == \"acc\" else alt.Scale()\n",
    "        return alt.Chart(self.mdf).mark_rect().encode(\n",
    "                x='learning_rate:O',\n",
    "                y='batch_size:O',\n",
    "                color=alt.Color(f'{metric}:Q', scale=metric_specific_scale),\n",
    "                column='cond:N',\n",
    "            ).properties(title=metric.upper(), width=200, height=200)\n",
    "\n",
    "    def run_grid_glm(self, metric: str = 'acc'):\n",
    "\n",
    "        m = smf.glm(formula=f'zscore({metric}) ~ zscore(learning_rate) * zscore(batch_size) * cond_num', data=self.mdf).fit()\n",
    "        print(f\"===== Grid level GLM on average {metric.upper()} =====\")\n",
    "        print(m.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GlushkoTest(b, sel_epoch_sem09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.plot_selection_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.plot_cond_heatmap(metric='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.run_grid_glm(metric='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.plot_cond_heatmap(metric='sse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.run_grid_glm('sse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Img-HS04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgTest:\n",
    "    def __init__(self, batch: Batch, sel_epoch: dict):\n",
    "        self.batch = batch\n",
    "        self.sel_epoch = sel_epoch\n",
    "        self.df = None  # Cleaned dataframe selected to sel_epoch from tidy()\n",
    "        self.mdf = None  # mean within cell of self.df from tidy()\n",
    "        self.beta = {}  # beta values from run_glm()\n",
    "        self.tidy()\n",
    "\n",
    "    def tidy(self):\n",
    "        # Tidy up\n",
    "        self.batch.mount_testset([\"hs04_img_240_triangle.csv\"])\n",
    "        self.batch.df = self.batch.subset_df(\n",
    "            output_name=\"pho\", timetick=range(8, 13), train_task=\"Triangle\"\n",
    "        )\n",
    "        self.batch.checkpoint_df()\n",
    "\n",
    "        # Create different dfs\n",
    "        self.df = self.batch.subset_by_epoch_dict(self.sel_epoch)\n",
    "        self.df[[\"freq\", \"op\", \"img\"]] = self.df.cond.str.split(\"_\", expand=True)\n",
    "        self.df[\"fc\"] = self.df.cond.apply(lambda x: x[:5])\n",
    "        self.df[\"freq_num\"] = self.df.freq.apply(lambda x: 0.5 if x == \"hf\" else -0.5)\n",
    "        self.df[\"op_num\"] = self.df.op.apply(lambda x: 0.5 if x == \"ls\" else -0.5)\n",
    "        self.df[\"img_num\"] = self.df.img.apply(lambda x: 0.5 if x == \"hi\" else -0.5)\n",
    "\n",
    "        self.mdf = (\n",
    "            self.df.groupby(\n",
    "                [\n",
    "                    \"batch_size\",\n",
    "                    \"learning_rate\",\n",
    "                    \"code_name\",\n",
    "                    \"cond\",\n",
    "                    \"fc\",\n",
    "                    \"freq\",\n",
    "                    \"op\",\n",
    "                    \"img\",\n",
    "                ]\n",
    "            )\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "    def plot_selection_acc(self):\n",
    "\n",
    "        acc_txt = (\n",
    "            alt.Chart(self.mdf)\n",
    "            .mark_text(dy=6)\n",
    "            .encode(\n",
    "                x=\"learning_rate:O\",\n",
    "                y=\"batch_size:O\",\n",
    "                text=alt.Text(\"mean(acc):Q\", format=\".2f\"),\n",
    "            )\n",
    "            .properties(\n",
    "                title=f\"Selected epoch and mean accuracy\", width=200, height=200\n",
    "            )\n",
    "        )\n",
    "\n",
    "        epoch_txt = acc_txt.mark_text(dy=-6).encode(\n",
    "            text=alt.Text(\"mean(epoch):Q\", format=\".0f\"),\n",
    "        )\n",
    "\n",
    "        heatmap = acc_txt.mark_rect().encode(color=\"mean(acc):Q\")\n",
    "\n",
    "        return heatmap + acc_txt + epoch_txt\n",
    "\n",
    "    def plot_bar_img(self, metric: str = \"acc\"):\n",
    "        metric_specific_scale = (\n",
    "            alt.Scale(domain=(0, 1)) if metric == \"acc\" else alt.Scale()\n",
    "        )\n",
    "        return (\n",
    "            alt.Chart(self.mdf)\n",
    "            .mark_bar()\n",
    "            .encode(\n",
    "                x=\"cond:N\",\n",
    "                y=alt.Y(f\"mean({metric}):Q\", scale=metric_specific_scale),\n",
    "                color=\"img:N\",\n",
    "                row=\"batch_size:O\",\n",
    "                column=\"learning_rate:O\",\n",
    "            )\n",
    "            .properties(title=metric.upper(), width=200, height=200)\n",
    "        )\n",
    "\n",
    "    def run_grid_glm(self, metric: str = \"acc\"):\n",
    "        m = smf.glm(\n",
    "            formula=f\"zscore({metric}) ~ zscore(learning_rate) * zscore(batch_size) * freq_num * op_num * img_num\",\n",
    "            data=self.mdf,\n",
    "        ).fit()\n",
    "        print(f\"===== Grid level GLM on average {metric.upper()} =====\")\n",
    "        print(m.summary())\n",
    "\n",
    "    def run_cell_glm(self, metric: str = \"acc\"):\n",
    "\n",
    "        assert metric in [\"acc\", \"sse\"]\n",
    "        get_beta = (\n",
    "            self.get_img_params_acc if metric == \"acc\" else self.get_img_params_sse\n",
    "        )\n",
    "\n",
    "        params = [\n",
    "            get_beta(self.df, code_name=x) for x in tqdm(self.df.code_name.unique())\n",
    "        ]\n",
    "        self.beta[metric] = pd.concat(params, ignore_index=True)\n",
    "        setting_map = (\n",
    "            self.mdf[[\"code_name\", \"batch_size\", \"learning_rate\"]]\n",
    "            .groupby([\"code_name\"])\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "        self.beta[metric] = self.beta[metric].merge(setting_map, on=\"code_name\")\n",
    "\n",
    "        # Restructure\n",
    "        self.beta[metric].columns = [\n",
    "            \"intercept\",\n",
    "            \"freq_effect\",\n",
    "            \"reg_effect\",\n",
    "            \"fxr\",\n",
    "            \"img_effect\",\n",
    "            \"fxi\",\n",
    "            \"rxi\",\n",
    "            \"fxrxi\",\n",
    "            \"code_name\",\n",
    "            \"batch_size\",\n",
    "            \"epsilon\",\n",
    "        ]\n",
    "\n",
    "        self.beta[metric] = self.beta[metric].melt(\n",
    "            id_vars=[\"code_name\", \"batch_size\", \"epsilon\"],\n",
    "            value_vars=[\n",
    "                \"intercept\",\n",
    "                \"freq_effect\",\n",
    "                \"reg_effect\",\n",
    "                \"fxr\",\n",
    "                \"img_effect\",\n",
    "                \"fxi\",\n",
    "                \"rxi\",\n",
    "                \"fxrxi\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def plot_glm_betas(self, metric: str = \"acc\", color_range: float = 25):\n",
    "        \"\"\"Plot the betas on grid.\"\"\"\n",
    "\n",
    "        if self.beta is {}:\n",
    "            raise Exception(\"Run run_glm() first.\")\n",
    "\n",
    "        # Plot betas\n",
    "        return (\n",
    "            alt.Chart(self.beta[metric])\n",
    "            .mark_rect()\n",
    "            .encode(\n",
    "                x=\"epsilon:O\",\n",
    "                y=\"batch_size:O\",\n",
    "                color=alt.Color(\n",
    "                    \"value:Q\",\n",
    "                    scale=alt.Scale(\n",
    "                        domain=(-color_range, color_range), scheme=\"redblue\"\n",
    "                    ),\n",
    "                ),\n",
    "                column=\"variable:N\",\n",
    "            )\n",
    "            .properties(width=200, height=200)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def get_img_params_acc(df, code_name):\n",
    "        try:\n",
    "            m = smf.glm(\n",
    "                formula=\"acc ~ freq_num * op_num * img_num\",\n",
    "                data=df.loc[df.code_name == code_name],\n",
    "                family=sm.families.Binomial(),\n",
    "            ).fit()\n",
    "            p = m.params\n",
    "            p[\"code_name\"] = code_name\n",
    "            return pd.DataFrame(p).T\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {code_name}\")\n",
    "            pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_img_params_sse(df, code_name):\n",
    "        try:\n",
    "            m = smf.glm(\n",
    "                formula=\"sse ~ freq_num * op_num * img_num\",\n",
    "                data=df.loc[df.code_name == code_name],\n",
    "            ).fit()\n",
    "            p = m.params\n",
    "            p[\"code_name\"] = code_name\n",
    "            return pd.DataFrame(p).T\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {code_name}\")\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = ImgTest(b, sel_epoch_sem09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.plot_bar_img(metric='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.run_grid_glm(metric='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.plot_bar_img(metric='sse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.run_grid_glm(metric='sse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.run_cell_glm(metric='acc')\n",
    "i.run_cell_glm(metric='sse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.plot_glm_betas(metric='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.plot_glm_betas(metric='sse',color_range=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.plot_selection_acc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PHO output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.mount_testset(['train_r100_ort_pho.csv', 'train_r100_exp_osp.csv', 'train_r100_triangle.csv'])\n",
    "b.df = b.subset_df(timetick=[12], output_name='pho', train_task=\"Triangle\")\n",
    "df = b.subset_by_epoch_dict(sel_epoch_sem09)\n",
    "dol_pho_mdf = df.groupby(['batch_size', 'learning_rate', 'code_name', 'task']).mean().reset_index()\n",
    "\n",
    "alt.Chart(dol_pho_mdf).mark_rect().encode(\n",
    "    x='learning_rate:O',\n",
    "    y='batch_size:O',\n",
    "    color=alt.Color('acc:Q', scale=alt.Scale(domain=(0, 1))),\n",
    "    column='task:N',\n",
    ").properties(width=200, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.mount_testset(['cos_train_r100_ort_sem.csv', 'cos_train_r100_exp_ops.csv', 'cos_train_r100_triangle.csv'])\n",
    "b.df = b.subset_df(timetick=[12], output_name='sem', train_task=\"Triangle\")\n",
    "df = b.subset_by_epoch_dict(sel_epoch_sem09)\n",
    "dol_sem_mdf = df.groupby(['batch_size', 'learning_rate', 'code_name', 'task']).mean().reset_index()\n",
    "\n",
    "alt.Chart(dol_sem_mdf).mark_rect().encode(\n",
    "    x='learning_rate:O',\n",
    "    y='batch_size:O',\n",
    "    color=alt.Color('acc:Q', scale=alt.Scale(domain=(0, 1))),\n",
    "    column='task:N',\n",
    ").properties(width=200, height=200)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
