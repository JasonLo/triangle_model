{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CUE: Normed Word Cue\n",
    "- TARGET: Response to Normed Word\n",
    "- #G: The number of participants serving in the group norming the word, \n",
    "- #P: The number of participants producing a particular response.\n",
    "- FSG: Forward Cue-to-Target Strength  \n",
    "    - dividing #P by #G which gives the proportion of subjects in the group who produce a particular target in the presence of the cue word.\n",
    "- BSG: Backward Target-to-Cue Strength\n",
    "- OSG: Overlapping strength. \n",
    "    - Two words comprising a particular pair may also have associates in common, what have sometimes been called overlapping, convergent or shared associates. The cue word and the target word may produce some of the same words as associates. For example, both ABILITY and CAPABILITY produce the same 6 words as associates, including able, strength, talent, potential, capacity, and knowledge. The overlap strength for this pair is calculated as shown in Table 2. From this example, it should be clear that OSG is calculated like MSG in that the strengths of the individual connections are cross multiplied and then summed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### University of South Florida Free Association Norms\n",
    "- see more at http://w3.usf.edu/FreeAssociation/\n",
    "\n",
    "### SimLex-999\n",
    "- see more at https://fh295.github.io//simlex.html\n",
    "- paper: Faruqui, M., Tsvetkov, Y., Rastogi, P., & Dyer, C. (2016). Problems With Evaluation of Word Embeddings Using Word Similarity Tasks. 30â€“35. https://doi.org/10.18653/v1/w16-2506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all existing overlapped words in BERT and LSA-TASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import sample\n",
    "# Select overlapping set in TASA and BERT\n",
    "bert = pd.read_csv('input/df_train_bert.csv')\n",
    "tasa = pd.read_csv('input/df_train_tasa.csv')\n",
    "\n",
    "bert_vec = np.load('input/y_train_bert.npz')['data']\n",
    "tasa_vec = np.load('input/y_train_tasa.npz')['data']\n",
    "\n",
    "selwords = list(tasa.word[tasa.word.isin(bert.word)].str.lower())\n",
    "print('Some samples: {}'.format(sample(selwords, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and clean Free Association Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fan = pd.read_csv('benchmark/free_asso/fan_manual.csv')\n",
    "sel_df = fan.loc[:, ['CUE', ' TARGET', ' OSG']]\n",
    "sel_df.dropna(inplace=True)\n",
    "sel_df.columns = ['cue', 'target', 'sim']\n",
    "sel_df['cue'] = sel_df.cue.str.strip().str.lower()\n",
    "sel_df['target'] = sel_df.target.str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and clean SimLex-999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl999 = pd.read_csv('benchmark/simlex_999/SimLex-999.txt', delimiter='\\t')\n",
    "sl999 = sl999.loc[:, ['word1', 'word2', 'SimLex999']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test case by overlapping items with two embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_df['cue_chk'] = sel_df.cue.isin(selwords)\n",
    "sel_df['tar_chk'] = sel_df.target.isin(selwords)\n",
    "sel_df['double_chk'] = sel_df.cue_chk & sel_df.tar_chk\n",
    "testcase_sem = sel_df.loc[sel_df.double_chk,\n",
    "                          ['cue', 'target', 'osg']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import cosine_similarity as cosdis\n",
    "\n",
    "\n",
    "def w2vec(word, words_df, words_vec):\n",
    "    if len(words_df) != len(words_vec):\n",
    "        print('CAUTION: WORDS DF AND WORDS VECTOR DONT MATCH IN LENGTH!!')\n",
    "    if word in list(words_df):\n",
    "        vec_id = words_df.index[words_df == word]\n",
    "        return words_vec[vec_id]\n",
    "    else:\n",
    "        print('not on list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vec('lamp', bert.word, bert_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run throught test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_similarity(w1, w2, emb):\n",
    "    if emb == 'bert':\n",
    "        words = bert.word\n",
    "        vecs = bert_vec\n",
    "    elif emb == 'tasa':\n",
    "        words = tasa.word\n",
    "        vecs = tasa_vec\n",
    "    else:\n",
    "        print('Use option emb = \"tasa\" or \"bert\"')\n",
    "\n",
    "    return -cosdis(w2vec(w1, words, vecs), w2vec(w2, words, vecs)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "bert_similarity = []\n",
    "tasa_similarity = []\n",
    "\n",
    "for i in tqdm(range(len(testcase_sem))):\n",
    "\n",
    "    bert_similarity.append(\n",
    "        cal_similarity(\n",
    "            testcase_sem.cue.str.lower()[i],\n",
    "            testcase_sem.target.str.lower()[i], 'bert'\n",
    "        )[0]\n",
    "    )\n",
    "\n",
    "    tasa_similarity.append(\n",
    "        cal_similarity(\n",
    "            testcase_sem.cue.str.lower()[i],\n",
    "            testcase_sem.target.str.lower()[i], 'tasa'\n",
    "        )[0]\n",
    "    )\n",
    "    \n",
    "testcase_sem['tasa_similarity'] = tasa_similarity\n",
    "testcase_sem['bert_similarity'] = bert_similarity\n",
    "\n",
    "testcase_sem.to_csv('testcase_sim.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate correlations / cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "print(pearsonr(testcase_sem.tasa_similarity, testcase_sem.bert_similarity)[0])\n",
    "print(pearsonr(testcase_sem.osg, testcase_sem.bert_similarity)[0])\n",
    "print(pearsonr(testcase_sem.osg, testcase_sem.tasa_similarity)[0])\n",
    "\n",
    "print(spearmanr(testcase_sem.tasa_similarity, testcase_sem.bert_similarity)[0])\n",
    "print(spearmanr(testcase_sem.osg, testcase_sem.bert_similarity)[0])\n",
    "print(spearmanr(testcase_sem.osg, testcase_sem.tasa_similarity)[0])\n",
    "\n",
    "print(1 - cosine(testcase_sem.tasa_similarity, testcase_sem.bert_similarity))\n",
    "print(1 - cosine(testcase_sem.osg, testcase_sem.bert_similarity))\n",
    "print(1 - cosine(testcase_sem.osg, testcase_sem.tasa_similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make plotting data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = testcase_sem.melt(\n",
    "    id_vars=['cue', 'target', 'rosg'],\n",
    "    value_vars=['tasa_similarity', 'bert_similarity'],\n",
    "    var_name='embedding',\n",
    "    value_name='similarity'\n",
    ")\n",
    "\n",
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcase_sem.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from random import sample\n",
    "alt.data_transformers.enable(\"default\")\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "samp_df = testcase_sem.sample(n=300, axis=0, random_state=9999)\n",
    "\n",
    "brush = alt.selection(type='interval')\n",
    "base = alt.Chart(samp_df).add_selection(brush)\n",
    "\n",
    "# Configure the points\n",
    "points_tasa = base.mark_point().encode(\n",
    "    x=alt.X('rosg:Q', title='', scale=alt.Scale(domain=(0, 1))),\n",
    "    y=alt.Y('tasa_similarity:Q', title='', scale=alt.Scale(domain=(-1, 1))),\n",
    "    color=alt.condition(brush, alt.value('blue'), alt.value('grey')),\n",
    "    tooltip=[\n",
    "        'cue:N', 'target:N', 'rosg:Q', 'tasa_similarity:Q', 'bert_similarity:Q'\n",
    "    ]\n",
    ")\n",
    "\n",
    "points_bert = base.mark_point().encode(\n",
    "    x=alt.X('rosg:Q', title='', scale=alt.Scale(domain=(0, 1))),\n",
    "    y=alt.Y('bert_similarity:Q', title='', scale=alt.Scale(domain=(-1, 1))),\n",
    "    color=alt.condition(brush, alt.value('orange'), alt.value('grey')),\n",
    "    tooltip=[\n",
    "        'cue:N', 'target:N', 'rosg:Q', 'tasa_similarity:Q', 'bert_similarity:Q'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Configure the ticks\n",
    "tick_axis = alt.Axis(labels=False, domain=False, ticks=False)\n",
    "\n",
    "x_ticks = base.mark_tick().encode(\n",
    "    x=alt.X('rosg', axis=tick_axis, scale=alt.Scale(domain=(0, 1))),\n",
    "    color=alt.condition(brush, alt.value('black'), alt.value('lightgrey'))\n",
    ")\n",
    "\n",
    "y_ticks_tasa = base.mark_tick().encode(\n",
    "    y=alt.Y(\n",
    "        'tasa_similarity:Q', axis=tick_axis, scale=alt.Scale(domain=(-1, 1))\n",
    "    ),\n",
    "    color=alt.condition(brush, alt.value('black'), alt.value('lightgrey'))\n",
    ")\n",
    "\n",
    "y_ticks_bert = base.mark_tick().encode(\n",
    "    y=alt.Y(\n",
    "        'bert_similarity:Q', axis=tick_axis, scale=alt.Scale(domain=(-1, 1))\n",
    "    ),\n",
    "    color=alt.condition(brush, alt.value('black'), alt.value('lightgrey'))\n",
    ")\n",
    "\n",
    "left = y_ticks_tasa | (points_tasa & x_ticks)\n",
    "\n",
    "right = y_ticks_bert | (points_bert & x_ticks)\n",
    "\n",
    "left | right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = left | right\n",
    "chart.save('semantic_testcase.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
