{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal install script for new VM\n",
    "!sudo pip install altair\n",
    "!sudo pip install pandas-gbq -U\n",
    "!sudo pip install nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta support functions\n",
    "This files contains scripts that support the whole \"Data --> Model --> Result --> Visualization\" pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting meta.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile meta.py\n",
    "from collections import OrderedDict\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def check_gpu():\n",
    "    if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "        print(\"GPU is available \\n\")\n",
    "    else:\n",
    "        print(\"GPU is NOT AVAILABLE \\n\")\n",
    "\n",
    "\n",
    "def gpu_mem_cap(b=2048):\n",
    "    # Set GPU memory cap per python kernal for parallel run\n",
    "    # Smaller models usually do not need 100% GPU throughput\n",
    "    # By limiting the memory cap per python kernal, we can run multiple models in parallel to maximize efficiency\n",
    "    # OSP model can archieve 2-3x saving\n",
    "\n",
    "    import tensorflow as tf\n",
    "    gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        try:\n",
    "            tf.config.experimental.set_virtual_device_configuration(\n",
    "                gpus[0],\n",
    "                [\n",
    "                    tf.config.experimental.VirtualDeviceConfiguration(\n",
    "                        memory_limit=b\n",
    "                    )\n",
    "                ],\n",
    "            )\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "            print(\n",
    "                len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\"\n",
    "            )\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            # Virtual devices must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "\n",
    "\n",
    "class model_cfg():\n",
    "    # This function keep all global model setting\n",
    "    # It will be use in almost every object downsteam, from modelling, evaluation, and visualization\n",
    "    # Just keep model_cfg() light... and don't attach any heavy object here for efficiency\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        code_name=None,\n",
    "        x_name='x_train',\n",
    "        y_name='y_train',\n",
    "        sample_name='hs04',\n",
    "        sample_rng_seed=329,\n",
    "        tf_rng_seed=123,\n",
    "        use_semantic=False,\n",
    "        sem_param_gf=4,\n",
    "        sem_param_gi=1,\n",
    "        sem_param_kf=100,\n",
    "        sem_param_ki=100,\n",
    "        sem_param_hf=5,\n",
    "        sem_param_hi=5,\n",
    "        o_input_dim=119,\n",
    "        hidden_units=150,\n",
    "        pho_units=250,\n",
    "        cleanup_units=50,\n",
    "        embed_attractor_cfg=None,\n",
    "        embed_attractor_h5=None,\n",
    "        w_oh_noise=0.,\n",
    "        w_hp_noise=0.,\n",
    "        w_pp_noise=0.,\n",
    "        w_pc_noise=0.,\n",
    "        w_cp_noise=0.,\n",
    "        tau=0.2,\n",
    "        max_unit_time=4.,\n",
    "        n_mil_sample=1.,\n",
    "        batch_size=128,\n",
    "        rnn_activation='sigmoid',\n",
    "        regularizer_const=0.,\n",
    "        w_initializer='glorot_uniform',\n",
    "        learning_rate=0.01,\n",
    "        save_freq=5,\n",
    "        bq_dataset='batch_test'\n",
    "    ):\n",
    "\n",
    "        # Unique run id for easier tracking\n",
    "        import uuid\n",
    "        self.uuid = uuid.uuid4().hex\n",
    "\n",
    "        self.code_name = code_name\n",
    "        self.x_name = x_name\n",
    "        self.y_name = y_name\n",
    "\n",
    "        # Sampling\n",
    "        self.sample_name = sample_name\n",
    "        self.sample_rng_seed = sample_rng_seed\n",
    "        self.tf_rng_seed = tf_rng_seed\n",
    "\n",
    "        # Semantic input parameters\n",
    "        self.use_semantic = use_semantic\n",
    "        self.sem_param_gf = sem_param_gf\n",
    "        self.sem_param_gi = sem_param_gi\n",
    "\n",
    "        self.sem_param_kf = sem_param_kf\n",
    "        self.sem_param_ki = sem_param_ki\n",
    "\n",
    "        self.sem_param_hf = sem_param_hf\n",
    "        self.sem_param_hi = sem_param_hi\n",
    "\n",
    "        # Architechture\n",
    "        self.o_input_dim = o_input_dim\n",
    "        self.hidden_units = hidden_units\n",
    "        self.pho_units = pho_units\n",
    "        self.cleanup_units = cleanup_units\n",
    "\n",
    "        self.embed_attractor_cfg = embed_attractor_cfg\n",
    "        self.embed_attractor_h5 = embed_attractor_h5\n",
    "\n",
    "        self.w_oh_noise = w_oh_noise\n",
    "        self.w_hp_noise = w_hp_noise\n",
    "        self.w_pp_noise = w_pp_noise\n",
    "        self.w_pc_noise = w_pc_noise\n",
    "        self.w_cp_noise = w_cp_noise\n",
    "\n",
    "        ## This is for switching between testing and training mode\n",
    "        self.w_oh_noise_backup = self.w_oh_noise\n",
    "        self.w_hp_noise_backup = self.w_hp_noise\n",
    "        self.w_pp_noise_backup = self.w_pp_noise\n",
    "        self.w_pc_noise_backup = self.w_pc_noise\n",
    "        self.w_cp_noise_backup = self.w_cp_noise\n",
    "\n",
    "        self.tau = tau\n",
    "        self.max_unit_time = max_unit_time\n",
    "        self.n_timesteps = int(self.max_unit_time * (1 / self.tau))\n",
    "\n",
    "        # Training\n",
    "        self.n_mil_sample = n_mil_sample\n",
    "        self.nEpo = int(n_mil_sample * 1e2)\n",
    "        self.batch_size = batch_size\n",
    "        self.steps_per_epoch = int(10000 / batch_size)\n",
    "        self.rnn_activation = rnn_activation\n",
    "        self.regularizer_const = regularizer_const\n",
    "        self.w_initializer = w_initializer\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Saving\n",
    "        self.save_freq = save_freq\n",
    "        self.save_freq_sample = self.save_freq * self.batch_size * self.steps_per_epoch  # For TF 2.1\n",
    "        self.eval_freq = self.save_freq\n",
    "        self.bq_dataset = bq_dataset\n",
    "\n",
    "        if self.code_name is not None:\n",
    "            self.gen_paths()\n",
    "            self.gen_cfg_dict()\n",
    "            self.write_cfg()\n",
    "\n",
    "    def gen_cfg_dict(self):\n",
    "\n",
    "        self.cfg_dict = OrderedDict()\n",
    "        self.cfg_dict['uuid'] = self.uuid\n",
    "        self.cfg_dict['code_name'] = self.code_name\n",
    "        self.cfg_dict['x_name'] = self.x_name\n",
    "        self.cfg_dict['y_name'] = self.y_name\n",
    "        self.cfg_dict['sample_name'] = self.sample_name\n",
    "        self.cfg_dict['sample_rng_seed'] = self.sample_rng_seed\n",
    "        self.cfg_dict['tf_rng_seed'] = self.tf_rng_seed\n",
    "        self.cfg_dict['use_semantic'] = self.use_semantic\n",
    "        self.cfg_dict['sem_param_gf'] = self.sem_param_gf\n",
    "        self.cfg_dict['sem_param_gi'] = self.sem_param_gi\n",
    "        self.cfg_dict['sem_param_kf'] = self.sem_param_kf\n",
    "        self.cfg_dict['sem_param_ki'] = self.sem_param_ki\n",
    "        self.cfg_dict['sem_param_hf'] = self.sem_param_hf\n",
    "        self.cfg_dict['sem_param_hi'] = self.sem_param_hi\n",
    "        self.cfg_dict['o_input_dim'] = self.o_input_dim\n",
    "        self.cfg_dict['hidden_units'] = self.hidden_units\n",
    "        self.cfg_dict['pho_units'] = self.pho_units\n",
    "        self.cfg_dict['cleanup_units'] = self.cleanup_units\n",
    "        self.cfg_dict['embed_attractor_cfg'] = self.embed_attractor_cfg\n",
    "        self.cfg_dict['embed_attractor_h5'] = self.embed_attractor_h5\n",
    "        self.cfg_dict['w_oh_noise'] = self.w_oh_noise\n",
    "        self.cfg_dict['w_hp_noise'] = self.w_hp_noise\n",
    "        self.cfg_dict['w_pp_noise'] = self.w_pp_noise\n",
    "        self.cfg_dict['w_pc_noise'] = self.w_pc_noise\n",
    "        self.cfg_dict['w_cp_noise'] = self.w_cp_noise\n",
    "        self.cfg_dict['tau'] = self.tau\n",
    "        self.cfg_dict['max_unit_time'] = self.max_unit_time\n",
    "        self.cfg_dict['n_timesteps'] = self.n_timesteps\n",
    "        self.cfg_dict['n_mil_sample'] = self.n_mil_sample\n",
    "        self.cfg_dict['nEpo'] = self.nEpo\n",
    "        self.cfg_dict['batch_size'] = self.batch_size\n",
    "        self.cfg_dict['steps_per_epoch'] = self.steps_per_epoch\n",
    "        self.cfg_dict['rnn_activation'] = self.rnn_activation\n",
    "        self.cfg_dict['w_initializer'] = self.w_initializer\n",
    "        self.cfg_dict['regularizer_const'] = self.regularizer_const\n",
    "        self.cfg_dict['learning_rate'] = self.learning_rate\n",
    "        self.cfg_dict['save_freq'] = self.save_freq\n",
    "        self.cfg_dict['save_freq_sample'] = self.save_freq_sample\n",
    "        self.cfg_dict['eval_freq'] = self.eval_freq\n",
    "        self.cfg_dict['bq_dataset'] = self.bq_dataset\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.cfg_dict)\n",
    "\n",
    "    def noise_off(self):\n",
    "        self.w_oh_noise = 0.\n",
    "        self.w_hp_noise = 0.\n",
    "        self.w_pp_noise = 0.\n",
    "        self.w_pc_noise = 0.\n",
    "        self.w_cp_noise = 0.\n",
    "\n",
    "    def noise_on(self):\n",
    "        # This is the default mode\n",
    "        self.w_oh_noise = self.w_oh_noise_backup\n",
    "        self.w_hp_noise = self.w_hp_noise_backup\n",
    "        self.w_pp_noise = self.w_pp_noise_backup\n",
    "        self.w_pc_noise = self.w_pc_noise_backup\n",
    "        self.w_cp_noise = self.w_cp_noise_backup\n",
    "\n",
    "    def load_cfg_json(self, file):\n",
    "        import json\n",
    "        with open(file) as json_file:\n",
    "            self.cfg_dict = json.load(json_file)\n",
    "\n",
    "            try:\n",
    "                self.uuid = self.cfg_dict['uuid']\n",
    "                self.code_name = self.cfg_dict['code_name']\n",
    "                self.x_name = self.cfg_dict['x_name']\n",
    "                self.y_name = self.cfg_dict['y_name']\n",
    "                self.sample_name = self.cfg_dict['sample_name']\n",
    "                self.sample_rng_seed = self.cfg_dict['sample_rng_seed']\n",
    "                self.tf_rng_seed = self.cfg_dict['tf_rng_seed']\n",
    "                self.use_semantic = self.cfg_dict['use_semantic']\n",
    "                self.sem_param_gf = self.cfg_dict['sem_param_gf']\n",
    "                self.sem_param_gi = self.cfg_dict['sem_param_gi']\n",
    "                self.sem_param_kf = self.cfg_dict['sem_param_kf']\n",
    "                self.sem_param_ki = self.cfg_dict['sem_param_ki']\n",
    "                self.sem_param_hf = self.cfg_dict['sem_param_hf']\n",
    "                self.sem_param_hi = self.cfg_dict['sem_param_hi']\n",
    "                self.o_input_dim = self.cfg_dict['o_input_dim']\n",
    "                self.hidden_units = self.cfg_dict['hidden_units']\n",
    "                self.pho_units = self.cfg_dict['pho_units']\n",
    "                self.cleanup_units = self.cfg_dict['cleanup_units']\n",
    "                self.embed_attractor_cfg = self.cfg_dict['embed_attractor_cfg']\n",
    "                self.embed_attractor_h5 = self.cfg_dict['embed_attractor_h5']\n",
    "                self.w_oh_noise = self.cfg_dict['w_oh_noise']\n",
    "                self.w_hp_noise = self.cfg_dict['w_hp_noise']\n",
    "                self.w_pp_noise = self.cfg_dict['w_pp_noise']\n",
    "                self.w_pc_noise = self.cfg_dict['w_pc_noise']\n",
    "                self.w_cp_noise = self.cfg_dict['w_cp_noise']\n",
    "                self.tau = self.cfg_dict['tau']\n",
    "                self.max_unit_time = self.cfg_dict['max_unit_time']\n",
    "                self.n_timesteps = self.cfg_dict['n_timesteps']\n",
    "                self.n_mil_sample = self.cfg_dict['n_mil_sample']\n",
    "                self.nEpo = self.cfg_dict['nEpo']\n",
    "                self.batch_size = self.cfg_dict['batch_size']\n",
    "                self.steps_per_epoch = self.cfg_dict['steps_per_epoch']\n",
    "                self.rnn_activation = self.cfg_dict['rnn_activation']\n",
    "                self.w_initializer = self.cfg_dict['w_initializer']\n",
    "                self.regularizer_const = self.cfg_dict['regularizer_const']\n",
    "                self.learning_rate = self.cfg_dict['learning_rate']\n",
    "                self.save_freq = self.cfg_dict['save_freq']\n",
    "                self.save_freq_sample = self.cfg_dict['save_freq_sample']\n",
    "                self.eval_freq = self.cfg_dict['eval_freq']\n",
    "                self.bq_dataset = self.cfg_dict['bq_dataset']\n",
    "\n",
    "            except:\n",
    "                print('Caution: some parameter do not exist in json')\n",
    "\n",
    "            self.gen_paths()\n",
    "            self.gen_cfg_dict()\n",
    "\n",
    "    def write_cfg(self):\n",
    "        import json\n",
    "        json = json.dumps(self.cfg_dict)\n",
    "        f = open(self.path_model_folder + 'model_config.json', \"w\")\n",
    "        f.write(json)\n",
    "        f.close()\n",
    "\n",
    "    def gen_paths(self):\n",
    "        import os\n",
    "\n",
    "        self.path_model_folder = 'models/' + self.code_name + '/'\n",
    "        self.path_weight_folder = self.path_model_folder + 'weights/'\n",
    "        self.path_plot_folder = self.path_model_folder + 'plots/'\n",
    "\n",
    "        self.path_weights_checkpoint = self.path_weight_folder + 'ep{epoch:04d}.h5'\n",
    "        self.path_history_pickle = self.path_model_folder + 'history.pickle'\n",
    "\n",
    "        if not os.path.exists(self.path_model_folder):\n",
    "            os.mkdir(self.path_model_folder)\n",
    "        if not os.path.exists(self.path_weight_folder):\n",
    "            os.mkdir(self.path_weight_folder)\n",
    "        if not os.path.exists(self.path_plot_folder):\n",
    "            os.mkdir(self.path_plot_folder)\n",
    "\n",
    "        self.path_weights_list = []\n",
    "        self.saved_epoch_list = []\n",
    "\n",
    "        for epoch in range(self.save_freq, self.nEpo + 1, self.save_freq):\n",
    "            self.path_weights_list += [\n",
    "                self.path_weight_folder + 'ep' + str(epoch).zfill(4) + '.h5'\n",
    "            ]\n",
    "\n",
    "            self.saved_epoch_list.append(epoch)\n",
    "\n",
    "        self.strain_item_csv = self.path_model_folder + 'result_strain_item.csv'\n",
    "        self.strain_epoch_csv = self.path_model_folder + 'result_strain_epoch.csv'\n",
    "        self.grain_item_csv = self.path_model_folder + 'result_grain_item.csv'\n",
    "        self.grain_epoch_csv = self.path_model_folder + 'result_grain_epoch.csv'\n",
    "\n",
    "\n",
    "def bq_conn(pid='idyllic-web-267716'):\n",
    "    from google.oauth2 import service_account\n",
    "    project_id = pid\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        '../common/bq_credential.json'\n",
    "    )\n",
    "\n",
    "\n",
    "def write_all_to_bq(cfg, strain_i_hist, grain_i_hist):\n",
    "    import pandas_gbq\n",
    "\n",
    "    bq_conn()\n",
    "\n",
    "    print('Writing data to Bigquery')\n",
    "\n",
    "    # Config file\n",
    "    pandas_gbq.to_gbq(\n",
    "        pd.DataFrame([cfg.cfg_dict]),\n",
    "        destination_table=cfg.bq_dataset + '.cfg',\n",
    "        project_id='idyllic-web-267716',\n",
    "        if_exists='append'\n",
    "    )\n",
    "\n",
    "    # Strain eval\n",
    "    pandas_gbq.to_gbq(\n",
    "        strain_i_hist,\n",
    "        destination_table=cfg.bq_dataset + '.strain',\n",
    "        project_id='idyllic-web-267716',\n",
    "        if_exists='append'\n",
    "    )\n",
    "\n",
    "    # Grain eval\n",
    "    pandas_gbq.to_gbq(\n",
    "        grain_i_hist,\n",
    "        destination_table=cfg.bq_dataset + '.grain',\n",
    "        project_id='idyllic-web-267716',\n",
    "        if_exists='append'\n",
    "    )\n",
    "\n",
    "    print('Completed')\n",
    "\n",
    "\n",
    "def read_bq_cfg(db_name):\n",
    "    import pandas_gbq\n",
    "\n",
    "    bq_conn()\n",
    "\n",
    "    sql = \"\"\"\n",
    "    SELECT * FROM `idyllic-web-267716.{}.cfg`\n",
    "    \"\"\".format(db_name)\n",
    "\n",
    "    return pandas_gbq.read_gbq(sql, project_id='idyllic-web-267716')\n",
    "\n",
    "\n",
    "def send_mail(batch_name):\n",
    "    import smtplib\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.ehlo()\n",
    "    server.starttls()\n",
    "    server.ehlo()\n",
    "    server.login('gcpdazzo@gmail.com', 'l3gnonveppl#')\n",
    "\n",
    "    subject = 'Batch training {batch_name} completed'\n",
    "    body = 'Job done'\n",
    "    msg = 'Subject: {}\\n\\n{}'.format(subject, body)\n",
    "\n",
    "    server.sendmail('gcpdazzo@gmail.com', 'lcmjlo@gmail.com', msg)\n",
    "    print('Email sent')\n",
    "    server.quit()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyORwTHf+x7Ea1qIUr2QtASl",
   "collapsed_sections": [],
   "name": "misc.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
