{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbgouQwZ1Y1f"
   },
   "source": [
    "# O2S model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters block for Papermill\n",
    "- Instead of using model_cfg directly, this extra step is needed for batch run using Papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "code_name = 'O2S_v0000'\n",
    "\n",
    "embedding = 'tasa'\n",
    "sample_name = 'hal'  #hal log frequency with clipping like HS04 (did not use it for control...)\n",
    "sample_rng_seed = 1234\n",
    "tf_rng_seed = 4321\n",
    "\n",
    "# Model architechture\n",
    "o_input_dim = 119\n",
    "hidden_units = 100\n",
    "cleanup_units = 50\n",
    "rnn_activation = 'sigmoid'\n",
    "regularizer_const = 0.\n",
    "\n",
    "p_noise = 0.  # i.e. w_pp, w_pc, and w_cp noise\n",
    "tau = 1.\n",
    "max_unit_time = 2.\n",
    "\n",
    "# Training\n",
    "n_mil_sample = 1.\n",
    "batch_size = 128\n",
    "learning_rate = 0.0001\n",
    "save_freq = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_name = 'x_train_{}.npz'.format(embedding)\n",
    "y_name = 'y_train_{}.npz'.format(embedding)\n",
    "csv_name = 'df_train_{}.csv'.format(embedding)\n",
    "\n",
    "if embedding == 'tasa':\n",
    "    sem_units = 300\n",
    "if embedding == 'bert':\n",
    "    sem_units = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packing parameters into model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Orthographic representation==========\n",
      "x_train shape: (4396, 119)\n",
      "y_train shape: (4396, 300)\n"
     ]
    }
   ],
   "source": [
    "from meta import model_cfg\n",
    "\n",
    "cfg = model_cfg(\n",
    "    code_name=code_name,\n",
    "    x_name=x_name,\n",
    "    y_name=y_name,\n",
    "    csv_name=csv_name,\n",
    "    sample_name=sample_name,\n",
    "    sample_rng_seed=sample_rng_seed,\n",
    "    tf_rng_seed=tf_rng_seed,\n",
    "    use_semantic=False,\n",
    "    sem_param_gf=0,\n",
    "    sem_param_gi=0,\n",
    "    sem_param_kf=0,\n",
    "    sem_param_ki=0,\n",
    "    sem_param_hf=0,\n",
    "    sem_param_hi=0,\n",
    "    o_input_dim=o_input_dim,\n",
    "    hidden_units=hidden_units,\n",
    "    pho_units=sem_units,  # Output become semantic embedding vector\n",
    "    cleanup_units=cleanup_units,\n",
    "    embed_attractor_cfg=None,\n",
    "    embed_attractor_h5=None,\n",
    "    w_oh_noise=0.,\n",
    "    w_hp_noise=0.,\n",
    "    w_pp_noise=p_noise,\n",
    "    w_pc_noise=p_noise,\n",
    "    w_cp_noise=p_noise,\n",
    "    tau=tau,\n",
    "    max_unit_time=max_unit_time,\n",
    "    n_mil_sample=n_mil_sample,\n",
    "    batch_size=batch_size,\n",
    "    rnn_activation=rnn_activation,\n",
    "    regularizer_const=regularizer_const,\n",
    "    learning_rate=learning_rate,\n",
    "    save_freq=save_freq,\n",
    "    bq_dataset=None\n",
    ")\n",
    "\n",
    "# TF random seed (Sampling is out of TF scope... change sample_rng_seed instead)\n",
    "tf.random.set_seed(cfg.tf_rng_seed)\n",
    "\n",
    "# Preload data\n",
    "from data_wrangling import sample_generator, my_data\n",
    "data = my_data(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0IwxbE29_0yx"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HFTsfceXUGIh",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Orthography (InputLayer)     [(None, 119)]             0         \n",
      "_________________________________________________________________\n",
      "Hidden (Dense)               (None, 100)               12000     \n",
      "_________________________________________________________________\n",
      "Semantics (Dense)            (None, 300)               30300     \n",
      "=================================================================\n",
      "Total params: 42,300\n",
      "Trainable params: 42,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(training=True):\n",
    "    # Organization principal:\n",
    "    # Structure things, such as repeat vector should build within the model\n",
    "    # Static calculation of input --> Easier to modify --> build within sample generator\n",
    "\n",
    "    from tensorflow.keras import Model\n",
    "    from tensorflow.keras.layers import Layer, Input, concatenate, multiply, RepeatVector, Dense\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from modeling import rnn\n",
    "    #     from modeling_without_cleanup import rnn_no_cleanup_no_pp\n",
    "\n",
    "    # Train/test mode checking\n",
    "    cfg.noise_on() if training is True else cfg.noise_off()\n",
    "\n",
    "    input_o = Input(shape=(cfg.o_input_dim, ), name=\"Orthography\")\n",
    "    hidden = Dense(cfg.hidden_units, name=\"Hidden\")(input_o)\n",
    "    output = Dense(sem_units, name=\"Semantics\")(hidden)\n",
    "    model = Model(input_o, output)\n",
    "\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=Adam(\n",
    "            learning_rate=cfg.learning_rate,\n",
    "            beta_1=0.9,\n",
    "            beta_2=0.999,\n",
    "            amsgrad=False\n",
    "        ),\n",
    "        metrics=['accuracy', 'mse']\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKUOoZkP8QiA"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, pickle, os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from data_wrangling import sample_generator\n",
    "from IPython.display import clear_output\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    cfg.path_weights_checkpoint,\n",
    "    verbose=1,\n",
    "    save_freq=cfg.save_freq_sample,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    sample_generator(cfg, data),\n",
    "    steps_per_epoch=cfg.steps_per_epoch,\n",
    "    epochs=cfg.nEpo,\n",
    "    verbose=2,\n",
    "    callbacks=[checkpoint],\n",
    ")\n",
    "\n",
    "# Saving history and model\n",
    "pickle_out = open(cfg.path_history_pickle, \"wb\")\n",
    "pickle.dump(history.history, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "clear_output()\n",
    "print('Training done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMmNcbJdcPMh"
   },
   "source": [
    "\n",
    "# Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BqpDOQStugK"
   },
   "source": [
    "### Training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-5a3c1847c2444e6d89c077531456a58f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-5a3c1847c2444e6d89c077531456a58f\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"datasets\": {\"data-cd76a6ecaeb593b0cb026ff22c626fa8\": [{\"variable\": \"mse\", \"epoch\": 0, \"value\": 0.02970418520271778}, {\"variable\": \"mse\", \"epoch\": 1, \"value\": 0.016720665618777275}, {\"variable\": \"mse\", \"epoch\": 2, \"value\": 0.01174937654286623}, {\"variable\": \"mse\", \"epoch\": 3, \"value\": 0.008809996768832207}, {\"variable\": \"mse\", \"epoch\": 4, \"value\": 0.006781904958188534}, {\"variable\": \"mse\", \"epoch\": 5, \"value\": 0.005330120678991079}, {\"variable\": \"mse\", \"epoch\": 6, \"value\": 0.004272008780390024}, {\"variable\": \"mse\", \"epoch\": 7, \"value\": 0.003448807168751955}, {\"variable\": \"mse\", \"epoch\": 8, \"value\": 0.0028194834012538195}, {\"variable\": \"mse\", \"epoch\": 9, \"value\": 0.0023420690558850765}, {\"variable\": \"mse\", \"epoch\": 10, \"value\": 0.0019537382759153843}, {\"variable\": \"mse\", \"epoch\": 11, \"value\": 0.0016329067293554544}, {\"variable\": \"mse\", \"epoch\": 12, \"value\": 0.0014013431500643492}, {\"variable\": \"mse\", \"epoch\": 13, \"value\": 0.0011992944637313485}, {\"variable\": \"mse\", \"epoch\": 14, \"value\": 0.00101645034737885}, {\"variable\": \"mse\", \"epoch\": 15, \"value\": 0.0008867456344887614}, {\"variable\": \"mse\", \"epoch\": 16, \"value\": 0.0007745522889308631}, {\"variable\": \"mse\", \"epoch\": 17, \"value\": 0.0006735225324518979}, {\"variable\": \"mse\", \"epoch\": 18, \"value\": 0.000607559341005981}, {\"variable\": \"mse\", \"epoch\": 19, \"value\": 0.0005254096467979252}, {\"variable\": \"mse\", \"epoch\": 20, \"value\": 0.0004688325570896268}, {\"variable\": \"mse\", \"epoch\": 21, \"value\": 0.00043128756806254387}, {\"variable\": \"mse\", \"epoch\": 22, \"value\": 0.0003807237953878939}, {\"variable\": \"mse\", \"epoch\": 23, \"value\": 0.000352243660017848}, {\"variable\": \"mse\", \"epoch\": 24, \"value\": 0.0003233574971091002}, {\"variable\": \"mse\", \"epoch\": 25, \"value\": 0.0002912948839366436}, {\"variable\": \"mse\", \"epoch\": 26, \"value\": 0.00027128474903292954}, {\"variable\": \"mse\", \"epoch\": 27, \"value\": 0.00025182811077684164}, {\"variable\": \"mse\", \"epoch\": 28, \"value\": 0.00023014827456790954}, {\"variable\": \"mse\", \"epoch\": 29, \"value\": 0.00022152536257635802}, {\"variable\": \"mse\", \"epoch\": 30, \"value\": 0.00020525373111013323}, {\"variable\": \"mse\", \"epoch\": 31, \"value\": 0.0001967311545740813}, {\"variable\": \"mse\", \"epoch\": 32, \"value\": 0.0001867793034762144}, {\"variable\": \"mse\", \"epoch\": 33, \"value\": 0.0001780608290573582}, {\"variable\": \"mse\", \"epoch\": 34, \"value\": 0.00017018127255141735}, {\"variable\": \"mse\", \"epoch\": 35, \"value\": 0.00016321620205417275}, {\"variable\": \"mse\", \"epoch\": 36, \"value\": 0.00015574491408187896}, {\"variable\": \"mse\", \"epoch\": 37, \"value\": 0.00015175303269643337}, {\"variable\": \"mse\", \"epoch\": 38, \"value\": 0.0001536971249151975}, {\"variable\": \"mse\", \"epoch\": 39, \"value\": 0.00014745026419404894}, {\"variable\": \"mse\", \"epoch\": 40, \"value\": 0.00014219310833141208}, {\"variable\": \"mse\", \"epoch\": 41, \"value\": 0.0001364450145047158}, {\"variable\": \"mse\", \"epoch\": 42, \"value\": 0.00013795471750199795}, {\"variable\": \"mse\", \"epoch\": 43, \"value\": 0.00012789698666892946}, {\"variable\": \"mse\", \"epoch\": 44, \"value\": 0.00012584359501488507}, {\"variable\": \"mse\", \"epoch\": 45, \"value\": 0.00013495651364792138}, {\"variable\": \"mse\", \"epoch\": 46, \"value\": 0.0001249327906407416}, {\"variable\": \"mse\", \"epoch\": 47, \"value\": 0.0001293650857405737}, {\"variable\": \"mse\", \"epoch\": 48, \"value\": 0.00012362917186692357}, {\"variable\": \"mse\", \"epoch\": 49, \"value\": 0.0001257127005374059}, {\"variable\": \"mse\", \"epoch\": 50, \"value\": 0.00012470321962609887}, {\"variable\": \"mse\", \"epoch\": 51, \"value\": 0.000114573682367336}, {\"variable\": \"mse\", \"epoch\": 52, \"value\": 0.00011984055890934542}, {\"variable\": \"mse\", \"epoch\": 53, \"value\": 0.00011812469165306538}, {\"variable\": \"mse\", \"epoch\": 54, \"value\": 0.0001201638369821012}, {\"variable\": \"mse\", \"epoch\": 55, \"value\": 0.000113326808786951}, {\"variable\": \"mse\", \"epoch\": 56, \"value\": 0.00011525936861289665}, {\"variable\": \"mse\", \"epoch\": 57, \"value\": 0.00012071306264260784}, {\"variable\": \"mse\", \"epoch\": 58, \"value\": 0.00011224261106690392}, {\"variable\": \"mse\", \"epoch\": 59, \"value\": 0.00011830330186057836}, {\"variable\": \"mse\", \"epoch\": 60, \"value\": 0.00011927252489840612}, {\"variable\": \"mse\", \"epoch\": 61, \"value\": 0.00011500775872264057}, {\"variable\": \"mse\", \"epoch\": 62, \"value\": 0.00011317332973703742}, {\"variable\": \"mse\", \"epoch\": 63, \"value\": 0.00011508777242852375}, {\"variable\": \"mse\", \"epoch\": 64, \"value\": 0.00010814265988301486}, {\"variable\": \"mse\", \"epoch\": 65, \"value\": 0.00011743084905901924}, {\"variable\": \"mse\", \"epoch\": 66, \"value\": 0.00011386178812244907}, {\"variable\": \"mse\", \"epoch\": 67, \"value\": 0.00011860206723213196}, {\"variable\": \"mse\", \"epoch\": 68, \"value\": 0.00011836906924145296}, {\"variable\": \"mse\", \"epoch\": 69, \"value\": 0.00011547149915713817}, {\"variable\": \"mse\", \"epoch\": 70, \"value\": 0.00011127656034659594}, {\"variable\": \"mse\", \"epoch\": 71, \"value\": 0.00011361096403561532}, {\"variable\": \"mse\", \"epoch\": 72, \"value\": 0.000109644046460744}, {\"variable\": \"mse\", \"epoch\": 73, \"value\": 0.00011022714897990227}, {\"variable\": \"mse\", \"epoch\": 74, \"value\": 0.0001083366951206699}, {\"variable\": \"mse\", \"epoch\": 75, \"value\": 0.00011266665387665853}, {\"variable\": \"mse\", \"epoch\": 76, \"value\": 0.00011029485904145986}, {\"variable\": \"mse\", \"epoch\": 77, \"value\": 0.00011405636178096756}, {\"variable\": \"mse\", \"epoch\": 78, \"value\": 0.00011197927960893139}, {\"variable\": \"mse\", \"epoch\": 79, \"value\": 0.00010780619049910456}, {\"variable\": \"mse\", \"epoch\": 80, \"value\": 0.00010868459503399208}, {\"variable\": \"mse\", \"epoch\": 81, \"value\": 0.00011356948380125687}, {\"variable\": \"mse\", \"epoch\": 82, \"value\": 0.00011039760283892974}, {\"variable\": \"mse\", \"epoch\": 83, \"value\": 0.00011235388228669763}, {\"variable\": \"mse\", \"epoch\": 84, \"value\": 0.00010832986299647018}, {\"variable\": \"mse\", \"epoch\": 85, \"value\": 0.00011086983431596309}, {\"variable\": \"mse\", \"epoch\": 86, \"value\": 0.00010783823381643742}, {\"variable\": \"mse\", \"epoch\": 87, \"value\": 0.00011055566574214026}, {\"variable\": \"mse\", \"epoch\": 88, \"value\": 0.00010909046977758408}, {\"variable\": \"mse\", \"epoch\": 89, \"value\": 0.00010844083590200171}, {\"variable\": \"mse\", \"epoch\": 90, \"value\": 0.00010897832544287667}, {\"variable\": \"mse\", \"epoch\": 91, \"value\": 0.00010972285963362083}, {\"variable\": \"mse\", \"epoch\": 92, \"value\": 0.00010578190995147452}, {\"variable\": \"mse\", \"epoch\": 93, \"value\": 0.00010806779755512252}, {\"variable\": \"mse\", \"epoch\": 94, \"value\": 0.0001136869759648107}, {\"variable\": \"mse\", \"epoch\": 95, \"value\": 0.00011095107038272545}, {\"variable\": \"mse\", \"epoch\": 96, \"value\": 0.00011182300659129396}, {\"variable\": \"mse\", \"epoch\": 97, \"value\": 0.00011130640632472932}, {\"variable\": \"mse\", \"epoch\": 98, \"value\": 0.00010902705980697647}, {\"variable\": \"mse\", \"epoch\": 99, \"value\": 0.00010423817002447322}]}, \"selection\": {\"selector005\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"], \"bind\": \"scales\"}}, \"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"encoding\": {\"y\": {\"type\": \"quantitative\", \"field\": \"value\"}, \"color\": {\"type\": \"nominal\", \"legend\": null, \"field\": \"variable\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"epoch\"}, {\"type\": \"nominal\", \"field\": \"variable\"}], \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"title\": \"MSE\", \"data\": {\"name\": \"data-cd76a6ecaeb593b0cb026ff22c626fa8\"}, \"mark\": \"line\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import training_history\n",
    "\n",
    "hist = training_history(cfg.path_history_pickle)\n",
    "hist.plot_mse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse item level stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Orthography (InputLayer)     [(None, 119)]             0         \n",
      "_________________________________________________________________\n",
      "Hidden (Dense)               (None, 100)               12000     \n",
      "_________________________________________________________________\n",
      "Semantics (Dense)            (None, 300)               30300     \n",
      "=================================================================\n",
      "Total params: 42,300\n",
      "Trainable params: 42,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Must turn training mode off before evaluation\n",
    "model = build_model(training=False)\n",
    "\n",
    "y_pred = model.predict(data.x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19130826,  0.14361797, -0.0518714 , ..., -0.10423132,\n",
       "         0.22558671, -0.1633707 ],\n",
       "       [ 0.00066379,  0.02678338,  0.02864611, ..., -0.19239369,\n",
       "         0.20771423,  0.06096496],\n",
       "       [ 0.02039404, -0.03012507,  0.19949976, ..., -0.09693385,\n",
       "         0.03851636,  0.04558969],\n",
       "       ...,\n",
       "       [ 0.23184729, -0.08342867, -0.12137806, ..., -0.41747522,\n",
       "        -0.12579043,  0.38710123],\n",
       "       [ 0.06144564, -0.15860046, -0.04251904, ..., -0.02996553,\n",
       "         0.1484257 ,  0.23482406],\n",
       "       [ 0.05765904, -0.2551763 , -0.03772504, ...,  0.09433322,\n",
       "         0.1695753 ,  0.28444177]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "df = pd.DataFrame()\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic lesion in Strain\n",
    "strain_ns = strain_eval(cfg, data, model)\n",
    "strain_ns.start_evaluate(\n",
    "    test_use_semantic=False,\n",
    "    output=cfg.path_model_folder + 'result_strain_ns_item.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grain\n",
    "model = build_model(training=False)\n",
    "from evaluate import strain_eval, grain_eval\n",
    "grain = grain_eval(cfg, data, model)\n",
    "grain.start_evaluate(\n",
    "    test_use_semantic=False,\n",
    "    output=cfg.path_model_folder + 'result_grain_item.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KnxCNzMyWah"
   },
   "source": [
    "### Strain plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import vis\n",
    "\n",
    "vis_ns = vis(\n",
    "    cfg.path_model_folder, 'result_strain_ns_item.csv', 'result_grain_item.csv'\n",
    ")\n",
    "\n",
    "vis = vis(\n",
    "    cfg.path_model_folder, 'result_strain_item.csv', 'result_grain_item.csv'\n",
    ")\n",
    "\n",
    "vis_ns.parse_cond_df()\n",
    "vis.parse_cond_df()\n",
    "\n",
    "full = vis.plot_dev('acc').properties(title='Full input')\n",
    "lesion = vis_ns.plot_dev('acc').properties(title='Semantic lesion')\n",
    "\n",
    "strain_plot = full | lesion\n",
    "strain_plot.save(cfg.path_plot_folder + 'strain.html')\n",
    "strain_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesion development deep dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_inter = vis_ns.plot_dev_interactive('acc')\n",
    "dev_inter.save(cfg.path_plot_folder + 'interactive_strain_dev.html')\n",
    "dev_inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesion time plot deep dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_inter = vis_ns.plot_time_interactive('acc')\n",
    "time_inter.save(cfg.path_plot_folder + 'interactive_strain_time.html')\n",
    "time_inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grain plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = vis.plot_dev('acc_small_grain', exp='grain')\n",
    "large = vis.plot_dev('acc_large_grain', exp='grain')\n",
    "grain_plot = small | large\n",
    "grain_plot.save(cfg.path_plot_folder + 'grain.html')\n",
    "grain_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imageability effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis.parse_cond_df(cond_strain='cond_img')\n",
    "# vis.plot_dev('acc', exp='strain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis.parse_cond_df(cond_strain='cond_wf')\n",
    "# vis.plot_dev('acc', exp='strain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phonological regularity effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis.parse_cond_df(cond_strain='cond_pho')\n",
    "# vis.plot_dev('acc', exp='strain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import plot_variables\n",
    "plot_variables(model, cfg.path_plot_folder + 'variables.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write notebook to html (Must save notebook first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only work for manual run\n",
    "# !jupyter nbconvert --to html --ExecutePreprocessor.store_widget_state=True --output-dir=$cfg.path_model_folder basicOSP_master.ipynba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push results to GCP-BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if cfg.bq_dataset is not None:\n",
    "#     from meta import write_all_to_bq\n",
    "\n",
    "#     for attempt in range(10):\n",
    "#         try:\n",
    "#             write_all_to_bq(cfg, strain.i_hist, grain.i_hist)\n",
    "#             print('Results pushed to BQ')\n",
    "#         except:\n",
    "#             from time import sleep\n",
    "#             sleep(10)\n",
    "#         else:\n",
    "#             break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "basicO2P_master.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
