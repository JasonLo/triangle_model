{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbgouQwZ1Y1f"
   },
   "source": [
    "# O2S model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters block for Papermill\n",
    "- Instead of using model_cfg directly, this extra step is needed for batch run using Papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "code_name = 'O2S_v0001'\n",
    "\n",
    "x_name = 'x_train_4721'\n",
    "y_name = 'tasa_4721'\n",
    "\n",
    "sample_name = 'hal'  #hal log frequency with clipping like HS04\n",
    "sample_rng_seed = 1234\n",
    "tf_rng_seed = 4321\n",
    "\n",
    "# Model architechture\n",
    "o_input_dim = 119\n",
    "hidden_units = 100\n",
    "\n",
    "sem_units = 300 if y_name == 'tasa_4721' else 768\n",
    "cleanup_units = 10\n",
    "rnn_activation = 'sigmoid'\n",
    "regularizer_const = 0.\n",
    "\n",
    "embed_attractor_cfg = None\n",
    "embed_attractor_h5 = None\n",
    "\n",
    "p_noise = 0.  # i.e. w_pp, w_pc, and w_cp noise\n",
    "tau = 1.\n",
    "max_unit_time = 2.\n",
    "\n",
    "# Training\n",
    "n_mil_sample = 1.\n",
    "batch_size = 128\n",
    "learning_rate = 0.0001\n",
    "save_freq = 5\n",
    "\n",
    "# Results push to BQ database\n",
    "bq_dataset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packing parameters into model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Orthographic representation==========\n",
      "x_train shape: (4721, 119)\n",
      "x_strain shape: (160, 119)\n",
      "\n",
      "==========Phonological representation==========\n",
      "38  phonemes:  dict_keys(['p', 'f', 'm', 'C', 'E', '@', 'e', 'b', 'A', '_', 'S', 'Z', 'z', 's', 'v', 'O', 'n', 'U', 'r', 'y', 'T', 'o', 'u', 'k', '^', 'Y', 'a', 'h', 'w', 'i', 'W', 'l', 'D', 't', 'g', 'd', 'I', 'J'])\n",
      "y_train shape: (4721, 300)\n",
      "y_strain shape: (160, 300)\n"
     ]
    }
   ],
   "source": [
    "from meta import model_cfg\n",
    "\n",
    "cfg = model_cfg(\n",
    "    code_name=code_name,\n",
    "    x_name=x_name,\n",
    "    y_name=y_name,\n",
    "    sample_name=sample_name,\n",
    "    sample_rng_seed=sample_rng_seed,\n",
    "    tf_rng_seed=tf_rng_seed,\n",
    "    use_semantic=False,\n",
    "    sem_param_gf=0,\n",
    "    sem_param_gi=0,\n",
    "    sem_param_kf=0,\n",
    "    sem_param_ki=0,\n",
    "    sem_param_hf=0,\n",
    "    sem_param_hi=0,\n",
    "    o_input_dim=o_input_dim,\n",
    "    hidden_units=hidden_units,\n",
    "    pho_units=sem_units,  # Output become semantic embedding vector\n",
    "    cleanup_units=cleanup_units,\n",
    "    embed_attractor_cfg=embed_attractor_cfg,\n",
    "    embed_attractor_h5=embed_attractor_h5,\n",
    "    w_oh_noise=0.,\n",
    "    w_hp_noise=0.,\n",
    "    w_pp_noise=p_noise,\n",
    "    w_pc_noise=p_noise,\n",
    "    w_cp_noise=p_noise,\n",
    "    tau=tau,\n",
    "    max_unit_time=max_unit_time,\n",
    "    n_mil_sample=n_mil_sample,\n",
    "    batch_size=batch_size,\n",
    "    rnn_activation=rnn_activation,\n",
    "    regularizer_const=regularizer_const,\n",
    "    learning_rate=learning_rate,\n",
    "    save_freq=save_freq,\n",
    "    bq_dataset=None\n",
    ")\n",
    "\n",
    "# TF random seed (Sampling is out of TF scope... change sample_rng_seed instead)\n",
    "tf.random.set_seed(cfg.tf_rng_seed)\n",
    "\n",
    "# Preload data\n",
    "from data_wrangling import sample_generator, my_data\n",
    "data = my_data(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0IwxbE29_0yx"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HFTsfceXUGIh",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_O (InputLayer)         [(None, 119)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               12000     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               30300     \n",
      "=================================================================\n",
      "Total params: 42,300\n",
      "Trainable params: 42,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(training=True):\n",
    "    # Organization principal:\n",
    "    # Structure things, such as repeat vector should build within the model\n",
    "    # Static calculation of input --> Easier to modify --> build within sample generator\n",
    "\n",
    "    from tensorflow.keras import Model\n",
    "    from tensorflow.keras.layers import Layer, Input, concatenate, multiply, RepeatVector, Dense\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from modeling import rnn\n",
    "    #     from modeling_without_cleanup import rnn_no_cleanup_no_pp\n",
    "\n",
    "    # Train/test mode checking\n",
    "    cfg.noise_on() if training is True else cfg.noise_off()\n",
    "\n",
    "    input_o = Input(shape=(cfg.o_input_dim, ), name=\"Input_O\")\n",
    "    hidden = Dense(cfg.hidden_units)(input_o)\n",
    "    output = Dense(sem_units)(hidden)\n",
    "    model = Model(input_o, output)\n",
    "\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=Adam(\n",
    "            learning_rate=cfg.learning_rate,\n",
    "            beta_1=0.9,\n",
    "            beta_2=0.999,\n",
    "            amsgrad=False\n",
    "        ),\n",
    "        metrics=['accuracy', 'mse']\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arming attractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config indicates no attractor, I have do nothing.\n"
     ]
    }
   ],
   "source": [
    "if cfg.embed_attractor_cfg is not None:\n",
    "    print('Found attractor info in config (cfg), arming attractor...')\n",
    "    from modeling import attractor, arm_attractor\n",
    "    from evaluate import plot_variables\n",
    "\n",
    "    attractor_cfg = model_cfg(None)\n",
    "    attractor_cfg.load_cfg_json(cfg.embed_attractor_cfg)\n",
    "    attractor_obj = attractor(attractor_cfg, cfg.embed_attractor_h5)\n",
    "\n",
    "    model = arm_attractor(model, attractor_obj)\n",
    "    plot_variables(model)\n",
    "else:\n",
    "    print('Config indicates no attractor, I have do nothing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKUOoZkP8QiA"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ort</th>\n",
       "      <th>pho</th>\n",
       "      <th>wf</th>\n",
       "      <th>frequency</th>\n",
       "      <th>pho_consistency</th>\n",
       "      <th>imageability</th>\n",
       "      <th>img</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ball</td>\n",
       "      <td>__ba_ll___</td>\n",
       "      <td>__bal_____</td>\n",
       "      <td>1393</td>\n",
       "      <td>HF</td>\n",
       "      <td>INC</td>\n",
       "      <td>HI</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bank</td>\n",
       "      <td>__ba_nk___</td>\n",
       "      <td>__b@nk____</td>\n",
       "      <td>53170</td>\n",
       "      <td>HF</td>\n",
       "      <td>CON</td>\n",
       "      <td>HI</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beach</td>\n",
       "      <td>__beach___</td>\n",
       "      <td>__biC_____</td>\n",
       "      <td>1691</td>\n",
       "      <td>HF</td>\n",
       "      <td>CON</td>\n",
       "      <td>HI</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beak</td>\n",
       "      <td>__beak____</td>\n",
       "      <td>__bik_____</td>\n",
       "      <td>10</td>\n",
       "      <td>LF</td>\n",
       "      <td>INC</td>\n",
       "      <td>HI</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beard</td>\n",
       "      <td>__beard___</td>\n",
       "      <td>__bird____</td>\n",
       "      <td>210</td>\n",
       "      <td>LF</td>\n",
       "      <td>INC</td>\n",
       "      <td>HI</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>wool</td>\n",
       "      <td>__wool____</td>\n",
       "      <td>__wUl_____</td>\n",
       "      <td>153</td>\n",
       "      <td>LF</td>\n",
       "      <td>INC</td>\n",
       "      <td>HI</td>\n",
       "      <td>5.8</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>worm</td>\n",
       "      <td>__wo_rm___</td>\n",
       "      <td>__w^rm____</td>\n",
       "      <td>100</td>\n",
       "      <td>LF</td>\n",
       "      <td>INC</td>\n",
       "      <td>HI</td>\n",
       "      <td>6.6</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>worth</td>\n",
       "      <td>__wo_rth__</td>\n",
       "      <td>__w^rT____</td>\n",
       "      <td>5251</td>\n",
       "      <td>HF</td>\n",
       "      <td>INC</td>\n",
       "      <td>LI</td>\n",
       "      <td>2.3</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>wrong</td>\n",
       "      <td>_wro_ng___</td>\n",
       "      <td>__rang____</td>\n",
       "      <td>3195</td>\n",
       "      <td>HF</td>\n",
       "      <td>CON</td>\n",
       "      <td>LI</td>\n",
       "      <td>2.4</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>zone</td>\n",
       "      <td>__zo_ne___</td>\n",
       "      <td>__zon_____</td>\n",
       "      <td>721</td>\n",
       "      <td>LF</td>\n",
       "      <td>INC</td>\n",
       "      <td>LI</td>\n",
       "      <td>4.1</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word         ort         pho     wf frequency pho_consistency  \\\n",
       "0     ball  __ba_ll___  __bal_____   1393        HF             INC   \n",
       "1     bank  __ba_nk___  __b@nk____  53170        HF             CON   \n",
       "2    beach  __beach___  __biC_____   1691        HF             CON   \n",
       "3     beak  __beak____  __bik_____     10        LF             INC   \n",
       "4    beard  __beard___  __bird____    210        LF             INC   \n",
       "..     ...         ...         ...    ...       ...             ...   \n",
       "155   wool  __wool____  __wUl_____    153        LF             INC   \n",
       "156   worm  __wo_rm___  __w^rm____    100        LF             INC   \n",
       "157  worth  __wo_rth__  __w^rT____   5251        HF             INC   \n",
       "158  wrong  _wro_ng___  __rang____   3195        HF             CON   \n",
       "159   zone  __zo_ne___  __zon_____    721        LF             INC   \n",
       "\n",
       "    imageability  img   id  \n",
       "0             HI  6.6    0  \n",
       "1             HI  6.1    1  \n",
       "2             HI  6.5    2  \n",
       "3             HI  5.2    3  \n",
       "4             HI  6.3    4  \n",
       "..           ...  ...  ...  \n",
       "155           HI  5.8  155  \n",
       "156           HI  6.6  156  \n",
       "157           LI  2.3  157  \n",
       "158           LI  2.4  158  \n",
       "159           LI  4.1  159  \n",
       "\n",
       "[160 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_strain = data.df_strain\n",
    "df_strain['id'] = df_strain.index\n",
    "df_strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfid = df_strain.loc[df_strain.frequency == 'HF', 'id']\n",
    "lfid = df_strain.loc[df_strain.frequency == 'LF', 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to match target structure and sample_weight_modes structure:\n  ['...', '...']\n    to  \n  ['...']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[0;34m(nest1, nest2, check_types, expand_composites)\u001b[0m\n\u001b[1;32m    329\u001b[0m     _pywrap_utils.AssertSameStructure(nest1, nest2, check_types,\n\u001b[0;32m--> 330\u001b[0;31m                                       expand_composites)\n\u001b[0m\u001b[1;32m    331\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=tuple str=(array([[ 2.86830546e-05,  3.02942010e-05, -3.29324638e-05, ...,\n        -5.20695574e-05, -4.00811216e-04,  5.10389975e-04],\n       [ 3.49016034e-05,  6.58344832e-05, -3.91099897e-06, ...,\n         8.38790013e-06, -3.77695585e-04,  6.78414417e-05],\n       [ 3.46908166e-03,  4.57070489e-03, -1.14218356e-03, ...,\n         2.71125959e-03,  4.14688764e-03, -6.09294502e-03],\n       ...,\n       [ 9.93818545e-04,  1.33141789e-03, -1.22224026e-05, ...,\n        -2.38516321e-03, -3.96675492e-03, -2.28988195e-03],\n       [ 1.15302314e-04,  7.91730599e-05, -5.67694313e-05, ...,\n         3.01126291e-04,  3.54721733e-04, -1.82943476e-05],\n       [ 2.17257784e-03,  1.54250320e-03, -2.16479296e-03, ...,\n         2.05588659e-03,  2.76933053e-03,  1.98457313e-03]]), array([[ 2.86830546e-05,  3.02942010e-05, -3.29324638e-05, ...,\n        -5.20695574e-05, -4.00811216e-04,  5.10389975e-04],\n       [ 3.49016034e-05,  6.58344832e-05, -3.91099897e-06, ...,\n         8.38790013e-06, -3.77695585e-04,  6.78414417e-05],\n       [ 3.46908166e-03,  4.57070489e-03, -1.14218356e-03, ...,\n         2.71125959e-03,  4.14688764e-03, -6.09294502e-03],\n       ...,\n       [ 9.93818545e-04,  1.33141789e-03, -1.22224026e-05, ...,\n        -2.38516321e-03, -3.96675492e-03, -2.28988195e-03],\n       [ 1.15302314e-04,  7.91730599e-05, -5.67694313e-05, ...,\n         3.01126291e-04,  3.54721733e-04, -1.82943476e-05],\n       [ 2.17257784e-03,  1.54250320e-03, -2.16479296e-03, ...,\n         2.05588659e-03,  2.76933053e-03,  1.98457313e-03]]))\n\nSecond structure: type=tuple str=(None,)\n\nMore specifically: The two structures don't have the same number of elements. First structure: type=tuple str=(array([[ 2.86830546e-05,  3.02942010e-05, -3.29324638e-05, ...,\n        -5.20695574e-05, -4.00811216e-04,  5.10389975e-04],\n       [ 3.49016034e-05,  6.58344832e-05, -3.91099897e-06, ...,\n         8.38790013e-06, -3.77695585e-04,  6.78414417e-05],\n       [ 3.46908166e-03,  4.57070489e-03, -1.14218356e-03, ...,\n         2.71125959e-03,  4.14688764e-03, -6.09294502e-03],\n       ...,\n       [ 9.93818545e-04,  1.33141789e-03, -1.22224026e-05, ...,\n        -2.38516321e-03, -3.96675492e-03, -2.28988195e-03],\n       [ 1.15302314e-04,  7.91730599e-05, -5.67694313e-05, ...,\n         3.01126291e-04,  3.54721733e-04, -1.82943476e-05],\n       [ 2.17257784e-03,  1.54250320e-03, -2.16479296e-03, ...,\n         2.05588659e-03,  2.76933053e-03,  1.98457313e-03]]), array([[ 2.86830546e-05,  3.02942010e-05, -3.29324638e-05, ...,\n        -5.20695574e-05, -4.00811216e-04,  5.10389975e-04],\n       [ 3.49016034e-05,  6.58344832e-05, -3.91099897e-06, ...,\n         8.38790013e-06, -3.77695585e-04,  6.78414417e-05],\n       [ 3.46908166e-03,  4.57070489e-03, -1.14218356e-03, ...,\n         2.71125959e-03,  4.14688764e-03, -6.09294502e-03],\n       ...,\n       [ 9.93818545e-04,  1.33141789e-03, -1.22224026e-05, ...,\n        -2.38516321e-03, -3.96675492e-03, -2.28988195e-03],\n       [ 1.15302314e-04,  7.91730599e-05, -5.67694313e-05, ...,\n         3.01126291e-04,  3.54721733e-04, -1.82943476e-05],\n       [ 2.17257784e-03,  1.54250320e-03, -2.16479296e-03, ...,\n         2.05588659e-03,  2.76933053e-03,  1.98457313e-03]])). Second structure: type=tuple str=(None,)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mbroadcast_sample_weight_modes\u001b[0;34m(target_structure, sample_weight_modes)\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           training_utils.list_to_tuple(sample_weight_modes))\n\u001b[0m\u001b[1;32m   1079\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[0;34m(nest1, nest2, check_types, expand_composites)\u001b[0m\n\u001b[1;32m    336\u001b[0m                   \u001b[0;34m\"Entire second structure:\\n%s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m                   % (str(e), str1, str2))\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=tuple str=(array([[ 2.86830546e-05,  3.02942010e-05, -3.29324638e-05, ...,\n        -5.20695574e-05, -4.00811216e-04,  5.10389975e-04],\n       [ 3.49016034e-05,  6.58344832e-05, -3.91099897e-06, ...,\n         8.38790013e-06, -3.77695585e-04,  6.78414417e-05],\n       [ 3.46908166e-03,  4.57070489e-03, -1.14218356e-03, ...,\n         2.71125959e-03,  4.14688764e-03, -6.09294502e-03],\n       ...,\n       [ 9.93818545e-04,  1.33141789e-03, -1.22224026e-05, ...,\n        -2.38516321e-03, -3.96675492e-03, -2.28988195e-03],\n       [ 1.15302314e-04,  7.91730599e-05, -5.67694313e-05, ...,\n         3.01126291e-04,  3.54721733e-04, -1.82943476e-05],\n       [ 2.17257784e-03,  1.54250320e-03, -2.16479296e-03, ...,\n         2.05588659e-03,  2.76933053e-03,  1.98457313e-03]]), array([[ 2.86830546e-05,  3.02942010e-05, -3.29324638e-05, ...,\n        -5.20695574e-05, -4.00811216e-04,  5.10389975e-04],\n       [ 3.49016034e-05,  6.58344832e-05, -3.91099897e-06, ...,\n         8.38790013e-06, -3.77695585e-04,  6.78414417e-05],\n       [ 3.46908166e-03,  4.57070489e-03, -1.14218356e-03, ...,\n         2.71125959e-03,  4.14688764e-03, -6.09294502e-03],\n       ...,\n       [ 9.93818545e-04,  1.33141789e-03, -1.22224026e-05, ...,\n        -2.38516321e-03, -3.96675492e-03, -2.28988195e-03],\n       [ 1.15302314e-04,  7.91730599e-05, -5.67694313e-05, ...,\n         3.01126291e-04,  3.54721733e-04, -1.82943476e-05],\n       [ 2.17257784e-03,  1.54250320e-03, -2.16479296e-03, ...,\n         2.05588659e-03,  2.76933053e-03,  1.98457313e-03]]))\n\nSecond structure: type=tuple str=(None,)\n\nMore specifically: The two structures don't have the same number of elements. First structure: type=tuple str=(array([[ 2.86830546e-05,  3.02942010e-05, -3.29324638e-05, ...,\n        -5.20695574e-05, -4.00811216e-04,  5.10389975e-04],\n       [ 3.49016034e-05,  6.58344832e-05, -3.91099897e-06, ...,\n         8.38790013e-06, -3.77695585e-04,  6.78414417e-05],\n       [ 3.46908166e-03,  4.57070489e-03, -1.14218356e-03, ...,\n         2.71125959e-03,  4.14688764e-03, -6.09294502e-03],\n       ...,\n       [ 9.93818545e-04,  1.33141789e-03, -1.22224026e-05, ...,\n        -2.38516321e-03, -3.96675492e-03, -2.28988195e-03],\n       [ 1.15302314e-04,  7.91730599e-05, -5.67694313e-05, ...,\n         3.01126291e-04,  3.54721733e-04, -1.82943476e-05],\n       [ 2.17257784e-03,  1.54250320e-03, -2.16479296e-03, ...,\n         2.05588659e-03,  2.76933053e-03,  1.98457313e-03]]), array([[ 2.86830546e-05,  3.02942010e-05, -3.29324638e-05, ...,\n        -5.20695574e-05, -4.00811216e-04,  5.10389975e-04],\n       [ 3.49016034e-05,  6.58344832e-05, -3.91099897e-06, ...,\n         8.38790013e-06, -3.77695585e-04,  6.78414417e-05],\n       [ 3.46908166e-03,  4.57070489e-03, -1.14218356e-03, ...,\n         2.71125959e-03,  4.14688764e-03, -6.09294502e-03],\n       ...,\n       [ 9.93818545e-04,  1.33141789e-03, -1.22224026e-05, ...,\n        -2.38516321e-03, -3.96675492e-03, -2.28988195e-03],\n       [ 1.15302314e-04,  7.91730599e-05, -5.67694313e-05, ...,\n         3.01126291e-04,  3.54721733e-04, -1.82943476e-05],\n       [ 2.17257784e-03,  1.54250320e-03, -2.16479296e-03, ...,\n         2.05588659e-03,  2.76933053e-03,  1.98457313e-03]])). Second structure: type=tuple str=(None,)\nEntire first structure:\n(., .)\nEntire second structure:\n(.,)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    457\u001b[0m     final_index, packed = _packed_nest_with_indices(structure, flat_sequence,\n\u001b[0;32m--> 458\u001b[0;31m                                                     0, is_seq, sequence_fn)\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m_packed_nest_with_indices\u001b[0;34m(structure, flat, index, is_seq, sequence_fn)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m       \u001b[0mpacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mbroadcast_sample_weight_modes\u001b[0;34m(target_structure, sample_weight_modes)\u001b[0m\n\u001b[1;32m   1087\u001b[0m         sample_weight_modes = nest.pack_sequence_as(\n\u001b[0;32m-> 1088\u001b[0;31m             target_structure, nest.flatten(sample_weight_modes))\n\u001b[0m\u001b[1;32m   1089\u001b[0m         logging.warning(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    503\u001b[0m   \"\"\"\n\u001b[0;32m--> 504\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    466\u001b[0m           \u001b[0;34m\"flat_sequence had %d elements.  Structure: %s, flat_sequence: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m           (len(flat_structure), len(flat_sequence), structure, flat_sequence))\n\u001b[0m\u001b[1;32m    468\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msequence_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not pack sequence. Structure had 2 elements, but flat_sequence had 1 elements.  Structure: [array([[ 2.86830546e-05,  3.02942010e-05, -3.29324638e-05, ...,\n        -5.20695574e-05, -4.00811216e-04,  5.10389975e-04],\n       [ 3.49016034e-05,  6.58344832e-05, -3.91099897e-06, ...,\n         8.38790013e-06, -3.77695585e-04,  6.78414417e-05],\n       [ 3.46908166e-03,  4.57070489e-03, -1.14218356e-03, ...,\n         2.71125959e-03,  4.14688764e-03, -6.09294502e-03],\n       ...,\n       [ 9.93818545e-04,  1.33141789e-03, -1.22224026e-05, ...,\n        -2.38516321e-03, -3.96675492e-03, -2.28988195e-03],\n       [ 1.15302314e-04,  7.91730599e-05, -5.67694313e-05, ...,\n         3.01126291e-04,  3.54721733e-04, -1.82943476e-05],\n       [ 2.17257784e-03,  1.54250320e-03, -2.16479296e-03, ...,\n         2.05588659e-03,  2.76933053e-03,  1.98457313e-03]]), array([[ 2.86830546e-05,  3.02942010e-05, -3.29324638e-05, ...,\n        -5.20695574e-05, -4.00811216e-04,  5.10389975e-04],\n       [ 3.49016034e-05,  6.58344832e-05, -3.91099897e-06, ...,\n         8.38790013e-06, -3.77695585e-04,  6.78414417e-05],\n       [ 3.46908166e-03,  4.57070489e-03, -1.14218356e-03, ...,\n         2.71125959e-03,  4.14688764e-03, -6.09294502e-03],\n       ...,\n       [ 9.93818545e-04,  1.33141789e-03, -1.22224026e-05, ...,\n        -2.38516321e-03, -3.96675492e-03, -2.28988195e-03],\n       [ 1.15302314e-04,  7.91730599e-05, -5.67694313e-05, ...,\n         3.01126291e-04,  3.54721733e-04, -1.82943476e-05],\n       [ 2.17257784e-03,  1.54250320e-03, -2.16479296e-03, ...,\n         2.05588659e-03,  2.76933053e-03,  1.98457313e-03]])], flat_sequence: [None].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f27a49e861eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnEpo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[1;32m    750\u001b[0m     (peek, wrap_in_tuple, elements_to_keep, partial_sample_weight,\n\u001b[1;32m    751\u001b[0m      \u001b[0msample_weight_modes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnested_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnested_dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m     ) = self._canonicalize_peek(peek, kwargs.get(\"sample_weight_modes\"))\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;31m# Note that dataset API takes a callable that creates a generator object,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_canonicalize_peek\u001b[0;34m(self, peek, sample_weight_modes)\u001b[0m\n\u001b[1;32m    806\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    807\u001b[0m         \u001b[0msample_weights_peek\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_weights_peek\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my_peek\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         sample_weight_modes)\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mbroadcast_sample_weight_modes\u001b[0;34m(target_structure, sample_weight_modes)\u001b[0m\n\u001b[1;32m   1093\u001b[0m         raise ValueError(\n\u001b[1;32m   1094\u001b[0m             \u001b[0;34m\"Unable to match target structure and sample_weight_modes \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m             \"structure:\\n  {}\\n    to  \\n  {}\".format(target_str, mode_str))\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msample_weight_modes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to match target structure and sample_weight_modes structure:\n  ['...', '...']\n    to  \n  ['...']"
     ]
    }
   ],
   "source": [
    "import h5py, pickle, os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from data_wrangling import sample_generator\n",
    "from IPython.display import clear_output\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    cfg.path_weights_checkpoint,\n",
    "    verbose=1,\n",
    "    save_freq=cfg.save_freq_sample,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    sample_generator(cfg, data),\n",
    "    validation_data=(data.x_strain, data.y_strain),\n",
    "    steps_per_epoch=cfg.steps_per_epoch,\n",
    "    epochs=cfg.nEpo,\n",
    "    verbose=0,\n",
    "    callbacks=[checkpoint],\n",
    ")\n",
    "\n",
    "# Saving history and model\n",
    "pickle_out = open(cfg.path_history_pickle, \"wb\")\n",
    "pickle.dump(history.history, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "clear_output()\n",
    "print('Training done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMmNcbJdcPMh"
   },
   "source": [
    "# Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BqpDOQStugK"
   },
   "source": [
    "### Training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-12e1dcc9d2f749aba3bdbf41ea8b1bea\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-12e1dcc9d2f749aba3bdbf41ea8b1bea\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"hconcat\": [{\"vconcat\": [{\"encoding\": {\"color\": {\"field\": \"variable\", \"legend\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"variable\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}}, \"title\": \"Loss\", \"data\": {\"name\": \"data-94930a88c1427856255847fb91ba7fdc\"}, \"mark\": \"line\", \"selection\": {\"selector001\": {\"bind\": \"scales\", \"encodings\": [\"x\", \"y\"], \"type\": \"interval\"}}}, {\"encoding\": {\"color\": {\"field\": \"variable\", \"legend\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"variable\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}}, \"title\": \"Accuracy\", \"data\": {\"name\": \"data-690c9458d0df2b2f9b7e6dc5a251350f\"}, \"mark\": \"line\", \"selection\": {\"selector002\": {\"bind\": \"scales\", \"encodings\": [\"x\", \"y\"], \"type\": \"interval\"}}}]}, {\"encoding\": {\"color\": {\"field\": \"variable\", \"legend\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"variable\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}}, \"title\": \"MSE\", \"data\": {\"name\": \"data-9a3590f2a8c950c5946cc9a03633cd5a\"}, \"mark\": \"line\", \"selection\": {\"selector003\": {\"bind\": \"scales\", \"encodings\": [\"x\", \"y\"], \"type\": \"interval\"}}}], \"datasets\": {\"data-94930a88c1427856255847fb91ba7fdc\": [{\"variable\": \"rnn_1_loss\", \"value\": 0.1641601026058197, \"epoch\": 0}, {\"variable\": \"rnn_1_loss\", \"value\": 0.08896029740571976, \"epoch\": 1}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0640212669968605, \"epoch\": 2}, {\"variable\": \"rnn_1_loss\", \"value\": 0.04594583064317703, \"epoch\": 3}, {\"variable\": \"rnn_1_loss\", \"value\": 0.03271958604454994, \"epoch\": 4}, {\"variable\": \"rnn_1_loss\", \"value\": 0.023539353162050247, \"epoch\": 5}, {\"variable\": \"rnn_1_loss\", \"value\": 0.017295077443122864, \"epoch\": 6}, {\"variable\": \"rnn_1_loss\", \"value\": 0.013029210269451141, \"epoch\": 7}, {\"variable\": \"rnn_1_loss\", \"value\": 0.010066919960081577, \"epoch\": 8}, {\"variable\": \"rnn_1_loss\", \"value\": 0.007964301854372025, \"epoch\": 9}, {\"variable\": \"rnn_1_loss\", \"value\": 0.006419600453227758, \"epoch\": 10}, {\"variable\": \"rnn_1_loss\", \"value\": 0.005267389118671417, \"epoch\": 11}, {\"variable\": \"rnn_1_loss\", \"value\": 0.004392426460981369, \"epoch\": 12}, {\"variable\": \"rnn_1_loss\", \"value\": 0.003717200132086873, \"epoch\": 13}, {\"variable\": \"rnn_1_loss\", \"value\": 0.003174376208335161, \"epoch\": 14}, {\"variable\": \"rnn_1_loss\", \"value\": 0.002748161321505904, \"epoch\": 15}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0023972205817699432, \"epoch\": 16}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0021048146300017834, \"epoch\": 17}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0018651514546945691, \"epoch\": 18}, {\"variable\": \"rnn_1_loss\", \"value\": 0.001663535600528121, \"epoch\": 19}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0014952723868191242, \"epoch\": 20}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0013472425052896142, \"epoch\": 21}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0012227720580995083, \"epoch\": 22}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0011134736705571413, \"epoch\": 23}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0010203777346760035, \"epoch\": 24}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0009393307263962924, \"epoch\": 25}, {\"variable\": \"rnn_1_loss\", \"value\": 0.000866674177814275, \"epoch\": 26}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0007991119637154043, \"epoch\": 27}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0007421075715683401, \"epoch\": 28}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0006931286188773811, \"epoch\": 29}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0006442074663937092, \"epoch\": 30}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0005993623053655028, \"epoch\": 31}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0005696954904124141, \"epoch\": 32}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0005231194081716239, \"epoch\": 33}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0005026197177357972, \"epoch\": 34}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0004708409251179546, \"epoch\": 35}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0004413991409819573, \"epoch\": 36}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00042147026397287846, \"epoch\": 37}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00039850256871432066, \"epoch\": 38}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00038231414509937167, \"epoch\": 39}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0003634009335655719, \"epoch\": 40}, {\"variable\": \"rnn_1_loss\", \"value\": 0.000345890992321074, \"epoch\": 41}, {\"variable\": \"rnn_1_loss\", \"value\": 0.000332851690473035, \"epoch\": 42}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0003173417644575238, \"epoch\": 43}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00030370563035830855, \"epoch\": 44}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0002887092705350369, \"epoch\": 45}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00027771040913648903, \"epoch\": 46}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00026861001970246434, \"epoch\": 47}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0002571784716565162, \"epoch\": 48}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00024625621153973043, \"epoch\": 49}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0002361546503379941, \"epoch\": 50}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00023267674259841442, \"epoch\": 51}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0002243294584332034, \"epoch\": 52}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00021901268337387592, \"epoch\": 53}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0002050212788162753, \"epoch\": 54}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00020488091104198247, \"epoch\": 55}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00019764770695474, \"epoch\": 56}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00019443535711616278, \"epoch\": 57}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0001861391356214881, \"epoch\": 58}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00018500295118428767, \"epoch\": 59}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00017525843577459455, \"epoch\": 60}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0001753904070938006, \"epoch\": 61}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00017036432109307498, \"epoch\": 62}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00016374874394387007, \"epoch\": 63}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0001629959442652762, \"epoch\": 64}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00015809507749509066, \"epoch\": 65}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00015953273396007717, \"epoch\": 66}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00015253528545144945, \"epoch\": 67}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00014897205983288586, \"epoch\": 68}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00014995737001299858, \"epoch\": 69}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0001427101669833064, \"epoch\": 70}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00013901294732932, \"epoch\": 71}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00013730628415942192, \"epoch\": 72}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00013584285625256598, \"epoch\": 73}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0001334984990535304, \"epoch\": 74}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0001294072571909055, \"epoch\": 75}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00012797664385288954, \"epoch\": 76}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00012892675295006484, \"epoch\": 77}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0001274490641662851, \"epoch\": 78}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00012411507486831397, \"epoch\": 79}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00012130601680837572, \"epoch\": 80}, {\"variable\": \"rnn_1_loss\", \"value\": 0.000122498968266882, \"epoch\": 81}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00012494091060943902, \"epoch\": 82}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00012310438614804298, \"epoch\": 83}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00011436014028731734, \"epoch\": 84}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00011710268881870434, \"epoch\": 85}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00011229032679693773, \"epoch\": 86}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00011396413901820779, \"epoch\": 87}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0001154470446635969, \"epoch\": 88}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0001090958176064305, \"epoch\": 89}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00010799644223880023, \"epoch\": 90}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00010966468835249543, \"epoch\": 91}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00011183758761035278, \"epoch\": 92}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00010741585720097646, \"epoch\": 93}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00010297093831468374, \"epoch\": 94}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00010580135858617723, \"epoch\": 95}, {\"variable\": \"rnn_1_loss\", \"value\": 0.0001066638869815506, \"epoch\": 96}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00010735793330240995, \"epoch\": 97}, {\"variable\": \"rnn_1_loss\", \"value\": 0.00010376571299275383, \"epoch\": 98}, {\"variable\": \"rnn_1_loss\", \"value\": 9.885212784865871e-05, \"epoch\": 99}, {\"variable\": \"rnn_loss\", \"value\": 0.14496777951717377, \"epoch\": 0}, {\"variable\": \"rnn_loss\", \"value\": 0.040029603987932205, \"epoch\": 1}, {\"variable\": \"rnn_loss\", \"value\": 0.01790459267795086, \"epoch\": 2}, {\"variable\": \"rnn_loss\", \"value\": 0.010290258564054966, \"epoch\": 3}, {\"variable\": \"rnn_loss\", \"value\": 0.006646404042840004, \"epoch\": 4}, {\"variable\": \"rnn_loss\", \"value\": 0.004591720644384623, \"epoch\": 5}, {\"variable\": \"rnn_loss\", \"value\": 0.0033284707460552454, \"epoch\": 6}, {\"variable\": \"rnn_loss\", \"value\": 0.002517432440072298, \"epoch\": 7}, {\"variable\": \"rnn_loss\", \"value\": 0.0019617462530732155, \"epoch\": 8}, {\"variable\": \"rnn_loss\", \"value\": 0.0015853862278163433, \"epoch\": 9}, {\"variable\": \"rnn_loss\", \"value\": 0.0012985910288989544, \"epoch\": 10}, {\"variable\": \"rnn_loss\", \"value\": 0.0010922371875494719, \"epoch\": 11}, {\"variable\": \"rnn_loss\", \"value\": 0.0009324176353402436, \"epoch\": 12}, {\"variable\": \"rnn_loss\", \"value\": 0.0008146221516653895, \"epoch\": 13}, {\"variable\": \"rnn_loss\", \"value\": 0.000713286513928324, \"epoch\": 14}, {\"variable\": \"rnn_loss\", \"value\": 0.0006370077608153224, \"epoch\": 15}, {\"variable\": \"rnn_loss\", \"value\": 0.0005701581831090152, \"epoch\": 16}, {\"variable\": \"rnn_loss\", \"value\": 0.0005144629976712167, \"epoch\": 17}, {\"variable\": \"rnn_loss\", \"value\": 0.00046979455510154366, \"epoch\": 18}, {\"variable\": \"rnn_loss\", \"value\": 0.0004315768019296229, \"epoch\": 19}, {\"variable\": \"rnn_loss\", \"value\": 0.0003997838357463479, \"epoch\": 20}, {\"variable\": \"rnn_loss\", \"value\": 0.00037022793549112976, \"epoch\": 21}, {\"variable\": \"rnn_loss\", \"value\": 0.0003460303705651313, \"epoch\": 22}, {\"variable\": \"rnn_loss\", \"value\": 0.00032534683123230934, \"epoch\": 23}, {\"variable\": \"rnn_loss\", \"value\": 0.0003066076897084713, \"epoch\": 24}, {\"variable\": \"rnn_loss\", \"value\": 0.00029240595176815987, \"epoch\": 25}, {\"variable\": \"rnn_loss\", \"value\": 0.00027800185489468277, \"epoch\": 26}, {\"variable\": \"rnn_loss\", \"value\": 0.00026173467631451786, \"epoch\": 27}, {\"variable\": \"rnn_loss\", \"value\": 0.000251190533163026, \"epoch\": 28}, {\"variable\": \"rnn_loss\", \"value\": 0.0002423983096377924, \"epoch\": 29}, {\"variable\": \"rnn_loss\", \"value\": 0.00023023788526188582, \"epoch\": 30}, {\"variable\": \"rnn_loss\", \"value\": 0.00021780148381367326, \"epoch\": 31}, {\"variable\": \"rnn_loss\", \"value\": 0.0002177198912249878, \"epoch\": 32}, {\"variable\": \"rnn_loss\", \"value\": 0.0001979170338017866, \"epoch\": 33}, {\"variable\": \"rnn_loss\", \"value\": 0.00020063560805283487, \"epoch\": 34}, {\"variable\": \"rnn_loss\", \"value\": 0.00019131143926642835, \"epoch\": 35}, {\"variable\": \"rnn_loss\", \"value\": 0.00018140458269044757, \"epoch\": 36}, {\"variable\": \"rnn_loss\", \"value\": 0.00017937537631951272, \"epoch\": 37}, {\"variable\": \"rnn_loss\", \"value\": 0.00017294799908995628, \"epoch\": 38}, {\"variable\": \"rnn_loss\", \"value\": 0.00017197172564920038, \"epoch\": 39}, {\"variable\": \"rnn_loss\", \"value\": 0.00016726419562473893, \"epoch\": 40}, {\"variable\": \"rnn_loss\", \"value\": 0.00016210071044042706, \"epoch\": 41}, {\"variable\": \"rnn_loss\", \"value\": 0.00016123759269248694, \"epoch\": 42}, {\"variable\": \"rnn_loss\", \"value\": 0.00015633515431545675, \"epoch\": 43}, {\"variable\": \"rnn_loss\", \"value\": 0.0001526545820524916, \"epoch\": 44}, {\"variable\": \"rnn_loss\", \"value\": 0.0001469272538088262, \"epoch\": 45}, {\"variable\": \"rnn_loss\", \"value\": 0.00014490251487586647, \"epoch\": 46}, {\"variable\": \"rnn_loss\", \"value\": 0.00014374483725987375, \"epoch\": 47}, {\"variable\": \"rnn_loss\", \"value\": 0.00013965688413009048, \"epoch\": 48}, {\"variable\": \"rnn_loss\", \"value\": 0.0001356821449007839, \"epoch\": 49}, {\"variable\": \"rnn_loss\", \"value\": 0.00013185312855057418, \"epoch\": 50}, {\"variable\": \"rnn_loss\", \"value\": 0.00013453321298584342, \"epoch\": 51}, {\"variable\": \"rnn_loss\", \"value\": 0.0001317436690442264, \"epoch\": 52}, {\"variable\": \"rnn_loss\", \"value\": 0.0001317176065640524, \"epoch\": 53}, {\"variable\": \"rnn_loss\", \"value\": 0.00012248607526998967, \"epoch\": 54}, {\"variable\": \"rnn_loss\", \"value\": 0.00012690502626355737, \"epoch\": 55}, {\"variable\": \"rnn_loss\", \"value\": 0.000124060912639834, \"epoch\": 56}, {\"variable\": \"rnn_loss\", \"value\": 0.00012477650307118893, \"epoch\": 57}, {\"variable\": \"rnn_loss\", \"value\": 0.00012039922148687765, \"epoch\": 58}, {\"variable\": \"rnn_loss\", \"value\": 0.000122684970847331, \"epoch\": 59}, {\"variable\": \"rnn_loss\", \"value\": 0.0001161510735983029, \"epoch\": 60}, {\"variable\": \"rnn_loss\", \"value\": 0.00011944312427658588, \"epoch\": 61}, {\"variable\": \"rnn_loss\", \"value\": 0.00011732947314158082, \"epoch\": 62}, {\"variable\": \"rnn_loss\", \"value\": 0.00011352034198353067, \"epoch\": 63}, {\"variable\": \"rnn_loss\", \"value\": 0.00011545648885658011, \"epoch\": 64}, {\"variable\": \"rnn_loss\", \"value\": 0.00011293397983536124, \"epoch\": 65}, {\"variable\": \"rnn_loss\", \"value\": 0.0001166843285318464, \"epoch\": 66}, {\"variable\": \"rnn_loss\", \"value\": 0.00011192294186912477, \"epoch\": 67}, {\"variable\": \"rnn_loss\", \"value\": 0.00011042699770769104, \"epoch\": 68}, {\"variable\": \"rnn_loss\", \"value\": 0.00011319264740450308, \"epoch\": 69}, {\"variable\": \"rnn_loss\", \"value\": 0.00010788677172968164, \"epoch\": 70}, {\"variable\": \"rnn_loss\", \"value\": 0.00010592852049740031, \"epoch\": 71}, {\"variable\": \"rnn_loss\", \"value\": 0.00010586729331407696, \"epoch\": 72}, {\"variable\": \"rnn_loss\", \"value\": 0.0001058755224221386, \"epoch\": 73}, {\"variable\": \"rnn_loss\", \"value\": 0.00010506024409551173, \"epoch\": 74}, {\"variable\": \"rnn_loss\", \"value\": 0.00010239176481263712, \"epoch\": 75}, {\"variable\": \"rnn_loss\", \"value\": 0.00010224882862530649, \"epoch\": 76}, {\"variable\": \"rnn_loss\", \"value\": 0.00010448955436004326, \"epoch\": 77}, {\"variable\": \"rnn_loss\", \"value\": 0.00010415775614092126, \"epoch\": 78}, {\"variable\": \"rnn_loss\", \"value\": 0.00010190186731051654, \"epoch\": 79}, {\"variable\": \"rnn_loss\", \"value\": 0.00010017085878644139, \"epoch\": 80}, {\"variable\": \"rnn_loss\", \"value\": 0.00010236296657240018, \"epoch\": 81}, {\"variable\": \"rnn_loss\", \"value\": 0.0001057960107573308, \"epoch\": 82}, {\"variable\": \"rnn_loss\", \"value\": 0.00010486958490218967, \"epoch\": 83}, {\"variable\": \"rnn_loss\", \"value\": 9.691092418506742e-05, \"epoch\": 84}, {\"variable\": \"rnn_loss\", \"value\": 0.00010049843695014715, \"epoch\": 85}, {\"variable\": \"rnn_loss\", \"value\": 9.649519779486582e-05, \"epoch\": 86}, {\"variable\": \"rnn_loss\", \"value\": 9.889728244161233e-05, \"epoch\": 87}, {\"variable\": \"rnn_loss\", \"value\": 0.00010107122216140851, \"epoch\": 88}, {\"variable\": \"rnn_loss\", \"value\": 9.540517203276977e-05, \"epoch\": 89}, {\"variable\": \"rnn_loss\", \"value\": 9.49502646108158e-05, \"epoch\": 90}, {\"variable\": \"rnn_loss\", \"value\": 9.723022230900824e-05, \"epoch\": 91}, {\"variable\": \"rnn_loss\", \"value\": 9.994745050789788e-05, \"epoch\": 92}, {\"variable\": \"rnn_loss\", \"value\": 9.60935722105205e-05, \"epoch\": 93}, {\"variable\": \"rnn_loss\", \"value\": 9.21511891647242e-05, \"epoch\": 94}, {\"variable\": \"rnn_loss\", \"value\": 9.551665425533429e-05, \"epoch\": 95}, {\"variable\": \"rnn_loss\", \"value\": 9.680786024546251e-05, \"epoch\": 96}, {\"variable\": \"rnn_loss\", \"value\": 9.795076766749844e-05, \"epoch\": 97}, {\"variable\": \"rnn_loss\", \"value\": 9.476654668105766e-05, \"epoch\": 98}, {\"variable\": \"rnn_loss\", \"value\": 9.027135092765093e-05, \"epoch\": 99}], \"data-9a3590f2a8c950c5946cc9a03633cd5a\": [{\"variable\": \"rnn_1_mse\", \"value\": 0.1641601026058197, \"epoch\": 0}, {\"variable\": \"rnn_1_mse\", \"value\": 0.08896029740571976, \"epoch\": 1}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0640212669968605, \"epoch\": 2}, {\"variable\": \"rnn_1_mse\", \"value\": 0.04594583064317703, \"epoch\": 3}, {\"variable\": \"rnn_1_mse\", \"value\": 0.03271958604454994, \"epoch\": 4}, {\"variable\": \"rnn_1_mse\", \"value\": 0.023539353162050247, \"epoch\": 5}, {\"variable\": \"rnn_1_mse\", \"value\": 0.017295077443122864, \"epoch\": 6}, {\"variable\": \"rnn_1_mse\", \"value\": 0.013029210269451141, \"epoch\": 7}, {\"variable\": \"rnn_1_mse\", \"value\": 0.010066919960081577, \"epoch\": 8}, {\"variable\": \"rnn_1_mse\", \"value\": 0.007964301854372025, \"epoch\": 9}, {\"variable\": \"rnn_1_mse\", \"value\": 0.006419600453227758, \"epoch\": 10}, {\"variable\": \"rnn_1_mse\", \"value\": 0.005267389118671417, \"epoch\": 11}, {\"variable\": \"rnn_1_mse\", \"value\": 0.004392426460981369, \"epoch\": 12}, {\"variable\": \"rnn_1_mse\", \"value\": 0.003717200132086873, \"epoch\": 13}, {\"variable\": \"rnn_1_mse\", \"value\": 0.003174376208335161, \"epoch\": 14}, {\"variable\": \"rnn_1_mse\", \"value\": 0.002748161321505904, \"epoch\": 15}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0023972205817699432, \"epoch\": 16}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0021048146300017834, \"epoch\": 17}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0018651514546945691, \"epoch\": 18}, {\"variable\": \"rnn_1_mse\", \"value\": 0.001663535600528121, \"epoch\": 19}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0014952723868191242, \"epoch\": 20}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0013472425052896142, \"epoch\": 21}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0012227720580995083, \"epoch\": 22}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0011134736705571413, \"epoch\": 23}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0010203777346760035, \"epoch\": 24}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0009393307263962924, \"epoch\": 25}, {\"variable\": \"rnn_1_mse\", \"value\": 0.000866674177814275, \"epoch\": 26}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0007991119637154043, \"epoch\": 27}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0007421075715683401, \"epoch\": 28}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0006931286188773811, \"epoch\": 29}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0006442074663937092, \"epoch\": 30}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0005993623053655028, \"epoch\": 31}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0005696954904124141, \"epoch\": 32}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0005231194081716239, \"epoch\": 33}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0005026197177357972, \"epoch\": 34}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0004708409251179546, \"epoch\": 35}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0004413991409819573, \"epoch\": 36}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00042147026397287846, \"epoch\": 37}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00039850256871432066, \"epoch\": 38}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00038231414509937167, \"epoch\": 39}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0003634009335655719, \"epoch\": 40}, {\"variable\": \"rnn_1_mse\", \"value\": 0.000345890992321074, \"epoch\": 41}, {\"variable\": \"rnn_1_mse\", \"value\": 0.000332851690473035, \"epoch\": 42}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0003173417644575238, \"epoch\": 43}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00030370563035830855, \"epoch\": 44}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0002887092705350369, \"epoch\": 45}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00027771040913648903, \"epoch\": 46}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00026861001970246434, \"epoch\": 47}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0002571784716565162, \"epoch\": 48}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00024625621153973043, \"epoch\": 49}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0002361546503379941, \"epoch\": 50}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00023267674259841442, \"epoch\": 51}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0002243294584332034, \"epoch\": 52}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00021901268337387592, \"epoch\": 53}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0002050212788162753, \"epoch\": 54}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00020488091104198247, \"epoch\": 55}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00019764770695474, \"epoch\": 56}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00019443535711616278, \"epoch\": 57}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0001861391356214881, \"epoch\": 58}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00018500295118428767, \"epoch\": 59}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00017525843577459455, \"epoch\": 60}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0001753904070938006, \"epoch\": 61}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00017036432109307498, \"epoch\": 62}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00016374874394387007, \"epoch\": 63}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0001629959442652762, \"epoch\": 64}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00015809507749509066, \"epoch\": 65}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00015953273396007717, \"epoch\": 66}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00015253528545144945, \"epoch\": 67}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00014897205983288586, \"epoch\": 68}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00014995737001299858, \"epoch\": 69}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0001427101669833064, \"epoch\": 70}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00013901294732932, \"epoch\": 71}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00013730628415942192, \"epoch\": 72}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00013584285625256598, \"epoch\": 73}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0001334984990535304, \"epoch\": 74}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0001294072571909055, \"epoch\": 75}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00012797664385288954, \"epoch\": 76}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00012892675295006484, \"epoch\": 77}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0001274490641662851, \"epoch\": 78}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00012411507486831397, \"epoch\": 79}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00012130601680837572, \"epoch\": 80}, {\"variable\": \"rnn_1_mse\", \"value\": 0.000122498968266882, \"epoch\": 81}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00012494091060943902, \"epoch\": 82}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00012310438614804298, \"epoch\": 83}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00011436014028731734, \"epoch\": 84}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00011710268881870434, \"epoch\": 85}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00011229032679693773, \"epoch\": 86}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00011396413901820779, \"epoch\": 87}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0001154470446635969, \"epoch\": 88}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0001090958176064305, \"epoch\": 89}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00010799644223880023, \"epoch\": 90}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00010966468835249543, \"epoch\": 91}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00011183758761035278, \"epoch\": 92}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00010741585720097646, \"epoch\": 93}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00010297093831468374, \"epoch\": 94}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00010580135858617723, \"epoch\": 95}, {\"variable\": \"rnn_1_mse\", \"value\": 0.0001066638869815506, \"epoch\": 96}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00010735793330240995, \"epoch\": 97}, {\"variable\": \"rnn_1_mse\", \"value\": 0.00010376571299275383, \"epoch\": 98}, {\"variable\": \"rnn_1_mse\", \"value\": 9.885212784865871e-05, \"epoch\": 99}, {\"variable\": \"rnn_mse\", \"value\": 0.14496777951717377, \"epoch\": 0}, {\"variable\": \"rnn_mse\", \"value\": 0.040029603987932205, \"epoch\": 1}, {\"variable\": \"rnn_mse\", \"value\": 0.01790459267795086, \"epoch\": 2}, {\"variable\": \"rnn_mse\", \"value\": 0.010290258564054966, \"epoch\": 3}, {\"variable\": \"rnn_mse\", \"value\": 0.006646404042840004, \"epoch\": 4}, {\"variable\": \"rnn_mse\", \"value\": 0.004591720644384623, \"epoch\": 5}, {\"variable\": \"rnn_mse\", \"value\": 0.0033284707460552454, \"epoch\": 6}, {\"variable\": \"rnn_mse\", \"value\": 0.002517432440072298, \"epoch\": 7}, {\"variable\": \"rnn_mse\", \"value\": 0.0019617462530732155, \"epoch\": 8}, {\"variable\": \"rnn_mse\", \"value\": 0.0015853862278163433, \"epoch\": 9}, {\"variable\": \"rnn_mse\", \"value\": 0.0012985910288989544, \"epoch\": 10}, {\"variable\": \"rnn_mse\", \"value\": 0.0010922371875494719, \"epoch\": 11}, {\"variable\": \"rnn_mse\", \"value\": 0.0009324176353402436, \"epoch\": 12}, {\"variable\": \"rnn_mse\", \"value\": 0.0008146221516653895, \"epoch\": 13}, {\"variable\": \"rnn_mse\", \"value\": 0.000713286513928324, \"epoch\": 14}, {\"variable\": \"rnn_mse\", \"value\": 0.0006370077608153224, \"epoch\": 15}, {\"variable\": \"rnn_mse\", \"value\": 0.0005701581831090152, \"epoch\": 16}, {\"variable\": \"rnn_mse\", \"value\": 0.0005144629976712167, \"epoch\": 17}, {\"variable\": \"rnn_mse\", \"value\": 0.00046979455510154366, \"epoch\": 18}, {\"variable\": \"rnn_mse\", \"value\": 0.0004315768019296229, \"epoch\": 19}, {\"variable\": \"rnn_mse\", \"value\": 0.0003997838357463479, \"epoch\": 20}, {\"variable\": \"rnn_mse\", \"value\": 0.00037022793549112976, \"epoch\": 21}, {\"variable\": \"rnn_mse\", \"value\": 0.0003460303705651313, \"epoch\": 22}, {\"variable\": \"rnn_mse\", \"value\": 0.00032534683123230934, \"epoch\": 23}, {\"variable\": \"rnn_mse\", \"value\": 0.0003066076897084713, \"epoch\": 24}, {\"variable\": \"rnn_mse\", \"value\": 0.00029240595176815987, \"epoch\": 25}, {\"variable\": \"rnn_mse\", \"value\": 0.00027800185489468277, \"epoch\": 26}, {\"variable\": \"rnn_mse\", \"value\": 0.00026173467631451786, \"epoch\": 27}, {\"variable\": \"rnn_mse\", \"value\": 0.000251190533163026, \"epoch\": 28}, {\"variable\": \"rnn_mse\", \"value\": 0.0002423983096377924, \"epoch\": 29}, {\"variable\": \"rnn_mse\", \"value\": 0.00023023788526188582, \"epoch\": 30}, {\"variable\": \"rnn_mse\", \"value\": 0.00021780148381367326, \"epoch\": 31}, {\"variable\": \"rnn_mse\", \"value\": 0.0002177198912249878, \"epoch\": 32}, {\"variable\": \"rnn_mse\", \"value\": 0.0001979170338017866, \"epoch\": 33}, {\"variable\": \"rnn_mse\", \"value\": 0.00020063560805283487, \"epoch\": 34}, {\"variable\": \"rnn_mse\", \"value\": 0.00019131143926642835, \"epoch\": 35}, {\"variable\": \"rnn_mse\", \"value\": 0.00018140458269044757, \"epoch\": 36}, {\"variable\": \"rnn_mse\", \"value\": 0.00017937537631951272, \"epoch\": 37}, {\"variable\": \"rnn_mse\", \"value\": 0.00017294799908995628, \"epoch\": 38}, {\"variable\": \"rnn_mse\", \"value\": 0.00017197172564920038, \"epoch\": 39}, {\"variable\": \"rnn_mse\", \"value\": 0.00016726419562473893, \"epoch\": 40}, {\"variable\": \"rnn_mse\", \"value\": 0.00016210071044042706, \"epoch\": 41}, {\"variable\": \"rnn_mse\", \"value\": 0.00016123759269248694, \"epoch\": 42}, {\"variable\": \"rnn_mse\", \"value\": 0.00015633515431545675, \"epoch\": 43}, {\"variable\": \"rnn_mse\", \"value\": 0.0001526545820524916, \"epoch\": 44}, {\"variable\": \"rnn_mse\", \"value\": 0.0001469272538088262, \"epoch\": 45}, {\"variable\": \"rnn_mse\", \"value\": 0.00014490251487586647, \"epoch\": 46}, {\"variable\": \"rnn_mse\", \"value\": 0.00014374483725987375, \"epoch\": 47}, {\"variable\": \"rnn_mse\", \"value\": 0.00013965688413009048, \"epoch\": 48}, {\"variable\": \"rnn_mse\", \"value\": 0.0001356821449007839, \"epoch\": 49}, {\"variable\": \"rnn_mse\", \"value\": 0.00013185312855057418, \"epoch\": 50}, {\"variable\": \"rnn_mse\", \"value\": 0.00013453321298584342, \"epoch\": 51}, {\"variable\": \"rnn_mse\", \"value\": 0.0001317436690442264, \"epoch\": 52}, {\"variable\": \"rnn_mse\", \"value\": 0.0001317176065640524, \"epoch\": 53}, {\"variable\": \"rnn_mse\", \"value\": 0.00012248607526998967, \"epoch\": 54}, {\"variable\": \"rnn_mse\", \"value\": 0.00012690502626355737, \"epoch\": 55}, {\"variable\": \"rnn_mse\", \"value\": 0.000124060912639834, \"epoch\": 56}, {\"variable\": \"rnn_mse\", \"value\": 0.00012477650307118893, \"epoch\": 57}, {\"variable\": \"rnn_mse\", \"value\": 0.00012039922148687765, \"epoch\": 58}, {\"variable\": \"rnn_mse\", \"value\": 0.000122684970847331, \"epoch\": 59}, {\"variable\": \"rnn_mse\", \"value\": 0.0001161510735983029, \"epoch\": 60}, {\"variable\": \"rnn_mse\", \"value\": 0.00011944312427658588, \"epoch\": 61}, {\"variable\": \"rnn_mse\", \"value\": 0.00011732947314158082, \"epoch\": 62}, {\"variable\": \"rnn_mse\", \"value\": 0.00011352034198353067, \"epoch\": 63}, {\"variable\": \"rnn_mse\", \"value\": 0.00011545648885658011, \"epoch\": 64}, {\"variable\": \"rnn_mse\", \"value\": 0.00011293397983536124, \"epoch\": 65}, {\"variable\": \"rnn_mse\", \"value\": 0.0001166843285318464, \"epoch\": 66}, {\"variable\": \"rnn_mse\", \"value\": 0.00011192294186912477, \"epoch\": 67}, {\"variable\": \"rnn_mse\", \"value\": 0.00011042699770769104, \"epoch\": 68}, {\"variable\": \"rnn_mse\", \"value\": 0.00011319264740450308, \"epoch\": 69}, {\"variable\": \"rnn_mse\", \"value\": 0.00010788677172968164, \"epoch\": 70}, {\"variable\": \"rnn_mse\", \"value\": 0.00010592852049740031, \"epoch\": 71}, {\"variable\": \"rnn_mse\", \"value\": 0.00010586729331407696, \"epoch\": 72}, {\"variable\": \"rnn_mse\", \"value\": 0.0001058755224221386, \"epoch\": 73}, {\"variable\": \"rnn_mse\", \"value\": 0.00010506024409551173, \"epoch\": 74}, {\"variable\": \"rnn_mse\", \"value\": 0.00010239176481263712, \"epoch\": 75}, {\"variable\": \"rnn_mse\", \"value\": 0.00010224882862530649, \"epoch\": 76}, {\"variable\": \"rnn_mse\", \"value\": 0.00010448955436004326, \"epoch\": 77}, {\"variable\": \"rnn_mse\", \"value\": 0.00010415775614092126, \"epoch\": 78}, {\"variable\": \"rnn_mse\", \"value\": 0.00010190186731051654, \"epoch\": 79}, {\"variable\": \"rnn_mse\", \"value\": 0.00010017085878644139, \"epoch\": 80}, {\"variable\": \"rnn_mse\", \"value\": 0.00010236296657240018, \"epoch\": 81}, {\"variable\": \"rnn_mse\", \"value\": 0.0001057960107573308, \"epoch\": 82}, {\"variable\": \"rnn_mse\", \"value\": 0.00010486958490218967, \"epoch\": 83}, {\"variable\": \"rnn_mse\", \"value\": 9.691092418506742e-05, \"epoch\": 84}, {\"variable\": \"rnn_mse\", \"value\": 0.00010049843695014715, \"epoch\": 85}, {\"variable\": \"rnn_mse\", \"value\": 9.649519779486582e-05, \"epoch\": 86}, {\"variable\": \"rnn_mse\", \"value\": 9.889728244161233e-05, \"epoch\": 87}, {\"variable\": \"rnn_mse\", \"value\": 0.00010107122216140851, \"epoch\": 88}, {\"variable\": \"rnn_mse\", \"value\": 9.540517203276977e-05, \"epoch\": 89}, {\"variable\": \"rnn_mse\", \"value\": 9.49502646108158e-05, \"epoch\": 90}, {\"variable\": \"rnn_mse\", \"value\": 9.723022230900824e-05, \"epoch\": 91}, {\"variable\": \"rnn_mse\", \"value\": 9.994745050789788e-05, \"epoch\": 92}, {\"variable\": \"rnn_mse\", \"value\": 9.60935722105205e-05, \"epoch\": 93}, {\"variable\": \"rnn_mse\", \"value\": 9.21511891647242e-05, \"epoch\": 94}, {\"variable\": \"rnn_mse\", \"value\": 9.551665425533429e-05, \"epoch\": 95}, {\"variable\": \"rnn_mse\", \"value\": 9.680786024546251e-05, \"epoch\": 96}, {\"variable\": \"rnn_mse\", \"value\": 9.795076766749844e-05, \"epoch\": 97}, {\"variable\": \"rnn_mse\", \"value\": 9.476654668105766e-05, \"epoch\": 98}, {\"variable\": \"rnn_mse\", \"value\": 9.027135092765093e-05, \"epoch\": 99}], \"data-690c9458d0df2b2f9b7e6dc5a251350f\": [{\"variable\": \"rnn_1_accuracy\", \"value\": 0.00430689100176096, \"epoch\": 0}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0052083334885537624, \"epoch\": 1}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006610576994717121, \"epoch\": 2}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005008012987673283, \"epoch\": 3}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005809294991195202, \"epoch\": 4}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.004807692486792803, \"epoch\": 5}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.00761217949911952, \"epoch\": 6}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.008413461968302727, \"epoch\": 7}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.00761217949911952, \"epoch\": 8}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0052083334885537624, \"epoch\": 9}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.007011217996478081, \"epoch\": 10}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.00741185899823904, \"epoch\": 11}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.007512019015848637, \"epoch\": 12}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006109775509685278, \"epoch\": 13}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006710737012326717, \"epoch\": 14}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006710737012326717, \"epoch\": 15}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006009615492075682, \"epoch\": 16}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006310096010565758, \"epoch\": 17}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.00761217949911952, \"epoch\": 18}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.007912660017609596, \"epoch\": 19}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0072115384973585606, \"epoch\": 20}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006610576994717121, \"epoch\": 21}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0065104165114462376, \"epoch\": 22}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.00761217949911952, \"epoch\": 23}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006610576994717121, \"epoch\": 24}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006310096010565758, \"epoch\": 25}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005408653989434242, \"epoch\": 26}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005809294991195202, \"epoch\": 27}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.007111378014087677, \"epoch\": 28}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006109775509685278, \"epoch\": 29}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006710737012326717, \"epoch\": 30}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0078125, \"epoch\": 31}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006009615492075682, \"epoch\": 32}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0065104165114462376, \"epoch\": 33}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.007512019015848637, \"epoch\": 34}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005608974490314722, \"epoch\": 35}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.007011217996478081, \"epoch\": 36}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.00741185899823904, \"epoch\": 37}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006810897495597601, \"epoch\": 38}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005809294991195202, \"epoch\": 39}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.007011217996478081, \"epoch\": 40}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.004907852504402399, \"epoch\": 41}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005709134507924318, \"epoch\": 42}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006610576994717121, \"epoch\": 43}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005108173005282879, \"epoch\": 44}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0062099359929561615, \"epoch\": 45}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.004907852504402399, \"epoch\": 46}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005008012987673283, \"epoch\": 47}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.007111378014087677, \"epoch\": 48}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006009615492075682, \"epoch\": 49}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006610576994717121, \"epoch\": 50}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0055088140070438385, \"epoch\": 51}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005909455008804798, \"epoch\": 52}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0062099359929561615, \"epoch\": 53}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.004707532003521919, \"epoch\": 54}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.007011217996478081, \"epoch\": 55}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.004607371985912323, \"epoch\": 56}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0045072115026414394, \"epoch\": 57}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005709134507924318, \"epoch\": 58}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006310096010565758, \"epoch\": 59}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005408653989434242, \"epoch\": 60}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006710737012326717, \"epoch\": 61}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005809294991195202, \"epoch\": 62}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.004707532003521919, \"epoch\": 63}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006610576994717121, \"epoch\": 64}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.004707532003521919, \"epoch\": 65}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005809294991195202, \"epoch\": 66}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0065104165114462376, \"epoch\": 67}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005608974490314722, \"epoch\": 68}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.004807692486792803, \"epoch\": 69}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006710737012326717, \"epoch\": 70}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005008012987673283, \"epoch\": 71}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0062099359929561615, \"epoch\": 72}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006410256493836641, \"epoch\": 73}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0052083334885537624, \"epoch\": 74}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005608974490314722, \"epoch\": 75}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0045072115026414394, \"epoch\": 76}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0055088140070438385, \"epoch\": 77}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006410256493836641, \"epoch\": 78}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005709134507924318, \"epoch\": 79}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.007111378014087677, \"epoch\": 80}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005709134507924318, \"epoch\": 81}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005308493506163359, \"epoch\": 82}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005909455008804798, \"epoch\": 83}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005408653989434242, \"epoch\": 84}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005308493506163359, \"epoch\": 85}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.004907852504402399, \"epoch\": 86}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006009615492075682, \"epoch\": 87}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006109775509685278, \"epoch\": 88}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005408653989434242, \"epoch\": 89}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005008012987673283, \"epoch\": 90}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.004807692486792803, \"epoch\": 91}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0052083334885537624, \"epoch\": 92}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005909455008804798, \"epoch\": 93}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.0052083334885537624, \"epoch\": 94}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005709134507924318, \"epoch\": 95}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005008012987673283, \"epoch\": 96}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.005308493506163359, \"epoch\": 97}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006911057513207197, \"epoch\": 98}, {\"variable\": \"rnn_1_accuracy\", \"value\": 0.006610576994717121, \"epoch\": 99}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002904647495597601, \"epoch\": 0}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0033052884973585606, \"epoch\": 1}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002904647495597601, \"epoch\": 2}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0018028846243396401, \"epoch\": 3}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0012019231216982007, \"epoch\": 4}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0022035257425159216, \"epoch\": 5}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0016025641234591603, \"epoch\": 6}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0012019231216982007, \"epoch\": 7}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0022035257425159216, \"epoch\": 8}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0020032052416354418, \"epoch\": 9}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0017027243738994002, \"epoch\": 10}, {\"variable\": \"rnn_accuracy\", \"value\": 0.005108173005282879, \"epoch\": 11}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0036057692486792803, \"epoch\": 12}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0035056089982390404, \"epoch\": 13}, {\"variable\": \"rnn_accuracy\", \"value\": 0.004907852504402399, \"epoch\": 14}, {\"variable\": \"rnn_accuracy\", \"value\": 0.00410657050088048, \"epoch\": 15}, {\"variable\": \"rnn_accuracy\", \"value\": 0.00390625, \"epoch\": 16}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0011017628712579608, \"epoch\": 17}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0, \"epoch\": 18}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0, \"epoch\": 19}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0, \"epoch\": 20}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0, \"epoch\": 21}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0007011218112893403, \"epoch\": 22}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0032051282469183207, \"epoch\": 23}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002704326994717121, \"epoch\": 24}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0022035257425159216, \"epoch\": 25}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0026041667442768812, \"epoch\": 26}, {\"variable\": \"rnn_accuracy\", \"value\": 0.003004807746037841, \"epoch\": 27}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0025040064938366413, \"epoch\": 28}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0033052884973585606, \"epoch\": 29}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0025040064938366413, \"epoch\": 30}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0034054487477988005, \"epoch\": 31}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002704326994717121, \"epoch\": 32}, {\"variable\": \"rnn_accuracy\", \"value\": 0.00390625, \"epoch\": 33}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0031049679964780807, \"epoch\": 34}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0014022436225786805, \"epoch\": 35}, {\"variable\": \"rnn_accuracy\", \"value\": 0.00190304487477988, \"epoch\": 36}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002904647495597601, \"epoch\": 37}, {\"variable\": \"rnn_accuracy\", \"value\": 0.00190304487477988, \"epoch\": 38}, {\"variable\": \"rnn_accuracy\", \"value\": 0.00380608974955976, \"epoch\": 39}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0022035257425159216, \"epoch\": 40}, {\"variable\": \"rnn_accuracy\", \"value\": 0.003004807746037841, \"epoch\": 41}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002704326994717121, \"epoch\": 42}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0034054487477988005, \"epoch\": 43}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002904647495597601, \"epoch\": 44}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002904647495597601, \"epoch\": 45}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0026041667442768812, \"epoch\": 46}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002904647495597601, \"epoch\": 47}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0032051282469183207, \"epoch\": 48}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0022035257425159216, \"epoch\": 49}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002804487245157361, \"epoch\": 50}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002904647495597601, \"epoch\": 51}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0034054487477988005, \"epoch\": 52}, {\"variable\": \"rnn_accuracy\", \"value\": 0.003004807746037841, \"epoch\": 53}, {\"variable\": \"rnn_accuracy\", \"value\": 0.003004807746037841, \"epoch\": 54}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002704326994717121, \"epoch\": 55}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002804487245157361, \"epoch\": 56}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0032051282469183207, \"epoch\": 57}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0033052884973585606, \"epoch\": 58}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002704326994717121, \"epoch\": 59}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002804487245157361, \"epoch\": 60}, {\"variable\": \"rnn_accuracy\", \"value\": 0.00190304487477988, \"epoch\": 61}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0034054487477988005, \"epoch\": 62}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0025040064938366413, \"epoch\": 63}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0025040064938366413, \"epoch\": 64}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0020032052416354418, \"epoch\": 65}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002704326994717121, \"epoch\": 66}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0022035257425159216, \"epoch\": 67}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0021033654920756817, \"epoch\": 68}, {\"variable\": \"rnn_accuracy\", \"value\": 0.002904647495597601, \"epoch\": 69}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0025040064938366413, \"epoch\": 70}, {\"variable\": \"rnn_accuracy\", \"value\": 0.00190304487477988, \"epoch\": 71}, {\"variable\": \"rnn_accuracy\", \"value\": 0.0023036859929561615, \"epoch\": 72}, {\"variable\": \"rnn_accuracy\", \"value\": 0.008814102970063686, \"epoch\": 73}, {\"variable\": \"rnn_accuracy\", \"value\": 0.010316506028175354, \"epoch\": 74}, {\"variable\": \"rnn_accuracy\", \"value\": 0.01091746799647808, \"epoch\": 75}, {\"variable\": \"rnn_accuracy\", \"value\": 0.010516826994717121, \"epoch\": 76}, {\"variable\": \"rnn_accuracy\", \"value\": 0.012319711968302727, \"epoch\": 77}, {\"variable\": \"rnn_accuracy\", \"value\": 0.009915865026414394, \"epoch\": 78}, {\"variable\": \"rnn_accuracy\", \"value\": 0.012319711968302727, \"epoch\": 79}, {\"variable\": \"rnn_accuracy\", \"value\": 0.010516826994717121, \"epoch\": 80}, {\"variable\": \"rnn_accuracy\", \"value\": 0.011518429033458233, \"epoch\": 81}, {\"variable\": \"rnn_accuracy\", \"value\": 0.013120993971824646, \"epoch\": 82}, {\"variable\": \"rnn_accuracy\", \"value\": 0.010416666977107525, \"epoch\": 83}, {\"variable\": \"rnn_accuracy\", \"value\": 0.013120993971824646, \"epoch\": 84}, {\"variable\": \"rnn_accuracy\", \"value\": 0.01131810899823904, \"epoch\": 85}, {\"variable\": \"rnn_accuracy\", \"value\": 0.011418269015848637, \"epoch\": 86}, {\"variable\": \"rnn_accuracy\", \"value\": 0.013120993971824646, \"epoch\": 87}, {\"variable\": \"rnn_accuracy\", \"value\": 0.010516826994717121, \"epoch\": 88}, {\"variable\": \"rnn_accuracy\", \"value\": 0.010817307978868484, \"epoch\": 89}, {\"variable\": \"rnn_accuracy\", \"value\": 0.012019230984151363, \"epoch\": 90}, {\"variable\": \"rnn_accuracy\", \"value\": 0.010717147029936314, \"epoch\": 91}, {\"variable\": \"rnn_accuracy\", \"value\": 0.009515224024653435, \"epoch\": 92}, {\"variable\": \"rnn_accuracy\", \"value\": 0.010516826994717121, \"epoch\": 93}, {\"variable\": \"rnn_accuracy\", \"value\": 0.010817307978868484, \"epoch\": 94}, {\"variable\": \"rnn_accuracy\", \"value\": 0.011217948980629444, \"epoch\": 95}, {\"variable\": \"rnn_accuracy\", \"value\": 0.01091746799647808, \"epoch\": 96}, {\"variable\": \"rnn_accuracy\", \"value\": 0.009615384973585606, \"epoch\": 97}, {\"variable\": \"rnn_accuracy\", \"value\": 0.012920673005282879, \"epoch\": 98}, {\"variable\": \"rnn_accuracy\", \"value\": 0.011618589982390404, \"epoch\": 99}]}, \"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import training_history\n",
    "\n",
    "hist = training_history(cfg.path_history_pickle)\n",
    "hist.plot_all(cfg.path_plot_folder + 'history.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>rnn_1_accuracy</th>\n",
       "      <th>rnn_1_loss</th>\n",
       "      <th>rnn_1_mse</th>\n",
       "      <th>rnn_accuracy</th>\n",
       "      <th>rnn_loss</th>\n",
       "      <th>rnn_mse</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.309128</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>0.164160</td>\n",
       "      <td>0.164160</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.144968</td>\n",
       "      <td>0.144968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.128990</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.088960</td>\n",
       "      <td>0.088960</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.040030</td>\n",
       "      <td>0.040030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081926</td>\n",
       "      <td>0.006611</td>\n",
       "      <td>0.064021</td>\n",
       "      <td>0.064021</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.017905</td>\n",
       "      <td>0.017905</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056236</td>\n",
       "      <td>0.005008</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.010290</td>\n",
       "      <td>0.010290</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039366</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>0.032720</td>\n",
       "      <td>0.032720</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.006646</td>\n",
       "      <td>0.006646</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.011218</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.005008</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.010917</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.006911</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.012921</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.006611</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.011619</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  rnn_1_accuracy  rnn_1_loss  rnn_1_mse  rnn_accuracy  rnn_loss  \\\n",
       "0   0.309128        0.004307    0.164160   0.164160      0.002905  0.144968   \n",
       "1   0.128990        0.005208    0.088960   0.088960      0.003305  0.040030   \n",
       "2   0.081926        0.006611    0.064021   0.064021      0.002905  0.017905   \n",
       "3   0.056236        0.005008    0.045946   0.045946      0.001803  0.010290   \n",
       "4   0.039366        0.005809    0.032720   0.032720      0.001202  0.006646   \n",
       "..       ...             ...         ...        ...           ...       ...   \n",
       "95  0.000201        0.005709    0.000106   0.000106      0.011218  0.000096   \n",
       "96  0.000203        0.005008    0.000107   0.000107      0.010917  0.000097   \n",
       "97  0.000205        0.005308    0.000107   0.000107      0.009615  0.000098   \n",
       "98  0.000199        0.006911    0.000104   0.000104      0.012921  0.000095   \n",
       "99  0.000189        0.006611    0.000099   0.000099      0.011619  0.000090   \n",
       "\n",
       "     rnn_mse  epoch  \n",
       "0   0.144968      0  \n",
       "1   0.040030      1  \n",
       "2   0.017905      2  \n",
       "3   0.010290      3  \n",
       "4   0.006646      4  \n",
       "..       ...    ...  \n",
       "95  0.000096     95  \n",
       "96  0.000097     96  \n",
       "97  0.000098     97  \n",
       "98  0.000095     98  \n",
       "99  0.000090     99  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse item level stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must turn training mode off before evaluation\n",
    "model = build_model(training=False)\n",
    "from evaluate import strain_eval\n",
    "\n",
    "# Strain full model\n",
    "strain = strain_eval(cfg, data, model)\n",
    "strain.start_evaluate(\n",
    "    test_use_semantic=True,\n",
    "    output=cfg.path_model_folder + 'result_strain_item.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic lesion in Strain\n",
    "strain_ns = strain_eval(cfg, data, model)\n",
    "strain_ns.start_evaluate(\n",
    "    test_use_semantic=False,\n",
    "    output=cfg.path_model_folder + 'result_strain_ns_item.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grain\n",
    "model = build_model(training=False)\n",
    "from evaluate import strain_eval, grain_eval\n",
    "grain = grain_eval(cfg, data, model)\n",
    "grain.start_evaluate(\n",
    "    test_use_semantic=False,\n",
    "    output=cfg.path_model_folder + 'result_grain_item.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KnxCNzMyWah"
   },
   "source": [
    "### Strain plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import vis\n",
    "\n",
    "vis_ns = vis(\n",
    "    cfg.path_model_folder, 'result_strain_ns_item.csv', 'result_grain_item.csv'\n",
    ")\n",
    "\n",
    "vis = vis(\n",
    "    cfg.path_model_folder, 'result_strain_item.csv', 'result_grain_item.csv'\n",
    ")\n",
    "\n",
    "vis_ns.parse_cond_df()\n",
    "vis.parse_cond_df()\n",
    "\n",
    "full = vis.plot_dev('acc').properties(title='Full input')\n",
    "lesion = vis_ns.plot_dev('acc').properties(title='Semantic lesion')\n",
    "\n",
    "strain_plot = full | lesion\n",
    "strain_plot.save(cfg.path_plot_folder + 'strain.html')\n",
    "strain_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesion development deep dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_inter = vis_ns.plot_dev_interactive('acc')\n",
    "dev_inter.save(cfg.path_plot_folder + 'interactive_strain_dev.html')\n",
    "dev_inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesion time plot deep dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_inter = vis_ns.plot_time_interactive('acc')\n",
    "time_inter.save(cfg.path_plot_folder + 'interactive_strain_time.html')\n",
    "time_inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grain plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = vis.plot_dev('acc_small_grain', exp='grain')\n",
    "large = vis.plot_dev('acc_large_grain', exp='grain')\n",
    "grain_plot = small | large\n",
    "grain_plot.save(cfg.path_plot_folder + 'grain.html')\n",
    "grain_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imageability effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis.parse_cond_df(cond_strain='cond_img')\n",
    "# vis.plot_dev('acc', exp='strain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis.parse_cond_df(cond_strain='cond_wf')\n",
    "# vis.plot_dev('acc', exp='strain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phonological regularity effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis.parse_cond_df(cond_strain='cond_pho')\n",
    "# vis.plot_dev('acc', exp='strain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import plot_variables\n",
    "plot_variables(model, cfg.path_plot_folder + 'variables.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write notebook to html (Must save notebook first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only work for manual run\n",
    "# !jupyter nbconvert --to html --ExecutePreprocessor.store_widget_state=True --output-dir=$cfg.path_model_folder basicOSP_master.ipynba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push results to GCP-BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if cfg.bq_dataset is not None:\n",
    "#     from meta import write_all_to_bq\n",
    "\n",
    "#     for attempt in range(10):\n",
    "#         try:\n",
    "#             write_all_to_bq(cfg, strain.i_hist, grain.i_hist)\n",
    "#             print('Results pushed to BQ')\n",
    "#         except:\n",
    "#             from time import sleep\n",
    "#             sleep(10)\n",
    "#         else:\n",
    "#             break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "basicO2P_master.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
