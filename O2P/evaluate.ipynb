{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ny1o7LuorSE8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd 'drive/My Drive/Colab Notebooks/basicO2P'\n",
    "\n",
    "%cd '/home/jupyter/tf/O2P'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Older version for keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AKqtcK64rYnT"
   },
   "outputs": [],
   "source": [
    "%%writefile my_eval.py\n",
    "\n",
    "\n",
    "\n",
    "class training_history():\n",
    "\n",
    "    def __init__(self, pickle_file):\n",
    "        import pandas as pd\n",
    "        import pickle\n",
    "\n",
    "        self.pickle_file = pickle_file\n",
    "        pickle_in = open(self.pickle_file,\"rb\")\n",
    "        hist_obj = pickle.load(pickle_in)\n",
    "        self.history = pd.DataFrame(hist_obj)\n",
    "        self.history['epoch'] = self.history.index\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        return self.plot(col_contains='_loss', plot_title='Loss')\n",
    "\n",
    "    def plot_acc(self):\n",
    "        return self.plot(col_contains='Accuracy', plot_title='Binary accuracy')\n",
    "\n",
    "    def plot_mse(self):\n",
    "        return self.plot(col_contains='_mse', plot_title='MSE')\n",
    "\n",
    "    def plot_all(self, save_file=None):\n",
    "        # plot all 3 training history plots\n",
    "        # Optionally save plot to html file, see altair plot save documentation\n",
    "        self.all_plots = self.plot_loss() & self.plot_acc() | self.plot_mse()\n",
    "        if save_file is not None:\n",
    "            self.all_plots.save(save_file)\n",
    "        return self.all_plots\n",
    "\n",
    "    def plot(self, col_contains, plot_title):\n",
    "        import altair as alt\n",
    "        alt.data_transformers.disable_max_rows()\n",
    "\n",
    "        sel_cols = [col for col in self.history.columns if col_contains in col]\n",
    "        sel_pd = self.history[['epoch']+sel_cols].melt('epoch')\n",
    "\n",
    "        plot = alt.Chart(sel_pd).mark_line().encode(\n",
    "                x='epoch',\n",
    "                y='value',\n",
    "                color=alt.Color('variable', legend=None),\n",
    "                tooltip=['epoch', 'variable']\n",
    "                ).interactive(\n",
    "                ).properties(title=plot_title)\n",
    "        \n",
    "        return plot\n",
    "\n",
    "class strain():\n",
    "\n",
    "    def __init__(self, model_shell, cfg, data):\n",
    "        import pandas as pd\n",
    "        # from my_eval import get_pronunciation_fast, get_all_pronunciations_fast\n",
    "        self.model = model_shell\n",
    "        self.data = data\n",
    "        self.cfg = cfg\n",
    "        self.y_true = get_all_pronunciations_fast(self.data.y_strain, self.data.phon_key)\n",
    "\n",
    "        self.i_hist = pd.DataFrame()  # item history\n",
    "        self.e_hist = pd.DataFrame()  # epoch history\n",
    "\n",
    "    def start_evaluate(self):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        from IPython.display import clear_output\n",
    "\n",
    "        for model_idx, model_h5_name in enumerate(self.cfg.path_weights_list):\n",
    "            # Verbose progress \n",
    "            clear_output(wait=True)\n",
    "            progress = model_idx + 1\n",
    "            totalworks = len(self.cfg.path_weights_list)\n",
    "            print(\"Evaluating Strain:\", np.round(100*progress/totalworks, 0), \"%\")\n",
    "\n",
    "            self.model.load_weights(model_h5_name)\n",
    "            y_pred_matrix = self.model.predict(self.data.x_strain)\n",
    "\n",
    "            for timestep in range(self.cfg.n_timesteps):\n",
    "                # Extract output from test set\n",
    "                y_pred = get_all_pronunciations_fast(y_pred_matrix[timestep], self.data.phon_key)\n",
    "                item_eval, cond_eval = self.eval1_strain(model_h5_name, y_pred, y_pred_matrix, timestep)\n",
    "\n",
    "                # Stack epoch results to global dataframe\n",
    "                self.i_hist = pd.concat([self.i_hist, item_eval], ignore_index=True, axis=0)\n",
    "                self.e_hist = pd.concat([self.e_hist, cond_eval], ignore_index=True, axis=0)\n",
    "\n",
    "        clear_output()\n",
    "        self.parse_strain()\n",
    "        print('All done')\n",
    "\n",
    "    def eval1_strain(self, this_h5_name, y_pred, y_pred_matrix, timestep):\n",
    "        import pandas as pd\n",
    "        # Item level statistics\n",
    "        item_eval = self.data.df_strain # Copy keys\n",
    "        item_eval['model'] = this_h5_name\n",
    "        item_eval['epoch'] = item_eval.model.str.slice(-7,-3).astype(int) \n",
    "        item_eval['timestep'] = timestep\n",
    "        item_eval['output'] = y_pred\n",
    "        item_eval['acc'] = get_accuracy(y_pred, self.y_true)\n",
    "        item_eval['sse'] = get_sse(y_pred_matrix[timestep], self.data.y_strain)\n",
    "\n",
    "        # Flattened condition level statistics\n",
    "        pivot_item = item_eval.pivot_table(['acc', 'sse'], \n",
    "                                           columns=['pho_consistency', 'frequency'])\n",
    "        labels = list(pivot_item.keys().to_series().str.join('_'))\n",
    "        cond_eval = pd.DataFrame([list(pivot_item)], columns=labels)\n",
    "        cond_eval['model'] = this_h5_name\n",
    "        cond_eval['epoch'] = cond_eval.model.str.slice(-7,-3).astype(int)\n",
    "        cond_eval['timestep'] = timestep\n",
    "\n",
    "        return item_eval, cond_eval\n",
    "\n",
    "    def read_eval_from_file(self):\n",
    "        import pandas as pd\n",
    "        self.i_hist = pd.read_csv(self.cfg.strain_item_csv)\n",
    "        self.e_hist = pd.read_csv(self.cfg.strain_epoch_csv)\n",
    "        self.parse_strain()\n",
    "        print('Done')\n",
    "\n",
    "    def parse_strain(self):\n",
    "        self.e_hist_long = self.e_hist[['epoch', 'timestep', 'acc_CON_HF', 'acc_CON_LF', \n",
    "                     'acc_INC_HF', 'acc_INC_LF', 'sse_CON_HF', 'sse_CON_LF', \n",
    "                     'sse_INC_HF', 'sse_INC_LF']].melt(['epoch', 'timestep'])\n",
    "\n",
    "        self.e_hist_long[['metric', 'pho', 'wf']] = self.e_hist_long.variable.str.split(pat='_', expand=True)\n",
    "        self.e_hist_long['condition'] = self.e_hist_long['pho'] + '_' + self.e_hist_long['wf']\n",
    "        self.e_hist_long['sample'] = self.e_hist_long['epoch'] * self.cfg.steps_per_epoch * self.cfg.batch_size\n",
    "        self.e_hist_long['sample_mil'] = self.e_hist_long['sample']/1e6\n",
    "        self.e_hist_long['unit_time'] = self.e_hist_long['timestep'] * self.cfg.tau\n",
    "\n",
    "        self.i_hist['unit_time'] = self.i_hist['timestep'] * self.cfg.tau\n",
    "\n",
    "        self.e_hist_long['model_version'] = self.cfg.code_name\n",
    "        self.e_hist_long['test_set'] = 'strain'\n",
    "\n",
    "        self.i_hist['model_version'] = self.cfg.code_name\n",
    "        self.i_hist['test_set'] = 'strain'\n",
    "\n",
    "        self.i_hist.to_csv(self.cfg.strain_item_csv, index = False)\n",
    "        self.e_hist_long.to_csv(self.cfg.strain_epoch_csv, index = False)\n",
    "\n",
    "    def plot_development(self, plot_time_step=None):\n",
    "        import altair as alt\n",
    "        from altair.expr import datum\n",
    "\n",
    "        if plot_time_step is None: plot_time_step = self.cfg.n_timesteps - 1\n",
    "\n",
    "        base = alt.Chart(self.e_hist_long[lambda df: df['timestep'] == plot_time_step]\n",
    "                                ).mark_line(point=True).encode(\n",
    "            x='sample_mil',\n",
    "            y='value',\n",
    "            color='condition',\n",
    "            tooltip=['epoch', 'timestep', 'sample', 'value']\n",
    "        )\n",
    "\n",
    "        dev_plot = alt.hconcat()\n",
    "        for m in ['acc', 'sse']:\n",
    "            dev_plot |= base.transform_filter(datum.metric == m\n",
    "                                                        ).properties(title=m)\n",
    "\n",
    "        return dev_plot\n",
    "\n",
    "    def plot_time_course(self, plot_epoch=None):\n",
    "        import altair as alt\n",
    "        from altair.expr import datum\n",
    "\n",
    "        if plot_epoch is None: plot_epoch = self.cfg.nEpo\n",
    "\n",
    "        base = alt.Chart(self.e_hist_long[lambda df: df['epoch'] == plot_epoch]\n",
    "                                ).mark_line(point=True).encode(\n",
    "            x='unit_time',\n",
    "            y='value',\n",
    "            color='condition',\n",
    "            tooltip=['epoch', 'timestep', 'sample', 'value']\n",
    "        )\n",
    "\n",
    "        time_plot = alt.hconcat()\n",
    "        for m in ['acc', 'sse']:\n",
    "            time_plot |= base.transform_filter(datum.metric == m\n",
    "                                                        ).properties(title=m)\n",
    "\n",
    "        return time_plot\n",
    "\n",
    "class grain():\n",
    "\n",
    "    def __init__(self, model_shell, cfg, data):\n",
    "        import pandas as pd\n",
    "        self.model = model_shell\n",
    "        self.data = data\n",
    "        self.cfg = cfg\n",
    "        self.y_large_grain_true = get_all_pronunciations_fast(self.data.y_large_grain, \n",
    "                                                              self.data.phon_key)\n",
    "        self.y_small_grain_true = get_all_pronunciations_fast(self.data.y_small_grain, \n",
    "                                                              self.data.phon_key)\n",
    "\n",
    "        self.i_hist = pd.DataFrame()  # item history\n",
    "        self.e_hist = pd.DataFrame()  # epoch history\n",
    "\n",
    "    def start_evaluate(self):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        from IPython.display import clear_output\n",
    "\n",
    "        for model_idx, model_h5_name in enumerate(self.cfg.path_weights_list):\n",
    "\n",
    "            # Verbose progress \n",
    "            clear_output(wait=True)\n",
    "            progress = model_idx + 1\n",
    "            totalworks = len(self.cfg.path_weights_list)\n",
    "            print(\"Evaluating Grain:\", np.round(100*progress/totalworks, 0), \"%\")\n",
    "\n",
    "            self.model.load_weights(model_h5_name)\n",
    "            y_pred_matrix = self.model.predict(self.data.x_grain)\n",
    "\n",
    "            for timestep in range(self.cfg.n_timesteps):\n",
    "\n",
    "                # Extract output from test set\n",
    "                y_pred = get_all_pronunciations_fast(y_pred_matrix[timestep], self.data.phon_key)\n",
    "                item_eval, cond_eval = self.eval1_grain(model_h5_name, y_pred, y_pred_matrix, timestep)\n",
    "\n",
    "                # Stack epoch results to global dataframe\n",
    "                self.i_hist = pd.concat([self.i_hist, item_eval], ignore_index=True, axis=0)\n",
    "                self.e_hist = pd.concat([self.e_hist, cond_eval], ignore_index=True, axis=0)\n",
    "\n",
    "        clear_output()\n",
    "        self.parse_grain()\n",
    "        print('Done')\n",
    "\n",
    "    def eval1_grain(self, this_h5_name, y_pred, y_pred_matrix, timestep):\n",
    "        import pandas as pd\n",
    "        # Item level statistics\n",
    "        item_eval = self.data.df_grain # Copy keys\n",
    "        item_eval['model'] = this_h5_name\n",
    "        item_eval['epoch'] = item_eval.model.str.slice(-7,-3).astype(int) \n",
    "        item_eval['timestep'] = timestep\n",
    "        item_eval['output'] = y_pred\n",
    "        item_eval['acc_large_grain'] = get_accuracy(y_pred, self.y_large_grain_true)\n",
    "        item_eval['acc_small_grain'] = get_accuracy(y_pred, self.y_small_grain_true)\n",
    "        item_eval['acc_acceptable'] = item_eval['acc_large_grain'] + item_eval['acc_small_grain']\n",
    "        item_eval['sse_large_grain'] = get_sse(y_pred_matrix[timestep], self.data.y_large_grain)\n",
    "        item_eval['sse_small_grain'] = get_sse(y_pred_matrix[timestep], self.data.y_small_grain)\n",
    "        item_eval['sse_acceptable'] = item_eval[['sse_large_grain','sse_small_grain']].min(axis=1)\n",
    "\n",
    "        # Flattened condition level statistics\n",
    "        pivot_item = item_eval.pivot_table(['acc_large_grain', 'acc_small_grain', 'acc_acceptable', \n",
    "                                            'sse_small_grain', 'sse_large_grain'], \n",
    "                                           columns='condition')\n",
    "        labels = [None] * 10\n",
    "\n",
    "        for i, col in enumerate(pivot_item.keys().values):\n",
    "            labels[i*5:(i+1)*5] = list(pivot_item.index.values + '_' + col)\n",
    "\n",
    "        cond_eval = pd.DataFrame([pivot_item.values.flatten('F')], columns=labels)\n",
    "        cond_eval['model'] = this_h5_name\n",
    "        cond_eval['epoch'] = cond_eval.model.str.slice(-7,-3).astype(int)\n",
    "        cond_eval['timestep'] = timestep\n",
    "\n",
    "        return item_eval, cond_eval\n",
    "\n",
    "    def read_eval_from_file(self):\n",
    "        import pandas as pd\n",
    "        self.i_hist = pd.read_csv(self.cfg.grain_item_csv)\n",
    "        self.e_hist = pd.read_csv(self.cfg.grain_epoch_csv)\n",
    "        self.parse_grain()\n",
    "        print('Done')\n",
    "\n",
    "    def parse_grain(self):\n",
    "        self.e_hist['sample'] = self.e_hist['epoch'] * self.cfg.steps_per_epoch * self.cfg.batch_size\n",
    "        self.e_hist['sample_mil'] = self.e_hist['sample']/1e6\n",
    "        self.e_hist['unit_time'] = self.e_hist['timestep'] * self.cfg.tau\n",
    "\n",
    "        self.e_hist_long = self.e_hist[['epoch', 'timestep', 'sample', 'sample_mil', 'unit_time',\n",
    "                        'acc_large_grain_ambiguous', 'acc_small_grain_ambiguous',\n",
    "                        'acc_large_grain_unambiguous', 'acc_small_grain_unambiguous',\n",
    "                        'sse_large_grain_ambiguous', 'sse_small_grain_ambiguous', \n",
    "                        'sse_large_grain_unambiguous', 'sse_small_grain_unambiguous']\n",
    "                        ].melt(['epoch', 'timestep', 'sample', 'sample_mil', 'unit_time'])\n",
    "\n",
    "        self.e_hist_long[['metric', 'res1', 'res2', 'condition']] = self.e_hist_long.variable.str.split(pat='_', expand=True)\n",
    "        self.e_hist_long['respond'] = self.e_hist_long['res1'] + '_' + self.e_hist_long['res2']\n",
    "        self.e_hist_long['cond_resp'] = self.e_hist_long['condition'] + '_' + self.e_hist_long['respond']\n",
    "        self.e_hist_long = self.e_hist_long.drop(columns=['res1', 'res2', 'variable'])\n",
    "\n",
    "        self.e_hist_long['model_version'] = self.cfg.code_name\n",
    "        self.e_hist_long['test_set'] = 'grain'\n",
    "\n",
    "        self.i_hist['model_version'] = self.cfg.code_name\n",
    "        self.i_hist['test_set'] = 'grain'\n",
    "\n",
    "        self.i_hist.to_csv(self.cfg.grain_item_csv, index = False)\n",
    "        self.e_hist_long.to_csv(self.cfg.grain_epoch_csv, index = False)\n",
    "\n",
    "    def plot_development(self, plot_time_step=None):\n",
    "        import altair as alt\n",
    "        from altair.expr import datum\n",
    "\n",
    "        if plot_time_step is None: plot_time_step = self.cfg.n_timesteps - 1\n",
    "\n",
    "        data = self.e_hist_long[lambda df: df['timestep'] == plot_time_step]\n",
    "        sel = alt.selection(type='single', on='click', fields=['condition'], empty='all')\n",
    "\n",
    "        base = alt.Chart(data).add_selection(sel).mark_line(point=True).encode(\n",
    "            x='sample_mil',\n",
    "            y='value',\n",
    "            color='cond_resp',\n",
    "            opacity = alt.condition(sel, alt.value(1), alt.value(0)),\n",
    "            tooltip=['epoch', 'timestep', 'sample', 'value'])\n",
    "\n",
    "        dev_plot = alt.hconcat()\n",
    "        for m in ['acc', 'sse']:\n",
    "            dev_plot |= base.transform_filter(datum.metric == m\n",
    "                             ).properties(title=m)\n",
    "\n",
    "        return dev_plot\n",
    "\n",
    "\n",
    "    def plot_time_course(self, plot_epoch=None):\n",
    "        import altair as alt\n",
    "        from altair.expr import datum\n",
    "\n",
    "        if plot_epoch is None: plot_epoch = self.cfg.nEpo\n",
    "\n",
    "        data = self.e_hist_long[lambda df: df['epoch'] == plot_epoch]\n",
    "        sel = alt.selection(type='single', on='click', fields=['condition'], empty='all')\n",
    "\n",
    "        base = alt.Chart(data).add_selection(sel).mark_line(point=True).encode(\n",
    "            x='unit_time',\n",
    "            y='value',\n",
    "            color='cond_resp',\n",
    "            opacity = alt.condition(sel, alt.value(1), alt.value(0)),\n",
    "            tooltip=['epoch', 'timestep', 'sample', 'value'])\n",
    "\n",
    "        dev_plot = alt.hconcat()\n",
    "        for m in ['acc', 'sse']:\n",
    "            dev_plot |= base.transform_filter(datum.metric == m\n",
    "                             ).properties(title=m)\n",
    "\n",
    "        return dev_plot\n",
    "\n",
    "\n",
    "################################################################\n",
    "################### function for evaluations ###################\n",
    "################################################################\n",
    "\n",
    "def get_pronunciation_fast(act, phon_key):\n",
    "    import numpy as np\n",
    "\n",
    "    phonemes = list(phon_key.keys())\n",
    "    act10 = np.tile([v for k, v in phon_key.items()], 10)\n",
    "\n",
    "    d = np.abs(act10 - act)\n",
    "    d_mat = np.reshape(d, (38, 10, 25))\n",
    "    sumd_mat = np.squeeze(np.sum(d_mat, 2))\n",
    "    map_idx = np.argmin(sumd_mat,0)\n",
    "    out = str()\n",
    "    for x in map_idx: out += phonemes[x]\n",
    "    return out\n",
    "\n",
    "def get_all_pronunciations_fast(act, phon_key):\n",
    "    import numpy as np\n",
    "    return np.apply_along_axis(get_pronunciation_fast, 1, act, phon_key)\n",
    "\n",
    "def get_accuracy(output, target):\n",
    "    import numpy as np\n",
    "    # Pronunciation level metric\n",
    "    current_word = 0\n",
    "    accuracy_list = []\n",
    "    target = target.tolist()\n",
    "    for pronunciation in output:\n",
    "        accuracy_list.append(int(pronunciation == target[current_word]))\n",
    "        current_word += 1\n",
    "    return np.array(accuracy_list)\n",
    "\n",
    "def get_mean_accuracy(output, target):\n",
    "    import numpy as np\n",
    "    # Pronunciation level metric\n",
    "    return np.mean(get_accuracy(output, target))\n",
    "\n",
    "def get_sse(output, target):\n",
    "    import numpy as np\n",
    "    # output level metric\n",
    "    # Sum of square error\n",
    "    sse_list = []\n",
    "    target = target.tolist()\n",
    "    for i in range(len(output)):\n",
    "        sse_list.append(np.sum(np.square(output[i] - target[i])))\n",
    "    return np.array(sse_list)\n",
    "\n",
    "def get_mean_sse(output, target):\n",
    "    import numpy as np\n",
    "    # Mean sum of square error\n",
    "    # ouput level metric\n",
    "    return np.mean(get_sse(output, target)) / len(output)\n",
    "\n",
    "def gen_pkey(p_file=\"patterns/mapping_v2.txt\"):\n",
    "    import pandas as pd\n",
    "    # read phonological patterns from the mapping file\n",
    "    # See Harm & Seidenberg PDF file\n",
    "    mapping = pd.read_table(p_file, header=None, delim_whitespace=True)\n",
    "    m_dict = mapping.set_index(0).T.to_dict('list')\n",
    "    return m_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile my_eval.py\n",
    "\n",
    "class training_history():\n",
    "\n",
    "    def __init__(self, pickle_file):\n",
    "        import pandas as pd\n",
    "        import pickle\n",
    "\n",
    "        self.pickle_file = pickle_file\n",
    "        pickle_in = open(self.pickle_file,\"rb\")\n",
    "        hist_obj = pickle.load(pickle_in)\n",
    "        self.history = pd.DataFrame(hist_obj)\n",
    "        self.history['epoch'] = self.history.index\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        return self.plot(col_contains='_loss', plot_title='Loss')\n",
    "\n",
    "    def plot_acc(self):\n",
    "        return self.plot(col_contains='Accuracy', plot_title='Binary accuracy')\n",
    "\n",
    "    def plot_mse(self):\n",
    "        return self.plot(col_contains='_mse', plot_title='MSE')\n",
    "\n",
    "    def plot_all(self, save_file=None):\n",
    "        # plot all 3 training history plots\n",
    "        # Optionally save plot to html file, see altair plot save documentation\n",
    "        self.all_plots = self.plot_loss() & self.plot_acc() | self.plot_mse()\n",
    "        if save_file is not None:\n",
    "            self.all_plots.save(save_file)\n",
    "        return self.all_plots\n",
    "\n",
    "    def plot(self, col_contains, plot_title):\n",
    "        import altair as alt\n",
    "        alt.data_transformers.disable_max_rows()\n",
    "\n",
    "        sel_cols = [col for col in self.history.columns if col_contains in col]\n",
    "        sel_pd = self.history[['epoch']+sel_cols].melt('epoch')\n",
    "\n",
    "        plot = alt.Chart(sel_pd).mark_line().encode(\n",
    "                x='epoch',\n",
    "                y='value',\n",
    "                color=alt.Color('variable', legend=None),\n",
    "                tooltip=['epoch', 'variable']\n",
    "                ).interactive(\n",
    "                ).properties(title=plot_title)\n",
    "        \n",
    "        return plot\n",
    "\n",
    "class strain():\n",
    "\n",
    "    def __init__(self, model_shell, cfg, data):\n",
    "        import pandas as pd\n",
    "        # from my_eval import get_pronunciation_fast, get_all_pronunciations_fast\n",
    "        self.model = model_shell\n",
    "        \n",
    "        self.data = data\n",
    "        self.cfg = cfg\n",
    "        self.y_true = get_all_pronunciations_fast(self.data.y_strain, self.data.phon_key)\n",
    "\n",
    "        self.i_hist = pd.DataFrame()  # item history\n",
    "        self.e_hist = pd.DataFrame()  # epoch history\n",
    "\n",
    "    def start_evaluate(self):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        from IPython.display import clear_output\n",
    "\n",
    "        for model_idx, model_h5_name in enumerate(self.cfg.path_weights_list):\n",
    "            # Verbose progress \n",
    "            clear_output(wait=True)\n",
    "            progress = model_idx + 1\n",
    "            totalworks = len(self.cfg.path_weights_list)\n",
    "            print(\"Evaluating Strain:\", np.round(100*progress/totalworks, 0), \"%\")\n",
    "\n",
    "            self.model.load_weights(model_h5_name)\n",
    "            y_pred_matrix = self.model.predict(self.data.x_strain)\n",
    "\n",
    "            for timestep in range(self.cfg.n_timesteps):\n",
    "                # Extract output from test set\n",
    "                y_pred = get_all_pronunciations_fast(y_pred_matrix[timestep], self.data.phon_key)\n",
    "                item_eval, cond_eval = self.eval1_strain(model_h5_name, y_pred, y_pred_matrix, timestep)\n",
    "\n",
    "                # Stack epoch results to global dataframe\n",
    "                self.i_hist = pd.concat([self.i_hist, item_eval], ignore_index=True, axis=0)\n",
    "                self.e_hist = pd.concat([self.e_hist, cond_eval], ignore_index=True, axis=0)\n",
    "\n",
    "        clear_output()\n",
    "        self.parse_strain()\n",
    "        print('All done')\n",
    "\n",
    "    def eval1_strain(self, this_h5_name, y_pred, y_pred_matrix, timestep):\n",
    "        import pandas as pd\n",
    "        # Item level statistics\n",
    "        item_eval = self.data.df_strain # Copy keys\n",
    "        item_eval['model'] = this_h5_name\n",
    "        item_eval['epoch'] = item_eval.model.str.slice(-7,-3).astype(int) \n",
    "        item_eval['timestep'] = timestep\n",
    "        item_eval['output'] = y_pred\n",
    "        item_eval['acc'] = get_accuracy(y_pred, self.y_true)\n",
    "        item_eval['sse'] = get_sse(y_pred_matrix[timestep], self.data.y_strain)\n",
    "\n",
    "        # Flattened condition level statistics\n",
    "        pivot_item = item_eval.pivot_table(['acc', 'sse'], \n",
    "                                           columns=['pho_consistency', 'frequency'])\n",
    "        labels = list(pivot_item.keys().to_series().str.join('_'))\n",
    "        cond_eval = pd.DataFrame([list(pivot_item)], columns=labels)\n",
    "        cond_eval['model'] = this_h5_name\n",
    "        cond_eval['epoch'] = cond_eval.model.str.slice(-7,-3).astype(int)\n",
    "        cond_eval['timestep'] = timestep\n",
    "\n",
    "        return item_eval, cond_eval\n",
    "\n",
    "    def read_eval_from_file(self):\n",
    "        import pandas as pd\n",
    "        self.i_hist = pd.read_csv(self.cfg.strain_item_csv)\n",
    "        self.e_hist = pd.read_csv(self.cfg.strain_epoch_csv)\n",
    "        self.parse_strain()\n",
    "        print('Done')\n",
    "\n",
    "    def parse_strain(self):\n",
    "        self.e_hist_long = self.e_hist[['epoch', 'timestep', 'acc_CON_HF', 'acc_CON_LF', \n",
    "                     'acc_INC_HF', 'acc_INC_LF', 'sse_CON_HF', 'sse_CON_LF', \n",
    "                     'sse_INC_HF', 'sse_INC_LF']].melt(['epoch', 'timestep'])\n",
    "\n",
    "        self.e_hist_long[['metric', 'pho', 'wf']] = self.e_hist_long.variable.str.split(pat='_', expand=True)\n",
    "        self.e_hist_long['condition'] = self.e_hist_long['pho'] + '_' + self.e_hist_long['wf']\n",
    "        self.e_hist_long['sample'] = self.e_hist_long['epoch'] * self.cfg.steps_per_epoch * self.cfg.batch_size\n",
    "        self.e_hist_long['sample_mil'] = self.e_hist_long['sample']/1e6\n",
    "        self.e_hist_long['unit_time'] = self.e_hist_long['timestep'] * self.cfg.tau\n",
    "\n",
    "        self.i_hist['unit_time'] = self.i_hist['timestep'] * self.cfg.tau\n",
    "\n",
    "        self.e_hist_long['model_version'] = self.cfg.code_name\n",
    "        self.e_hist_long['test_set'] = 'strain'\n",
    "\n",
    "        self.i_hist['model_version'] = self.cfg.code_name\n",
    "        self.i_hist['test_set'] = 'strain'\n",
    "\n",
    "        self.i_hist.to_csv(self.cfg.strain_item_csv, index = False)\n",
    "        self.e_hist_long.to_csv(self.cfg.strain_epoch_csv, index = False)\n",
    "\n",
    "    def plot_development(self, plot_time_step=None):\n",
    "        import altair as alt\n",
    "        from altair.expr import datum\n",
    "\n",
    "        if plot_time_step is None: plot_time_step = self.cfg.n_timesteps - 1\n",
    "\n",
    "        base = alt.Chart(self.e_hist_long[lambda df: df['timestep'] == plot_time_step]\n",
    "                                ).mark_line(point=True).encode(\n",
    "            x='sample_mil',\n",
    "            y='value',\n",
    "            color='condition',\n",
    "            tooltip=['epoch', 'timestep', 'sample', 'value']\n",
    "        )\n",
    "\n",
    "        dev_plot = alt.hconcat()\n",
    "        for m in ['acc', 'sse']:\n",
    "            dev_plot |= base.transform_filter(datum.metric == m\n",
    "                                                        ).properties(title=m)\n",
    "\n",
    "        return dev_plot\n",
    "\n",
    "    def plot_time_course(self, plot_epoch=None):\n",
    "        import altair as alt\n",
    "        from altair.expr import datum\n",
    "\n",
    "        if plot_epoch is None: plot_epoch = self.cfg.nEpo\n",
    "\n",
    "        base = alt.Chart(self.e_hist_long[lambda df: df['epoch'] == plot_epoch]\n",
    "                                ).mark_line(point=True).encode(\n",
    "            x='unit_time',\n",
    "            y='value',\n",
    "            color='condition',\n",
    "            tooltip=['epoch', 'timestep', 'sample', 'value']\n",
    "        )\n",
    "\n",
    "        time_plot = alt.hconcat()\n",
    "        for m in ['acc', 'sse']:\n",
    "            time_plot |= base.transform_filter(datum.metric == m\n",
    "                                                        ).properties(title=m)\n",
    "\n",
    "        return time_plot\n",
    "\n",
    "class grain():\n",
    "\n",
    "    def __init__(self, model_shell, cfg, data):\n",
    "        import pandas as pd\n",
    "        self.model = model_shell\n",
    "        self.data = data\n",
    "        self.cfg = cfg\n",
    "        self.y_large_grain_true = get_all_pronunciations_fast(self.data.y_large_grain, \n",
    "                                                              self.data.phon_key)\n",
    "        self.y_small_grain_true = get_all_pronunciations_fast(self.data.y_small_grain, \n",
    "                                                              self.data.phon_key)\n",
    "\n",
    "        self.i_hist = pd.DataFrame()  # item history\n",
    "        self.e_hist = pd.DataFrame()  # epoch history\n",
    "\n",
    "    def start_evaluate(self):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        from IPython.display import clear_output\n",
    "\n",
    "        for model_idx, model_h5_name in enumerate(self.cfg.path_weights_list):\n",
    "\n",
    "            # Verbose progress \n",
    "            clear_output(wait=True)\n",
    "            progress = model_idx + 1\n",
    "            totalworks = len(self.cfg.path_weights_list)\n",
    "            print(\"Evaluating Grain:\", np.round(100*progress/totalworks, 0), \"%\")\n",
    "\n",
    "            self.model.load_weights(model_h5_name)\n",
    "            y_pred_matrix = self.model.predict(self.data.x_grain)\n",
    "\n",
    "            for timestep in range(self.cfg.n_timesteps):\n",
    "\n",
    "                # Extract output from test set\n",
    "                y_pred = get_all_pronunciations_fast(y_pred_matrix[timestep], self.data.phon_key)\n",
    "                item_eval, cond_eval = self.eval1_grain(model_h5_name, y_pred, y_pred_matrix, timestep)\n",
    "\n",
    "                # Stack epoch results to global dataframe\n",
    "                self.i_hist = pd.concat([self.i_hist, item_eval], ignore_index=True, axis=0)\n",
    "                self.e_hist = pd.concat([self.e_hist, cond_eval], ignore_index=True, axis=0)\n",
    "\n",
    "        clear_output()\n",
    "        self.parse_grain()\n",
    "        print('Done')\n",
    "\n",
    "    def eval1_grain(self, this_h5_name, y_pred, y_pred_matrix, timestep):\n",
    "        import pandas as pd\n",
    "        # Item level statistics\n",
    "        item_eval = self.data.df_grain # Copy keys\n",
    "        item_eval['model'] = this_h5_name\n",
    "        item_eval['epoch'] = item_eval.model.str.slice(-7,-3).astype(int) \n",
    "        item_eval['timestep'] = timestep\n",
    "        item_eval['output'] = y_pred\n",
    "        item_eval['acc_large_grain'] = get_accuracy(y_pred, self.y_large_grain_true)\n",
    "        item_eval['acc_small_grain'] = get_accuracy(y_pred, self.y_small_grain_true)\n",
    "        item_eval['acc_acceptable'] = item_eval['acc_large_grain'] + item_eval['acc_small_grain']\n",
    "        item_eval['sse_large_grain'] = get_sse(y_pred_matrix[timestep], self.data.y_large_grain)\n",
    "        item_eval['sse_small_grain'] = get_sse(y_pred_matrix[timestep], self.data.y_small_grain)\n",
    "        item_eval['sse_acceptable'] = item_eval[['sse_large_grain','sse_small_grain']].min(axis=1)\n",
    "\n",
    "        # Flattened condition level statistics\n",
    "        pivot_item = item_eval.pivot_table(['acc_large_grain', 'acc_small_grain', 'acc_acceptable', \n",
    "                                            'sse_small_grain', 'sse_large_grain'], \n",
    "                                           columns='condition')\n",
    "        labels = [None] * 10\n",
    "\n",
    "        for i, col in enumerate(pivot_item.keys().values):\n",
    "            labels[i*5:(i+1)*5] = list(pivot_item.index.values + '_' + col)\n",
    "\n",
    "        cond_eval = pd.DataFrame([pivot_item.values.flatten('F')], columns=labels)\n",
    "        cond_eval['model'] = this_h5_name\n",
    "        cond_eval['epoch'] = cond_eval.model.str.slice(-7,-3).astype(int)\n",
    "        cond_eval['timestep'] = timestep\n",
    "\n",
    "        return item_eval, cond_eval\n",
    "\n",
    "    def read_eval_from_file(self):\n",
    "        import pandas as pd\n",
    "        self.i_hist = pd.read_csv(self.cfg.grain_item_csv)\n",
    "        self.e_hist = pd.read_csv(self.cfg.grain_epoch_csv)\n",
    "        self.parse_grain()\n",
    "        print('Done')\n",
    "\n",
    "    def parse_grain(self):\n",
    "        self.e_hist['sample'] = self.e_hist['epoch'] * self.cfg.steps_per_epoch * self.cfg.batch_size\n",
    "        self.e_hist['sample_mil'] = self.e_hist['sample']/1e6\n",
    "        self.e_hist['unit_time'] = self.e_hist['timestep'] * self.cfg.tau\n",
    "\n",
    "        self.e_hist_long = self.e_hist[['epoch', 'timestep', 'sample', 'sample_mil', 'unit_time',\n",
    "                        'acc_large_grain_ambiguous', 'acc_small_grain_ambiguous',\n",
    "                        'acc_large_grain_unambiguous', 'acc_small_grain_unambiguous',\n",
    "                        'sse_large_grain_ambiguous', 'sse_small_grain_ambiguous', \n",
    "                        'sse_large_grain_unambiguous', 'sse_small_grain_unambiguous']\n",
    "                        ].melt(['epoch', 'timestep', 'sample', 'sample_mil', 'unit_time'])\n",
    "\n",
    "        self.e_hist_long[['metric', 'res1', 'res2', 'condition']] = self.e_hist_long.variable.str.split(pat='_', expand=True)\n",
    "        self.e_hist_long['respond'] = self.e_hist_long['res1'] + '_' + self.e_hist_long['res2']\n",
    "        self.e_hist_long['cond_resp'] = self.e_hist_long['condition'] + '_' + self.e_hist_long['respond']\n",
    "        self.e_hist_long = self.e_hist_long.drop(columns=['res1', 'res2', 'variable'])\n",
    "\n",
    "        self.e_hist_long['model_version'] = self.cfg.code_name\n",
    "        self.e_hist_long['test_set'] = 'grain'\n",
    "\n",
    "        self.i_hist['model_version'] = self.cfg.code_name\n",
    "        self.i_hist['test_set'] = 'grain'\n",
    "\n",
    "        self.i_hist.to_csv(self.cfg.grain_item_csv, index = False)\n",
    "        self.e_hist_long.to_csv(self.cfg.grain_epoch_csv, index = False)\n",
    "\n",
    "    def plot_development(self, plot_time_step=None):\n",
    "        import altair as alt\n",
    "        from altair.expr import datum\n",
    "\n",
    "        if plot_time_step is None: plot_time_step = self.cfg.n_timesteps - 1\n",
    "\n",
    "        data = self.e_hist_long[lambda df: df['timestep'] == plot_time_step]\n",
    "        sel = alt.selection(type='single', on='click', fields=['condition'], empty='all')\n",
    "\n",
    "        base = alt.Chart(data).add_selection(sel).mark_line(point=True).encode(\n",
    "            x='sample_mil',\n",
    "            y='value',\n",
    "            color='cond_resp',\n",
    "            opacity = alt.condition(sel, alt.value(1), alt.value(0)),\n",
    "            tooltip=['epoch', 'timestep', 'sample', 'value'])\n",
    "\n",
    "        dev_plot = alt.hconcat()\n",
    "        for m in ['acc', 'sse']:\n",
    "            dev_plot |= base.transform_filter(datum.metric == m\n",
    "                             ).properties(title=m)\n",
    "\n",
    "        return dev_plot\n",
    "\n",
    "\n",
    "    def plot_time_course(self, plot_epoch=None):\n",
    "        import altair as alt\n",
    "        from altair.expr import datum\n",
    "\n",
    "        if plot_epoch is None: plot_epoch = self.cfg.nEpo\n",
    "\n",
    "        data = self.e_hist_long[lambda df: df['epoch'] == plot_epoch]\n",
    "        sel = alt.selection(type='single', on='click', fields=['condition'], empty='all')\n",
    "\n",
    "        base = alt.Chart(data).add_selection(sel).mark_line(point=True).encode(\n",
    "            x='unit_time',\n",
    "            y='value',\n",
    "            color='cond_resp',\n",
    "            opacity = alt.condition(sel, alt.value(1), alt.value(0)),\n",
    "            tooltip=['epoch', 'timestep', 'sample', 'value'])\n",
    "\n",
    "        dev_plot = alt.hconcat()\n",
    "        for m in ['acc', 'sse']:\n",
    "            dev_plot |= base.transform_filter(datum.metric == m\n",
    "                             ).properties(title=m)\n",
    "\n",
    "        return dev_plot\n",
    "\n",
    "\n",
    "################################################################\n",
    "################### function for evaluations ###################\n",
    "################################################################\n",
    "\n",
    "def get_pronunciation_fast(act, phon_key):\n",
    "    import numpy as np\n",
    "\n",
    "    phonemes = list(phon_key.keys())\n",
    "    act10 = np.tile([v for k, v in phon_key.items()], 10)\n",
    "\n",
    "    d = np.abs(act10 - act)\n",
    "    d_mat = np.reshape(d, (38, 10, 25))\n",
    "    sumd_mat = np.squeeze(np.sum(d_mat, 2))\n",
    "    map_idx = np.argmin(sumd_mat,0)\n",
    "    out = str()\n",
    "    for x in map_idx: out += phonemes[x]\n",
    "    return out\n",
    "\n",
    "def get_all_pronunciations_fast(act, phon_key):\n",
    "    import numpy as np\n",
    "    return np.apply_along_axis(get_pronunciation_fast, 1, act, phon_key)\n",
    "\n",
    "def get_accuracy(output, target):\n",
    "    import numpy as np\n",
    "    # Pronunciation level metric\n",
    "    current_word = 0\n",
    "    accuracy_list = []\n",
    "    target = target.tolist()\n",
    "    for pronunciation in output:\n",
    "        accuracy_list.append(int(pronunciation == target[current_word]))\n",
    "        current_word += 1\n",
    "    return np.array(accuracy_list)\n",
    "\n",
    "def get_mean_accuracy(output, target):\n",
    "    import numpy as np\n",
    "    # Pronunciation level metric\n",
    "    return np.mean(get_accuracy(output, target))\n",
    "\n",
    "def get_sse(output, target):\n",
    "    import numpy as np\n",
    "    # output level metric\n",
    "    # Sum of square error\n",
    "    sse_list = []\n",
    "    target = target.tolist()\n",
    "    for i in range(len(output)):\n",
    "        sse_list.append(np.sum(np.square(output[i] - target[i])))\n",
    "    return np.array(sse_list)\n",
    "\n",
    "def get_mean_sse(output, target):\n",
    "    import numpy as np\n",
    "    # Mean sum of square error\n",
    "    # ouput level metric\n",
    "    return np.mean(get_sse(output, target)) / len(output)\n",
    "\n",
    "def gen_pkey(p_file=\"patterns/mapping_v2.txt\"):\n",
    "    import pandas as pd\n",
    "    # read phonological patterns from the mapping file\n",
    "    # See Harm & Seidenberg PDF file\n",
    "    mapping = pd.read_table(p_file, header=None, delim_whitespace=True)\n",
    "    m_dict = mapping.set_index(0).T.to_dict('list')\n",
    "    return m_dict\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP/JcRPTcW+JWH88YI34eun",
   "collapsed_sections": [],
   "name": "evaluate.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
