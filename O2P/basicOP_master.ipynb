{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbgouQwZ1Y1f"
   },
   "source": [
    "# O->P model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- noise to weight implemented\n",
    "- Pretrain attractor implementing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i80sCQZmPNVw"
   },
   "source": [
    "## Master config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOtePZ2ddw8d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\", '\\n')\n",
    "!ls\n",
    "\n",
    "# Becareful on the variable type in each cfg setting\n",
    "# Do not use integer (e.g., 1, 2, 3, 0) in those variables\n",
    "# that can be float32 (e.g., w_oh_noise, tau...)\n",
    "# Use integer with a dot instead (e.g., 1., 2., 3., 0.)\n",
    "from misc import model_cfg\n",
    "\n",
    "cfg = model_cfg(code_name='RNN_v0.58', \n",
    "                sample_name='hs04', \n",
    "                sample_rng_seed=303,\n",
    "                hidden_units=150, \n",
    "                pho_units=250, \n",
    "                cleanup_units=50,\n",
    "                embed_attractor='p_task_v0.02',\n",
    "                w_oh_noise=0.,\n",
    "                w_hp_noise=0.,\n",
    "                w_pp_noise=4.,\n",
    "                w_pc_noise=4.,\n",
    "                w_cp_noise=4.,\n",
    "                act_p_noise=0.,\n",
    "                tau=0.2, \n",
    "                unit_time=4., \n",
    "                n_mil_sample=1., \n",
    "                batch_size=128, \n",
    "                rnn_activation = 'sigmoid',\n",
    "                w_initializer = 'glorot_uniform',\n",
    "                learning_rate=0.01,\n",
    "                save_freq=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0IwxbE29_0yx"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HFTsfceXUGIh"
   },
   "source": [
    "## Build model\n",
    "Fully custom 4-layer recurrent time-averaged input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9892,
     "status": "ok",
     "timestamp": 1581348683298,
     "user": {
      "displayName": "Jason Lo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB2QWsl_vzihRifHZBxq7M-ofOQkG8cBrTfFhl_Kzs=s64",
      "userId": "10618067338459780934"
     },
     "user_tz": 300
    },
    "id": "h7_bIy_lOX4B",
    "outputId": "e1d6ba90-bcb9-465f-9a12-b303b3cc0ebf"
   },
   "outputs": [],
   "source": [
    "def buildModel(training=True):\n",
    "    from tensorflow.keras import Model\n",
    "    from tensorflow.keras.layers import Layer, Input\n",
    "    from custom_layer import rnn\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "    # Train/test mode checking\n",
    "    if training is True:\n",
    "        cfg.w_oh_noise = cfg.w_oh_noise_backup\n",
    "        cfg.w_hp_noise = cfg.w_hp_noise_backup\n",
    "        cfg.w_pp_noise = cfg.w_pp_noise_backup\n",
    "        cfg.w_pc_noise = cfg.w_pc_noise_backup\n",
    "        cfg.w_cp_noise = cfg.w_cp_noise_backup\n",
    "        cfg.act_p_noise = cfg.act_p_noise_backup\n",
    "    else:\n",
    "        cfg.w_oh_noise = 0\n",
    "        cfg.w_hp_noise = 0\n",
    "        cfg.w_pp_noise = 0\n",
    "        cfg.w_pc_noise = 0\n",
    "        cfg.w_cp_noise = 0\n",
    "        cfg.act_p_noise = 0\n",
    "\n",
    "    input_o = Input(shape=(119,))\n",
    "    rnn_model = rnn(cfg)(input_o)\n",
    "    model = Model(input_o, rnn_model)\n",
    "\n",
    "    adam = Adam(learning_rate=cfg.learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer=adam,\n",
    "                metrics=['BinaryAccuracy', 'mse'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "model = buildModel(training=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arm attractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import attractor\n",
    "attractor = attractor(cfg, 'models/p_task_v0.02/model.h5')\n",
    "\n",
    "names = [weight.name for weight in model.get_layer('rnn').weights] \n",
    "weights = model.get_weights()\n",
    "\n",
    "n_matrices = len(model.get_layer('rnn').weights)\n",
    "new_weights = []\n",
    "for i in range(n_matrices):\n",
    "    # Align model and attractor weight matrices\n",
    "    \n",
    "    # Get attractor value if weight matrix name match attractor \n",
    "    if model.get_layer('rnn').weights[i].name.endswith('w_pp:0'):\n",
    "        new_weights.append(attractor.pretrained_w_pp)\n",
    "\n",
    "    if model.get_layer('rnn').weights[i].name.endswith('w_pc:0'): \n",
    "        new_weights.append(attractor.pretrained_w_pc)\n",
    "        \n",
    "    if model.get_layer('rnn').weights[i].name.endswith('w_cp:0'): \n",
    "        new_weights.append(attractor.pretrained_w_cp)\n",
    "        \n",
    "    if model.get_layer('rnn').weights[i].name.endswith('bias_p:0'): \n",
    "        new_weights.append(attractor.pretrained_bias_p)\n",
    "        \n",
    "    if model.get_layer('rnn').weights[i].name.endswith('bias_c:0'): \n",
    "        new_weights.append(attractor.pretrained_bias_c)\n",
    "    \n",
    "    # Fill original value if this slot have not been filled\n",
    "    if len(new_weights) < i + 1:\n",
    "        new_weights.append(model.get_weights()[i])\n",
    "\n",
    "# new_weights\n",
    "\n",
    "model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check again...\n",
    "\n",
    "from misc import plot_variables\n",
    "plot_variables(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKUOoZkP8QiA"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2616,
     "status": "ok",
     "timestamp": 1581348685950,
     "user": {
      "displayName": "Jason Lo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB2QWsl_vzihRifHZBxq7M-ofOQkG8cBrTfFhl_Kzs=s64",
      "userId": "10618067338459780934"
     },
     "user_tz": 300
    },
    "id": "UzTIeyDp4Mrz",
    "outputId": "da084caa-be29-4fc1-e0d6-5e15e916e52a"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from data_wrangling import sampleGenerator\n",
    "import h5py, pickle, os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from misc import my_data\n",
    "data = my_data(cfg)\n",
    "\n",
    "checkpoint = ModelCheckpoint(cfg.path_weights_checkpoint, verbose=1, \n",
    "                             period=cfg.save_freq, save_weights_only=True) \n",
    "\n",
    "history = model.fit(sampleGenerator(data.x_train, data.y_train, \n",
    "                                    cfg.n_timesteps, cfg.batch_size, \n",
    "                                    data.sample_p, cfg.sample_rng_seed),\n",
    "                                    steps_per_epoch = cfg.steps_per_epoch,\n",
    "                                    epochs = cfg.nEpo,\n",
    "                                    verbose=0,  \n",
    "                                    callbacks=[checkpoint])\n",
    "\n",
    "# Saving history and model\n",
    "pickle_out = open(cfg.path_history_pickle,\"wb\")\n",
    "pickle.dump(history.history, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "clear_output()\n",
    "print('Training done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMmNcbJdcPMh"
   },
   "source": [
    "# Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BqpDOQStugK"
   },
   "source": [
    "Training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1434,
     "status": "ok",
     "timestamp": 1581347970076,
     "user": {
      "displayName": "Jason Lo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB2QWsl_vzihRifHZBxq7M-ofOQkG8cBrTfFhl_Kzs=s64",
      "userId": "10618067338459780934"
     },
     "user_tz": 300
    },
    "id": "qHSvyt9BbJgo",
    "outputId": "cc8a416e-07db-4739-e2d4-cea6b4c6e488"
   },
   "outputs": [],
   "source": [
    "from my_eval import training_history\n",
    "\n",
    "hist = training_history(cfg.path_history_pickle)\n",
    "hist.plot_all(cfg.path_plot_folder + 'history.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UBwmkAQlEC5j"
   },
   "source": [
    "### Critical note when model contain noise\n",
    "- Must recompile model with zero noise during eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1399,
     "status": "ok",
     "timestamp": 1581348273318,
     "user": {
      "displayName": "Jason Lo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB2QWsl_vzihRifHZBxq7M-ofOQkG8cBrTfFhl_Kzs=s64",
      "userId": "10618067338459780934"
     },
     "user_tz": 300
    },
    "id": "HWyRq6ESECCB",
    "outputId": "a742160c-5b3a-4b3c-9f96-bdd9f658ef81"
   },
   "outputs": [],
   "source": [
    "model = buildModel(training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KnxCNzMyWah"
   },
   "source": [
    "## Strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 778
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1581348740670,
     "user": {
      "displayName": "Jason Lo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB2QWsl_vzihRifHZBxq7M-ofOQkG8cBrTfFhl_Kzs=s64",
      "userId": "10618067338459780934"
     },
     "user_tz": 300
    },
    "id": "p8hh2944gdzK",
    "outputId": "f449c6e9-479f-4062-889a-bc49020457ab"
   },
   "outputs": [],
   "source": [
    "from my_eval import strain, grain\n",
    "\n",
    "strain = strain(model, cfg, data)\n",
    "strain.start_evaluate()\n",
    "\n",
    "sdev = strain.plot_development()\n",
    "stim = strain.plot_time_course()\n",
    "\n",
    "s = sdev & stim\n",
    "\n",
    "s.save(cfg.path_plot_folder + 'strain_plots.html')\n",
    "s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4m3mSf_PC0Z"
   },
   "source": [
    "## Grain\n",
    "Terminology remarks:\n",
    "- Condition\n",
    "    - Ambiguous = Experimental = Critical\n",
    "    - Unambiguous = Control\n",
    "- Response\n",
    "    - Large grain = decode using context\n",
    "    - Small grain = decode using GPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 425902,
     "status": "ok",
     "timestamp": 1581052114413,
     "user": {
      "displayName": "Chor Ming Lo",
      "photoUrl": "",
      "userId": "13873017605408138339"
     },
     "user_tz": 300
    },
    "id": "-2N61skLmdob",
    "outputId": "9137d64b-df83-4fd3-a8d3-d4c23a33fe09"
   },
   "outputs": [],
   "source": [
    "from my_eval import grain\n",
    "\n",
    "grain = grain(model, cfg, data)\n",
    "grain.start_evaluate()\n",
    "\n",
    "gdev = grain.plot_development()\n",
    "gtim = grain.plot_time_course()\n",
    "\n",
    "g = gdev & gtim\n",
    "g.save(cfg.path_plot_folder + 'grain_plots.html')\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import plot_variables\n",
    "plot_variables(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZ0BIdAJzl2a"
   },
   "source": [
    "# Dev zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all config history from bq_table\n",
    "bq_table_cfg = 'batch_test.cfg'\n",
    "sql =  \"\"\"SELECT * FROM `\"\"\" + bq_table_cfg + \"\"\"`\"\"\"\n",
    "df = pandas_gbq.read_gbq(sql, project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rop-42L22Cjy"
   },
   "outputs": [],
   "source": [
    "# Copy csv file to CSV ingest bucket\n",
    "\n",
    "\n",
    "\n",
    "file_name = 'models/RNN_v0.42_test/result_grain_epoch.csv'\n",
    "project_id = 'idyllic-web-267716'\n",
    "bucket_name = 'rnn_ingest'\n",
    "!gsutil cp -r {file_name} gs://{bucket_name}/ \n",
    "    \n",
    "# Maybe just use pandas_gbq... much easier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rop-42L22Cjy"
   },
   "outputs": [],
   "source": [
    "# Create ingest CSV job for bigquery\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "table_ref = client.dataset('batch_test').table('strain_epoch')\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "\n",
    "uri = \"gs://rnn_ingest/*\"\n",
    "load_job = client.load_table_from_uri(uri, table_ref, job_config=job_config)\n",
    "print(\"Starting job {}\".format(load_job.job_id))\n",
    "\n",
    "load_job.result()  # Waits for table load to complete.\n",
    "print(\"Job finished.\")\n",
    "\n",
    "destination_table = client.get_table(table_ref)\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IgeTi0d2UxUM"
   },
   "source": [
    "try https://github.com/keras-team/keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7873,
     "status": "ok",
     "timestamp": 1581123029039,
     "user": {
      "displayName": "Jason Lo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB2QWsl_vzihRifHZBxq7M-ofOQkG8cBrTfFhl_Kzs=s64",
      "userId": "10618067338459780934"
     },
     "user_tz": 300
    },
    "id": "8C-lQMFTRoyl",
    "outputId": "1cd4556e-5905-4623-e2e5-93ebafe360ce"
   },
   "outputs": [],
   "source": [
    "!pip install -U keras-tuner\n",
    "from kerastuner.tuners import RandomSearch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k7dd2_vfg92c"
   },
   "source": [
    "## Item level plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckiIeqo2hEqA"
   },
   "outputs": [],
   "source": [
    "# Strain item\n",
    "\n",
    "sel = alt.selection(type='single', on='click', fields=['word'], empty='all')\n",
    "\n",
    "strain_chart_items = alt.Chart(result_strain_items[lambda df: df['epoch'] == nEpo]\n",
    "                               ).add_selection(sel).mark_line(point=True).encode(\n",
    "    y='sse',\n",
    "    x='unit_time',\n",
    "    color = 'word',\n",
    "    opacity = alt.condition(sel, alt.value(1), alt.value(0)),\n",
    "    column = 'frequency',\n",
    "    row = 'pho_consistency',\n",
    "    tooltip=['epoch', 'word', 'pho', 'output', 'acc', 'sse']\n",
    "    )\n",
    "\n",
    "\n",
    "strain_chart_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FREM5q1MhIsp"
   },
   "outputs": [],
   "source": [
    " def plot_development_item(self, plot_time_step=None):\n",
    "        import altair as alt\n",
    "        if plot_time_step is None: plot_time_step = self.cfg.n_timesteps - 1\n",
    "\n",
    "        \n",
    "        sel = alt.selection(type='single', on='click', fields=['word'], empty='all')\n",
    "\n",
    "        strain_chart_items = alt.Chart(result_strain_items[lambda df: df['timestep'] == n_timesteps - 1]\n",
    "                                    ).add_selection(sel).mark_line(point=True).encode(\n",
    "            y='sse',\n",
    "            x='epoch',\n",
    "            color = 'word',\n",
    "            opacity = alt.condition(sel, alt.value(1), alt.value(0)),\n",
    "            column = 'frequency',\n",
    "            row = 'pho_consistency',\n",
    "            tooltip=['epoch', 'word', 'pho', 'output', 'acc', 'sse']\n",
    "            )\n",
    "\n",
    "\n",
    "        strain_chart_items.save(plotsPath + 'strain_chart_items.html')\n",
    "        strain_chart_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sirRvLQSiHr6"
   },
   "outputs": [],
   "source": [
    "sel = alt.selection(type='single', on='click', fields=['word'], empty='all')\n",
    "\n",
    "base = alt.Chart(result_grain_items[lambda df: df['epoch'] == nEpo]\n",
    "                 ).add_selection(sel).mark_line(point=True).encode(\n",
    "    x='unit_time',\n",
    "    color = 'word',\n",
    "    column = 'condition', \n",
    "    opacity = alt.condition(sel, alt.value(1), alt.value(0)),\n",
    "    tooltip=['epoch', 'word', 'output', 'pho_large', 'pho_small', 'is_large_grain', 'is_small_grain']\n",
    "    )\n",
    "\n",
    "amb = base.encode(\n",
    "    y='sse_large_grain'\n",
    "    ).transform_filter(\n",
    "    (datum.condition == 'ambiguous')\n",
    "    )\n",
    "\n",
    "unamb = base.encode(\n",
    "    y='sse_small_grain'\n",
    "    ).transform_filter(\n",
    "    (datum.condition == 'unambiguous')\n",
    "    )\n",
    "\n",
    "\n",
    "grain_chart_items = amb | unamb\n",
    "grain_chart_items.save(plotsPath + 'grain_chart_items.html')\n",
    "grain_chart_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kA0LESOBiMRT"
   },
   "outputs": [],
   "source": [
    "result_grain_items['unit_time'] = result_grain_items['timestep'] * tau\n",
    "\n",
    "sel = alt.selection(type='single', on='click', fields=['word'], empty='all')\n",
    "\n",
    "base = alt.Chart(result_grain_items[lambda df: df['epoch'] == nEpo]\n",
    "                 ).add_selection(sel).mark_line(point=True).encode(\n",
    "    y='sse_acceptable',\n",
    "    x='unit_time',\n",
    "    color = 'word',\n",
    "    opacity = alt.condition(sel, alt.value(1), alt.value(0)),\n",
    "    tooltip=['epoch', 'word', 'output', 'pho_large', 'pho_small', 'is_large_grain', 'is_small_grain']\n",
    "    )\n",
    "\n",
    "base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqDTJ45giw0u"
   },
   "outputs": [],
   "source": [
    "sel = alt.selection(type='single', on='click', fields=['word'], empty='all')\n",
    "\n",
    "base = alt.Chart(result_grain_items[lambda df: df['timestep'] == n_timesteps - 1]\n",
    "                 ).add_selection(sel).mark_line(point=True).encode(\n",
    "    y='sse_acceptable',\n",
    "    x='epoch',\n",
    "    color = 'word',\n",
    "    opacity = alt.condition(sel, alt.value(1), alt.value(0)),\n",
    "    tooltip=['epoch', 'word', 'output', 'pho_large', 'pho_small', 'is_large_grain', 'is_small_grain']\n",
    "    )\n",
    "\n",
    "base\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "basicO2P_master.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
