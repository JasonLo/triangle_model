{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fb_7P_80yRjH"
   },
   "source": [
    "# Misc support functions\n",
    "The class object in this script can easily pass all needed config and data to any object (instead of putting it one by one...)\n",
    "- model_cfg: a header class to store every settings\n",
    "- my_data: a data loader, obtain every data needed for modeling and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nidZ7PunyTEf"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd 'drive/My Drive/Colab Notebooks/basicO2P'\n",
    "%cd '/home/jupyter/tf/O2P'\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YujyTC8xyPf5"
   },
   "outputs": [],
   "source": [
    "%%writefile misc.py\n",
    "\n",
    "class model_cfg():\n",
    "    \n",
    "    def __init__(self, code_name=None, sample_name='hs04', sample_rng_seed=329, \n",
    "                 o_input_dim=119, hidden_units=150, pho_units=250, cleanup_units=50, \n",
    "                 embed_attractor=None,\n",
    "                 w_oh_noise=0., w_hp_noise=0., w_pp_noise=0., w_pc_noise=0., w_cp_noise=0.,\n",
    "                 act_p_noise=0., \n",
    "                 tau=0.2, unit_time=4.,\n",
    "                 n_mil_sample=1., batch_size=128, rnn_activation='sigmoid',\n",
    "                 w_initializer='glorot_uniform', learning_rate=0.01, save_freq=5):\n",
    "        \n",
    "        self.code_name = code_name\n",
    "\n",
    "        # Sampling\n",
    "        self.sample_name = sample_name\n",
    "        self.sample_rng_seed = sample_rng_seed\n",
    "\n",
    "        # Architechture\n",
    "        self.o_input_dim = o_input_dim\n",
    "        self.hidden_units = hidden_units\n",
    "        self.pho_units = pho_units\n",
    "        self.cleanup_units = cleanup_units\n",
    "        \n",
    "        self.embed_attractor = embed_attractor\n",
    "\n",
    "        self.w_oh_noise = w_oh_noise\n",
    "        self.w_hp_noise = w_hp_noise\n",
    "        self.w_pp_noise = w_pp_noise\n",
    "        self.w_pc_noise = w_pc_noise\n",
    "        self.w_cp_noise = w_cp_noise\n",
    "        self.act_p_noise = act_p_noise\n",
    "\n",
    "        ## This is for switching between testing and training mode\n",
    "        self.w_oh_noise_backup = self.w_oh_noise   \n",
    "        self.w_hp_noise_backup = self.w_hp_noise\n",
    "        self.w_pp_noise_backup = self.w_pp_noise\n",
    "        self.w_pc_noise_backup = self.w_pc_noise\n",
    "        self.w_cp_noise_backup = self.w_cp_noise\n",
    "        self.act_p_noise_backup = self.act_p_noise\n",
    "\n",
    "        self.tau = tau\n",
    "        self.unit_time = unit_time\n",
    "        self.n_timesteps = int(self.unit_time * (1/self.tau))\n",
    "\n",
    "        # Training\n",
    "        self.n_mil_sample = n_mil_sample\n",
    "        self.nEpo = int(n_mil_sample * 1e2)                 \n",
    "        self.batch_size = batch_size\n",
    "        self.steps_per_epoch = int(10000/batch_size)\n",
    "        self.rnn_activation = rnn_activation\n",
    "        self.w_initializer = w_initializer\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Saving\n",
    "        self.save_freq = save_freq          \n",
    "        self.eval_freq = self.save_freq\n",
    "\n",
    "        self.gen_paths()\n",
    "        self.gen_cfg_dict()\n",
    "        self.write_cfg()\n",
    "\n",
    "    def gen_cfg_dict(self):\n",
    "        self.cfg_dict = {'code_name': self.code_name, \n",
    "                        'sample_name': self.sample_name,\n",
    "                        'sample_rng_seed': self.sample_rng_seed,\n",
    "                        'o_input_dim': self.o_input_dim,\n",
    "                        'hidden_units': self.hidden_units,\n",
    "                        'pho_units': self.pho_units,\n",
    "                        'cleanup_units': self.cleanup_units, \n",
    "                        'embed_attractor': self.embed_attractor,\n",
    "                        'w_oh_noise': self.w_oh_noise,\n",
    "                        'w_hp_noise': self.w_hp_noise,\n",
    "                        'w_pp_noise': self.w_pp_noise,\n",
    "                        'w_pc_noise': self.w_pc_noise,\n",
    "                        'w_cp_noise': self.w_cp_noise,\n",
    "                        'act_p_noise': self.act_p_noise,\n",
    "                        'tau': self.tau,\n",
    "                        'unit_time': self.unit_time,\n",
    "                        'n_timesteps': self.n_timesteps,\n",
    "                        'n_mil_sample': self.n_mil_sample, \n",
    "                        'nEpo': self.nEpo, \n",
    "                        'batch_size': self.batch_size, \n",
    "                        'steps_per_epoch': self.steps_per_epoch, \n",
    "                        'rnn_activation': self.rnn_activation, \n",
    "                        'w_initializer': self.w_initializer, \n",
    "                        'learning_rate': self.learning_rate}\n",
    "\n",
    "    def write_cfg(self):\n",
    "        import json\n",
    "        json = json.dumps(self.cfg_dict)\n",
    "        f = open(self.path_model_folder + 'model_config.json',\"w\")\n",
    "        f.write(json)\n",
    "        f.close()\n",
    "        \n",
    "       \n",
    "    def gen_paths(self):\n",
    "        import os\n",
    "    \n",
    "        self.path_model_folder = 'models/'+ self.code_name + '/'\n",
    "        self.path_log_folder = self.path_model_folder + 'log/'\n",
    "        self.path_weight_folder = self.path_model_folder + 'weights/'\n",
    "        self.path_plot_folder = self.path_model_folder + 'plots/'\n",
    "\n",
    "        self.path_weights_checkpoint = self.path_weight_folder + 'ep{epoch:04d}.h5'\n",
    "        self.path_history_pickle = self.path_model_folder + 'history.pickle'\n",
    "        \n",
    "        if self.embed_attractor is not None:\n",
    "            self.path_attractor = 'models/'+ self.embed_attractor + '/model.h5'\n",
    "\n",
    "        if not os.path.exists(self.path_model_folder): os.mkdir(self.path_model_folder) \n",
    "        if not os.path.exists(self.path_weight_folder): os.mkdir(self.path_weight_folder) \n",
    "        if not os.path.exists(self.path_log_folder): os.mkdir(self.path_log_folder) \n",
    "        if not os.path.exists(self.path_plot_folder): os.mkdir(self.path_plot_folder)  \n",
    "\n",
    "        self.path_weights_list = []\n",
    "        self.saved_epoch_list = []\n",
    "        \n",
    "        for epoch in range(self.save_freq, self.nEpo+1, self.save_freq):\n",
    "            self.path_weights_list += [self.path_weight_folder + 'ep' + \n",
    "                                       str(epoch).zfill(4) + '.h5']\n",
    "            \n",
    "            self.saved_epoch_list.append(epoch)\n",
    "\n",
    "        self.strain_item_csv = self.path_model_folder + 'result_strain_item.csv'\n",
    "        self.strain_epoch_csv = self.path_model_folder + 'result_strain_epoch.csv'\n",
    "        self.grain_item_csv = self.path_model_folder + 'result_grain_item.csv'\n",
    "        self.grain_epoch_csv = self.path_model_folder + 'result_grain_epoch.csv'\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "            \n",
    "def plot_variables(model):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    nv = len(model.trainable_variables)\n",
    "    plt.figure(figsize=(20,20), facecolor='w')\n",
    "    for i in range(nv):\n",
    "\n",
    "        # Expand dimension for biases\n",
    "        if model.trainable_variables[i].numpy().ndim == 1:\n",
    "            plot_data = model.trainable_variables[i].numpy()[np.newaxis,:]\n",
    "        else:\n",
    "            plot_data = model.trainable_variables[i].numpy()\n",
    "\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        plt.title(model.trainable_variables[i].name)\n",
    "        plt.imshow(plot_data, cmap='jet', interpolation='nearest', aspect=\"auto\")\n",
    "        plt.colorbar()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class attractor():\n",
    "    def __init__(self, cfg):\n",
    "        from misc import plot_variables\n",
    "        self.cfg = cfg\n",
    "        self.model = self.build_model()\n",
    "        self.model.load_weights(cfg.path_attractor)\n",
    "        \n",
    "        rnn_layer = self.model.get_layer('rnn')\n",
    "        names = [weight.name for weight in rnn_layer.weights]\n",
    "        weights = self.model.get_weights()\n",
    "\n",
    "        for name, weight in zip(names, weights):\n",
    "            print(name, weight.shape)\n",
    "            if name.endswith('w_pp:0'): self.pretrained_w_pp = weight\n",
    "            if name.endswith('w_pc:0'): self.pretrained_w_pc = weight\n",
    "            if name.endswith('w_cp:0'): self.pretrained_w_cp = weight\n",
    "            if name.endswith('bias_p:0'): self.pretrained_bias_p = weight\n",
    "            if name.endswith('bias_c:0'): self.pretrained_bias_c = weight\n",
    "        \n",
    "        plot_variables(self.model)\n",
    "    \n",
    "def build_model(self):\n",
    "        from tensorflow.keras import Model\n",
    "        from tensorflow.keras.layers import Layer, Input\n",
    "        from custom_layer import rnn_pho_task\n",
    "        from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "        input_p = Input(shape=(self.cfg.pho_units,), name='pho_task_input')\n",
    "        rnn_model = rnn_pho_task(self.cfg, name='rnn')(input_p)\n",
    "        model = Model(input_p, rnn_model)\n",
    "\n",
    "#         adam = Adam(learning_rate=self.cfg.learning_rate, \n",
    "#                     beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "#         model.compile(loss='binary_crossentropy',\n",
    "#                     optimizer=adam,\n",
    "#                     metrics=['BinaryAccuracy', 'mse'])\n",
    "\n",
    "#         model.summary()\n",
    "        \n",
    "        return model\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attractor():\n",
    "    def __init__(self, cfg):\n",
    "        from misc import plot_variables\n",
    "        self.cfg = cfg\n",
    "        self.model = self.build_model()\n",
    "        self.model.load_weights(cfg.path_attractor)\n",
    "        \n",
    "        rnn_layer = self.model.get_layer('rnn')\n",
    "        names = [weight.name for weight in rnn_layer.weights]\n",
    "        weights = self.model.get_weights()\n",
    "\n",
    "        for name, weight in zip(names, weights):\n",
    "            print(name, weight.shape)\n",
    "            if name.endswith('w_pp:0'): self.pretrained_w_pp = weight\n",
    "            if name.endswith('w_pc:0'): self.pretrained_w_pc = weight\n",
    "            if name.endswith('w_cp:0'): self.pretrained_w_cp = weight\n",
    "            if name.endswith('bias_p:0'): self.pretrained_bias_p = weight\n",
    "            if name.endswith('bias_c:0'): self.pretrained_bias_c = weight\n",
    "        \n",
    "        plot_variables(self.model)\n",
    "    \n",
    "    def build_model(self):\n",
    "        from tensorflow.keras import Model\n",
    "        from tensorflow.keras.layers import Layer, Input\n",
    "        from custom_layer import rnn_pho_task\n",
    "        from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "        input_p = Input(shape=(self.cfg.pho_units,), name='pho_task_input')\n",
    "        rnn_model = rnn_pho_task(self.cfg, name='rnn')(input_p)\n",
    "        model = Model(input_p, rnn_model)\n",
    "\n",
    "#         adam = Adam(learning_rate=self.cfg.learning_rate, \n",
    "#                     beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "#         model.compile(loss='binary_crossentropy',\n",
    "#                     optimizer=adam,\n",
    "#                     metrics=['BinaryAccuracy', 'mse'])\n",
    "\n",
    "#         model.summary()\n",
    "        \n",
    "        return model\n",
    "cfg = model_cfg(code_name='RNN_v0.60', \n",
    "                sample_name='hs04', \n",
    "                sample_rng_seed=303,\n",
    "                hidden_units=150, \n",
    "                pho_units=250, \n",
    "                cleanup_units=50,\n",
    "                embed_attractor='p_task_v0.02',\n",
    "                w_oh_noise=0.,\n",
    "                w_hp_noise=0.,\n",
    "                w_pp_noise=4.,\n",
    "                w_pc_noise=4.,\n",
    "                w_cp_noise=4.,\n",
    "                act_p_noise=0.,\n",
    "                tau=0.2, \n",
    "                unit_time=4., \n",
    "                n_mil_sample=1., \n",
    "                batch_size=128, \n",
    "                rnn_activation = 'sigmoid',\n",
    "                w_initializer = 'glorot_uniform',\n",
    "                learning_rate=0.01,\n",
    "                save_freq=5)\n",
    "attractor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arm_attractor(model, cfg):\n",
    "    from misc import attractor\n",
    "    attractor = attractor(cfg)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "names = [weight.name for weight in model.get_layer('rnn').weights] \n",
    "weights = model.get_weights()\n",
    "\n",
    "n_matrices = len(model.get_layer('rnn').weights)\n",
    "new_weights = []\n",
    "for i in range(n_matrices):\n",
    "    # Align model and attractor weight matrices\n",
    "    \n",
    "    # Get attractor value if weight matrix name match attractor \n",
    "    if model.get_layer('rnn').weights[i].name.endswith('w_pp:0'):\n",
    "        new_weights.append(attractor.pretrained_w_pp)\n",
    "\n",
    "    if model.get_layer('rnn').weights[i].name.endswith('w_pc:0'): \n",
    "        new_weights.append(attractor.pretrained_w_pc)\n",
    "        \n",
    "    if model.get_layer('rnn').weights[i].name.endswith('w_cp:0'): \n",
    "        new_weights.append(attractor.pretrained_w_cp)\n",
    "        \n",
    "    if model.get_layer('rnn').weights[i].name.endswith('bias_p:0'): \n",
    "        new_weights.append(attractor.pretrained_bias_p)\n",
    "        \n",
    "    if model.get_layer('rnn').weights[i].name.endswith('bias_c:0'): \n",
    "        new_weights.append(attractor.pretrained_bias_c)\n",
    "    \n",
    "    # Fill original value if this slot have not been filled\n",
    "    if len(new_weights) < i + 1:\n",
    "        new_weights.append(model.get_weights()[i])\n",
    "\n",
    "# new_weights\n",
    "\n",
    "model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal install script for new DLVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install altair\n",
    "!sudo pip install pandas-gbq -U\n",
    "!sudo pip install yapf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_influence_np(t, f, g=5, k=2000):\n",
    "    import numpy as np\n",
    "    # Based on Plaut et al. 96 sims 4\n",
    "    # This function is for checking semantic_influence()\n",
    "    # S = g (log(f+2)*t) / (log(g+2)*t + k)\n",
    "    # Where g and k is scaling factors\n",
    "    # t is epoch\n",
    "    # f is word frequency\n",
    "    lt = np.log(f+2)*t\n",
    "    return g*lt/(lt+k)\n",
    "\n",
    "# Sanity check Plaut96 fig.21\n",
    "t= range(2000)\n",
    "s_high = [semantic_influence_np(x, 1222) for x in t]\n",
    "s_low = [semantic_influence_np(x, 20) for x in t]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(t, s_high, label='High-frequency (1222/mil)')\n",
    "line2, = ax.plot(t, s_low, label='Low-frequency (20/mil)', linestyle='dashed')\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Contribution of Semantic Pathway')\n",
    "ax.set_xlabel('Training Epoch')\n",
    "ax.set_ylabel('External Input to Phonemes')\n",
    "plt.ylim(top=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code formatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from yapf.yapflib.yapf_api import FormatFile\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file.endswith('.py'):\n",
    "        FormatFile(file, in_place=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyORwTHf+x7Ea1qIUr2QtASl",
   "collapsed_sections": [],
   "name": "misc.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
