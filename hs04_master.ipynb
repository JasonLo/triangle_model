{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext lab_black\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/jupyter/tf/src\")\n",
    "import meta, data_wrangling, modeling\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_name = \"hs04_test\"\n",
    "tf_root = \"/home/jupyter/tf\"\n",
    "\n",
    "# Dataset\n",
    "sample_name = \"hs04\"\n",
    "rng_seed = 53797\n",
    "\n",
    "# Model architechture\n",
    "ort_units = 119\n",
    "pho_units = 250\n",
    "pho_hidden_units = 100\n",
    "pho_cleanup_units = 50\n",
    "pho_noise_level = 0.0\n",
    "\n",
    "activation = \"sigmoid\"\n",
    "\n",
    "tau = 1 / 3\n",
    "max_unit_time = 4.0\n",
    "output_ticks = 2\n",
    "\n",
    "# Training\n",
    "n_mil_sample = 0.1\n",
    "batch_size = 100\n",
    "learning_rate = 0.005\n",
    "save_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {}\n",
    "\n",
    "# Load global cfg variables into a dictionary\n",
    "for v in meta.CORE_CONFIGS:\n",
    "    try:\n",
    "        config_dict[v] = globals()[v]\n",
    "    except:\n",
    "        print(\"Missing CORE config(s)\")\n",
    "\n",
    "for v in meta.OPTIONAL_CONFIGS:\n",
    "    try:\n",
    "        config_dict[v] = globals()[v]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Construct ModelConfig object\n",
    "cfg = meta.ModelConfig(**config_dict)\n",
    "cfg.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(rng_seed)\n",
    "data = data_wrangling.MyData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightning style code refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "class RNN(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Main time-averaged input implementation based on Plaut 96 (Fig 12.)\n",
    "    With additional attractor (cleanup) network\n",
    "    Option to use semantic input by cfg.use_semantic == True\n",
    "    Semantic equation can be change in modeling.input_s()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        activation,\n",
    "        pho_units,\n",
    "        pho_hidden_units,\n",
    "        pho_cleanup_units,\n",
    "        pho_noise_level,\n",
    "        n_timesteps,\n",
    "        tau,\n",
    "        output_ticks,\n",
    "        name=\"rnn\",\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "        self.pho_hidden_units = pho_hidden_units\n",
    "        self.pho_units = pho_units\n",
    "        self.pho_cleanup_units = pho_cleanup_units\n",
    "        self.pho_noise_level = pho_noise_level\n",
    "        self.tau = tau\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.output_ticks = output_ticks\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        weight_initializer = tf.random_uniform_initializer(minval=-0.1, maxval=0.1)\n",
    "\n",
    "        \"\"\"Build weights and biases\"\"\"\n",
    "        self.w_oh = self.add_weight(\n",
    "            name=\"w_oh\",\n",
    "            shape=(input_shape[-1], self.pho_hidden_units),\n",
    "            initializer=weight_initializer,\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        self.w_hp = self.add_weight(\n",
    "            name=\"w_hp\",\n",
    "            shape=(self.pho_hidden_units, self.pho_units),\n",
    "            initializer=weight_initializer,\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        self.w_pp = self.add_weight(\n",
    "            name=\"w_pp\",\n",
    "            shape=(self.pho_units, self.pho_units),\n",
    "            initializer=weight_initializer,\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        self.w_pc = self.add_weight(\n",
    "            name=\"w_pc\",\n",
    "            shape=(self.pho_units, self.pho_cleanup_units),\n",
    "            initializer=weight_initializer,\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        self.w_cp = self.add_weight(\n",
    "            name=\"w_cp\",\n",
    "            shape=(self.pho_cleanup_units, self.pho_units),\n",
    "            initializer=weight_initializer,\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        self.bias_h = self.add_weight(\n",
    "            shape=(self.pho_hidden_units,),\n",
    "            name=\"bias_h\",\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        self.bias_p = self.add_weight(\n",
    "            shape=(self.pho_units,),\n",
    "            name=\"bias_p\",\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        self.bias_c = self.add_weight(\n",
    "            shape=(self.pho_cleanup_units,),\n",
    "            name=\"bias_c\",\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Dimension note: (batch, timestep, input_dim)\n",
    "        Hack for complying keras.layers.concatenate() format\n",
    "        Spliting input_dim below (index = 2)\n",
    "        \"\"\"\n",
    "\n",
    "        # init\n",
    "        input_h_list, input_p_list, input_c_list = [], [], []\n",
    "        act_h_list, act_p_list, act_c_list = [], [], []\n",
    "\n",
    "        # Set inputs to 0\n",
    "        input_h_list.append(tf.zeros((1, self.pho_hidden_units), dtype=tf.float32))\n",
    "        input_p_list.append(tf.zeros((1, self.pho_units), dtype=tf.float32))\n",
    "        input_c_list.append(tf.zeros((1, self.pho_cleanup_units), dtype=tf.float32))\n",
    "\n",
    "        # Set activations to 0.5\n",
    "        act_h_list.append(input_h_list[0] + 0.5)\n",
    "        act_p_list.append(input_p_list[0] + 0.5)\n",
    "        act_c_list.append(input_c_list[0] + 0.5)\n",
    "\n",
    "        for t in range(self.n_timesteps):\n",
    "            # Inject fresh white noise to weights and biases within pho system in each time step\n",
    "            w_pp = K.in_train_phase(\n",
    "                self._inject_noise(self.w_pp, self.pho_noise_level), self.w_pp\n",
    "            )\n",
    "            w_pc = K.in_train_phase(\n",
    "                self._inject_noise(self.w_pc, self.pho_noise_level), self.w_pc\n",
    "            )\n",
    "            w_cp = K.in_train_phase(\n",
    "                self._inject_noise(self.w_cp, self.pho_noise_level), self.w_cp\n",
    "            )\n",
    "            bias_c = K.in_train_phase(\n",
    "                self._inject_noise(self.bias_c, self.pho_noise_level), self.bias_c\n",
    "            )\n",
    "            bias_p = K.in_train_phase(\n",
    "                self._inject_noise(self.bias_p, self.pho_noise_level), self.bias_p\n",
    "            )\n",
    "\n",
    "            ##### Hidden layer #####\n",
    "            oh = tf.matmul(inputs[:, t, :], self.w_oh)\n",
    "            h = self.tau * (oh + self.bias_h) + (1 - self.tau) * input_h_list[t]\n",
    "\n",
    "            ##### Phonology layer #####\n",
    "            hp = tf.matmul(act_h_list[t], self.w_hp)\n",
    "            pp = tf.matmul(act_p_list[t], w_pp)\n",
    "            cp = tf.matmul(act_c_list[t], w_cp)\n",
    "\n",
    "            p = self.tau * (hp + pp + cp + bias_p)\n",
    "            p += (1 - self.tau) * input_p_list[t]\n",
    "\n",
    "            ##### Cleanup layer #####\n",
    "            pc = tf.matmul(act_p_list[t], w_pc)\n",
    "            c = self.tau * (pc + bias_c) + (1 - self.tau) * input_c_list[t]\n",
    "\n",
    "            # Record this timestep to list\n",
    "            input_h_list.append(h)\n",
    "            input_p_list.append(p)\n",
    "            input_c_list.append(c)\n",
    "\n",
    "            act_h_list.append(self.activation(h))\n",
    "            act_p_list.append(self.activation(p))\n",
    "            act_c_list.append(self.activation(c))\n",
    "\n",
    "        return act_p_list[-self.output_ticks :]\n",
    "\n",
    "    def _inject_noise(self, x, noise_sd):\n",
    "        \"\"\"Inject Gaussian noise if noise_sd > 0\"\"\"\n",
    "        if noise_sd > 0:\n",
    "            noise = K.random_normal(shape=K.shape(x), mean=0.0, stddev=noise_sd)\n",
    "\n",
    "            return x + noise\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config().copy()\n",
    "        cfg.update(\n",
    "            {\n",
    "                \"pho_hidden_units\": self.pho_hidden_units,\n",
    "                \"pho_units\": self.pho_units,\n",
    "                \"pho_cleanup_units\": self.pho_cleanup_units,\n",
    "                \"pho_noise_level\": self.pho_noise_level,\n",
    "                \"tau\": self.tau,\n",
    "                \"n_timesteps\": self.n_timesteps,\n",
    "                \"output_ticks\": self.output_ticks,\n",
    "                \"activation\": tf.keras.activations.serialize(self.activation),\n",
    "            }\n",
    "        )\n",
    "        return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, RepeatVector\n",
    "\n",
    "\n",
    "def build_model(training=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Create model\n",
    "    \"\"\"\n",
    "    input_o = Input(shape=(cfg.ort_units,), name=\"Input_O\")\n",
    "    input_o_t = RepeatVector(cfg.n_timesteps, name=\"Input_Ot\")(input_o)\n",
    "    rnn_model = RNN(\n",
    "        activation=cfg.activation,\n",
    "        pho_units=cfg.pho_units,\n",
    "        pho_hidden_units=cfg.pho_hidden_units,\n",
    "        pho_cleanup_units=cfg.pho_cleanup_units,\n",
    "        pho_noise_level=cfg.pho_noise_level,\n",
    "        n_timesteps=cfg.n_timesteps,\n",
    "        tau=cfg.tau,\n",
    "        output_ticks=cfg.output_ticks,\n",
    "    )(input_o_t)\n",
    "    model = tf.keras.Model(input_o, rnn_model)\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=cfg.learning_rate, beta_1=0.0, beta_2=0.999, amsgrad=False\n",
    "    ),\n",
    "    metrics=[\"BinaryAccuracy\", \"mse\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sampling instance\n",
    "my_sampling = data_wrangling.Sampling(cfg, data)\n",
    "\n",
    "checkpoint = modeling.ModelCheckpoint_custom(\n",
    "    cfg.path[\"weights_checkpoint_fstring\"],\n",
    "    save_weights_only=True,\n",
    "    period=cfg.save_freq,\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    my_sampling.sample_generator(),\n",
    "    steps_per_epoch=cfg.steps_per_epoch,\n",
    "    epochs=cfg.total_number_of_epoch,\n",
    "    verbose=0,\n",
    "    callbacks=[checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving history and model\n",
    "with open(cfg.path[\"history_pickle\"], \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "clear_output()\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(\"model.h5\", custom_objects={\"RNN\": RNN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import importlib\n",
    "\n",
    "importlib.reload(evaluate)\n",
    "strain = evaluate.strain_eval(cfg, data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "strain.start_evaluate(\n",
    "    test_use_semantic=False,\n",
    "    output=os.path.join(cfg.path[\"model_folder\"], \"result_strain_item.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "strain.i_hist.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(strain.i_hist).mark_line().encode(\n",
    "    x=\"epoch:Q\", y=\"mean(acc):Q\", color=\"condition_pf:N\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
