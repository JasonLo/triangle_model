{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HS04 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The semantic component consisted of the 1,989 semantic features described above. These units were all connected to 50 units in the semantic cleanup apparatus...\n",
    "\n",
    "- *50 sem_cleanup*\n",
    "\n",
    "> The phonological representation consisted of the 200 phonolog-ical units (eight slots of 25 units each), which projected onto a set of 50 phonological cleanup units. These...\n",
    "\n",
    "- *50 pho_cleanup*\n",
    "\n",
    "> The semantic component mapped onto the phonological component via a set of 500 hidden units. There was feedback in both directions. \n",
    "\n",
    "- *500 sem_pho_hidden_units*\n",
    "- *500 pho_sem_hidden_units*\n",
    "\n",
    "> The phonological form of the target word was clamped on the phonological units for 2.66 units of time. Then a target signal was provided for the next 1.33 units of time, in which the network was required to retain the phonological pattern in the absence of external clamping. \n",
    "\n",
    "- *4 output_ticks* \n",
    "\n",
    "> In Harm and Seidenberg (1999), auto-connections were used to give the units a tendency to retain their value but gradually decay. To accomplish the task, the network had to learn enough of the statistical regularities of the representations to prevent this decay. In the current simulations, the idea is the same, but because continuous time units were used, auto-connections were not necessary to provide the units with a tendency to gradually decay; this was part of the unitsâ€™ normal processing dynamics.\n",
    "\n",
    "> HS99: This makes it easier to read weights as correlations between units. Each phonological unit has an auto-connection: a weight set to 0.75 and frozen to that value.\n",
    "\n",
    "- *No auto-connection lock*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The weights that were obtained at the end of the Phase 1 model were frozen and embedded in the larger reading model. Thus, only the connections from orthography to other units were trained in Phase 2. Freezing the weights is not strictly necessary; earlier work (Harm & Seidenberg, 1997) used a process of intermixing in which comprehension trials were used along with reading trials. Weight freezing has the same effect but is simpler and less computationally burdensome to implement. Intermixing is effective and real- istic but adds substantially to network training time.\n",
    "\n",
    "- *Pretraining is necessary\n",
    "\n",
    "> One set of 500 hidden units mediated the mapping from these orthographic units to semantics...\n",
    "\n",
    "- *500 sem_hidden_units*\n",
    "\n",
    "> ...a second set of 100 hidden units mediated the orth-phon pathway.\n",
    "\n",
    "- *100 pho_hidden_units*\n",
    "\n",
    "> To computationally instantiate the principle that the reading system is under pressure to perform rapidly as well as accurately, we injected error into the semantic and phonological representa- tions early, from time samples 2 to 12. \n",
    "- *11 output_ticks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modeling individual differences\n",
    "- Simulating ERPs\n",
    "- Link to reliance of OP vs OS\n",
    "- Use equation to model semantic / phonetic input to P/S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext lab_black\n",
    "import pickle, os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/jupyter/tf/src\")\n",
    "import meta, data_wrangling, modeling, metrics, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters block (for papermill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "code_name = \"hs04_5M_pretraining\"\n",
    "tf_root = \"/home/jupyter/tf\"\n",
    "\n",
    "# Model architechture\n",
    "ort_units = 119  # Phase 2 param (P2)\n",
    "pho_units = 250\n",
    "sem_units = 2446\n",
    "\n",
    "hidden_os_units = 500  # P2\n",
    "hidden_op_units = 100  # P2\n",
    "hidden_ps_units = 500\n",
    "hidden_sp_units = 500\n",
    "\n",
    "pho_cleanup_units = 50\n",
    "sem_cleanup_units = 50\n",
    "\n",
    "pho_noise_level = 0.0  # P3\n",
    "sem_noise_level = 0.0  # P3\n",
    "\n",
    "activation = \"sigmoid\"\n",
    "tau = 1 / 3\n",
    "max_unit_time = 4.0\n",
    "output_ticks = 4\n",
    "\n",
    "# Training\n",
    "sample_name = \"hs04\"\n",
    "rng_seed = 53797\n",
    "learning_rate = 0.01\n",
    "n_mil_sample = 5.0\n",
    "batch_size = 100\n",
    "save_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {}\n",
    "\n",
    "# Load global cfg variables into a dictionary for feeding into ModelConfig()\n",
    "for v in meta.CORE_CONFIGS:\n",
    "    try:\n",
    "        config_dict[v] = globals()[v]\n",
    "    except:\n",
    "        raise\n",
    "\n",
    "for v in meta.OPTIONAL_CONFIGS:\n",
    "    try:\n",
    "        config_dict[v] = globals()[v]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Construct ModelConfig object\n",
    "cfg = meta.ModelConfig(**config_dict)\n",
    "cfg.save()\n",
    "del config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model and all supporting components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(cfg.rng_seed)\n",
    "data = data_wrangling.MyData()\n",
    "model = modeling.HS04Model(cfg)\n",
    "\n",
    "sampler = data_wrangling.FastSampling(cfg, data)\n",
    "generators = {\n",
    "    \"pho_sem\": sampler.sample_generator(x=\"pho\", y=\"sem\"),\n",
    "    \"sem_pho\": sampler.sample_generator(x=\"sem\", y=\"pho\"),\n",
    "    \"pho_pho\": sampler.sample_generator(x=\"pho\", y=\"pho\"),\n",
    "    \"sem_sem\": sampler.sample_generator(x=\"sem\", y=\"sem\"),\n",
    "    \"triangle\": sampler.sample_generator(x=\"ort\", y=[\"pho\", \"sem\"]),\n",
    "}\n",
    "\n",
    "# Instantiate optimizer for each task\n",
    "optimizers = {\n",
    "    \"pho_pho\": tf.keras.optimizers.Adam(learning_rate=cfg.learning_rate),\n",
    "    \"sem_sem\": tf.keras.optimizers.Adam(learning_rate=cfg.learning_rate),\n",
    "    \"pho_sem\": tf.keras.optimizers.Adam(learning_rate=cfg.learning_rate),\n",
    "    \"sem_pho\": tf.keras.optimizers.Adam(learning_rate=cfg.learning_rate),\n",
    "    \"triangle\": tf.keras.optimizers.Adam(learning_rate=cfg.learning_rate),\n",
    "}\n",
    "\n",
    "# Instantiate loss_fn for each task\n",
    "loss_fns = {\n",
    "    \"pho_pho\": tf.keras.losses.BinaryCrossentropy(),\n",
    "    \"sem_sem\": tf.keras.losses.BinaryCrossentropy(),\n",
    "    \"pho_sem\": tf.keras.losses.BinaryCrossentropy(),\n",
    "    \"sem_pho\": tf.keras.losses.BinaryCrossentropy(),\n",
    "    \"triangle\": tf.keras.losses.BinaryCrossentropy(),\n",
    "}\n",
    "\n",
    "# Mean loss (for TensorBoard)\n",
    "train_losses = {\n",
    "    \"pho_pho\": tf.keras.metrics.Mean(\"train_loss_pho_pho\", dtype=tf.float32),\n",
    "    \"sem_sem\": tf.keras.metrics.Mean(\"train_loss_sem_sem\", dtype=tf.float32),\n",
    "    \"pho_sem\": tf.keras.metrics.Mean(\"train_loss_pho_sem\", dtype=tf.float32),\n",
    "    \"sem_pho\": tf.keras.metrics.Mean(\"train_loss_sem_pho\", dtype=tf.float32),\n",
    "    \"triangle\": tf.keras.metrics.Mean(\"train_loss_triangle\", dtype=tf.float32),\n",
    "}\n",
    "\n",
    "# Train metrics\n",
    "train_acc = {\n",
    "    \"pho_pho\": metrics.RightSideAccuracy(\"acc_pho_pho\"),\n",
    "    \"sem_sem\": metrics.RightSideAccuracy(\"acc_sem_sem\"),\n",
    "    \"pho_sem\": metrics.RightSideAccuracy(\"acc_pho_sem\"),\n",
    "    \"sem_pho\": metrics.RightSideAccuracy(\"acc_sem_pho\"),\n",
    "    \"triangle_pho\": metrics.RightSideAccuracy(\"acc_triangle_pho\"),\n",
    "    \"triangle_sem\": metrics.RightSideAccuracy(\"acc_triangle_sem\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train step for each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some low-level technical reason, each sub-task must be trained with separate optimizer,\n",
    "# instead of sharing the same optimizer instance (https://github.com/tensorflow/tensorflow/issues/27120)\n",
    "\n",
    "\n",
    "def get_train_step():\n",
    "    \"\"\"Wrap universal train step for instantiation in each sub task\"\"\"\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(x, y, model, task, loss_fn, optimizer, train_metric, train_losses):\n",
    "\n",
    "        train_weights_name = [x + \":0\" for x in modeling.WEIGHTS_AND_BIASES[task]]\n",
    "        train_weights = [x for x in model.weights if x.name in train_weights_name]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x, training=True)\n",
    "            loss_value = loss_fn(y, y_pred)\n",
    "\n",
    "        grads = tape.gradient(loss_value, train_weights)\n",
    "        optimizer.apply_gradients(zip(grads, train_weights))\n",
    "\n",
    "        # Mean loss for Tensorboard\n",
    "        train_losses.update_state(loss_value)\n",
    "\n",
    "        # Metric for last time step (output first dimension is time ticks, from -cfg.output_ticks to end)\n",
    "        train_metric.update_state(tf.cast(y[-1], tf.float32), y_pred[-1])\n",
    "\n",
    "    return train_step\n",
    "\n",
    "\n",
    "train_steps = {\n",
    "    \"pho_pho\": get_train_step(),\n",
    "    \"pho_sem\": get_train_step(),\n",
    "    \"sem_sem\": get_train_step(),\n",
    "    \"sem_pho\": get_train_step(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle model (Phase 2 in HS04) specific train step\n",
    "Because we have both P and S output, the trainstep need to cater for this dual output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_triangle(\n",
    "    x,\n",
    "    y,\n",
    "    model,\n",
    "    task,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    train_metric_pho,\n",
    "    train_metric_sem,\n",
    "    train_losses,\n",
    "):\n",
    "\n",
    "    train_weights_name = [x + \":0\" for x in modeling.WEIGHTS_AND_BIASES[task]]\n",
    "    train_weights = [x for x in model.weights if x.name in train_weights_name]\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        pho_pred, sem_pred = model(x, training=True)\n",
    "        loss_value_pho = loss_fn(y[0], pho_pred)\n",
    "        loss_value_sem = loss_fn(y[1], sem_pred)\n",
    "        loss_value = loss_value_pho + loss_value_sem\n",
    "\n",
    "    grads = tape.gradient(loss_value, train_weights)\n",
    "    optimizer.apply_gradients(zip(grads, train_weights))\n",
    "\n",
    "    # Mean loss for Tensorboard\n",
    "    train_losses.update_state(loss_value)\n",
    "\n",
    "    # Metric for last time step (output first dimension is time ticks, from -cfg.output_ticks to end)\n",
    "    train_metric_pho.update_state(tf.cast(y[0][-1], tf.float32), pho_pred[-1])\n",
    "    train_metric_sem.update_state(tf.cast(y[1][-1], tf.float32), sem_pred[-1])\n",
    "\n",
    "\n",
    "train_steps[\"triangle\"] = train_step_triangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model.build()\n",
    "phase1_tasks = [\"pho_sem\", \"sem_pho\", \"pho_pho\", \"sem_sem\"]\n",
    "phase1_tasks_probability = [0.4, 0.4, 0.1, 0.1]\n",
    "\n",
    "# TensorBoard writer\n",
    "train_summary_writer = tf.summary.create_file_writer(cfg.path[\"tensorboard_folder\"])\n",
    "\n",
    "for epoch in range(cfg.total_number_of_epoch):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for step in range(cfg.steps_per_epoch):\n",
    "        # Intermix tasks (Draw a new task in each step)\n",
    "        task = np.random.choice(phase1_tasks, p=phase1_tasks_probability)\n",
    "        model.set_active_task(task)\n",
    "        x_batch_train, y_batch_train = next(generators[task])\n",
    "\n",
    "        if task == \"triangle\":\n",
    "            train_steps[task](\n",
    "                x_batch_train,\n",
    "                y_batch_train,\n",
    "                model,\n",
    "                task,\n",
    "                loss_fns[task],\n",
    "                optimizers[task],\n",
    "                train_acc[\"triangle_pho\"],\n",
    "                train_acc[\"triangle_sem\"],\n",
    "                train_losses[task],\n",
    "            )\n",
    "        else:\n",
    "            train_steps[task](\n",
    "                x_batch_train,\n",
    "                y_batch_train,\n",
    "                model,\n",
    "                task,\n",
    "                loss_fns[task],\n",
    "                optimizers[task],\n",
    "                train_acc[task],\n",
    "                train_losses[task],\n",
    "            )\n",
    "\n",
    "    # End of epoch operations\n",
    "\n",
    "    ## Log all scalar metrics (losses and metrics)and histogram (weights and biases) to tensorboard\n",
    "    with train_summary_writer.as_default():\n",
    "        [\n",
    "            tf.summary.scalar(f\"loss_{x}\", train_losses[x].result(), step=epoch)\n",
    "            for x in train_losses.keys()\n",
    "        ]\n",
    "        [\n",
    "            tf.summary.scalar(f\"acc_{x}\", train_acc[x].result(), step=epoch)\n",
    "            for x in train_acc.keys()\n",
    "        ]\n",
    "        [tf.summary.histogram(f\"{x.name}\", x, step=epoch) for x in model.weights]\n",
    "\n",
    "    ## Print status\n",
    "    compute_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch + 1} trained for {compute_time:.0f}s\")\n",
    "    print(\n",
    "        \"Losses:\",\n",
    "        [f\"{x}: {train_losses[x].result().numpy()}\" for x in phase1_tasks],\n",
    "    )\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    ## Save weights\n",
    "    if (epoch < 10) or ((epoch + 1) % 10 == 0):\n",
    "        weight_path = cfg.path[\"weights_checkpoint_fstring\"].format(epoch=epoch + 1)\n",
    "        model.save_weights(weight_path, overwrite=True, save_format=\"tf\")\n",
    "\n",
    "    ## Reset metric and loss\n",
    "    [train_losses[x].reset_states() for x in train_losses.keys()]\n",
    "    [train_acc[x].reset_states() for x in train_acc.keys()]\n",
    "\n",
    "# End of training ops\n",
    "# model.save(cfg.path[\"save_model_folder\"])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS performance during oral phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_wrangling.MyData()\n",
    "model = modeling.HS04Model(cfg)\n",
    "model.build()\n",
    "model.set_active_task(\"pho_sem\")\n",
    "\n",
    "# Instantiate metrics\n",
    "ps_homophone_acc = metrics.RightSideAccuracy(\"ps_homophone_acc\")\n",
    "ps_non_homophone_acc = metrics.RightSideAccuracy(\"ps_non_homophone_acc\")\n",
    "ps_train_acc = metrics.RightSideAccuracy(\"ps_train_acc\")\n",
    "\n",
    "\n",
    "def my_eval(model, cfg, x, y, metrics):\n",
    "    pred_y = model([x] * cfg.n_timesteps)\n",
    "\n",
    "    output = []\n",
    "    for metric in metrics:\n",
    "        metric.update_state(y, pred_y[-1])\n",
    "        output.append(metric.result().numpy())\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def eval_oral_phase_ps(checkpoint):\n",
    "\n",
    "    model.load_weights(checkpoint)\n",
    "\n",
    "    non_homophone = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.testsets[\"non_homophone\"][\"pho\"],\n",
    "        data.testsets[\"non_homophone\"][\"sem\"],\n",
    "        [ps_non_homophone_acc],\n",
    "    )\n",
    "\n",
    "    homophone = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.testsets[\"homophone\"][\"pho\"],\n",
    "        data.testsets[\"homophone\"][\"sem\"],\n",
    "        [ps_homophone_acc],\n",
    "    )\n",
    "\n",
    "    all_train = my_eval(\n",
    "        model,\n",
    "        cfg,\n",
    "        data.pho_train,\n",
    "        data.sem_train,\n",
    "        [ps_train_acc],\n",
    "    )\n",
    "\n",
    "    return non_homophone[0], homophone[0], all_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "for chkpt in tqdm(cfg.path[\"weights_list\"]):\n",
    "    results.append(eval_oral_phase_ps(chkpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"non_homophone\", \"homophone\", \"total\"]\n",
    "df[\"epoch\"] = np.concatenate([np.linspace(1, 10, 10), np.linspace(20, 500, 49)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SP performance during oral phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local ssh to cloud tensorboard\n",
    "# gcloud compute ssh tensorflow-2-4-20210120-000018 --zone us-east4-b -- -L 6006:localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard dev upload --logdir tensorboard_log"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
