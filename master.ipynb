{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF model v4.0\n",
    "HS04 model incorporating non-stationary environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext lab_black\r\n",
    "import os\r\n",
    "import tensorflow as tf\r\n",
    "from tqdm import tqdm\r\n",
    "from time import sleep\r\n",
    "import meta, data_wrangling, metrics, benchmark_hs04, modeling\r\n",
    "\r\n",
    "meta.limit_gpu_memory_use(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters block (for papermill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "code_name = \"OS_ff\"\r\n",
    "batch_name = None\r\n",
    "tf_root = \"/home/jupyter/tf\"\r\n",
    "\r\n",
    "# Model configs\r\n",
    "ort_units = 119\r\n",
    "pho_units = 250\r\n",
    "sem_units = 2446\r\n",
    "hidden_os_units = 500\r\n",
    "hidden_op_units = 100\r\n",
    "hidden_ps_units = 500\r\n",
    "hidden_sp_units = 500\r\n",
    "pho_cleanup_units = 50\r\n",
    "sem_cleanup_units = 50\r\n",
    "pho_noise_level = 1.0\r\n",
    "sem_noise_level = 1.0\r\n",
    "activation = \"sigmoid\"\r\n",
    "\r\n",
    "tau = 1 / 3\r\n",
    "max_unit_time = 4.0\r\n",
    "output_ticks = 13\r\n",
    "inject_error_ticks = 6\r\n",
    "\r\n",
    "# Training configs\r\n",
    "learning_rate = 0.005\r\n",
    "zero_error_radius = 0.1\r\n",
    "save_freq = 10\r\n",
    "\r\n",
    "# Environment configs\r\n",
    "# tasks = (\"pho_sem\", \"sem_pho\", \"pho_pho\", \"sem_sem\", \"triangle\")\r\n",
    "tasks = (\"exp_os_ff\", \"triangle\")\r\n",
    "wf_compression = \"log\"\r\n",
    "wf_clip_low = 0\r\n",
    "wf_clip_high = 999_999_999\r\n",
    "oral_start_pct = 0.02\r\n",
    "# oral_end_pct = 0.5\r\n",
    "oral_end_pct = 1.0\r\n",
    "\r\n",
    "# oral_sample = 900_000\r\n",
    "# oral_tasks_ps = (0.4, 0.4, 0.1, 0.1, 0.)\r\n",
    "# transition_sample = 400_000\r\n",
    "# reading_sample = 4_100_000\r\n",
    "# reading_tasks_ps = (0.2, 0.2, 0.05, 0.05, 0.5)\r\n",
    "\r\n",
    "oral_sample = 1_000_000\r\n",
    "oral_tasks_ps = (1.0, 0.0)\r\n",
    "transition_sample = 0\r\n",
    "reading_sample = 1_000_000\r\n",
    "reading_tasks_ps = (1.0, 0.0)\r\n",
    "\r\n",
    "batch_size = 100\r\n",
    "rng_seed = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = meta.ModelConfig.from_global(globals_dict=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model and all supporting components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(cfg.rng_seed)\n",
    "data = data_wrangling.MyData()\n",
    "\n",
    "# Architechture\n",
    "model = modeling.MyModel(cfg)\n",
    "model.build()\n",
    "\n",
    "# Non-stationary Environment\n",
    "sampler = data_wrangling.Sampler(cfg, data)\n",
    "batch_generator = sampler.generator()\n",
    "sampler.plot_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core training modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since each sub-task has its own states, it must be trained with separate optimizer and losses,\n",
    "# instead of sharing the same optimizer instance (https://github.com/tensorflow/tensorflow/issues/27120)\n",
    "optimizers = {}\n",
    "loss_fns = {}\n",
    "train_losses = {}  # Mean loss (only for TensorBoard)\n",
    "train_metrics = {}\n",
    "\n",
    "# Task specific accuracy\n",
    "## Caution PhoAccuracy is stateful (only taking last batch value in an epoch)\n",
    "## Otherwise, all Stateless metrics are the average of all batches within an epoch\n",
    "\n",
    "acc = {\"pho\": metrics.PhoAccuracy, \"sem\": metrics.StatelessRightSideAccuracy}\n",
    "sse = metrics.StatelessSumSquaredError\n",
    "\n",
    "for task in cfg.tasks:\n",
    "    optimizers[task] = tf.keras.optimizers.Adam(learning_rate=cfg.learning_rate)\n",
    "    if cfg.zero_error_radius is not None:\n",
    "        loss_fns[task] = metrics.CustomBCE(radius=cfg.zero_error_radius)\n",
    "    else:\n",
    "        loss_fns[task] = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    train_losses[task] = tf.keras.metrics.Mean(\n",
    "        f\"train_loss_{task}\", dtype=tf.float32\n",
    "    )  # for tensorboard only\n",
    "\n",
    "    task_output = modeling.IN_OUT[task][1]\n",
    "\n",
    "    if type(task_output) is list:\n",
    "        train_metrics[task] = {}\n",
    "\n",
    "        for out in task_output:\n",
    "            train_metrics[task][out] = [\n",
    "                acc[out](f\"{task}_{out}_acc\"),\n",
    "                sse(f\"{task}_{out}_sse\"),\n",
    "            ]\n",
    "    else:\n",
    "        train_metrics[task] = [acc[task_output](f\"{task}_acc\"), sse(f\"{task}_sse\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainstep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_step(task):\n",
    "    input_name, output_name = modeling.IN_OUT[task]\n",
    "\n",
    "    if task == \"triangle\":\n",
    "\n",
    "        @tf.function\n",
    "        def train_step(\n",
    "            x, y, model, task, loss_fn, optimizer, train_metrics, train_losses\n",
    "        ):\n",
    "            \"\"\"Train a batch, log loss and metrics (last time step only)\"\"\"\n",
    "\n",
    "            train_weights_name = [x + \":0\" for x in modeling.WEIGHTS_AND_BIASES[task]]\n",
    "            train_weights = [x for x in model.weights if x.name in train_weights_name]\n",
    "\n",
    "            # TF Automatic differentiation\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(x, training=True)\n",
    "                # training flag can be access within model by K.in_train_phase()\n",
    "                # it can change the behavior in model() (e.g., turn on/off noise)\n",
    "\n",
    "                loss_value_pho = loss_fn(y[\"pho\"], y_pred[\"pho\"])\n",
    "                loss_value_sem = loss_fn(y[\"sem\"], y_pred[\"sem\"])\n",
    "                loss_value = loss_value_pho + loss_value_sem\n",
    "\n",
    "            grads = tape.gradient(loss_value, train_weights)\n",
    "\n",
    "            # Weight update\n",
    "            optimizer.apply_gradients(zip(grads, train_weights))\n",
    "\n",
    "            # Calculate mean loss and metrics for tensorboard\n",
    "            # Metrics update (Only last time step)\n",
    "            # for y_name, metrics in train_metrics.items():\n",
    "            #     if y_name == \"pho\":\n",
    "            #         # y[0] is pho, y[0][-1] is last time step in pho\n",
    "            #         [\n",
    "            #             m.update_state(\n",
    "            #                 tf.cast(y[\"pho\"][-1], tf.float32), y_pred[\"pho\"][-1]\n",
    "            #             )\n",
    "            #             for m in metrics\n",
    "            #         ]\n",
    "            #     else:\n",
    "            #         # y[1] is sem, y[0][-1] is last time step in sem\n",
    "            #         [\n",
    "            #             m.update_state(\n",
    "            #                 tf.cast(y[\"sem\"][-1], tf.float32), y_pred[\"sem\"][-1]\n",
    "            #             )\n",
    "            #             for m in metrics\n",
    "            #         ]\n",
    "\n",
    "            # # Mean loss\n",
    "            # train_losses.update_state(loss_value)\n",
    "\n",
    "    else:  # Single output tasks\n",
    "\n",
    "        @tf.function\n",
    "        def train_step(\n",
    "            x, y, model, task, loss_fn, optimizer, train_metrics, train_losses\n",
    "        ):\n",
    "            train_weights_name = [x + \":0\" for x in modeling.WEIGHTS_AND_BIASES[task]]\n",
    "            train_weights = [x for x in model.weights if x.name in train_weights_name]\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(x, training=True)\n",
    "                loss_value = loss_fn(y, y_pred[output_name])\n",
    "\n",
    "            grads = tape.gradient(loss_value, train_weights)\n",
    "            optimizer.apply_gradients(zip(grads, train_weights))\n",
    "\n",
    "            # [\n",
    "            #     m.update_state(tf.cast(y[-1], tf.float32), y_pred[output_name][-1])\n",
    "            #     for m in train_metrics\n",
    "            # ]\n",
    "            # train_losses.update_state(loss_value)\n",
    "\n",
    "    return train_step\n",
    "\n",
    "\n",
    "train_steps = {task: get_train_step(task) for task in cfg.tasks}\n",
    "# train_steps = {task: modeling.get_train_step(task) for task in cfg.tasks}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_scalar_to_tensorboard(task, step):\n",
    "#     \"\"\"Write metrics and loss to tensorboard\"\"\"\n",
    "#     loss = train_losses[task]\n",
    "#     tf.summary.scalar(loss.name, loss.result(), step=step)\n",
    "\n",
    "#     maybe_metrics = train_metrics[task]\n",
    "#     if task == \"triangle\":\n",
    "#         [\n",
    "#             tf.summary.scalar(m.name, m.result(), step=step)\n",
    "#             for metrics in maybe_metrics.values()\n",
    "#             for m in metrics\n",
    "#         ]\n",
    "#     else:\n",
    "#         [tf.summary.scalar(m.name, m.result(), step=step) for m in maybe_metrics]\n",
    "\n",
    "\n",
    "# def write_weight_histogram_to_tensorboard(step):\n",
    "#     \"\"\"Weight histogram\"\"\"\n",
    "#     [tf.summary.histogram(f\"{x.name}\", x, step=step) for x in model.weights]\n",
    "\n",
    "\n",
    "# def reset_metrics(task):\n",
    "#     maybe_metrics = train_metrics[task]\n",
    "#     if task == \"triangle\":\n",
    "#         [m.reset_states() for metrics in maybe_metrics.values() for m in metrics]\n",
    "#     else:\n",
    "#         [m.reset_states() for m in maybe_metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TensorBoard writer\n",
    "# train_summary_writer = tf.summary.create_file_writer(\n",
    "#     os.path.join(cfg.tensorboard_folder, \"train\")\n",
    "# )\n",
    "\n",
    "for epoch in tqdm(range(cfg.total_number_of_epoch)):\n",
    "    for step in range(cfg.steps_per_epoch):\n",
    "        # Draw task, create batch\n",
    "        task, exposed_words_idx, x_batch_train, y_batch_train = next(batch_generator)\n",
    "\n",
    "        # task switching must be done outside train_step function (will crash otherwise)\n",
    "        model.set_active_task(task)\n",
    "\n",
    "        # Run a train step\n",
    "        train_steps[task](\n",
    "            x_batch_train,\n",
    "            y_batch_train,\n",
    "            model,\n",
    "            task,\n",
    "            loss_fns[task],\n",
    "            optimizers[task],\n",
    "            train_metrics[task],\n",
    "            train_losses[task],\n",
    "        )\n",
    "\n",
    "    # with train_summary_writer.as_default():\n",
    "    #     ## Write log to tensorboard (Once per epoch)\n",
    "    #   x`  [write_scalar_to_tensorboard(task, step=epoch) for task in cfg.tasks]\n",
    "    #     write_weight_histogram_to_tensorboard(step=epoch)\n",
    "\n",
    "    #     ## Reset metric and loss\n",
    "    #     [train_losses[x].reset_states() for x in cfg.tasks]\n",
    "    #     [reset_metrics(x) for x in cfg.tasks]\n",
    "\n",
    "    # In training loop testset eval\n",
    "    # Kind of fast, but hard to integrate and customize... maybe use offline eval again.\n",
    "    # [strain(task, step=epoch) for task in strain.tasks]\n",
    "    # [grain(task, step=epoch) for task in grain.tasks]\n",
    "\n",
    "    ## Save weights\n",
    "    one_indexing_epoch = epoch + 1\n",
    "    if one_indexing_epoch in cfg.saved_epoches:\n",
    "        weight_path = cfg.saved_weights_fstring.format(epoch=one_indexing_epoch)\n",
    "        model.save_weights(weight_path, overwrite=True, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_hs04.main(code_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil -m rsync -d -r models/{code_name} gs://tf_mirror/{code_name}\n",
    "# sleep(30)\n",
    "# !sudo shutdown -P +0"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "interpreter": {
   "hash": "280b7e50828e23ca5d9e559e41b302061c59f2723c8a67cae862a91c4175be70"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
