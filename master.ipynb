{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triangle model\n",
    "This interactive notebook runs a triangle model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run parameters \n",
    "This block is necessary for running with [papermill](https://papermill.readthedocs.io/en/latest/) in run_papermill.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "code_name = \"share_pretrain_adam_extra_500\"\n",
    "batch_name = None\n",
    "\n",
    "# Model configs\n",
    "ort_units = 119\n",
    "pho_units = 250\n",
    "sem_units = 2446\n",
    "hidden_os_units = 500\n",
    "hidden_op_units = 100\n",
    "hidden_ps_units = 500\n",
    "hidden_sp_units = 500\n",
    "pho_cleanup_units = 50\n",
    "sem_cleanup_units = 50\n",
    "pho_noise_level = 0.0\n",
    "sem_noise_level = 0.0\n",
    "activation = \"sigmoid\"\n",
    "tau = 1 / 3\n",
    "max_unit_time = 4.0\n",
    "\n",
    "# Training configs\n",
    "pretrain_checkpoint = \"models/pretrain_10M/checkpoints/epoch-500\"\n",
    "optimizer = \"adam\"\n",
    "learning_rate = 0.005\n",
    "inject_error_ticks = 11\n",
    "zero_error_radius = 0.1\n",
    "loss_ramping = True\n",
    "\n",
    "# Environment configs\n",
    "wf_compression = \"root\"\n",
    "wf_clip_low = 1500\n",
    "wf_clip_high = 30000\n",
    "task_names = [\"triangle\"]\n",
    "tasks_ps = [1.0]\n",
    "total_sample = 5_000_000\n",
    "batch_size = 100\n",
    "\n",
    "# Misc configs\n",
    "rng_seed = 2021\n",
    "save_freq = 20\n",
    "which_gpu = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System environment\n",
    "Provision GPU resouses, set random seeds, and load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meta\n",
    "\n",
    "meta.split_gpu(which_gpu=which_gpu)  \n",
    "# IMPORTANT: do not import TensorFlow before this line\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set all seeds\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(rng_seed)\n",
    "tf.random.set_seed(rng_seed)\n",
    "np.random.seed(rng_seed)\n",
    "\n",
    "# Loads .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create run configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_root = os.environ.get(\"TF_ROOT\")\n",
    "# cfg = meta.Config.from_json(os.path.join(tf_root, \"models\", code_name, \"model_config.json\"))   # Load from json\n",
    "cfg = meta.Config.from_dict(**globals())\n",
    "print(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experience\n",
    "- `Experience()` defines what the model is trained on. It consists of one or more `Stage()`. \n",
    "- Each `Stage()` describes what tasks are the model trained with, and how often a task is used during training. It contains one or more `Task()`. \n",
    "- Each `Task()` contains how fast the corpus is opened (a set of word that can be sampled), defaults to full open.\n",
    "- CAUTION: Due to technical constrain, we cannot save the staging details in `Experience` in a json file, it requires the orginal code to recreate `Experience`.  \n",
    "- For complex experience, visualize with: \n",
    "    - `experience.plot_task_probability()`\n",
    "    - `experience.plot_corpus()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import Task, Stage, Experience\n",
    "\n",
    "stages = [\n",
    "    Stage(\n",
    "        name=\"one\",\n",
    "        tasks=[Task(x) for x in cfg.task_names],\n",
    "        stage_sample=cfg.total_sample,\n",
    "        task_probability_start=cfg.tasks_ps,\n",
    "    )\n",
    "]\n",
    "\n",
    "experience = Experience(stages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model trainer\n",
    "- In tf.keras terminology, `Trainer()` is the compiled model. \n",
    "- It includes data, model, optimizer, metrics, and loss function, etc.\n",
    "- Since each sub-task has its own states, it will create separate optimizer, metrics, losses in each task.\n",
    "- Once instantiate, It will automatically load cfg.pretrain_checkpoint if exists.\n",
    "- In tf.keras terminology, `trainer.train()` is `model.fit()`.\n",
    "- If trainer.train() try_to_resume argument is True, it will automatically load from unfinished training checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import Trainer, TensorBoardManager\n",
    "\n",
    "trainer = Trainer(cfg, experience)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "Restore from latest checkpoint if it exists. However, due to technical limit, Environment() will no longer be completely identical (same parameter, but new rng) after resuming from checkpoint. It will affects resuming ONLY, i.e., the model trained in one single session will be fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_manager = TensorBoardManager(\n",
    "    cfg, trainer.model, trainer.train_metrics, trainer.train_losses\n",
    ")\n",
    "trainer.train(tensorboard_manager=tb_manager, try_to_resume=True)\n",
    "\n",
    "del trainer  # Release memory before running tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests\n",
    "See `benchmarks.py` for a selection of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import benchmarks\n",
    "# benchmarks.run_oral_homophone(cfg)\n",
    "benchmarks.run_oral_eval(cfg)\n",
    "benchmarks.run_read_eval(cfg)\n",
    "benchmarks.run_lesion(cfg)\n",
    "benchmarks.run_lesion_extra(cfg)\n",
    "\n",
    "\n",
    "## Full training set test\n",
    "# import evaluate\n",
    "# test = evaluate.Test(cfg)\n",
    "# test.eval_train(\"triangle\", to_bq=True)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
