{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual differences (part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import helper\n",
    "from altair.expr import datum\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimResults:\n",
    "    \"\"\" Helper class for defining TD\n",
    "    I: Selection:\n",
    "    1. Control space h-param filter\n",
    "    2. Control space region filter\n",
    "    3. DVs Condition filter\n",
    "    \n",
    "    II: Plotting:\n",
    "    1. Where are the selected model in the control space\n",
    "    2. How's their average performance (in each cond / mean of all conds)\n",
    "    3. Some basic descriptives in title\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self._label_control_space()\n",
    "\n",
    "        # Reuseable plotting element\n",
    "        self.diagonal = (\n",
    "            alt.Chart(pd.DataFrame({\"x\": [0, 1], \"y\": [0, 1]}))\n",
    "            .mark_line(color=\"#D3D3D3\")\n",
    "            .encode(\n",
    "                x=alt.X(\"x\", axis=alt.Axis(title=\"word\")),\n",
    "                y=alt.X(\"y\", axis=alt.Axis(title=\"nonword\")),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def _label_control_space(self):\n",
    "\n",
    "        # Cell label\n",
    "        self.df[\"cell_code\"] = (\n",
    "            \"h\"\n",
    "            + self.df.hidden_units.astype(str)\n",
    "            + \"_p\"\n",
    "            + self.df.p_noise.astype(str)\n",
    "            + \"_l\"\n",
    "            + self.df.learning_rate.astype(str)\n",
    "        )\n",
    "\n",
    "        self.df[\"risk_count\"] = (\n",
    "            (self.df.hidden_units < 100) * 1\n",
    "            + (self.df.p_noise > 3) * 1\n",
    "            + (self.df.learning_rate < 0.004) * 1\n",
    "        )\n",
    "\n",
    "        # Region label\n",
    "        cond_list_p = [\n",
    "            self.df.p_noise < 2,\n",
    "            (self.df.p_noise >= 2) & (self.df.p_noise < 4),\n",
    "            self.df.p_noise >= 4,\n",
    "        ]\n",
    "\n",
    "        cond_list_h = [\n",
    "            self.df.hidden_units >= 250,\n",
    "            (self.df.hidden_units < 250) & (self.df.hidden_units >= 100),\n",
    "            self.df.hidden_units < 100,\n",
    "        ]\n",
    "        cond_list_e = [\n",
    "            self.df.learning_rate >= 0.01,\n",
    "            (self.df.learning_rate >= 0.004) & (self.df.learning_rate < 0.01),\n",
    "            self.df.learning_rate < 0.004,\n",
    "        ]\n",
    "        choice_list = [\"Good\", \"Base\", \"Bad\"]\n",
    "\n",
    "        self.df[\"control_region_p\"] = np.select(cond_list_p, choice_list)\n",
    "        self.df[\"control_region_h\"] = np.select(cond_list_h, choice_list)\n",
    "        self.df[\"control_region_e\"] = np.select(cond_list_e, choice_list)\n",
    "\n",
    "        self.df[\"control_region\"] = (\n",
    "            \"p\"\n",
    "            + self.df.control_region_p\n",
    "            + \"_h\"\n",
    "            + self.df.control_region_h\n",
    "            + \"_e\"\n",
    "            + self.df.control_region_e\n",
    "        )\n",
    "\n",
    "    def count_model(self):\n",
    "        return len(self.df.code_name.unique())\n",
    "\n",
    "    def select_by_control(\n",
    "        self,\n",
    "        hidden_units=None,\n",
    "        p_noise=None,\n",
    "        learning_rate=None,\n",
    "        cleanup_units=None,\n",
    "        verbose=True,\n",
    "    ):\n",
    "        \"\"\"Control space filter by h-params\"\"\"\n",
    "\n",
    "        n_pre = self.count_model()\n",
    "        if hidden_units is not None:\n",
    "            self.df = self.df.loc[self.df.hidden_units.isin(hidden_units)]\n",
    "        if p_noise is not None:\n",
    "            self.df = self.df.loc[self.df.p_noise.isin(p_noise)]\n",
    "        if learning_rate is not None:\n",
    "            self.df = self.df.loc[self.df.learning_rate.isin(learning_rate)]\n",
    "        if cleanup_units is not None:\n",
    "            self.df = self.df.loc[self.df.cleanup_units.isin(cleanup_units)]\n",
    "\n",
    "        n_post = self.count_model()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Selected {n_post} models from the original {n_pre} models\")\n",
    "\n",
    "    def select_by_region(self, region_name, verbose=True):\n",
    "        \"\"\"Control space filter by good/base/bad label\"\"\"\n",
    "\n",
    "        n_pre = self.count_model()\n",
    "        self.df = self.df.loc[self.df.control_region.isin(region_name)]\n",
    "        n_post = self.count_model()\n",
    "        if verbose:\n",
    "            print(f\"Selected {n_post} models from the original {n_pre} models\")\n",
    "\n",
    "    def select_by_cond(self, conds, verbose=True):\n",
    "        \"\"\"Filter DVs by condition\"\"\"\n",
    "\n",
    "        n_pre = self.count_model()\n",
    "        self.df = self.df.loc[self.df.cond.isin(conds)]\n",
    "        n_post = self.count_model()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Selected {n_post} models from the original {n_pre} models\")\n",
    "\n",
    "    ### Descriptives related functions ###\n",
    "    def get_rankpc_desc(self):\n",
    "        desc = self.df.groupby(\"code_name\").mean().reset_index().rank_pc.describe()\n",
    "        return f\"M:{desc['mean']:.3f} SD: {desc['std']:.3f} Min: {desc['min']:.3f} Max: {desc['max']:.3f}\"\n",
    "\n",
    "    def get_acc_desc(self):\n",
    "        desc = self.df.groupby(\"code_name\").mean().reset_index().score.describe()\n",
    "        return f\"M:{desc['mean']:.3f} SD: {desc['std']:.3f} Min: {desc['min']:.3f} Max: {desc['max']:.3f}\"\n",
    "\n",
    "    ### Plotting ###\n",
    "\n",
    "    def plot_control_space(self, color=\"count(code_name)\"):\n",
    "        \"\"\"Plot selected models at control space\"\"\"\n",
    "        pdf = (\n",
    "            self.df.groupby([\"cell_code\", \"control_region\", \"code_name\"])\n",
    "            .mean()\n",
    "            .round(3)\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        self.select_control_space = alt.selection(\n",
    "            type=\"multi\", on=\"click\", empty=\"none\", fields=[\"cell_code\"],\n",
    "        )\n",
    "\n",
    "        control_space = (\n",
    "            alt.Chart(pdf)\n",
    "            .mark_rect(stroke=\"white\", strokeWidth=2)\n",
    "            .encode(\n",
    "                x=\"p_noise:O\",\n",
    "                y=alt.Y(\"hidden_units:O\", sort=\"descending\"),\n",
    "                column=alt.Column(\"learning_rate:O\", sort=\"descending\"),\n",
    "                color=color,\n",
    "                detail=\"cell_code\",\n",
    "                opacity=alt.condition(\n",
    "                    self.select_control_space, alt.value(1), alt.value(0.2)\n",
    "                ),\n",
    "            )\n",
    "            .add_selection(self.select_control_space)\n",
    "        )\n",
    "        return control_space\n",
    "\n",
    "    #     THIS FUNCTION IS COMBINED WITH plot_mean_dev()\n",
    "    #     def _interactive_dev(self, show_sd, baseline=None):\n",
    "    #         \"\"\"Plot the mean development of all selected models\"\"\"\n",
    "\n",
    "    #         development_space_sd = (\n",
    "    #             alt.Chart(self.df)\n",
    "    #             .mark_errorband(extent=\"stdev\")\n",
    "    #             .encode(\n",
    "    #                 y=alt.Y(\"score:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "    #                 x=\"epoch:Q\",\n",
    "    #                 color=alt.Color(\"cond:N\", legend=alt.Legend(orient=\"top\")),\n",
    "    #             )\n",
    "    #             .properties(\n",
    "    #                 title=\"Developmental space: Accuracy in each condition over epoch\"\n",
    "    #             )\n",
    "    #             .transform_filter(self.select_control_space)\n",
    "    #         )\n",
    "\n",
    "    #         development_space_mean = development_space_sd.mark_line().encode(\n",
    "    #             y=\"mean(score):Q\"\n",
    "    #         )\n",
    "\n",
    "    #         if show_sd:\n",
    "    #             development_space_mean += development_space_sd\n",
    "\n",
    "    #         if baseline is not None:\n",
    "    #             development_space_mean += baseline\n",
    "\n",
    "    #         return development_space_mean\n",
    "\n",
    "    def make_wnw(self):\n",
    "        \"\"\" Averaged word vs. nonword over epoch\n",
    "        \"\"\"\n",
    "\n",
    "        variates = [\"hidden_units\", \"p_noise\", \"learning_rate\"]\n",
    "\n",
    "        df_wnw = self.df.loc[\n",
    "            (self.df.cond.isin([\"HF_INC\", \"NW_UN\"])),\n",
    "            variates + [\"code_name\", \"cell_code\", \"epoch\", \"cond\", \"score\"],\n",
    "        ]\n",
    "\n",
    "        df_wnw = df_wnw.pivot_table(\n",
    "            index=variates + [\"epoch\", \"code_name\", \"cell_code\"], columns=\"cond\"\n",
    "        ).reset_index()\n",
    "\n",
    "        df_wnw.columns = df_wnw.columns = [\n",
    "            \"\".join(c).strip() for c in df_wnw.columns.values\n",
    "        ]\n",
    "        df_wnw.rename(\n",
    "            columns={\"scoreHF_INC\": \"word_acc\", \"scoreNW_UN\": \"nonword_acc\",},\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        df_wnw[\"word_advantage\"] = df_wnw.word_acc - df_wnw.nonword_acc\n",
    "\n",
    "        return df_wnw\n",
    "\n",
    "    def _interactive_wnw(self, baseline=None):\n",
    "        \"\"\" Private function for interactive plot: Performance space plot \"\"\"\n",
    "        df = self.make_wnw()\n",
    "\n",
    "        base_wnw = (\n",
    "            alt.Chart(df)\n",
    "            .mark_line(color=\"black\")\n",
    "            .encode(\n",
    "                y=alt.Y(\"mean_nw:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "                x=alt.X(\"mean_w:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "                tooltip=[\"epoch\", \"mean_w:Q\", \"mean_nw:Q\"],\n",
    "            )\n",
    "            .transform_filter(self.select_control_space)\n",
    "            .transform_aggregate(\n",
    "                mean_w=\"mean(word_acc)\", mean_nw=\"mean(nonword_acc)\", groupby=[\"epoch\"]\n",
    "            )\n",
    "            .transform_calculate(\n",
    "                color=\"if(datum.epoch===0.05, 'red', if(datum.epoch === 0.3, 'green', ''))\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        points = (\n",
    "            base_wnw.mark_circle(size=200)\n",
    "            .encode(color=alt.Color(\"color:N\", scale=None))\n",
    "            .add_selection(alt.selection_single())\n",
    "        )\n",
    "\n",
    "        # text = wnw_line.mark_text(align=\"left\", dx=1, size=16).encode(text=\"epoch\")\n",
    "\n",
    "        base_wnw += points\n",
    "\n",
    "        if baseline is not None:\n",
    "            base_wnw += baseline\n",
    "\n",
    "        return (self.diagonal + base_wnw).properties(\n",
    "            title=\"Performance space: Nonword accuracy vs. Word accuracy\"\n",
    "        )\n",
    "\n",
    "    def plot_mean_dev(self, show_sd, by_cond=True, interactive=False, baseline=None):\n",
    "        \"\"\"Plot the mean development of all selected models\n",
    "        interactive = True for plot_interactive() ONLY!\n",
    "        baseline: Overlay a baseline plot\n",
    "        show_sd: Show SD in plot or not\n",
    "        by_cond: True: plot condition in separate line; False: Aggregate condition before plotting\n",
    "        \"\"\"\n",
    "\n",
    "        group_var = [\"code_name\", \"hidden_units\", \"p_noise\", \"learning_rate\", \"epoch\"]\n",
    "        pdf = self.df if by_cond else self.df.groupby(group_var).mean().reset_index()\n",
    "\n",
    "        development_space_sd = (\n",
    "            alt.Chart(pdf)\n",
    "            .mark_errorband(extent=\"stdev\")\n",
    "            .encode(y=alt.Y(\"score:Q\", scale=alt.Scale(domain=(0, 1))), x=\"epoch:Q\",)\n",
    "        )\n",
    "\n",
    "        if by_cond:\n",
    "            development_space_sd = development_space_sd.encode(\n",
    "                color=alt.Color(\"cond:N\", legend=alt.Legend(orient=\"top\"))\n",
    "            )\n",
    "\n",
    "        if interactive:\n",
    "            development_space_sd = development_space_sd.transform_filter(\n",
    "                self.select_control_space\n",
    "            )\n",
    "\n",
    "        # Add Mean\n",
    "        development_space_mean = development_space_sd.mark_line().encode(\n",
    "            y=\"mean(score):Q\"\n",
    "        )\n",
    "\n",
    "        if show_sd:\n",
    "            development_space_mean += development_space_sd\n",
    "\n",
    "        if baseline is not None:\n",
    "            development_space_mean += baseline\n",
    "\n",
    "        return development_space_mean\n",
    "\n",
    "    def plot_mean_wnw(self, baseline=None):\n",
    "        \"\"\"Plot all perforamance space only\"\"\"\n",
    "\n",
    "        df = self.make_wnw()\n",
    "        df = df.groupby(\"epoch\").mean().reset_index()\n",
    "\n",
    "        base_wnw = (\n",
    "            alt.Chart(df)\n",
    "            .mark_line(color=\"black\")\n",
    "            .encode(\n",
    "                y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "                x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "                tooltip=[\"epoch\", \"word_acc:Q\", \"nonword_acc:Q\"],\n",
    "            )\n",
    "            .transform_calculate(\n",
    "                color=\"if(datum.epoch===0.05, 'red', if(datum.epoch === 0.3, 'green', ''))\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        points = base_wnw.mark_circle(size=200).encode(\n",
    "            color=alt.Color(\"color:N\", scale=None)\n",
    "        )\n",
    "\n",
    "        base_wnw += points\n",
    "\n",
    "        if baseline is not None:\n",
    "            base_wnw += baseline\n",
    "\n",
    "        base_wnw += self.diagonal\n",
    "\n",
    "        return base_wnw\n",
    "\n",
    "    def stat_header(self):\n",
    "\n",
    "        n = len(self.df.code_name.unique())\n",
    "\n",
    "        t = [\n",
    "            \"Grand mean rank: \" + self.get_rankpc_desc(),\n",
    "            \"Grand mean acc  : \" + self.get_acc_desc(),\n",
    "        ]\n",
    "\n",
    "        return [f\" (n={n})\"] + t\n",
    "\n",
    "    def plot_interactive(self, title=None, show_sd=True, base_dev=None, base_wnw=None):\n",
    "        \"\"\"Plot averaged developmental and performance space + interactive control space selection\"\"\"\n",
    "\n",
    "        if title is not None:\n",
    "            t = [title] + self.stat_header()\n",
    "\n",
    "        all_plot = (\n",
    "            self.plot_control_space()\n",
    "            & (\n",
    "                self.plot_mean_dev(show_sd=show_sd, interactive=True, baseline=base_dev)\n",
    "                | self._interactive_wnw(baseline=base_wnw)\n",
    "            )\n",
    "        ).properties(title=t)\n",
    "\n",
    "        return all_plot\n",
    "\n",
    "    def plot_heatmap_wadv(self, mode=\"dev\"):\n",
    "        \"\"\"Plot word advantage heatmap\n",
    "        mode: (dev)elopment or (per)formance\n",
    "        \"\"\"\n",
    "        assert mode == \"per\" or mode == \"dev\"\n",
    "\n",
    "        if mode == \"dev\":\n",
    "            x = \"epoch:O\"\n",
    "\n",
    "        if mode == \"per\":\n",
    "            x = alt.X(\"word_acc:Q\", bin=alt.Bin(maxbins=20))\n",
    "\n",
    "        df = self.make_wnw()\n",
    "\n",
    "        plot = (\n",
    "            alt.Chart(df)\n",
    "            .mark_rect()\n",
    "            .encode(\n",
    "                x=x,\n",
    "                y=alt.Y(\"hidden_units:O\", sort=\"descending\"),\n",
    "                row=alt.Row(\"learning_rate:O\", sort=\"descending\"),\n",
    "                column=\"p_noise:O\",\n",
    "                tooltip=[\"epoch\", \"word_acc:Q\", \"nonword_acc:Q\"],\n",
    "                color=alt.Color(\n",
    "                    \"word_advantage\",\n",
    "                    scale=alt.Scale(scheme=\"redyellowgreen\", domain=(-0.3, 0.3)),\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return plot\n",
    "\n",
    "    def plot_performance_multiline(self, var, color=\"blues\"):\n",
    "\n",
    "        df = self.make_wnw()\n",
    "        df = df.groupby([\"epoch\"] + [var]).mean().reset_index()\n",
    "\n",
    "        sel = alt.selection(type=\"multi\", on=\"click\", fields=[var])\n",
    "\n",
    "        plot = (\n",
    "            alt.Chart(df)\n",
    "            .mark_line()\n",
    "            .encode(\n",
    "                y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "                x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "                color=alt.Color(var, type=\"ordinal\", scale=alt.Scale(scheme=color)),\n",
    "                opacity=alt.condition(sel, alt.value(1), alt.value(0.1)),\n",
    "                tooltip=[var, \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "            )\n",
    "            .add_selection(sel)\n",
    "        )\n",
    "\n",
    "        return self.diagonal + plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDGrouping(SimResults):\n",
    "    def __init__(self, main_df, baseline_df):\n",
    "        super().__init__(main_df)\n",
    "\n",
    "        # Criterion measures\n",
    "        self.include_conds = [\"HF_CON\", \"HF_INC\", \"LF_CON\", \"LF_INC\"]\n",
    "\n",
    "        self.td_df = baseline_df\n",
    "        self.td_stat = self.get_stat(self.td_df)\n",
    "\n",
    "        self.cadf = self._make_cadf()\n",
    "        self.zdf = self._make_zdf(self.cadf)\n",
    "        self.pcdf = self._make_pcdf(self.cadf)\n",
    "        self.mzdf = self._melt_zdf(self.zdf)\n",
    "        self.mpcdf = self._melt_pcdf(self.pcdf)\n",
    "\n",
    "    def get_stat(self, df):\n",
    "        \"\"\"Baseline statistics\n",
    "        Return mean and sd by epoch in word \n",
    "        \"\"\"\n",
    "        return (\n",
    "            df.loc[df.cond.isin(self.include_conds),]\n",
    "            .groupby([\"code_name\", \"epoch\"])\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .groupby([\"epoch\"])\n",
    "            .agg([\"mean\", \"std\"])\n",
    "            .score.reset_index()\n",
    "        ).to_dict()\n",
    "\n",
    "    def _reduce_epoch_resolution(self, df):\n",
    "        sel_epoch = [0.01, 0.03, 0.05, 0.07, 0.09, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        return df.loc[\n",
    "            df.epoch.isin(sel_epoch),\n",
    "        ]\n",
    "\n",
    "    def _calcuate_z_deviance(self, row):\n",
    "        \"\"\"Calcuate z score relative to TD at each epoch\n",
    "        \"\"\"\n",
    "        m = self.td_stat[\"mean\"][row[\"epoch_idx\"]]\n",
    "        sd = self.td_stat[\"std\"][row[\"epoch_idx\"]]\n",
    "\n",
    "        # Avoid zero division\n",
    "        if sd == 0:\n",
    "            sd = 1e-6\n",
    "\n",
    "        return (row[\"score\"] - m) / sd\n",
    "\n",
    "    def _calcuate_percetage_of_baseline(self, row):\n",
    "        \"\"\"Calcuate % relative to TD at each epoch\n",
    "        \"\"\"\n",
    "        m = self.td_stat[\"mean\"][row[\"epoch_idx\"]]\n",
    "\n",
    "        return row[\"score\"] / m\n",
    "\n",
    "    def _make_cadf(self):\n",
    "        \"\"\"Make condition avergage df (aggregate cond) with reduced epoch resolution\"\"\"\n",
    "        cadf = (\n",
    "            self.df.loc[self.df.cond.isin(self.include_conds),]\n",
    "            .groupby([\"code_name\", \"epoch\"])\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "        cadf[\"learning_rate\"] = round(cadf.learning_rate, 4)\n",
    "        cadf[\"epoch_idx\"] = cadf.apply(\n",
    "            lambda x: x.epoch * 100 if x.epoch <= 0.1 else x.epoch * 10 + 9, axis=1\n",
    "        )\n",
    "        cadf[\"epoch_idx\"] = cadf.epoch_idx.astype(int)\n",
    "        return self._reduce_epoch_resolution(cadf)\n",
    "\n",
    "    def _make_pcdf(self, cadf):\n",
    "        \"\"\" Make percetange based df\"\"\"\n",
    "        cadf[\"pc\"] = cadf.apply(self._calcuate_percetage_of_baseline, axis=1)\n",
    "\n",
    "        # Different cutoff of RDs by percentage (0 = RD, 1 = TD)\n",
    "        cadf[\"pc_group_50\"] = 1 * (cadf.pc > 0.50)\n",
    "        cadf[\"pc_group_55\"] = 1 * (cadf.pc > 0.55)\n",
    "        cadf[\"pc_group_60\"] = 1 * (cadf.pc > 0.60)\n",
    "        cadf[\"pc_group_65\"] = 1 * (cadf.pc > 0.65)\n",
    "        cadf[\"pc_group_70\"] = 1 * (cadf.pc > 0.70)\n",
    "        cadf[\"pc_group_75\"] = 1 * (cadf.pc > 0.75)\n",
    "        cadf[\"pc_group_80\"] = 1 * (cadf.pc > 0.80)\n",
    "        cadf[\"pc_group_85\"] = 1 * (cadf.pc > 0.85)\n",
    "        cadf[\"pc_group_90\"] = 1 * (cadf.pc > 0.90)\n",
    "\n",
    "        return cadf\n",
    "\n",
    "    def _make_zdf(self, cadf):\n",
    "        \"\"\"Make z-score based df\"\"\"\n",
    "\n",
    "        cadf[\"z_deviance\"] = cadf.apply(self._calcuate_z_deviance, axis=1)\n",
    "\n",
    "        # Different cutoff of RDs (0 = RD, 1 = TD)\n",
    "        cadf[\"group_10\"] = 1 * (cadf.z_deviance > -1.0)\n",
    "        cadf[\"group_11\"] = 1 * (cadf.z_deviance > -1.1)\n",
    "        cadf[\"group_12\"] = 1 * (cadf.z_deviance > -1.2)\n",
    "        cadf[\"group_13\"] = 1 * (cadf.z_deviance > -1.3)\n",
    "        cadf[\"group_14\"] = 1 * (cadf.z_deviance > -1.4)\n",
    "        cadf[\"group_15\"] = 1 * (cadf.z_deviance > -1.5)\n",
    "        cadf[\"group_16\"] = 1 * (cadf.z_deviance > -1.6)\n",
    "        cadf[\"group_17\"] = 1 * (cadf.z_deviance > -1.7)\n",
    "        cadf[\"group_18\"] = 1 * (cadf.z_deviance > -1.8)\n",
    "        cadf[\"group_19\"] = 1 * (cadf.z_deviance > -1.9)\n",
    "        cadf[\"group_20\"] = 1 * (cadf.z_deviance > -2.0)\n",
    "        cadf[\"group_21\"] = 1 * (cadf.z_deviance > -2.1)\n",
    "        cadf[\"group_22\"] = 1 * (cadf.z_deviance > -2.2)\n",
    "        cadf[\"group_23\"] = 1 * (cadf.z_deviance > -2.3)\n",
    "        cadf[\"group_24\"] = 1 * (cadf.z_deviance > -2.4)\n",
    "        cadf[\"group_25\"] = 1 * (cadf.z_deviance > -2.5)\n",
    "        cadf[\"group_26\"] = 1 * (cadf.z_deviance > -2.6)\n",
    "        cadf[\"group_27\"] = 1 * (cadf.z_deviance > -2.7)\n",
    "        cadf[\"group_28\"] = 1 * (cadf.z_deviance > -2.8)\n",
    "        cadf[\"group_29\"] = 1 * (cadf.z_deviance > -2.9)\n",
    "        cadf[\"group_30\"] = 1 * (cadf.z_deviance > -3.0)\n",
    "\n",
    "        return cadf\n",
    "\n",
    "    def _melt_pcdf(self, df):\n",
    "\n",
    "        mdf = df.melt(\n",
    "            id_vars=[\n",
    "                \"code_name\",\n",
    "                \"epoch\",\n",
    "                \"hidden_units\",\n",
    "                \"cleanup_units\",\n",
    "                \"p_noise\",\n",
    "                \"learning_rate\",\n",
    "            ],\n",
    "            value_vars=[\n",
    "                \"pc_group_50\",\n",
    "                \"pc_group_55\",\n",
    "                \"pc_group_60\",\n",
    "                \"pc_group_65\",\n",
    "                \"pc_group_70\",\n",
    "                \"pc_group_75\",\n",
    "                \"pc_group_80\",\n",
    "                \"pc_group_85\",\n",
    "                \"pc_group_90\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        mdf[\"cutoff\"] = mdf.variable.str[-2:].astype(float)\n",
    "\n",
    "        return mdf\n",
    "\n",
    "    def _melt_zdf(self, df):\n",
    "\n",
    "        mdf = df.melt(\n",
    "            id_vars=[\n",
    "                \"code_name\",\n",
    "                \"epoch\",\n",
    "                \"hidden_units\",\n",
    "                \"cleanup_units\",\n",
    "                \"p_noise\",\n",
    "                \"learning_rate\",\n",
    "            ],\n",
    "            value_vars=[\n",
    "                \"group_10\",\n",
    "                \"group_11\",\n",
    "                \"group_12\",\n",
    "                \"group_13\",\n",
    "                \"group_14\",\n",
    "                \"group_15\",\n",
    "                \"group_16\",\n",
    "                \"group_17\",\n",
    "                \"group_18\",\n",
    "                \"group_19\",\n",
    "                \"group_20\",\n",
    "                \"group_21\",\n",
    "                \"group_22\",\n",
    "                \"group_23\",\n",
    "                \"group_24\",\n",
    "                \"group_25\",\n",
    "                \"group_26\",\n",
    "                \"group_27\",\n",
    "                \"group_28\",\n",
    "                \"group_29\",\n",
    "                \"group_30\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        mdf[\"cutoff\"] = mdf.variable.str[-2:].astype(float) / 10\n",
    "\n",
    "        return mdf\n",
    "\n",
    "    def plot_heatmap(self, var):\n",
    "        \"\"\"Z-score deviance over epoch\"\"\"\n",
    "        if var == \"z_deviance\":\n",
    "            domain = (-5, 5)\n",
    "            df = self.zdf\n",
    "        elif var == \"score\":\n",
    "            domain = (0, 1)\n",
    "            df = self.zdf\n",
    "        elif var == \"pc\":\n",
    "            domain = (0, 1)\n",
    "            df = self.pcdf\n",
    "\n",
    "        mean_var = f\"mean({var})\"\n",
    "\n",
    "        hm = (\n",
    "            alt.Chart(df)\n",
    "            .mark_rect()\n",
    "            .encode(\n",
    "                x=\"p_noise:O\",\n",
    "                y=alt.Y(\"hidden_units:O\", sort=\"descending\"),\n",
    "                row=alt.Column(\"learning_rate:O\", sort=\"descending\"),\n",
    "                column=\"epoch:O\",\n",
    "                color=alt.Color(\n",
    "                    mean_var, scale=alt.Scale(domain=domain, scheme=\"redyellowgreen\"),\n",
    "                ),\n",
    "                tooltip=[\"mean(score)\", mean_var],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return hm\n",
    "\n",
    "    def _get_acc_cut(self, epoch, xsd, cond=None):\n",
    "        \"\"\"Get accuracy cut off value with reference to xsd below mean of TD\n",
    "        td_df: data file of typically developing readers (created by Select_Model().df)\n",
    "        epoch: at what epoch to classify RD [list]\n",
    "        xsd: how many sd below mean of TD\n",
    "        cond: include what condition, default = all conditions (no filtering)\n",
    "        \"\"\"\n",
    "\n",
    "        sel = (\n",
    "            self.td_df.loc[self.td_df.epoch.isin(epoch)]\n",
    "            if (cond is None)\n",
    "            else self.td_df.loc[\n",
    "                self.td_df.epoch.isin(epoch) & self.td_df.cond.isin(cond)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        stat = sel.groupby(\"code_name\").mean().score.agg([\"mean\", \"std\"])\n",
    "        return stat[\"mean\"] - xsd * stat[\"std\"]\n",
    "\n",
    "    def select_by_relative_sd(self, epoch, xsd, cond=None):\n",
    "        \"\"\"Select the models that has at least\n",
    "        X SD <xsd> below mean of TD at <epoch>\"\"\"\n",
    "\n",
    "        tmp = (\n",
    "            self.df.loc[self.df.epoch.isin(epoch)]\n",
    "            if (cond is None)\n",
    "            else self.df.loc[self.df.epoch.isin(epoch) & self.df.cond.isin(cond)]\n",
    "        )\n",
    "\n",
    "        mean_tmp = tmp.groupby(\"code_name\").mean().reset_index()\n",
    "        sel = mean_tmp.loc[mean_tmp.score < self._get_acc_cut(epoch, xsd, cond)]\n",
    "        self.df = self.df.loc[self.df.code_name.isin(sel[\"code_name\"])]\n",
    "\n",
    "        # Make deviance\n",
    "        self.cadf = self.make_condition_averaged_df()\n",
    "\n",
    "    def plot_interactive_group_heatmap(self, version=\"pc\"):\n",
    "        \"\"\" Plot interactive grouping heatmap\n",
    "        version: \"pc\" percentage definition\n",
    "                 \"z\" z-score definition\n",
    "        \"\"\"\n",
    "        assert (version == \"pc\") or (version == \"z\")\n",
    "        if version == \"pc\":\n",
    "            use_df = self.mpcdf\n",
    "            slider = alt.binding_range(\n",
    "                min=50.0, max=90.0, step=5.0, name=\"percentage cutoff:\"\n",
    "            )\n",
    "            selector = alt.selection_single(\n",
    "                name=\"SelectorName\",\n",
    "                fields=[\"cutoff\"],\n",
    "                bind=slider,\n",
    "                init={\"cutoff\": 80.0},\n",
    "            )\n",
    "        else:\n",
    "            use_df = self.mzdf\n",
    "            slider = alt.binding_range(min=1.0, max=3.0, step=0.1, name=\"z cutoff:\")\n",
    "            selector = alt.selection_single(\n",
    "                name=\"SelectorName\",\n",
    "                fields=[\"cutoff\"],\n",
    "                bind=slider,\n",
    "                init={\"cutoff\": 2.0},\n",
    "            )\n",
    "\n",
    "        df = (\n",
    "            use_df.groupby(\n",
    "                [\"hidden_units\", \"p_noise\", \"learning_rate\", \"epoch\", \"cutoff\"]\n",
    "            )\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        interactive_group_heatmap = (\n",
    "            alt.Chart(df)\n",
    "            .mark_rect()\n",
    "            .encode(\n",
    "                x=\"p_noise:O\",\n",
    "                y=alt.Y(\"hidden_units:O\", sort=\"descending\"),\n",
    "                row=alt.Column(\"learning_rate:O\", sort=\"descending\"),\n",
    "                column=\"epoch:O\",\n",
    "                color=alt.Color(\n",
    "                    \"value\", scale=alt.Scale(domain=(0, 1), scheme=\"redyellowgreen\"),\n",
    "                ),\n",
    "            )\n",
    "            .add_selection(selector)\n",
    "            .transform_filter(selector)\n",
    "        )\n",
    "\n",
    "        return interactive_group_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import parsed datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim2 = helper.parse_from_file(\"../sims/part3_1750.csv\")\n",
    "sim2 = SimResults(sim2)\n",
    "sim2.df = sim2.df.loc[sim2.df.risk_count >= 1]\n",
    "sim2.df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1520 = helper.parse_from_file(\"../sims/1520_sims.csv\")\n",
    "baseline = SimResults(df_1520)\n",
    "baseline.select_by_control(\n",
    "    hidden_units=[100, 150, 200],\n",
    "    p_noise=[1, 2, 3],\n",
    "    learning_rate=[0.004, 0.006, 0.008],\n",
    "    cleanup_units=[20],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SD in baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1520 = helper.parse_from_file(\"../sims/1520_sims.csv\")\n",
    "sd_df = SimResults(df_1520)\n",
    "sd_df.select_by_control(\n",
    "    hidden_units=[100, 150, 200],\n",
    "    p_noise=[1, 2, 3],\n",
    "    learning_rate=[0.004, 0.006, 0.008],\n",
    "    cleanup_units=[20],\n",
    ")\n",
    "\n",
    "sd_df.select_by_cond([\"HF_INC\", \"HF_CON\", \"LF_INC\", \"LF_CON\"])\n",
    "sd_df.plot_mean_dev(show_sd=True, by_cond=False).properties(\n",
    "    title=\"Mean and SD of word accuracy (all 4 conditions) over Epoch in Baseline\"\n",
    ").save(\"baseline_dev.html\")\n",
    "\n",
    "sd_df.df.cond.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading disability grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = RDGrouping(sim2.df, baseline.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw score / percentage / z-score over epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.plot_heatmap(\"score\").save(\"epoch_score.html\")\n",
    "rd.plot_heatmap(\"pc\").save(\"epoch_pc.html\")\n",
    "rd.plot_heatmap(\"z_deviance\").save(\"epoch_z.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.plot_interactive_group_heatmap(version=\"z\").save(\"grouping_z.html\")\n",
    "rd.plot_interactive_group_heatmap(version=\"pc\").save(\"grouping_pc.html\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
