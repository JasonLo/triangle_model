{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile mikenet_helper.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def parse_mikenet_sims(file_name, task):\n",
    "    \"\"\" Parse item level raw output from MikeNet to Condition level format\n",
    "    This version only export accuracy results\n",
    "    file_name: text file of MikeNet output\n",
    "    task: \"strain\" or \"grain\"\n",
    "    output: formatted pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_table(file_name)\n",
    "    df[\"ID\"] = df.run_id\n",
    "    df[\"Trial.Scaled\"] = df.trial / 1e6\n",
    "    df[\"Pnoise\"] = df.pnoise\n",
    "    df[\"Epsilon\"] = df.epsilon\n",
    "    df[\"Measure\"] = \"Accuracy\"\n",
    "\n",
    "    assert (task == \"strain\") or (task == \"grain\")\n",
    "\n",
    "    if task == \"strain\":\n",
    "        # Strain specific parsing\n",
    "        df[\"Type\"] = df.frequency_type + \"_\" + df.inc_con\n",
    "        df[\"Freq\"] = df.frequency_type\n",
    "        df[\"Cons\"] = df.inc_con\n",
    "        df[\"Score\"] = df.critical_hit\n",
    "\n",
    "    else:\n",
    "        # Grain specific parsing\n",
    "        df[\"Type\"] = df.control_critical.apply(\n",
    "            lambda x: \"NW_AMB\" if x == \"critical\" else \"NW_UN\"\n",
    "        )\n",
    "        df[\"Freq\"] = \"NW\"\n",
    "        df[\"Cons\"] = \"NW\"\n",
    "        df[\"Score\"] = df.acceptable_hit\n",
    "\n",
    "    grouping_variables = [\n",
    "        \"ID\",\n",
    "        \"Trial.Scaled\",\n",
    "        \"Hidden\",\n",
    "        \"PhoHid\",\n",
    "        \"Pnoise\",\n",
    "        \"Epsilon\",\n",
    "        \"Type\",\n",
    "        \"Measure\",\n",
    "        \"Freq\",\n",
    "        \"Cons\",\n",
    "    ]\n",
    "\n",
    "    # Aggregate condition level\n",
    "    parsed_df = df.groupby(grouping_variables, as_index=False).mean()\n",
    "\n",
    "    # Export (Preserving variable order)\n",
    "    export_variables = grouping_variables[0:8] + [\"Score\"] + grouping_variables[8:10]\n",
    "\n",
    "    return parsed_df[export_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = parse_mikenet_sims(\"all_grain_lowHUs.txt\", \"grain\")\n",
    "s1 = parse_mikenet_sims(\"all_strain_lowHUs.txt\", \"strain\")\n",
    "g2 = parse_mikenet_sims(\"all_grain_hiNoise.txt\", \"grain\")\n",
    "s2 = parse_mikenet_sims(\"all_strain_hiNoise.txt\", \"strain\")\n",
    "new_runs = pd.concat([g1, g2, s1, s2], ignore_index=True)\n",
    "new_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New model info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total no. of models: {len(new_runs.ID.unique())}\")\n",
    "\n",
    "[\n",
    "    print(f\"{x}: {new_runs[x].unique()}\")\n",
    "    for x in [\"Hidden\", \"Pnoise\", \"Epsilon\", \"PhoHid\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1250 = pd.read_csv(\"1250_sims.csv\", index_col=0)\n",
    "df_1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1250 + 270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1520 = pd.concat([df_1250, new_runs], ignore_index=True)\n",
    "df_1520.to_csv(\"1520_sims.csv\")\n",
    "df_1520"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safty check: last batch model ID is in new batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1325 = pd.read_csv(\"1325_sims.csv\", index_col=0)\n",
    "import numpy as np\n",
    "np.all(df_1325.ID.isin(df_1520.ID.unique()))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
