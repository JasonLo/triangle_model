{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from tqdm import tqdm\n",
    "\n",
    "alt.data_transformers.enable(\"default\")\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted accuracy over epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"req1_results.csv\", index_col=0)\n",
    "epochs = np.concatenate([np.linspace(0.0, 0.1, 11), np.linspace(0.2, 1.0, 9)])\n",
    "epochs = np.round(epochs, 3)\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vonb(x, max_acc, k, x0):\n",
    "    \"\"\" von Bertalanffy (1938)\n",
    "    Assume that the rate of growth of an organism declines with size \n",
    "    so that the rate of change in length, l,  may be described by:\n",
    "    dl/dt = K (L_inf - l) or under our context: dy/dx = k (max_acc - y)\n",
    "    max_acc: Maximum accuracy / upper asymtote\n",
    "    k: growth rate\n",
    "    x0: x value where model start to learn\n",
    "    \"\"\"\n",
    "    return max_acc * (1 - np.exp(-k * (x - x0)))\n",
    "\n",
    "\n",
    "def clipped_vonb(x, max_acc, k, x0):\n",
    "    return np.clip(max_acc * (1 - np.exp(-k * (x - x0))), 0, 1)\n",
    "\n",
    "\n",
    "def get_params(df, code_name, cond):\n",
    "    return df.loc[\n",
    "        (df.code_name == code_name) & (df.cond == cond), [\"max_acc\", \"k\", \"x0\"]\n",
    "    ].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hp = df.pivot_table(\n",
    "    index=\"code_name\",\n",
    "    values=[\"cleanup_units\", \"hidden_units\", \"learning_rate\", \"p_noise\"],\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame()\n",
    "\n",
    "for model in tqdm(df.code_name.unique()):\n",
    "    this_df = pd.DataFrame()\n",
    "    this_df[\"HF_INC\"] = clipped_vonb(epochs, *get_params(df, model, \"HF_INC\"))\n",
    "    this_df[\"HF_CON\"] = clipped_vonb(epochs, *get_params(df, model, \"HF_CON\"))\n",
    "    this_df[\"LF_INC\"] = clipped_vonb(epochs, *get_params(df, model, \"LF_INC\"))\n",
    "    this_df[\"LF_CON\"] = clipped_vonb(epochs, *get_params(df, model, \"LF_CON\"))\n",
    "    this_df[\"NW_UN\"] = clipped_vonb(epochs, *get_params(df, model, \"NW_UN\"))\n",
    "    this_df[\"NW_AMB\"] = clipped_vonb(epochs, *get_params(df, model, \"NW_AMB\"))\n",
    "    this_df[\"epoch\"] = np.round(epochs, 3)\n",
    "    this_df[\"code_name\"] = model\n",
    "    pdf = pd.concat([pdf, this_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export predicted value to Jay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.melt(id_vars=[\"code_name\", \"epoch\"]).merge(model_hp, on=\"code_name\").to_csv(\n",
    "    \"predicted.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W vs. NW plot for predicted accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(pdf).mark_point().encode(\n",
    "    x=\"HF_INC\",\n",
    "    y=\"NW_UN\",\n",
    "    color=alt.Color(\n",
    "        \"epoch:Q\", scale=alt.Scale(scheme=\"redyellowgreen\", domain=(0, 1)),\n",
    "    ),\n",
    "    opacity=alt.value(0.2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = (\n",
    "    alt.Chart(pdf)\n",
    "    .mark_point()\n",
    "    .encode(\n",
    "        x=\"word\",\n",
    "        y=\"nonword\",\n",
    "        color=alt.Color(\n",
    "            \"epoch:Q\", scale=alt.Scale(scheme=\"redyellowgreen\", domain=(0, 1)),\n",
    "        ),\n",
    "        opacity=alt.value(0.2),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv(\"1250_sims.csv\")\n",
    "sdf = real_df.loc[\n",
    "    (real_df.Measure == \"Accuracy\") & real_df.Type.isin([\"HF_INC\", \"NW_UN\"]),\n",
    "]\n",
    "\n",
    "pvt = sdf.pivot_table(index=[\"ID\", \"Trial.Scaled\"], columns=\"Type\").reset_index()\n",
    "\n",
    "rdf = pd.DataFrame()\n",
    "rdf[\"code_name\"] = pvt.ID\n",
    "rdf[\"epoch\"] = np.round(pvt[\"Trial.Scaled\"], 3)\n",
    "rdf[\"word\"] = pvt.Score.HF_INC\n",
    "rdf[\"nonword\"] = pvt.Score.NW_UN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = (\n",
    "    alt.Chart(rdf)\n",
    "    .mark_point()\n",
    "    .encode(\n",
    "        x=\"word\",\n",
    "        y=\"nonword\",\n",
    "        color=alt.Color(\n",
    "            \"epoch:Q\", scale=alt.Scale(scheme=\"redyellowgreen\", domain=(0, 1)),\n",
    "        ),\n",
    "        opacity=alt.value(0.2),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual | predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge actual and predicted df\n",
    "df = pdf.merge(rdf, on=[\"code_name\", \"epoch\"])\n",
    "df[\"d_word\"] = df.word_x - df.word_y\n",
    "df[\"d_nw\"] = df.nonword_x - df.nonword_y\n",
    "\n",
    "# Merge h-params\n",
    "merge_df = real_df[[\"ID\", \"Trial.Scaled\", \"Hidden\", \"PhoHid\", \"Pnoise\", \"Epsilon\"]]\n",
    "merge_df = merge_df.rename(columns={\"ID\": \"code_name\", \"Trial.Scaled\": \"epoch\"})\n",
    "df = df.merge(merge_df, on=[\"code_name\", \"epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_point().encode(x=\"epoch\", y=\"d_word\", tooltip=[\"d_word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_point().encode(x=\"epoch\", y=\"d_nw\", tooltip=[\"d_nw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.d_word.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.d_nw.mean()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
