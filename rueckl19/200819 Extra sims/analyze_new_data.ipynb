{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from IPython.display import clear_output\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load new (Aug 19, 2020) combined dataset 1325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"1325_sims.csv\", index_col=0)\n",
    "\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"ID\": \"code_name\",\n",
    "        \"Trial.Scaled\": \"epoch\",\n",
    "        \"Hidden\": \"hidden_units\",\n",
    "        \"PhoHid\": \"cleanup_units\",\n",
    "        \"Pnoise\": \"p_noise\",\n",
    "        \"Epsilon\": \"learning_rate\",\n",
    "        \"Type\": \"cond\",\n",
    "        \"Measure\": \"measure\",\n",
    "        \"Score\": \"score\",\n",
    "        \"Freq\": \"cond_freq\",\n",
    "        \"Cons\": \"cond_cons\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df = df.loc[df.measure == \"Accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count model in h-grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variates = [\"hidden_units\", \"cleanup_units\", \"p_noise\", \"learning_rate\"]\n",
    "settings = df[[\"code_name\"] + variates].pivot_table(index=\"code_name\")\n",
    "settings[\"code_name\"] = settings.index\n",
    "settings[\"learning_rate\"] = settings.learning_rate.round(4)\n",
    "\n",
    "count_settings = settings.pivot_table(\n",
    "    index=variates, aggfunc=\"count\", values=\"code_name\",\n",
    ")\n",
    "count_settings.reset_index(inplace=True)\n",
    "count_settings.rename(columns={\"code_name\": \"n\"}, inplace=True)\n",
    "count_settings\n",
    "\n",
    "plot_count = (\n",
    "    alt.Chart(count_settings)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=\"p_noise:O\",\n",
    "        y=\"hidden_units:O\",\n",
    "        row=\"learning_rate:O\",\n",
    "        column=\"cleanup_units:O\",\n",
    "        color=\"n:O\",\n",
    "        tooltip=variates + [\"n\"],\n",
    "    )\n",
    "    .properties(title=\"Model counts\")\n",
    ")\n",
    "\n",
    "plot_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset to 20 cleanup units and aggregrate within each h-param cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = df.loc[\n",
    "    df.cleanup_units == 20,\n",
    "]\n",
    "sdf = sdf.groupby(\n",
    "    [\"epoch\", \"p_noise\", \"hidden_units\", \"learning_rate\", \"cond\"], as_index=False\n",
    ").mean()\n",
    "sdf.drop(columns=[\"code_name\", \"cleanup_units\"], inplace=True)\n",
    "sdf[\"code_name\"] = sdf.agg(\n",
    "    lambda x: f'n{x[\"p_noise\"]}_h{x[\"hidden_units\"]}_l{x[\"learning_rate\"]}', axis=1\n",
    ")\n",
    "\n",
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last epoch accuracy in HF_INC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch_hfinc = sdf.loc[\n",
    "    (sdf.epoch == 1.0) & (sdf.cond == \"HF_INC\"),\n",
    "]\n",
    "\n",
    "alt.Chart(last_epoch_hfinc).mark_rect().encode(\n",
    "    x=\"p_noise:O\",\n",
    "    y=\"hidden_units:O\",\n",
    "    column=\"learning_rate:O\",\n",
    "    color=alt.Color(\"score\", scale=alt.Scale(scheme=\"redyellowgreen\", domain=(0, 1))),\n",
    "    tooltip=[\"score\"],\n",
    ").properties(title=\"End of training accuracy (HF_INC) in each hyperparameter setting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse df_wnw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variates = [\"hidden_units\", \"p_noise\", \"learning_rate\"]\n",
    "\n",
    "df_wnw = sdf.loc[\n",
    "    (sdf.cond.isin([\"HF_INC\", \"NW_UN\"])),\n",
    "    variates + [\"code_name\", \"epoch\", \"cond\", \"score\"],\n",
    "]\n",
    "\n",
    "df_wnw = df_wnw.pivot_table(\n",
    "    index=variates + [\"epoch\", \"code_name\"], columns=\"cond\"\n",
    ").reset_index()\n",
    "\n",
    "df_wnw.columns = df_wnw.columns = [\"\".join(c).strip() for c in df_wnw.columns.values]\n",
    "df_wnw.rename(\n",
    "    columns={\"scoreHF_INC\": \"word_acc\", \"scoreNW_UN\": \"nonword_acc\",}, inplace=True,\n",
    ")\n",
    "\n",
    "df_wnw[\"word_advantage\"] = df_wnw.word_acc - df_wnw.nonword_acc\n",
    "df_wnw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old dashboard reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "\n",
    "def main_dashboard(df, df_dev):\n",
    "\n",
    "    sel_run = alt.selection(type=\"multi\", on=\"click\", fields=[\"code_name\"])\n",
    "\n",
    "    # df for overview\n",
    "    df_ov = df[df.epoch == df.epoch.max()]\n",
    "\n",
    "    # Shared master over-view heatmap\n",
    "    overview = (\n",
    "        alt.Chart(df_ov)\n",
    "        .mark_rect()\n",
    "        .encode(\n",
    "            x=\"p_noise:O\",\n",
    "            y=\"hidden_units:O\",\n",
    "            row=\"learning_rate:O\",\n",
    "            color=alt.Color(\n",
    "                \"word_acc\", scale=alt.Scale(scheme=\"redyellowgreen\", domain=(0, 1))\n",
    "            ),\n",
    "            opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "            tooltip=[\"code_name\", \"word_acc\", \"nonword_acc\", \"word_advantage\"],\n",
    "        )\n",
    "        .add_selection(sel_run)\n",
    "        .properties(title=\"Word accuracy at the end of training\")\n",
    "    )\n",
    "\n",
    "    wnw_mdf = df.melt(\n",
    "        id_vars=[\"code_name\", \"epoch\"],\n",
    "        value_vars=[\"word_acc\", \"nonword_acc\"],\n",
    "        var_name=\"wnw\",\n",
    "        value_name=\"acc\",\n",
    "    )\n",
    "\n",
    "    # Developmental plot\n",
    "    plot_epoch = (\n",
    "        alt.Chart(sdf)\n",
    "        .mark_point()\n",
    "        .encode(\n",
    "            y=alt.Y(\"score:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "            x=\"epoch:Q\",\n",
    "            color=alt.Color(\"cond:N\"),\n",
    "            opacity=alt.condition(sel_run, alt.value(1), alt.value(0)),\n",
    "            tooltip=[\"code_name\", \"epoch\", \"score\"],\n",
    "        )\n",
    "        .properties(title=\"Plot word and nonword accuracy by epoch\")\n",
    "    )\n",
    "\n",
    "    # Word against Nonword\n",
    "    wnw_line = (\n",
    "        alt.Chart(df)\n",
    "        .mark_line()\n",
    "        .encode(\n",
    "            y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "            x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "            color=\"learning_rate:Q\",\n",
    "            opacity=alt.condition(sel_run, alt.value(1), alt.value(0)),\n",
    "            tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    wnw_point = wnw_line.mark_point().encode(\n",
    "        color=alt.Color(\"epoch\", scale=alt.Scale(scheme=\"redyellowgreen\"))\n",
    "    )\n",
    "\n",
    "    diagonal = (\n",
    "        alt.Chart(pd.DataFrame({\"x\": [0, 1], \"y\": [0, 1]}))\n",
    "        .mark_line(color=\"black\")\n",
    "        .encode(x=\"x\", y=\"y\")\n",
    "    )\n",
    "\n",
    "    wnw = diagonal + wnw_line + wnw_point\n",
    "\n",
    "    wnw_interactive = wnw.add_selection(sel_run).properties(\n",
    "        title=\"Word vs. Nonword accuracy at final time step\"\n",
    "    )\n",
    "\n",
    "    ### Mini heatmap ###\n",
    "\n",
    "    mini_wadv = (\n",
    "        alt.Chart(df)\n",
    "        .mark_rect()\n",
    "        .encode(\n",
    "            x=\"epoch:O\",\n",
    "            color=alt.Color(\n",
    "                \"word_advantage:Q\",\n",
    "                scale=alt.Scale(scheme=\"redyellowgreen\", domain=(-0.3, 0.3)),\n",
    "            ),\n",
    "            opacity=alt.condition(sel_run, alt.value(1), alt.value(0)),\n",
    "            tooltip=[\"word_acc\", \"nonword_acc\", \"word_advantage\"] + variates,\n",
    "        )\n",
    "        .properties(title=\"Word - Nonword\")\n",
    "    )\n",
    "\n",
    "    return (overview | (plot_epoch & mini_wadv) | wnw_interactive).resolve_scale(\n",
    "        y=\"independent\", color=\"independent\", shape=\"independent\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_run = alt.selection(type=\"multi\", on=\"click\", fields=[\"code_name\"])\n",
    "\n",
    "df_overview = df_wnw.loc[df_wnw.epoch == df_wnw.epoch.max()]\n",
    "\n",
    "overview = (\n",
    "    alt.Chart(df_overview)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=\"p_noise:O\",\n",
    "        y=\"hidden_units:O\",\n",
    "        row=\"learning_rate:O\",\n",
    "        color=alt.Color(\n",
    "            \"word_acc\", scale=alt.Scale(scheme=\"redyellowgreen\", domain=(0, 1))\n",
    "        ),\n",
    "        opacity=alt.condition(sel_run, alt.value(1), alt.value(0.1)),\n",
    "        tooltip=[\"code_name\", \"word_acc\", \"nonword_acc\", \"word_advantage\"],\n",
    "    )\n",
    "    .add_selection(sel_run)\n",
    "    .properties(title=\"Word accuracy at the end of training\")\n",
    ")\n",
    "\n",
    "overview\n",
    "\n",
    "df_wnw.sort_values(by=[\"code_name\", \"epoch\"], inplace=True)\n",
    "\n",
    "# Word against Nonword\n",
    "wnw_line = (\n",
    "    alt.Chart(df_wnw)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        order=[\"epoch\"],\n",
    "        color=\"code_name:N\",\n",
    "        opacity=alt.condition(sel_run, alt.value(1), alt.value(0)),\n",
    "        tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "diagonal = (\n",
    "    alt.Chart(pd.DataFrame({\"x\": [0, 1], \"y\": [0, 1]}))\n",
    "    .mark_line(color=\"black\")\n",
    "    .encode(x=\"x\", y=\"y\")\n",
    ")\n",
    "\n",
    "wnw = diagonal + wnw_line\n",
    "\n",
    "wnw_interactive = wnw.add_selection(sel_run).properties(\n",
    "    title=\"Word vs. Nonword accuracy at final time step\"\n",
    ")\n",
    "\n",
    "overview | wnw_interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating HS99 Fig 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of reducing learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df = df_wnw.loc[(df_wnw.hidden_units == 100) & (df_wnw.p_noise == 0.0)]\n",
    "\n",
    "\n",
    "wnw_line = (\n",
    "    alt.Chart(lr_df)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        order=[\"epoch\"],\n",
    "        color=alt.Color(\"learning_rate\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "diagonal = (\n",
    "    alt.Chart(pd.DataFrame({\"x\": [0, 1], \"y\": [0, 1]}))\n",
    "    .mark_line(color=\"black\")\n",
    "    .encode(x=\"x\", y=\"y\")\n",
    ")\n",
    "\n",
    "diagonal + wnw_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of all learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from altair.expr import datum\n",
    "\n",
    "wnw_point = (\n",
    "    alt.Chart(df_wnw)\n",
    "    .mark_point()\n",
    "    .encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        order=[\"epoch\"],\n",
    "        color=alt.Color(\"learning_rate:O\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "base = wnw_point + wnw_point.transform_loess(\n",
    "    \"word_acc\", \"nonword_acc\", groupby=[\"learning_rate\"], bandwidth=0.5\n",
    ").mark_line(size=4)\n",
    "\n",
    "gplot = alt.vconcat()\n",
    "\n",
    "\n",
    "for noise in np.sort(df_wnw.p_noise.unique())[::-1]:\n",
    "    plot = alt.hconcat()\n",
    "    for h in df_wnw.hidden_units.unique():\n",
    "        plot |= base.transform_filter(\n",
    "            (datum.hidden_units == h) & (datum.p_noise == noise)\n",
    "        ).properties(title=f\"hidden units = {h}, Pnoise = {noise}\")\n",
    "    gplot &= plot\n",
    "\n",
    "gplot.save(\"effect_lr.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of reducing hidden units (all levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_df = df_wnw.loc[(df_wnw.p_noise == 0.0) & (df_wnw.learning_rate == 0.01)]\n",
    "\n",
    "\n",
    "wnw_line = (\n",
    "    alt.Chart(hu_df)\n",
    "    .mark_point()\n",
    "    .encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        order=[\"epoch\"],\n",
    "        color=alt.Color(\"hidden_units\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "wnw_line + wnw_line.transform_loess(\n",
    "    \"word_acc\", \"nonword_acc\", groupby=[\"hidden_units\"], bandwidth=0.5\n",
    ").mark_line(size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of reducing hidden units (<=100 HU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_df = df_wnw.loc[\n",
    "    (df_wnw.hidden_units <= 100)\n",
    "    & (df_wnw.p_noise == 0.0)\n",
    "    & (df_wnw.learning_rate == 0.01)\n",
    "]\n",
    "\n",
    "\n",
    "wnw_line = (\n",
    "    alt.Chart(hu_df)\n",
    "    .mark_point()\n",
    "    .encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        order=[\"epoch\"],\n",
    "        color=alt.Color(\"hidden_units\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "wnw_line + wnw_line.transform_loess(\n",
    "    \"word_acc\", \"nonword_acc\", groupby=[\"hidden_units\"], bandwidth=0.5\n",
    ").mark_line(size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All hidden unit effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from altair.expr import datum\n",
    "\n",
    "wnw_point = (\n",
    "    alt.Chart(df_wnw)\n",
    "    .mark_point()\n",
    "    .encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        order=[\"epoch\"],\n",
    "        color=alt.Color(\"hidden_units:O\", scale=alt.Scale(scheme=\"redyellowgreen\")),\n",
    "        tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "base = wnw_point + wnw_point.transform_loess(\n",
    "    \"word_acc\", \"nonword_acc\", groupby=[\"hidden_units\"], bandwidth=0.5\n",
    ").mark_line(size=4)\n",
    "\n",
    "gplot = alt.vconcat()\n",
    "\n",
    "\n",
    "for noise in np.sort(df_wnw.p_noise.unique())[::-1]:\n",
    "    plot = alt.hconcat()\n",
    "    for lr in df_wnw.learning_rate.unique():\n",
    "        plot |= base.transform_filter(\n",
    "            (datum.learning_rate == lr) & (datum.p_noise == noise)\n",
    "        ).properties(title=f\"leanrning rate = {lr}, Pnoise = {noise}\")\n",
    "    gplot &= plot\n",
    "\n",
    "gplot.save(\"effect_hidden.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invasive P lesion in HS99 at development space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs99 = pd.read_csv(\"hs99_severe.csv\")\n",
    "hs99_w = (\n",
    "    alt.Chart(hs99)\n",
    "    .mark_line(color=\"blue\")\n",
    "    .encode(\n",
    "        x=alt.X(\"epoch\", scale=alt.Scale(domain=(0, 10))),\n",
    "        y=alt.Y(\"w_acc\", scale=alt.Scale(domain=(0, 100))),\n",
    "    )\n",
    ")\n",
    "\n",
    "hs99_nw = (\n",
    "    alt.Chart(hs99)\n",
    "    .mark_line(color=\"red\")\n",
    "    .encode(\n",
    "        x=alt.X(\"epoch\", scale=alt.Scale(domain=(0, 10))),\n",
    "        y=alt.Y(\"nw_acc\", scale=alt.Scale(domain=(0, 100))),\n",
    "    )\n",
    ")\n",
    "\n",
    "hs99_w + hs99_nw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invasive P lesion in HS99 at performance space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = (\n",
    "    alt.Chart(hs99)\n",
    "    .mark_point()\n",
    "    .encode(\n",
    "        x=alt.X(\"w_acc\", scale=alt.Scale(domain=(0, 100))),\n",
    "        y=alt.Y(\"nw_acc\", scale=alt.Scale(domain=(0, 100))),\n",
    "        color=\"epoch:Q\",\n",
    "    )\n",
    ")\n",
    "\n",
    "line = (\n",
    "    alt.Chart(hs99)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        x=alt.X(\"w_acc\", scale=alt.Scale(domain=(0, 100))),\n",
    "        y=alt.Y(\"nw_acc\", scale=alt.Scale(domain=(0, 100))),\n",
    "        order=\"epoch\",\n",
    "    )\n",
    ")\n",
    "\n",
    "point + line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-noise effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_df = df_wnw.loc[(df_wnw.hidden_units == 100) & (df_wnw.learning_rate == 0.01)]\n",
    "noise_df.columns\n",
    "\n",
    "wnw_line = (\n",
    "    alt.Chart(noise_df)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        order=[\"epoch\"],\n",
    "        color=alt.Color(\n",
    "            \"p_noise\", scale=alt.Scale(scheme=\"redyellowgreen\", reverse=True)\n",
    "        ),\n",
    "        tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "diagonal = (\n",
    "    alt.Chart(pd.DataFrame({\"x\": [0, 1], \"y\": [0, 1]}))\n",
    "    .mark_line(color=\"black\")\n",
    "    .encode(x=\"x\", y=\"y\")\n",
    ")\n",
    "\n",
    "diagonal + wnw_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_point = wnw_line.mark_point()\n",
    "\n",
    "noise_point + noise_point.transform_loess(\n",
    "    \"word_acc\", \"nonword_acc\", groupby=[\"p_noise\"], bandwidth=0.5\n",
    ").mark_line(size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P_noise full range effect at hidden = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_df = df_wnw.loc[(df_wnw.hidden_units == 75) & (df_wnw.learning_rate == 0.01)]\n",
    "noise_df.columns\n",
    "\n",
    "wnw_line = (\n",
    "    alt.Chart(noise_df)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        order=[\"epoch\"],\n",
    "        color=alt.Color(\n",
    "            \"p_noise\", scale=alt.Scale(scheme=\"redyellowgreen\", reverse=True)\n",
    "        ),\n",
    "        tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "diagonal = (\n",
    "    alt.Chart(pd.DataFrame({\"x\": [0, 1], \"y\": [0, 1]}))\n",
    "    .mark_line(color=\"black\")\n",
    "    .encode(x=\"x\", y=\"y\")\n",
    ")\n",
    "\n",
    "diagonal + wnw_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_point = wnw_line.mark_point()\n",
    "\n",
    "noise_point + noise_point.transform_loess(\n",
    "    \"word_acc\", \"nonword_acc\", groupby=[\"p_noise\"], bandwidth=0.5\n",
    ").mark_line(size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All p-noise effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from altair.expr import datum\n",
    "\n",
    "noise_df = df_wnw\n",
    "noise_df.columns\n",
    "\n",
    "\n",
    "wnw_point = (\n",
    "    alt.Chart(noise_df)\n",
    "    .mark_point()\n",
    "    .encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        order=[\"epoch\"],\n",
    "        color=alt.Color(\n",
    "            \"p_noise\", scale=alt.Scale(scheme=\"redyellowgreen\", reverse=True)\n",
    "        ),\n",
    "        tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "base = wnw_point + wnw_point.transform_loess(\n",
    "    \"word_acc\", \"nonword_acc\", groupby=[\"p_noise\"], bandwidth=0.5\n",
    ").mark_line(size=4)\n",
    "\n",
    "gplot = alt.vconcat()\n",
    "\n",
    "\n",
    "for h in df_wnw.hidden_units.unique():\n",
    "    plot = alt.hconcat()\n",
    "    for lr in df_wnw.learning_rate.unique():\n",
    "        plot |= base.transform_filter(\n",
    "            (datum.learning_rate == lr) & (datum.hidden_units == h)\n",
    "        ).properties(title=f\"leanrning rate = {lr}, hidden units = {h}\")\n",
    "    gplot &= plot\n",
    "\n",
    "gplot.save(\"effect_p_noise.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: will there be a HF group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"1325_sims.csv\", index_col=0)\n",
    "\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"ID\": \"code_name\",\n",
    "        \"Trial.Scaled\": \"epoch\",\n",
    "        \"Hidden\": \"hidden_units\",\n",
    "        \"PhoHid\": \"cleanup_units\",\n",
    "        \"Pnoise\": \"p_noise\",\n",
    "        \"Epsilon\": \"learning_rate\",\n",
    "        \"Type\": \"cond\",\n",
    "        \"Measure\": \"measure\",\n",
    "        \"Score\": \"score\",\n",
    "        \"Freq\": \"cond_freq\",\n",
    "        \"Cons\": \"cond_cons\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df = df.loc[df.measure == \"Accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part2 = df.loc[\n",
    "    df.cleanup_units == 20,\n",
    "]\n",
    "df_part2.columns\n",
    "df_part2.drop(columns=[\"cleanup_units\", \"measure\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model level performance grouping 0-25, 25-75, 75-100 percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gacc = df_part2.groupby(\"code_name\", as_index=False).mean()\n",
    "gacc = gacc[[\"code_name\", \"score\"]]\n",
    "gacc[\"rank_pc\"] = gacc.score.rank(pct=True)\n",
    "gacc[\"group\"] = gacc.rank_pc.map(\n",
    "    lambda x: \"High\" if x > 0.75 else (\"Mid\" if x > 0.25 else \"Low\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new df for grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = (\n",
    "    df_part2.merge(gacc[[\"code_name\", \"group\"]], how=\"left\")\n",
    "    .groupby([\"group\", \"epoch\", \"cond\"], as_index=False)\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_group).mark_line().encode(\n",
    "    x=\"epoch:Q\", y=\"score:Q\", color=\"cond:N\", column=\"group:N\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wnw_group = df_group.pivot_table(\n",
    "    index=[\"group\", \"epoch\"], columns=\"cond\", values=\"score\"\n",
    ").reset_index()\n",
    "\n",
    "alt.Chart(df_wnw_group).mark_line().encode(x=\"HF_INC\", y=\"NW_UN\", color=\"group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_all = df_part2.merge(gacc[[\"code_name\", \"group\"]], how=\"left\")\n",
    "\n",
    "df_wnw_group_all = df_group_all.pivot_table(\n",
    "    index=[\"group\", \"epoch\", \"code_name\"], columns=\"cond\", values=\"score\"\n",
    ").reset_index()\n",
    "\n",
    "alt.Chart(\n",
    "    df_wnw_group_all.loc[df_wnw_group_all.group.isin([\"Mid\", \"High\"])],\n",
    ").mark_boxplot().encode(x=\"HF_INC\", y=\"NW_UN\", color=\"group\",).properties(\n",
    "    width=800\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refit growth model with robust von bertaleffy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vonb(x, max_acc, k, x0):\n",
    "    \"\"\" von Bertalanffy (1938)\n",
    "    Assume that the rate of growth of an organism declines with size \n",
    "    so that the rate of change in length, l,  may be described by:\n",
    "    dl/dt = K (L_inf - l) or under our context: dy/dx = k (max_acc - y)\n",
    "    max_acc: Maximum accuracy / upper asymtote\n",
    "    k: growth rate\n",
    "    x0: x value where model start to learn\n",
    "    \"\"\"\n",
    "    return max_acc * (1 - np.exp(-k * (x - x0)))\n",
    "\n",
    "\n",
    "def get_df(df, code_name, cond, remove_zero=False):\n",
    "    \"\"\"\n",
    "    Convienient function for subsetting data\n",
    "    \"\"\"\n",
    "    data = df.loc[\n",
    "        (df.code_name == code_name)\n",
    "        & (df.cond == cond)\n",
    "        & (df.measure == \"Accuracy\"),  # Early points are too volatile\n",
    "        [\"epoch\", \"score\"],\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    if remove_zero:\n",
    "        data = data.loc[\n",
    "            data.score > 0,\n",
    "        ]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "class growth_model:\n",
    "    def __init__(self, df, growth_fx, bounds, name, robust=False, f_scale=0.02):\n",
    "        \"\"\" Fit growth models\n",
    "        df: datafile with score (y) and epoch (x)\n",
    "        growth_fx: growth function to fit\n",
    "        bounds: model constrain of parameters\n",
    "        name: model name\n",
    "        robust: whether to use robust method\n",
    "        f_scale (only or robust = True): soft residual cutoff for outlier, \n",
    "            used in scipy.optimize.least_squares()\n",
    "        See https://scipy-cookbook.readthedocs.io/items/robust_regression.html\n",
    "        for more details\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.growth_fx = growth_fx\n",
    "        self.bounds = (-np.inf, np.inf) if bounds == None else bounds\n",
    "        self.__name__ = name\n",
    "        self.f_scale = f_scale\n",
    "\n",
    "        # Create plotting dataset\n",
    "        self.df[\"set\"] = \"actual\"\n",
    "        self.actual = self.df.score\n",
    "        self.n = len(self.df)\n",
    "\n",
    "        # Fit model\n",
    "        self.fit_robust() if robust else self.fit()\n",
    "\n",
    "        # Predicts\n",
    "        self.pred = self.growth_fx(self.df.epoch, *self.params)\n",
    "        self.res = np.sum(np.square(self.pred - self.actual))\n",
    "        self.adj_res = self.res * 19 / self.n\n",
    "\n",
    "        model_df = pd.DataFrame(\n",
    "            {\"epoch\": self.df.epoch, \"score\": self.pred, \"set\": \"predict\",}\n",
    "        )\n",
    "        self.df = pd.concat([self.df, model_df], ignore_index=True)\n",
    "\n",
    "    def fit(self):\n",
    "\n",
    "        self.params, _ = curve_fit(\n",
    "            self.growth_fx, self.df.epoch, self.df.score, bounds=self.bounds\n",
    "        )\n",
    "\n",
    "    def fit_robust(self):\n",
    "        \"\"\" Fitting the selected curve with robust method\n",
    "        \"\"\"\n",
    "        self.params, _ = curve_fit(\n",
    "            self.growth_fx,\n",
    "            self.df.epoch,\n",
    "            self.df.score,\n",
    "            bounds=self.bounds,\n",
    "            maxfev=10000,\n",
    "            method=\"trf\",  # Relatively robust method\n",
    "            loss=\"soft_l1\",  # More robust to outlier\n",
    "            f_scale=self.f_scale,  # Soft boundary for outlier residual, based on specific data set,\n",
    "        )\n",
    "\n",
    "    def plot(self):\n",
    "        return (\n",
    "            alt.Chart(self.df)\n",
    "            .mark_line(point=True)\n",
    "            .encode(\n",
    "                y=alt.Y(\"score\", scale=alt.Scale(domain=(0, 1))),\n",
    "                x=alt.X(\"epoch\", scale=alt.Scale(domain=(0, 1))),\n",
    "                color=\"set\",\n",
    "            )\n",
    "            .properties(\n",
    "                title=[\n",
    "                    f\"Model: {self.__name__}\",\n",
    "                    f\"Parameters: {self.params.round(3)}\",\n",
    "                    f\"Residual (SSE): {self.res:.3f}\",\n",
    "                    f\"Data point adjusted residual {self.adj_res:.3f}\",\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_df = df.loc[\n",
    "    df.code_name == df.code_name.unique()[1292],\n",
    "]\n",
    "\n",
    "sel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.cond.unique():\n",
    "    print(c)\n",
    "    tmp = get_df(df, 163115474, c, remove_zero=True)\n",
    "    print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit growth model in each run x condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "n = len(df.code_name.unique())\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for m in df.code_name.unique():\n",
    "    clear_output(wait=True)\n",
    "    i += 1\n",
    "    print(\"Processing model {} of {}\".format(i, n))\n",
    "    for c in df.cond.unique():\n",
    "        m1 = growth_model(\n",
    "            get_df(df, m, c, remove_zero=True),\n",
    "            vonb,\n",
    "            (0, [1, np.inf, 1]),\n",
    "            \"rEQ1\",\n",
    "            True,\n",
    "            0.01,\n",
    "        )\n",
    "        m1_result = pd.DataFrame(\n",
    "            {\n",
    "                \"model\": \"EQ1\",\n",
    "                \"adj_residual\": m1.adj_res,\n",
    "                \"max_acc\": m1.params[0],\n",
    "                \"k\": m1.params[1],\n",
    "                \"x0\": m1.params[2],\n",
    "            },\n",
    "            index=[0],\n",
    "        )\n",
    "        m1_result[\"code_name\"] = m\n",
    "        m1_result[\"cond\"] = c\n",
    "\n",
    "        results = pd.concat([results, m1_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec = df.groupby(\"code_name\").mean().reset_index()\n",
    "model_spec.drop(columns=[\"epoch\", \"score\"], inplace=True)\n",
    "\n",
    "robust_eq1_results = robust_eq1_results.reset_index()\n",
    "robust_eq1_results = robust_eq1_results.merge(model_spec, on=\"code_name\")\n",
    "robust_eq1_results.to_csv(\"growth_1325.csv\")\n",
    "print(f\"EQ 1 mean residual = {robust_eq1_results.adj_residual.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
