{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual differences (part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import helper\n",
    "from altair.expr import datum\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Select_Model:\n",
    "    \"\"\" Helper class for defining TD\n",
    "    I: Selection:\n",
    "    1. Control space filter\n",
    "    2. Rank filter\n",
    "    3. Accuracy filter (developmental)\n",
    "    \n",
    "    II: Plotting:\n",
    "    1. Where are the selected model in the control space\n",
    "    2. How's their average performance (in each cond / mean of all conds)\n",
    "    3. Some basic descriptives in title\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "        self.df[\"cell_code\"] = (\n",
    "            \"h\"\n",
    "            + self.df.hidden_units.astype(str)\n",
    "            + \"_p\"\n",
    "            + self.df.p_noise.astype(str)\n",
    "            + \"_l\"\n",
    "            + self.df.learning_rate.astype(str)\n",
    "        )\n",
    "\n",
    "    def count_model(self):\n",
    "        return len(self.df.code_name.unique())\n",
    "\n",
    "    # Selection related functions\n",
    "\n",
    "    def select_by_performance(self, threshold_low, threshold_hi, t_low, t_hi):\n",
    "\n",
    "        n_pre = self.count_model()\n",
    "        tmp = self.pivot_to_wide(self.df, t_low, t_hi)\n",
    "        # Selected models\n",
    "        tmp = tmp.loc[(tmp.t_low < threshold_low) & (tmp.t_hi > threshold_hi)]\n",
    "\n",
    "        # Create full dataframe of selected models\n",
    "        self.df = (\n",
    "            self.df.loc[self.df.code_name.isin(tmp.code_name)]\n",
    "            .sort_values(by=[\"code_name\", \"cond\", \"epoch\"])\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        n_post = self.count_model()\n",
    "        print(f\"Selected {n_post} models from the original {n_pre} models\")\n",
    "\n",
    "    def select_by_control(self, hidden_units=None, p_noise=None, learning_rate=None):\n",
    "\n",
    "        n_pre = self.count_model()\n",
    "        if hidden_units is not None:\n",
    "            self.df = self.df.loc[self.df.hidden_units.isin(hidden_units)]\n",
    "        if p_noise is not None:\n",
    "            self.df = self.df.loc[self.df.p_noise.isin(p_noise)]\n",
    "        if learning_rate is not None:\n",
    "            self.df = self.df.loc[self.df.learning_rate.isin(learning_rate)]\n",
    "\n",
    "        n_post = self.count_model()\n",
    "        print(f\"Selected {n_post} models from the original {n_pre} models\")\n",
    "\n",
    "    def select_by_rankpc(self, minpc, maxpc):\n",
    "        n_pre = self.count_model()\n",
    "        self.df = self.df.loc[(self.df.rank_pc >= minpc) & (self.df.rank_pc <= maxpc)]\n",
    "        n_post = self.count_model()\n",
    "        print(f\"Selected {n_post} models from the original {n_pre} models\")\n",
    "\n",
    "    def select_by_cond(self, conds):\n",
    "        n_pre = self.count_model()\n",
    "        self.df = self.df.loc[self.df.cond.isin(conds)]\n",
    "        n_post = self.count_model()\n",
    "        print(f\"Selected {n_post} models from the original {n_pre} models\")\n",
    "\n",
    "    # Descriptives related functions\n",
    "\n",
    "    def get_rankpc_desc(self):\n",
    "        desc = self.df.groupby(\"code_name\").mean().reset_index().rank_pc.describe()\n",
    "        return f\"M:{desc['mean']:.3f} SD: {desc['std']:.3f} Min: {desc['min']:.3f} Max: {desc['max']:.3f}\"\n",
    "\n",
    "    def get_acc_desc(self):\n",
    "        desc = self.df.groupby(\"code_name\").mean().reset_index().score.describe()\n",
    "        return f\"M:{desc['mean']:.3f} SD: {desc['std']:.3f} Min: {desc['min']:.3f} Max: {desc['max']:.3f}\"\n",
    "\n",
    "    # Plotting related functions\n",
    "\n",
    "    def pivot_to_wide(self, df, t_low, t_hi):\n",
    "        \"\"\" Create a pivot table of model's t_low and t_hi as column\n",
    "        df: input datafile\n",
    "        t_low: epoch used in applying threshold_low\n",
    "        t_hi : epoch used in applying threshold_hi\n",
    "        \"\"\"\n",
    "        tmp = df.loc[(df.epoch.isin([t_low, t_hi]))]\n",
    "\n",
    "        index_names = [\n",
    "            \"code_name\",\n",
    "            \"hidden_units\",\n",
    "            \"p_noise\",\n",
    "            \"learning_rate\",\n",
    "        ]\n",
    "\n",
    "        pvt = tmp.pivot_table(\n",
    "            index=index_names, columns=\"epoch\", values=\"score\",\n",
    "        ).reset_index()\n",
    "\n",
    "        # Rename new columns\n",
    "        pvt.columns = index_names + [\"t_low\", \"t_hi\"]\n",
    "        return pvt\n",
    "\n",
    "    def plot_control_space(self):\n",
    "        \"\"\"Plot selected models at control space\"\"\"\n",
    "        pdf = self.df.groupby(\"code_name\").mean().round(3).reset_index()\n",
    "\n",
    "        pdf[\"cell_code\"] = (\n",
    "            \"h\"\n",
    "            + pdf.hidden_units.astype(str)\n",
    "            + \"_p\"\n",
    "            + pdf.p_noise.astype(str)\n",
    "            + \"_l\"\n",
    "            + pdf.learning_rate.astype(str)\n",
    "        )\n",
    "\n",
    "        self.select_control_space = alt.selection(\n",
    "            type=\"multi\", on=\"click\", empty=\"none\", fields=[\"cell_code\"],\n",
    "        )\n",
    "\n",
    "        control_space = (\n",
    "            alt.Chart(pdf)\n",
    "            .mark_rect()\n",
    "            .encode(\n",
    "                x=\"p_noise:O\",\n",
    "                y=alt.Y(\"hidden_units:O\", sort=\"descending\"),\n",
    "                column=alt.Column(\"learning_rate:O\", sort=\"descending\"),\n",
    "                color=\"count(code_name)\",\n",
    "                detail=\"cell_code\",\n",
    "                opacity=alt.condition(\n",
    "                    self.select_control_space, alt.value(1), alt.value(0.2)\n",
    "                ),\n",
    "            )\n",
    "            .add_selection(self.select_control_space)\n",
    "        )\n",
    "        return control_space\n",
    "\n",
    "    def plot_mean_development(self, show_sd):\n",
    "        \"\"\"Plot the mean development of all selected models\"\"\"\n",
    "\n",
    "        development_space_sd = (\n",
    "            alt.Chart(self.df)\n",
    "            .mark_errorband(extent=\"stdev\")\n",
    "            .encode(\n",
    "                y=alt.Y(\"score:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "                x=\"epoch:Q\",\n",
    "                color=alt.Color(\"cond:N\", legend=alt.Legend(orient=\"top\")),\n",
    "            )\n",
    "            .properties(\n",
    "                title=\"Developmental space: Accuracy in each condition over epoch\"\n",
    "            )\n",
    "            .transform_filter(self.select_control_space)\n",
    "        )\n",
    "\n",
    "        development_space_mean = development_space_sd.mark_line().encode(\n",
    "            y=\"mean(score):Q\"\n",
    "        )\n",
    "\n",
    "        this_plot = (\n",
    "            (development_space_mean + development_space_sd)\n",
    "            if show_sd\n",
    "            else development_space_mean\n",
    "        )\n",
    "        return this_plot\n",
    "\n",
    "    def plot_all_cond_mean(self, show_sd):\n",
    "        \"\"\"Plot the average accuracy in all conditions over epoch of all selected models\"\"\"\n",
    "        group_var = [\"code_name\", \"hidden_units\", \"p_noise\", \"learning_rate\", \"epoch\"]\n",
    "        pdf = self.df.groupby(group_var).mean().reset_index()\n",
    "\n",
    "        dev_all_sd = (\n",
    "            alt.Chart(pdf)\n",
    "            .mark_errorband(extent=\"stdev\")\n",
    "            .encode(y=alt.Y(\"score:Q\", scale=alt.Scale(domain=(0, 1))), x=\"epoch:Q\",)\n",
    "            .properties(\n",
    "                title=\"Developmental space: Mean Accuracy in all conditions over epoch\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        dev_all_m = dev_all_sd.mark_line().encode(y=\"mean(score):Q\")\n",
    "\n",
    "        this_plot = (dev_all_m + dev_all_sd) if show_sd else dev_all_m\n",
    "        return this_plot\n",
    "\n",
    "    def make_wnw(self):\n",
    "\n",
    "        variates = [\"hidden_units\", \"p_noise\", \"learning_rate\"]\n",
    "\n",
    "        df_wnw = self.df.loc[\n",
    "            (self.df.cond.isin([\"HF_INC\", \"NW_UN\"])),\n",
    "            variates + [\"code_name\", \"cell_code\", \"epoch\", \"cond\", \"score\"],\n",
    "        ]\n",
    "\n",
    "        df_wnw = df_wnw.pivot_table(\n",
    "            index=variates + [\"epoch\", \"code_name\", \"cell_code\"], columns=\"cond\"\n",
    "        ).reset_index()\n",
    "\n",
    "        df_wnw.columns = df_wnw.columns = [\n",
    "            \"\".join(c).strip() for c in df_wnw.columns.values\n",
    "        ]\n",
    "        df_wnw.rename(\n",
    "            columns={\"scoreHF_INC\": \"word_acc\", \"scoreNW_UN\": \"nonword_acc\",},\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        df_wnw[\"word_advantage\"] = df_wnw.word_acc - df_wnw.nonword_acc\n",
    "        return df_wnw\n",
    "\n",
    "    def plot_wnw(self):\n",
    "        \"\"\" Performance space plot \"\"\"\n",
    "        df = self.make_wnw()\n",
    "\n",
    "        wnw_line = (\n",
    "            alt.Chart(df)\n",
    "            .mark_line(color=\"black\")\n",
    "            .encode(\n",
    "                y=alt.Y(\"mean_nw:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "                x=alt.X(\"mean_w:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "                tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "                opacity=alt.value(0.5),\n",
    "            )\n",
    "            .transform_filter(self.select_control_space)\n",
    "            .transform_aggregate(\n",
    "                mean_nw=\"mean(nonword_acc)\", mean_w=\"mean(word_acc)\", groupby=[\"epoch\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        diagonal = (\n",
    "            alt.Chart(pd.DataFrame({\"x\": [0, 1], \"y\": [0, 1]}))\n",
    "            .mark_line(color=\"#D3D3D3\")\n",
    "            .encode(\n",
    "                x=alt.X(\"x\", axis=alt.Axis(title=\"word\")),\n",
    "                y=alt.X(\"y\", axis=alt.Axis(title=\"nonword\")),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return (diagonal + wnw_line).properties(\n",
    "            title=\"Performance space: Nonword accuracy vs. Word accuracy\"\n",
    "        )\n",
    "\n",
    "    def stat_header(self):\n",
    "\n",
    "        n = len(self.df.code_name.unique())\n",
    "\n",
    "        t = [\n",
    "            \"Grand mean rank: \" + self.get_rankpc_desc(),\n",
    "            \"Grand mean acc  : \" + self.get_acc_desc(),\n",
    "        ]\n",
    "\n",
    "        return [f\" (n={n})\"] + t\n",
    "\n",
    "\n",
    "    def plot(self, title=None, show_sd=True):\n",
    "        \"\"\"Plot all relevant stuffs\"\"\"\n",
    "\n",
    "        if title is not None:\n",
    "            t = [title] + self.stat_header()\n",
    "\n",
    "        all_plot = (\n",
    "            self.plot_control_space()\n",
    "            & (self.plot_mean_development(show_sd=show_sd) | self.plot_wnw())\n",
    "        ).properties(title=t)\n",
    "\n",
    "        return all_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = helper.parse_from_file(\"../sims/1520_sims.csv\")\n",
    "hpar = [\"hidden_units\", \"cleanup_units\", \"p_noise\", \"learning_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.select_by_cond([\"HF_INC\", \"NW_UN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.plot2(\"Baseline: Middle control space 3x3x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Select_Model(df_all)\n",
    "baseline.select_by_control(\n",
    "    hidden_units=[100, 150, 200], p_noise=[1, 2, 3], learning_rate=[0.004, 0.006, 0.008]\n",
    ")\n",
    "baseline.select_by_cond([\"HF_INC\", \"NW_UN\"])\n",
    "baseline.plot2(\"Baseline: Middle control space 3x3x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Select_Model(df_all)\n",
    "baseline.select_by_control(hidden_units=[200], p_noise=[2, 3], learning_rate=[0.004])\n",
    "# baseline.plot1(\"Baseline: Middle control space 3x3x3\")\n",
    "\n",
    "baseline.plot2(\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = baseline.select_by_control(hidden_units=[200], p_noise=[3], learning_rate=[0.004])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.plot1(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.plot2(\"tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Part3 Datafile (n=1225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = helper.parse_from_file(\"../sims/part3_1750.csv\")\n",
    "\n",
    "# Mask at-risk: to show models that has at least one < baseline \n",
    "df[\"risk_count\"] = (\n",
    "    (df.hidden_units < 100) * 1 + (df.p_noise > 3) * 1 + (df.learning_rate < 0.004) * 1\n",
    ")\n",
    "\n",
    "df = df.loc[df.risk_count >= 1]\n",
    "helper.count_grid(df, hpar).save(\"count_models_masked.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RD object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate RD analysis class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_word = Select_RD(\n",
    "    df, baseline.df, include_conds=[\"HF_INC\", \"LF_INC\", \"HF_CON\", \"LF_CON\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_word.plot_bundle(baseline).save(\"bundle.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compensator_df = df.loc[\n",
    "    (\n",
    "        df.hidden_units.isin([200, 250])\n",
    "        & (df.p_noise == 4)\n",
    "        & (df.learning_rate == 0.004)\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compensator = helper.Select_Model(compensator_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compensator.plot_mean_development(show_sd=True) | baseline.plot_mean_development(\n",
    "    show_sd=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compensator.plot_wnw(mean=True) + baseline.plot_wnw(mean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_word.plot_heatmap(\"score\").save(\"score.html\")\n",
    "rd_word.plot_heatmap(\"pc\").save(\"pc.html\")\n",
    "rd_word.plot_heatmap(\"z_deviance\").save(\"z.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = helper.Select_Model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_word.df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_epoch_resolution(df):\n",
    "    sel_epoch = [0.01, 0.02, 0.03, 0.05, 0.07, 0.09, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "    return df.loc[\n",
    "        df.epoch.isin(sel_epoch),\n",
    "    ]\n",
    "\n",
    "\n",
    "rd_mean_df = rd_word.df.copy()\n",
    "\n",
    "rd_mean_df = (\n",
    "    rd_mean_df.groupby([\"epoch\", \"hidden_units\", \"p_noise\", \"learning_rate\", \"cond\"])\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "rd_mean_df = reduce_epoch_resolution(df=rd_mean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all cond raw score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_raw_heat(var):\n",
    "\n",
    "    p = (\n",
    "        alt.Chart(rd_mean_df)\n",
    "        .mark_rect()\n",
    "        .encode(\n",
    "            x=\"p_noise:O\",\n",
    "            y=alt.Y(\"hidden_units:O\", sort=\"descending\"),\n",
    "            row=alt.Column(\"learning_rate:O\", sort=\"descending\"),\n",
    "            column=\"epoch:O\",\n",
    "            color=alt.Color(\n",
    "                \"score\", scale=alt.Scale(domain=(0, 1), scheme=\"redyellowgreen\"),\n",
    "            ),\n",
    "            tooltip=[\"score\", \"score\"],\n",
    "        )\n",
    "        .transform_filter(datum.cond == var)\n",
    "    ).title()\n",
    "\n",
    "    p.save(f\"raw_score_{var}.html\")\n",
    "    \n",
    "for v in df.cond.unique():\n",
    "    save_raw_heat(v)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive grouping plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_word.plot_interactive_group_heatmap(version=\"z\").save(\"grouping_z.html\")\n",
    "rd_word.plot_interactive_group_heatmap(version=\"pc\").save(\"grouping_pc.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old interactive plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variates = [\"hidden_units\", \"p_noise\", \"learning_rate\"]\n",
    "\n",
    "df_wnw = df.loc[\n",
    "    (df.cond.isin([\"HF_INC\", \"NW_UN\"])),\n",
    "    variates + [\"code_name\", \"epoch\", \"cond\", \"score\"],\n",
    "]\n",
    "\n",
    "df_wnw = df_wnw.pivot_table(\n",
    "    index=variates + [\"epoch\", \"code_name\"], columns=\"cond\"\n",
    ").reset_index()\n",
    "\n",
    "df_wnw.columns = df_wnw.columns = [\"\".join(c).strip() for c in df_wnw.columns.values]\n",
    "df_wnw.rename(\n",
    "    columns={\"scoreHF_INC\": \"word_acc\", \"scoreNW_UN\": \"nonword_acc\",}, inplace=True,\n",
    ")\n",
    "\n",
    "df_wnw[\"word_advantage\"] = df_wnw.word_acc - df_wnw.nonword_acc\n",
    "df_wnw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_control_space = alt.selection(\n",
    "    type=\"multi\",\n",
    "    on=\"click\",\n",
    "    empty=\"none\",\n",
    "    fields=[\"code_name\"],\n",
    "    init=[{\"code_name\": \"n0_h100_l0.01\"}],\n",
    ")\n",
    "\n",
    "# Control space\n",
    "df_overview = df_wnw.loc[df_wnw.epoch == df_wnw.epoch.max()]\n",
    "\n",
    "control_space = (\n",
    "    alt.Chart(df_overview)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=\"p_noise:O\",\n",
    "        y=alt.Y(\"hidden_units:O\", sort=\"descending\"),\n",
    "        column=alt.Column(\"learning_rate:O\", sort=\"descending\"),\n",
    "        color=alt.Color(\n",
    "            \"word_acc\", scale=alt.Scale(scheme=\"redyellowgreen\", domain=(0, 1))\n",
    "        ),\n",
    "        opacity=alt.condition(select_control_space, alt.value(1), alt.value(0.3)),\n",
    "        tooltip=[\"code_name\", \"word_acc\", \"nonword_acc\", \"word_advantage\"],\n",
    "    )\n",
    "    .add_selection(select_control_space)\n",
    "    .properties(title=\"Select a control parameter setting:\")\n",
    ")\n",
    "\n",
    "# Development space\n",
    "df.sort_values(by=[\"code_name\", \"cond\"], inplace=True)\n",
    "\n",
    "development_space = (\n",
    "    alt.Chart(df)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        y=alt.Y(\"score:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=\"epoch:Q\",\n",
    "        color=\"cond:N\",\n",
    "        tooltip=[\"code_name\", \"epoch\", \"score\"],\n",
    "    )\n",
    "    .transform_filter(select_control_space)\n",
    "    .properties(title=\"Developmental space: Accuracy in each condition over epoch\")\n",
    ")\n",
    "\n",
    "# Performance space\n",
    "wnw_line = (\n",
    "    alt.Chart(df_wnw)\n",
    "    .mark_line(color=\"black\")\n",
    "    .encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "    )\n",
    "    .transform_filter(select_control_space)\n",
    ")\n",
    "\n",
    "diagonal = (\n",
    "    alt.Chart(pd.DataFrame({\"x\": [0, 1], \"y\": [0, 1]}))\n",
    "    .mark_line(color=\"#D3D3D3\")\n",
    "    .encode(\n",
    "        x=alt.X(\"x\", axis=alt.Axis(title=\"word\")),\n",
    "        y=alt.X(\"y\", axis=alt.Axis(title=\"nonword\")),\n",
    "    )\n",
    ")\n",
    "\n",
    "performance_space = (diagonal + wnw_line).properties(\n",
    "    title=\"Performance space: Nonword accuracy vs. Word accuracy\"\n",
    ")\n",
    "\n",
    "dev_heat = alt.Chart()\n",
    "\n",
    "\n",
    "# Merge dashboard\n",
    "dashboard = control_space & (development_space | performance_space)\n",
    "dashboard.save(\"dashboard_with_baseline.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the underlying causes that give rise to different subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Select_Subtype(helper.Select_Model):\n",
    "    def __init__(\n",
    "        self, df, td_df, include_conds=[\"HF_CON\", \"HF_INC\", \"LF_CON\", \"LF_INC\"]\n",
    "    ):\n",
    "        self.include_conds = include_conds\n",
    "        self.df = df\n",
    "        self.td_df = td_df\n",
    "        self.td_stat = self.get_stat()\n",
    "        self.cadf = self.make_cadf()\n",
    "        self.zdf = self.make_zdf(self.cadf)\n",
    "        self.pcdf = self.make_pcdf(self.cadf)\n",
    "        self.mzdf = self.melt_zdf(self.zdf)\n",
    "        self.mpcdf = self.melt_pcdf(self.pcdf)\n",
    "\n",
    "    def get_stat(self):\n",
    "        \"\"\"Baseline statistics\n",
    "        Return mean and sd by epoch in word \n",
    "        \"\"\"\n",
    "        return (\n",
    "            self.td_df\n",
    "            .groupby([\"code_name\", \"epoch\", \"cond\"])\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .groupby([\"epoch\"])\n",
    "            .agg([\"mean\", \"std\"])\n",
    "            .score.reset_index()\n",
    "        ).to_dict()\n",
    "\n",
    "    def make_cadf(self):\n",
    "        \"\"\"Make condition avergage df (aggregate cond) with reduced epoch resolution\"\"\"\n",
    "        cadf = (\n",
    "            self.df.loc[self.df.cond.isin(self.include_conds),]\n",
    "            .groupby([\"code_name\", \"epoch\"])\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "        cadf[\"learning_rate\"] = round(cadf.learning_rate, 4)\n",
    "        cadf[\"epoch_idx\"] = cadf.apply(\n",
    "            lambda x: x.epoch * 100 if x.epoch <= 0.1 else x.epoch * 10 + 9, axis=1\n",
    "        )\n",
    "        cadf[\"epoch_idx\"] = cadf.epoch_idx.astype(int)\n",
    "        return self.reduce_epoch_resolution(cadf)\n",
    "\n",
    "    def make_pcdf(self, cadf):\n",
    "        \"\"\" Make percetange based df\"\"\"\n",
    "        cadf[\"pc\"] = cadf.apply(self.calcuate_percetage_of_baseline, axis=1)\n",
    "\n",
    "        # Different cutoff of RDs by percentage (0 = RD, 1 = TD)\n",
    "        cadf[\"pc_group_50\"] = 1 * (cadf.pc > 0.50)\n",
    "        cadf[\"pc_group_55\"] = 1 * (cadf.pc > 0.55)\n",
    "        cadf[\"pc_group_60\"] = 1 * (cadf.pc > 0.60)\n",
    "        cadf[\"pc_group_65\"] = 1 * (cadf.pc > 0.65)\n",
    "        cadf[\"pc_group_70\"] = 1 * (cadf.pc > 0.70)\n",
    "        cadf[\"pc_group_75\"] = 1 * (cadf.pc > 0.75)\n",
    "        cadf[\"pc_group_80\"] = 1 * (cadf.pc > 0.80)\n",
    "        cadf[\"pc_group_85\"] = 1 * (cadf.pc > 0.85)\n",
    "        cadf[\"pc_group_90\"] = 1 * (cadf.pc > 0.90)\n",
    "\n",
    "        return cadf\n",
    "\n",
    "    def melt_pcdf(self, df):\n",
    "\n",
    "        mdf = df.melt(\n",
    "            id_vars=[\n",
    "                \"code_name\",\n",
    "                \"epoch\",\n",
    "                \"hidden_units\",\n",
    "                \"cleanup_units\",\n",
    "                \"p_noise\",\n",
    "                \"learning_rate\",\n",
    "            ],\n",
    "            value_vars=[\n",
    "                \"pc_group_50\",\n",
    "                \"pc_group_55\",\n",
    "                \"pc_group_60\",\n",
    "                \"pc_group_65\",\n",
    "                \"pc_group_70\",\n",
    "                \"pc_group_75\",\n",
    "                \"pc_group_80\",\n",
    "                \"pc_group_85\",\n",
    "                \"pc_group_90\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        mdf[\"cutoff\"] = mdf.variable.str[-2:].astype(float)\n",
    "\n",
    "        return mdf\n",
    "\n",
    "    def make_zdf(self, cadf):\n",
    "        \"\"\"Make z-score based df\"\"\"\n",
    "\n",
    "        cadf[\"z_deviance\"] = cadf.apply(self.calcuate_z_deviance, axis=1)\n",
    "\n",
    "        # Different cutoff of RDs (0 = RD, 1 = TD)\n",
    "        cadf[\"group_10\"] = 1 * (cadf.z_deviance > -1.0)\n",
    "        cadf[\"group_11\"] = 1 * (cadf.z_deviance > -1.1)\n",
    "        cadf[\"group_12\"] = 1 * (cadf.z_deviance > -1.2)\n",
    "        cadf[\"group_13\"] = 1 * (cadf.z_deviance > -1.3)\n",
    "        cadf[\"group_14\"] = 1 * (cadf.z_deviance > -1.4)\n",
    "        cadf[\"group_15\"] = 1 * (cadf.z_deviance > -1.5)\n",
    "        cadf[\"group_16\"] = 1 * (cadf.z_deviance > -1.6)\n",
    "        cadf[\"group_17\"] = 1 * (cadf.z_deviance > -1.7)\n",
    "        cadf[\"group_18\"] = 1 * (cadf.z_deviance > -1.8)\n",
    "        cadf[\"group_19\"] = 1 * (cadf.z_deviance > -1.9)\n",
    "        cadf[\"group_20\"] = 1 * (cadf.z_deviance > -2.0)\n",
    "        cadf[\"group_21\"] = 1 * (cadf.z_deviance > -2.1)\n",
    "        cadf[\"group_22\"] = 1 * (cadf.z_deviance > -2.2)\n",
    "        cadf[\"group_23\"] = 1 * (cadf.z_deviance > -2.3)\n",
    "        cadf[\"group_24\"] = 1 * (cadf.z_deviance > -2.4)\n",
    "        cadf[\"group_25\"] = 1 * (cadf.z_deviance > -2.5)\n",
    "        cadf[\"group_26\"] = 1 * (cadf.z_deviance > -2.6)\n",
    "        cadf[\"group_27\"] = 1 * (cadf.z_deviance > -2.7)\n",
    "        cadf[\"group_28\"] = 1 * (cadf.z_deviance > -2.8)\n",
    "        cadf[\"group_29\"] = 1 * (cadf.z_deviance > -2.9)\n",
    "        cadf[\"group_30\"] = 1 * (cadf.z_deviance > -3.0)\n",
    "\n",
    "        return cadf\n",
    "\n",
    "    def melt_zdf(self, df):\n",
    "\n",
    "        mdf = df.melt(\n",
    "            id_vars=[\n",
    "                \"code_name\",\n",
    "                \"epoch\",\n",
    "                \"hidden_units\",\n",
    "                \"cleanup_units\",\n",
    "                \"p_noise\",\n",
    "                \"learning_rate\",\n",
    "            ],\n",
    "            value_vars=[\n",
    "                \"group_10\",\n",
    "                \"group_11\",\n",
    "                \"group_12\",\n",
    "                \"group_13\",\n",
    "                \"group_14\",\n",
    "                \"group_15\",\n",
    "                \"group_16\",\n",
    "                \"group_17\",\n",
    "                \"group_18\",\n",
    "                \"group_19\",\n",
    "                \"group_20\",\n",
    "                \"group_21\",\n",
    "                \"group_22\",\n",
    "                \"group_23\",\n",
    "                \"group_24\",\n",
    "                \"group_25\",\n",
    "                \"group_26\",\n",
    "                \"group_27\",\n",
    "                \"group_28\",\n",
    "                \"group_29\",\n",
    "                \"group_30\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        mdf[\"cutoff\"] = mdf.variable.str[-2:].astype(float) / 10\n",
    "\n",
    "        return mdf\n",
    "\n",
    "    def plot_heatmap(self, var):\n",
    "        \"\"\"Z-score deviance over epoch\"\"\"\n",
    "        if var == \"z_deviance\":\n",
    "            domain = (-5, 5)\n",
    "            df = self.zdf\n",
    "        elif var == \"score\":\n",
    "            domain = (0, 1)\n",
    "            df = self.zdf\n",
    "        elif var == \"pc\":\n",
    "            domain = (0, 1)\n",
    "            df = self.pcdf\n",
    "\n",
    "        mean_var = f\"mean({var})\"\n",
    "\n",
    "        hm = (\n",
    "            alt.Chart(df)\n",
    "            .mark_rect()\n",
    "            .encode(\n",
    "                x=\"p_noise:O\",\n",
    "                y=alt.Y(\"hidden_units:O\", sort=\"descending\"),\n",
    "                row=alt.Column(\"learning_rate:O\", sort=\"descending\"),\n",
    "                column=\"epoch:O\",\n",
    "                color=alt.Color(\n",
    "                    mean_var, scale=alt.Scale(domain=domain, scheme=\"redyellowgreen\"),\n",
    "                ),\n",
    "                tooltip=[\"mean(score)\", mean_var],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return hm\n",
    "\n",
    "    def reduce_epoch_resolution(self, df):\n",
    "        sel_epoch = [0.01, 0.02, 0.03, 0.05, 0.07, 0.09, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        return df.loc[\n",
    "            df.epoch.isin(sel_epoch),\n",
    "        ]\n",
    "\n",
    "    def calcuate_z_deviance(self, row):\n",
    "        \"\"\"Calcuate z score relative to TD at each epoch\n",
    "        \"\"\"\n",
    "        m = self.td_stat[\"mean\"][row[\"epoch_idx\"]]\n",
    "        sd = self.td_stat[\"std\"][row[\"epoch_idx\"]]\n",
    "\n",
    "        # Avoid zero division\n",
    "        if sd == 0:\n",
    "            sd = 1e-6\n",
    "\n",
    "        return (row[\"score\"] - m) / sd\n",
    "\n",
    "    def calcuate_percetage_of_baseline(self, row):\n",
    "        \"\"\"Calcuate % relative to TD at each epoch\n",
    "        \"\"\"\n",
    "        m = self.td_stat[\"mean\"][row[\"epoch_idx\"]]\n",
    "\n",
    "        return row[\"score\"] / m\n",
    "\n",
    "    def get_acc_cut(self, epoch, xsd, cond=None):\n",
    "        \"\"\"Get accuracy cut off value with reference to xsd below mean of TD\n",
    "        td_df: data file of typically developing readers (created by Select_Model().df)\n",
    "        epoch: at what epoch to classify RD [list]\n",
    "        xsd: how many sd below mean of TD\n",
    "        cond: include what condition, default = all conditions (no filtering)\n",
    "        \"\"\"\n",
    "\n",
    "        sel = (\n",
    "            self.td_df.loc[self.td_df.epoch.isin(epoch)]\n",
    "            if (cond is None)\n",
    "            else self.td_df.loc[\n",
    "                self.td_df.epoch.isin(epoch) & self.td_df.cond.isin(cond)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        stat = sel.groupby(\"code_name\").mean().score.agg([\"mean\", \"std\"])\n",
    "        return stat[\"mean\"] - xsd * stat[\"std\"]\n",
    "\n",
    "    def select_by_relative_sd(self, epoch, xsd, cond=None):\n",
    "        \"\"\"Select the models that has at least\n",
    "        X SD <xsd> below mean of TD at <epoch>\"\"\"\n",
    "\n",
    "        tmp = (\n",
    "            self.df.loc[self.df.epoch.isin(epoch)]\n",
    "            if (cond is None)\n",
    "            else self.df.loc[self.df.epoch.isin(epoch) & self.df.cond.isin(cond)]\n",
    "        )\n",
    "\n",
    "        mean_tmp = tmp.groupby(\"code_name\").mean().reset_index()\n",
    "        sel = mean_tmp.loc[mean_tmp.score < self.get_acc_cut(epoch, xsd, cond)]\n",
    "        self.df = self.df.loc[self.df.code_name.isin(sel[\"code_name\"])]\n",
    "\n",
    "        # Make deviance\n",
    "        self.cadf = self.make_condition_averaged_df()\n",
    "\n",
    "    def plot_bundle(self, baseline_model):\n",
    "        \"\"\" Plot all with baseline model as reference group\n",
    "        \"\"\"\n",
    "\n",
    "        dev_cond = (\n",
    "            self.plot_mean_development(show_sd=False)\n",
    "            + baseline_model.plot_mean_development(show_sd=True)\n",
    "        ).properties(title=\"Each condition\")\n",
    "\n",
    "        dev_mean = (\n",
    "            self.plot_all_cond_mean(show_sd=False)\n",
    "            + baseline_model.plot_all_cond_mean(show_sd=True)\n",
    "        ).properties(title=\"Mean in all conditions\")\n",
    "\n",
    "        wnw_mean = (\n",
    "            self.plot_wnw(mean=True) + baseline_model.plot_wnw(mean=True)\n",
    "        ).properties(title=\"Word vs. NW\")\n",
    "\n",
    "        return (\n",
    "            self.plot_control_space() & (dev_cond | dev_mean | wnw_mean)\n",
    "        ).properties(title=self.stat_header())\n",
    "\n",
    "    def plot_interactive_group_heatmap(self, version=\"pc\"):\n",
    "        \"\"\" Plot interactive grouping heatmap\n",
    "        version: \"pc\" percentage definition\n",
    "                 \"z\" z-score definition\n",
    "        \"\"\"\n",
    "        assert (version == \"pc\") or (version == \"z\")\n",
    "        if version == \"pc\":\n",
    "            use_df = self.mpcdf\n",
    "            slider = alt.binding_range(\n",
    "                min=50.0, max=90.0, step=5.0, name=\"percentage cutoff:\"\n",
    "            )\n",
    "            selector = alt.selection_single(\n",
    "                name=\"SelectorName\",\n",
    "                fields=[\"cutoff\"],\n",
    "                bind=slider,\n",
    "                init={\"cutoff\": 80.0},\n",
    "            )\n",
    "        else:\n",
    "            use_df = self.mzdf\n",
    "            slider = alt.binding_range(min=1.0, max=3.0, step=0.1, name=\"z cutoff:\")\n",
    "            selector = alt.selection_single(\n",
    "                name=\"SelectorName\",\n",
    "                fields=[\"cutoff\"],\n",
    "                bind=slider,\n",
    "                init={\"cutoff\": 2.0},\n",
    "            )\n",
    "\n",
    "        df = (\n",
    "            use_df.groupby(\n",
    "                [\"hidden_units\", \"p_noise\", \"learning_rate\", \"epoch\", \"cutoff\"]\n",
    "            )\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        interactive_group_heatmap = (\n",
    "            alt.Chart(df)\n",
    "            .mark_rect()\n",
    "            .encode(\n",
    "                x=\"p_noise:O\",\n",
    "                y=alt.Y(\"hidden_units:O\", sort=\"descending\"),\n",
    "                row=alt.Column(\"learning_rate:O\", sort=\"descending\"),\n",
    "                column=\"epoch:O\",\n",
    "                color=alt.Color(\n",
    "                    \"value\", scale=alt.Scale(domain=(0, 1), scheme=\"redyellowgreen\"),\n",
    "                ),\n",
    "            )\n",
    "            .add_selection(selector)\n",
    "            .transform_filter(selector)\n",
    "        )\n",
    "\n",
    "        return interactive_group_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.df.groupby([\"epoch\", \"cond\"]).mean().reset_index().score.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.df\n",
    "\n",
    ".groupby([\"epoch\"])\n",
    "            \n",
    "            .score.reset_index()\n",
    "        ).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
