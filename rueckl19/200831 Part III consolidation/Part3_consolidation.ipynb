{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual differences simulation paper part III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from altair.expr import datum\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- Change heatmap directions (Top, Left always leads to better performance)\n",
    "- Add W-NW heatmap\n",
    "- Use line type to indicate 2x2 structure in performance space\n",
    "- Add origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load new (Aug 27, 2020) combined dataset 1520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"1520_sims.csv\", index_col=0)\n",
    "\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"ID\": \"code_name\",\n",
    "        \"Trial.Scaled\": \"epoch\",\n",
    "        \"Hidden\": \"hidden_units\",\n",
    "        \"PhoHid\": \"cleanup_units\",\n",
    "        \"Pnoise\": \"p_noise\",\n",
    "        \"Epsilon\": \"learning_rate\",\n",
    "        \"Type\": \"cond\",\n",
    "        \"Measure\": \"measure\",\n",
    "        \"Score\": \"score\",\n",
    "        \"Freq\": \"cond_freq\",\n",
    "        \"Cons\": \"cond_cons\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df = df.loc[df.measure == \"Accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_origin(df):\n",
    "    \"\"\"Add origin data point in each model\"\"\"\n",
    "\n",
    "    if df.epoch.min() > 0:\n",
    "        # Borrow epoch == 1.0 as a frame for epoch = 0\n",
    "        tmp = df.loc[df.epoch == 1.0,].copy()\n",
    "        tmp.score = 0\n",
    "        tmp.epoch = 0\n",
    "        df_with_origin = pd.concat([df, tmp], ignore_index=True)\n",
    "        return df_with_origin.sort_values(\n",
    "            by=[\"code_name\", \"cond\", \"epoch\"]\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "    else:\n",
    "        print(\"Already have origin, returning original df\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_origin(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count model in h-grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_grid(df, hpar):\n",
    "    \"\"\"Counting how many runs in each h-param cell \n",
    "    \"\"\"\n",
    "\n",
    "    settings = df[[\"code_name\"] + hpar].pivot_table(index=\"code_name\")\n",
    "    settings[\"code_name\"] = settings.index\n",
    "    settings[\"learning_rate\"] = settings.learning_rate.round(4)\n",
    "\n",
    "    count_settings = settings.pivot_table(\n",
    "        index=hpar, aggfunc=\"count\", values=\"code_name\",\n",
    "    )\n",
    "    count_settings.reset_index(inplace=True)\n",
    "    count_settings.rename(columns={\"code_name\": \"n\"}, inplace=True)\n",
    "\n",
    "    return (\n",
    "        alt.Chart(count_settings)\n",
    "        .mark_rect()\n",
    "        .encode(\n",
    "            x=\"p_noise:O\",\n",
    "            y=alt.Y(\"hidden_units:O\", sort=\"descending\"),\n",
    "            row=alt.Row(\"learning_rate:O\", sort=\"descending\"),\n",
    "            column=alt.Column(\"cleanup_units:O\", sort=\"descending\"),\n",
    "            color=\"n:O\",\n",
    "            tooltip=hpar + [\"n\"],\n",
    "        )\n",
    "        .properties(title=\"Model counts\")\n",
    "    )\n",
    "\n",
    "\n",
    "hpar = [\"hidden_units\", \"cleanup_units\", \"p_noise\", \"learning_rate\"]\n",
    "count_grid(df, hpar).save(\"count_models.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset to 20 cleanup units and aggregrate within each h-param cell (sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter cleanup == 20\n",
    "sdf = df.loc[\n",
    "    df.cleanup_units == 20,\n",
    "]\n",
    "\n",
    "\n",
    "# Cell specific code_name\n",
    "sdf = sdf.groupby(\n",
    "    [\"epoch\", \"p_noise\", \"hidden_units\", \"learning_rate\", \"cond\"], as_index=False\n",
    ").mean()\n",
    "sdf.drop(columns=[\"code_name\", \"cleanup_units\"], inplace=True)\n",
    "\n",
    "sdf[\"code_name\"] = sdf.agg(\n",
    "    lambda x: f'n{x[\"p_noise\"]}_h{x[\"hidden_units\"]}_l{x[\"learning_rate\"]}', axis=1\n",
    ")\n",
    "\n",
    "# Word vs. Nonword label\n",
    "sdf[\"type\"] = sdf.cond.apply(\n",
    "    lambda x: \"word\" if x in [\"HF_CON\", \"HF_INC\", \"LF_CON\", \"LF_INC\"] else \"nonword\"\n",
    ")\n",
    "\n",
    "\n",
    "sdf.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last epoch accuracy in mean word and nonword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_type_acc(df, type_name):\n",
    "\n",
    "    plot_df = df.loc[\n",
    "        (df.epoch == 1.0) & (df.type == type_name),\n",
    "    ]\n",
    "\n",
    "    return (\n",
    "        alt.Chart(plot_df)\n",
    "        .mark_rect()\n",
    "        .encode(\n",
    "            x=\"p_noise:O\",\n",
    "            y=alt.Y(\"hidden_units:O\", sort=\"descending\"),\n",
    "            column=alt.Column(\"learning_rate:O\", sort=\"descending\"),\n",
    "            color=alt.Color(\n",
    "                \"score\", scale=alt.Scale(scheme=\"redyellowgreen\", domain=(0, 1))\n",
    "            ),\n",
    "            tooltip=[\"score\"],\n",
    "        )\n",
    "        .properties(title=f\"{type_name} accuracy at the end of training\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_type_acc(sdf, \"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_type_acc(sdf, \"nonword\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse df_wnw (widen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variates = [\"hidden_units\", \"p_noise\", \"learning_rate\"]\n",
    "\n",
    "df_wnw = sdf.loc[\n",
    "    (sdf.cond.isin([\"HF_INC\", \"NW_UN\"])),\n",
    "    variates + [\"code_name\", \"epoch\", \"cond\", \"score\"],\n",
    "]\n",
    "\n",
    "df_wnw = df_wnw.pivot_table(\n",
    "    index=variates + [\"epoch\", \"code_name\"], columns=\"cond\"\n",
    ").reset_index()\n",
    "\n",
    "df_wnw.columns = df_wnw.columns = [\"\".join(c).strip() for c in df_wnw.columns.values]\n",
    "df_wnw.rename(\n",
    "    columns={\"scoreHF_INC\": \"word_acc\", \"scoreNW_UN\": \"nonword_acc\",}, inplace=True,\n",
    ")\n",
    "\n",
    "df_wnw[\"word_advantage\"] = df_wnw.word_acc - df_wnw.nonword_acc\n",
    "df_wnw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_control_space = alt.selection(\n",
    "    type=\"multi\",\n",
    "    on=\"click\",\n",
    "    empty=\"none\",\n",
    "    fields=[\"code_name\"],\n",
    "    init=[{\"code_name\": \"n0_h100_l0.01\"}],\n",
    ")\n",
    "\n",
    "# Control space\n",
    "df_overview = df_wnw.loc[df_wnw.epoch == df_wnw.epoch.max()]\n",
    "\n",
    "control_space = (\n",
    "    alt.Chart(df_overview)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=\"p_noise:O\",\n",
    "        y=alt.Y(\"hidden_units:O\", sort=\"descending\"),\n",
    "        column=alt.Column(\"learning_rate:O\", sort=\"descending\"),\n",
    "        color=alt.Color(\n",
    "            \"word_acc\", scale=alt.Scale(scheme=\"redyellowgreen\", domain=(0, 1))\n",
    "        ),\n",
    "        opacity=alt.condition(select_control_space, alt.value(1), alt.value(0.3)),\n",
    "        tooltip=[\"code_name\", \"word_acc\", \"nonword_acc\", \"word_advantage\"],\n",
    "    )\n",
    "    .add_selection(select_control_space)\n",
    "    .properties(title=\"Select a control parameter setting:\")\n",
    ")\n",
    "\n",
    "# Development space\n",
    "sdf.sort_values(by=[\"code_name\", \"cond\"], inplace=True)\n",
    "\n",
    "development_space = (\n",
    "    alt.Chart(sdf)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        y=alt.Y(\"score:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=\"epoch:Q\",\n",
    "        color=\"cond:N\",\n",
    "        tooltip=[\"code_name\", \"epoch\", \"score\"],\n",
    "    )\n",
    "    .transform_filter(select_control_space)\n",
    "    .properties(title=\"Developmental space: Accuracy in each condition over epoch\")\n",
    ")\n",
    "\n",
    "# Performance space\n",
    "wnw_line = (\n",
    "    alt.Chart(df_wnw)\n",
    "    .mark_line(color=\"black\")\n",
    "    .encode(\n",
    "        y=alt.Y(\"nonword_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        x=alt.X(\"word_acc:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "    )\n",
    "    .transform_filter(select_control_space)\n",
    ")\n",
    "\n",
    "diagonal = (\n",
    "    alt.Chart(pd.DataFrame({\"x\": [0, 1], \"y\": [0, 1]}))\n",
    "    .mark_line(color=\"#D3D3D3\")\n",
    "    .encode(\n",
    "        x=alt.X(\"x\", axis=alt.Axis(title=\"word\")),\n",
    "        y=alt.X(\"y\", axis=alt.Axis(title=\"nonword\")),\n",
    "    )\n",
    ")\n",
    "\n",
    "performance_space = (diagonal + wnw_line).properties(\n",
    "    title=\"Performance space: Nonword accuracy vs. Word accuracy\"\n",
    ")\n",
    "\n",
    "\n",
    "# Merge dashboard\n",
    "dashboard = control_space & (development_space | performance_space)\n",
    "dashboard.save(\"dashboard.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dyslexia: Heterogeneity in cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from altair.expr import datum\n",
    "\n",
    "df_corners = df_wnw.loc[\n",
    "    df_wnw.learning_rate.isin([df_wnw.learning_rate.max(), df_wnw.learning_rate.min()])\n",
    "    & df_wnw.hidden_units.isin([df_wnw.hidden_units.max(), df_wnw.hidden_units.min()])\n",
    "    & df_wnw.p_noise.isin([df_wnw.p_noise.max(), df_wnw.p_noise.min()])\n",
    "].copy()\n",
    "\n",
    "\n",
    "df_corners[\"h_group\"] = df_corners.hidden_units.apply(\n",
    "    lambda x: \"high\" if x == df_corners.hidden_units.max() else \"low\"\n",
    ")\n",
    "\n",
    "df_corners[\"p_group\"] = df_corners.p_noise.apply(\n",
    "    lambda x: \"high\" if x == df_corners.p_noise.max() else \"low\"\n",
    ")\n",
    "\n",
    "df_corners[\"condition_hp\"] = df_corners.agg(\n",
    "    lambda x: f\"{x.p_group} noise, {x.h_group} hidden\", axis=1\n",
    ")\n",
    "\n",
    "df_corners.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control parameter in extreme corner without smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_plot(df, x, y, smooth=False):\n",
    "    \"\"\" Easy plot for part III analysis\n",
    "    Panel column = Learning rate\n",
    "    df: must be in wide format, with word_acc and nonword_acc column\n",
    "    x: x-axis variable in altair format\n",
    "    y: y-axis variable in altair format\n",
    "    \"\"\"\n",
    "\n",
    "    base = (\n",
    "        alt.Chart(df)\n",
    "        .mark_line()\n",
    "        .encode(\n",
    "            x=alt.X(x, scale=alt.Scale(domain=(0, 1))),\n",
    "            y=alt.Y(y, scale=alt.Scale(domain=(0, 1))),\n",
    "            order=[\"epoch\"],\n",
    "            color=\"h_group:N\",\n",
    "            strokeDash=\"p_group:N\",\n",
    "            tooltip=[\"code_name\", \"epoch\", \"word_acc\", \"nonword_acc\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    plot = alt.vconcat()\n",
    "\n",
    "    for lr in df.learning_rate.unique():\n",
    "        plot |= base.transform_filter(datum.learning_rate == lr).properties(\n",
    "            title=[\n",
    "                \"High learning rate\"\n",
    "                if lr == df.learning_rate.max()\n",
    "                else \"Low learning rate\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_performance = easy_plot(df=df_corners, x=\"word_acc:Q\", y=\"nonword_acc:Q\")\n",
    "corner_performance.save(\"corner_performance.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developmental space "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words (HF_INC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_dev_w = easy_plot(df=df_corners, x=\"epoch:Q\", y=\"word_acc:Q\").properties(\n",
    "    title=\"Word accuracy (HF_INC)\"\n",
    ")\n",
    "corner_dev_w\n",
    "corner_dev_w.save(\"corner_dev_word.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nonwords (NW_UN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_dev_nw = easy_plot(df=df_corners, x=\"epoch:Q\", y=\"nonword_acc:Q\").properties(\n",
    "    title=\"Nonword accuracy (NW_UN)\"\n",
    ")\n",
    "corner_dev_nw\n",
    "corner_dev_nw.save(\"corner_dev_nonword.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word advantage heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_advantage_over_epoch = (\n",
    "    alt.Chart(df_wnw)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=\"p_noise:O\",\n",
    "        y=alt.Y(\"hidden_units:O\", sort=\"descending\"),\n",
    "        row=alt.Column(\"learning_rate\", sort=\"descending\"),\n",
    "        column=\"epoch:O\",\n",
    "        color=alt.Color(\n",
    "            \"word_advantage\",\n",
    "            scale=alt.Scale(scheme=\"redyellowgreen\", domain=(-0.3, 0.3)),\n",
    "            title=\"word advantage (W-NW)\",\n",
    "        ),\n",
    "        tooltip=[\"word_acc\", \"nonword_acc\", \"word_advantage\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "word_advantage_over_epoch.save(\"word_advantage.html\")\n",
    "word_advantage_over_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dyslexia: Heterogeneity in consequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model level performance grouping 0-25, 25-75, 75-100 percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gacc = df.groupby(\"code_name\", as_index=False).mean()\n",
    "gacc = gacc[[\"code_name\", \"score\"]]\n",
    "gacc[\"rank_pc\"] = gacc.score.rank(pct=True)\n",
    "gacc[\"group\"] = gacc.rank_pc.map(\n",
    "    lambda x: \"High\" if x > 0.75 else (\"Mid\" if x > 0.25 else \"Low\")\n",
    ")\n",
    "\n",
    "df_group = df.merge(gacc[[\"code_name\", \"group\"]], how=\"left\")\n",
    "df_group_mean = df_group.groupby([\"group\", \"epoch\", \"cond\"], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Developmental plot for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_group_dev = alt.hconcat()\n",
    "\n",
    "base = (\n",
    "    alt.Chart(df_group_mean)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        x=alt.X(\"epoch:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        y=alt.Y(\"score:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        color=\"group:N\",\n",
    "    )\n",
    ")\n",
    "row = alt.vconcat()\n",
    "\n",
    "for i, x in enumerate(df_group_mean.cond.unique()):\n",
    "    row |= base.transform_filter(datum.cond == x).properties(title=x)\n",
    "    # Reset and glue row\n",
    "    if (i + 1) % 2 == 0:\n",
    "        plot_group_dev &= row\n",
    "        row = alt.vconcat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_group_dev.save(\"group_dev_all.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facier plot with SD band in word and nonword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = (\n",
    "    alt.Chart(df_group)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        x=alt.X(\"epoch:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        y=alt.Y(\"mean(score):Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        color=\"group:N\",\n",
    "    )\n",
    ")\n",
    "\n",
    "band = (\n",
    "    alt.Chart(df_group)\n",
    "    .mark_errorband(extent=\"stdev\")\n",
    "    .encode(\n",
    "        x=alt.X(\"epoch:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        y=alt.Y(\"score:Q\", scale=alt.Scale(domain=(0, 1))),\n",
    "        color=\"group:N\",\n",
    "    )\n",
    ")\n",
    "\n",
    "base = line + band\n",
    "\n",
    "plot = alt.hconcat()\n",
    "\n",
    "for x in [\"HF_INC\", \"NW_UN\"]:\n",
    "\n",
    "    plot |= base.transform_filter(datum.cond == x).properties(\n",
    "        title=[\"Word (HF_INC)\" if x == \"HF_INC\" else \"Nonword (NW_UN)\"]\n",
    "    )\n",
    "\n",
    "\n",
    "plot.save(\"group_dev_wnw.html\")\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean plot for overall picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wnw_group = df_group.pivot_table(\n",
    "    index=[\"group\", \"epoch\", \"code_name\"], columns=\"cond\", values=\"score\"\n",
    ").reset_index()\n",
    "\n",
    "df_wnw_group_mean = df_group.pivot_table(\n",
    "    index=[\"group\", \"epoch\"], columns=\"cond\", values=\"score\"\n",
    ").reset_index()\n",
    "\n",
    "line = (\n",
    "    alt.Chart(df_wnw_group_mean)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        x=alt.X(\"HF_INC\", scale=alt.Scale(domain=(0, 1))),\n",
    "        y=alt.Y(\"NW_UN\", scale=alt.Scale(domain=(0, 1))),\n",
    "        color=\"group\",\n",
    "    )\n",
    ")\n",
    "\n",
    "band = (\n",
    "    alt.Chart(df_wnw_group)\n",
    "    .mark_errorband(extent=\"ci\")\n",
    "    .encode(\n",
    "        x=alt.X(\"HF_INC\", scale=alt.Scale(domain=(0, 1))),\n",
    "        y=alt.Y(\"NW_UN\", scale=alt.Scale(domain=(0, 1))),\n",
    "        color=\"group\",\n",
    "    )\n",
    ")\n",
    "\n",
    "line + band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_plotwnw(df, group, sample=None):\n",
    "\n",
    "    pdf = df.loc[\n",
    "        df.group == group,\n",
    "    ]\n",
    "\n",
    "    # Random sampling by code_name\n",
    "    if sample is not None:\n",
    "        ids = np.random.choice(df_wnw_group.code_name.unique(), sample)\n",
    "        pdf = pdf.loc[pdf.code_name.isin(ids)]\n",
    "\n",
    "    # Plot\n",
    "\n",
    "    return (\n",
    "        alt.Chart(pdf)\n",
    "        .mark_line()\n",
    "        .encode(\n",
    "            x=alt.X(\"HF_INC\", scale=alt.Scale(domain=(0, 1))),\n",
    "            y=alt.Y(\"NW_UN\", scale=alt.Scale(domain=(0, 1))),\n",
    "            color=\"group\",\n",
    "            detail=\"code_name\",\n",
    "            opacity=alt.value(0.9),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "easy_plotwnw(df_wnw_group, \"Low\", 30) + easy_plotwnw(\n",
    "    df_wnw_group, \"Mid\", 30\n",
    ") + easy_plotwnw(df_wnw_group, \"High\", 30)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
