{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Storage manager"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are two types of storage in tf project\n",
    "- file storage buckets (google storage bucket)\n",
    "- data warehouse database (bigquery)\n",
    "\n",
    "To gain access to GCP resources, we need to create service account and obtain a json key from [GCP](https://cloud.google.com/docs/authentication/getting-started#cloud-console)\n",
    "\n",
    "Alternatively, if running on compute engine (including Vertex AI notebook), authetication is not necessary"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Storage bucket"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bucket_name = \"tmp\"\n",
    "!gsutil mb gs://{bucket_name}/\n",
    "!gsutil rm -r gs://{bucket_name}/"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# GCP to GS\n",
    "code_name = 'triangle_high_time_res_4M_fix'\n",
    "!gsutil -m rsync -d -r models/{code_name} gs://tf_mirror/{code_name}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# GS to local\n",
    "code_name = 'Refrac_5M_fix'\n",
    "!mkdir models/{code_name}\n",
    "!gsutil -m rsync -r gs://tf_mirror/{code_name} models/{code_name}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from google.oauth2 import service_account\n",
    "\n",
    "def load_gcp_key(json:str=\"secret/gcp.json\") -> \"GCP credentials\":\n",
    "    \"\"\"Load Google Cloud credentials from json file\"\"\"\n",
    "    return service_account.Credentials.from_service_account_file(\n",
    "        json, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    "    )\n",
    "\n",
    "credentials = load_gcp_key()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'return': 'GCP credentials'}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# UConn Linux Box workflow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. I had put a secret json key in secret folder \"/secret/gcp.json\"\n",
    "2. Use load_gcp_key() function to get service_account.Credentials (credentials) object\n",
    "3. Use credentials to initialize clients (e.g., ```google.cloud.<service>.Client(credentials=credentials)```)\n",
    "4. Use google.cloud API to access GCP resources\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(credentials=credentials)\n",
    "# dataset = client.create_dataset('uconn_test', exists_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "from google.cloud import storage\n",
    "client = storage.Client(credentials=credentials)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from google.cloud import storage\n",
    "\n",
    "def upload_to_gcp(gcs_client, local_directory: str, bucket_name: str, bucket_directory: str):\n",
    "    \"\"\"Upload a directory to GCP storage bucket\"\"\"\n",
    "    assert os.path.isdir(local_directory)\n",
    "    relative_paths = glob(local_directory + '/**', recursive=True)\n",
    "    try:\n",
    "        bucket = gcs_client.get_bucket(bucket_name)\n",
    "    except:\n",
    "        bucket = gcs_client.create_bucket(bucket_name)\n",
    "\n",
    "    for local_file in tqdm(relative_paths):\n",
    "        remote_path = f'{bucket_directory}/{\"/\".join(local_file.split(os.sep)[1:])}'\n",
    "        if os.path.isfile(local_file):\n",
    "            blob = bucket.blob(remote_path)\n",
    "            blob.upload_from_filename(local_file)\n",
    "\n",
    "# upload_to_gcp(gcs_client=client, local_directory=\"src\", bucket_name=\"uconn_test2\", bucket_directory=\"src\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.61it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}